{"timestamp_utc": "2024-07-31T05:08:29.990Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Started by upstream project \"project/fss3/ci-regression\" build number 2999 <NL> originally caused by: <NL> Started by user Meenakshisundaram, Balaji (BMEENAKS)"}
{"timestamp_utc": "2024-07-31T05:08:30.032Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] Start of Pipeline"}
{"timestamp_utc": "2024-07-31T05:08:30.043Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] library"}
{"timestamp_utc": "2024-07-31T05:08:30.045Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Loading library cic-shared-library@project_latest <NL> Attempting to resolve project_latest from remote references... <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:08:30.205Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git ls-remote -- ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:08:30.575Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Found match: refs/tags/project_latest revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a <NL> Resolving tag commit... (remote references may be a lightweight tag or an annotated tag)"}
{"timestamp_utc": "2024-07-31T05:10:10.920Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git rev-parse --resolve-git-dir /atldata/jenkins/caches/git-81d7c0835bf8496255df022a875c0e23/.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:11.110Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Setting origin to ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git config remote.origin.url ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:11.231Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching origin..."}
{"timestamp_utc": "2024-07-31T05:10:11.232Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching upstream changes from origin <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:11.331Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3' <NL> > git config --get remote.origin.url # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:11.390Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git fetch --tags --force --progress -- origin +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:12.855Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git rev-parse refs/tags/project_latest^{commit} # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:12.927Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Resolved tag project_latest revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a"}
{"timestamp_utc": "2024-07-31T05:10:12.929Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "The recommended git tool is: git <NL> Warning: CredentialId \"jenkins\" could not be found."}
{"timestamp_utc": "2024-07-31T05:10:12.930Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Cloning the remote Git repository <NL> Cloning with configured refspecs honoured and with tags <NL> Cloning repository ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git init /atldata/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64_libs/e62eae340757e7d61d5116e39951ef47814af05333dabd029e21d997a41ab976 # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:13.004Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Fetching upstream changes from ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git <NL> > git --version # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:13.120Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git --version # 'git version 2.39.3'"}
{"timestamp_utc": "2024-07-31T05:10:13.121Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git fetch --tags --force --progress -- ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:27.082Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config remote.origin.url ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:27.139Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git config --add remote.origin.fetch +refs/heads/*:refs/remotes/origin/* # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:27.196Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Avoid second fetch <NL> Checking out Revision 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a (project_latest) <NL> > git config core.sparsecheckout # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:27.242Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "> git checkout -f 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a # timeout=10"}
{"timestamp_utc": "2024-07-31T05:10:27.475Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Commit message: \"saving manifest for tag project_cd1474\""}
{"timestamp_utc": "2024-07-31T05:10:27.985Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false"}
{"timestamp_utc": "2024-07-31T05:10:27.986Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:28.111Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp71 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64 <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T05:10:28.115Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:28.394Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.001 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.001"}
{"timestamp_utc": "2024-07-31T05:10:28.402Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:28.405Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:28.681Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.001/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.001/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:28.687Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T05:10:28.698Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:28.984Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git bootstrap-repo-subdir <NL> Cloning into 'bootstrap-repo-subdir'..."}
{"timestamp_utc": "2024-07-31T05:10:29.241Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T05:10:29.247Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:29.597Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (bootstrap-repo-subdir/jenkins/bootstrap-pipeline.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:29.615Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:29.617Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:29.622Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:29.627Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:29.906Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.001/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.001/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:29.912Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:29.914Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T05:10:29.988Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false <NL> [Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:30.068Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp71 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64 <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T05:10:30.072Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.345Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.002 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.002"}
{"timestamp_utc": "2024-07-31T05:10:30.351Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:30.356Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.633Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.002/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.002/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:30.640Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T05:10:30.641Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:30.918Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64"}
{"timestamp_utc": "2024-07-31T05:10:30.924Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T05:10:30.931Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T05:10:30.932Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "===== parameter values: ===== <NL> PIPELINE_JOB_NAME                  \"json-nt-ddcn-4-node-natRedistribute-nat64\" <NL> PIPELINE_JOB_FULL_NAME             \"project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64\" <NL> PIPELINE_JOB_PROJECT_FOLDER_NAME   \"fss3\" <NL> RECIPE_REPO_BASE_JOB_NAME          null <NL> (dflt) PROJECT_NAME                       \"fss3\" <NL> (dflt) RECIPE_REPO_NAME                   null <NL> (user) CI_BASE_BRANCH_NAME                \"fss3\" <NL> (user) NETWORK_TOPOLOGY_BRANCH_NAME       \"ntp_latest\" <NL> (user) CI_SUBMODULE_BRANCH_NAME           \"project_latest\" <NL> (user) PROJECT_INFO_BRANCH_NAME           \"master_cd23138\" <NL> (user) GROOVY_SCRIPT_NAME                 \"continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy\" <NL> ===== ===== ===== ===== ===== <NL> [Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:31.210Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ git clone --branch fss3 --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration.git continuous-integration <NL> Cloning into 'continuous-integration'... <NL> + rm -rf continuous-integration/continuous-integration-common <NL> + cd continuous-integration <NL> + git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git continuous-integration-common"}
{"timestamp_utc": "2024-07-31T05:10:31.467Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Cloning into 'continuous-integration-common'..."}
{"timestamp_utc": "2024-07-31T05:10:31.723Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd continuous-integration-common <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf repo <NL> + git clone --branch master --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/repo.git repo <NL> Cloning into 'repo'..."}
{"timestamp_utc": "2024-07-31T05:10:32.193Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cd repo <NL> + rm -rf .git <NL> + cd .."}
{"timestamp_utc": "2024-07-31T05:10:32.205Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:32.899Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:32.922Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:32.925Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:32.931Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:33.188Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.utilities.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:33.193Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:33.200Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:33.208Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:33.297Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.user_input.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:33.314Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:33.317Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:33.326Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:33.965Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.json_pipeline.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:33.971Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:33.976Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:33.984Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] load"}
{"timestamp_utc": "2024-07-31T05:10:34.356Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (continuous-integration/continuous-integration-common/jenkins/common/common.gitscm.groovy)"}
{"timestamp_utc": "2024-07-31T05:10:34.363Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:34.372Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // load"}
{"timestamp_utc": "2024-07-31T05:10:34.387Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T05:10:34.397Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T05:10:34.678Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.002/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.002/node-info.json"}
{"timestamp_utc": "2024-07-31T05:10:34.693Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T05:10:34.728Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T05:10:34.767Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> PIPELINE_JOB_NAME                 \"json-nt-ddcn-4-node-natRedistribute-nat64\" <NL> PIPELINE_JOB_FULL_NAME            \"project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64\" <NL> PIPELINE_JOB_PROJECT_FOLDER_NAME  \"fss3\" <NL> PROJECT_NAME                      \"fss3\" <NL> CI_BASE_BRANCH_NAME               \"fss3\" <NL> CI_SUBMODULE_BRANCH_NAME          \"project_latest\" <NL> CI_BUILD_URL                      \"\" <NL> CI_JOB_PARENT_ARTIFACT_INFO_FNAME \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\" <NL> GROOVY_SCRIPT_NAME                \"continuous-integration/continuous-integration-common/jenkins/ci-pipeline-job.groovy\" <NL> JPARAM_JOB_JSON_STRING            \"{\"job_type\":\"explicit\",\"job_timeout_unit\":\"HOURS\",\"job_timeout_amount\":6,\"job_propagate_flag\":true,\"job_template\":\"ci-pipeline-job.xml\",\"disable_flag.ci-release-recipe-repo\":true,\"disable_flag.ci-review\":true,\"disable_flag.ci-release-project\":true,\"job_command_list\":[\"ci-project-sanity-tfwk\",\"--\",\"--testcases-project-name\",\"fss3\",\"--\",\"--test-engine\",\"Warrior\",\"--topology-tag-name\",\"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\",\"--define-attr-defaults\",\"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\",\"--define-instance-attr\",\"NE1/main\",\"shelf-num=1\",\"--define-instance-attr\",\"NE1/main\",\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\",\"--define-instance-attr\",\"NE1/trib1\",\"shelf-num=2\",\"--define-instance-attr\",\"NE1/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE2/main\",\"shelf-num=1\",\"--define-instance-attr\",\"NE2/main\",\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\",\"--define-instance-attr\",\"NE2/trib1\",\"shelf-num=2\",\"--define-instance-attr\",\"NE2/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE3/main\",\"shelf-num=200\",\"--define-instance-attr\",\"NE3/main\",\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\",\"--define-instance-attr\",\"NE3/trib1\",\"shelf-num=1\",\"--define-instance-attr\",\"NE3/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--define-instance-attr\",\"NE4/main\",\"shelf-num=200\",\"--define-instance-attr\",\"NE4/main\",\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\",\"--define-instance-attr\",\"NE4/trib1\",\"shelf-num=1\",\"--define-instance-attr\",\"NE4/trib1\",\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\",\"--add-instance\",\"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\",\"--device-wait-startup-timeout\",\"1200\",\"--test-engine-begin\",\"--no_logger\",\"--test-engine-end\",\"--\",\"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\"],\"disable_flag.ci-update-manifest\":true,\"job_name\":\"nt-ddcn-4-node-natRedistribute-nat64\",\"job_quiet_period\":0,\"job_docker_container_flag\":true,\"job_wait_flag\":true,\"job_failure_handling\":\"pipeline-failure\",\"job_unstash_flag\":true,\"disable_flag.ci-update-manifest-recipe-repo\":true,\"disable_flag.ci-review-recipe-repo\":true,\"job_agent\":\"regression-sanity-docker\",\"previous_job_method\":\"previous-job\",\"job_stash_flag\":true,\"job_label\":\"nt-ddcn-4-node-natRedistribute-nat64\",\"job_docker_container_info\":null,\"job_kubernetes_info\":null,\"job_command_prefix\":[\"ci-get-archive-artifacts\",\"--project-info-basename\",\"project-info.json\",\"--project-info-extended-basename\",\"project-info-extended.json\",\"--\",\"ci-job-info\"],\"logstash_flag\":false,\"parent_info\":{\"jenkins_master\":\"jenkins.fnc.fujitsu.com\",\"jenkins_job_BUILD_URL\":\"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\",\"jenkins_job_full_name\":\"project/fss3/ci-regression\",\"jenkins_job_name\":\"ci-regression\",\"jenkins_job_build_number\":2999,\"jenkins_job_full_build_name\":\"project/fss3/ci-regression/2999\"},\"parent_pipeline_context_info\":{\"pipeline_type\":\"ci-regression\",\"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\":\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\"}}\" <NL> json_text: { <NL> \"job_type\": \"explicit\", <NL> \"job_timeout_unit\": \"HOURS\", <NL> \"job_timeout_amount\": 6, <NL> \"logstash_flag\": false, <NL> \"job_propagate_flag\": true, <NL> \"job_template\": \"ci-pipeline-job.xml\", <NL> \"job_quiet_period\": 0, <NL> \"job_docker_container_flag\": true, <NL> \"disable_flag.ci-update-manifest-recipe-repo\": true, <NL> \"previous_job_method\": \"previous-job\", <NL> \"job_docker_container_info\": null, <NL> \"job_stash_flag\": true, <NL> \"parent_info\": { <NL> \"jenkins_job_build_number\": 2999, <NL> \"jenkins_job_full_name\": \"project/fss3/ci-regression\", <NL> \"jenkins_job_name\": \"ci-regression\", <NL> \"jenkins_job_full_build_name\": \"project/fss3/ci-regression/2999\", <NL> \"jenkins_master\": \"jenkins.fnc.fujitsu.com\", <NL> \"jenkins_job_BUILD_URL\": \"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\" <NL> }, <NL> \"job_label\": \"nt-ddcn-4-node-natRedistribute-nat64\", <NL> \"job_command_prefix\": [ <NL> \"ci-get-archive-artifacts\", <NL> \"--project-info-basename\", <NL> \"project-info.json\", <NL> \"--project-info-extended-basename\", <NL> \"project-info-extended.json\", <NL> \"--\", <NL> \"ci-job-info\" <NL> ], <NL> \"disable_flag.ci-release-recipe-repo\": true, <NL> \"disable_flag.ci-review\": true, <NL> \"disable_flag.ci-release-project\": true, <NL> \"job_command_list\": [ <NL> \"ci-project-sanity-tfwk\", <NL> \"--\", <NL> \"--testcases-project-name\", <NL> \"fss3\", <NL> \"--\", <NL> \"--test-engine\", <NL> \"Warrior\", <NL> \"--topology-tag-name\", <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\", <NL> \"--define-attr-defaults\", <NL> \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--add-instance\", <NL> \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\", <NL> \"--device-wait-startup-timeout\", <NL> \"1200\", <NL> \"--test-engine-begin\", <NL> \"--no_logger\", <NL> \"--test-engine-end\", <NL> \"--\", <NL> \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\" <NL> ], <NL> \"job_kubernetes_info\": null, <NL> \"disable_flag.ci-update-manifest\": true, <NL> \"job_name\": \"nt-ddcn-4-node-natRedistribute-nat64\", <NL> \"job_wait_flag\": true, <NL> \"job_failure_handling\": \"pipeline-failure\", <NL> \"job_unstash_flag\": true, <NL> \"parent_pipeline_context_info\": { <NL> \"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\", <NL> \"pipeline_type\": \"ci-regression\" <NL> }, <NL> \"disable_flag.ci-review-recipe-repo\": true, <NL> \"job_agent\": \"regression-sanity-docker\" <NL> }"}
{"timestamp_utc": "2024-07-31T05:10:34.791Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T05:10:34.792Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pipeline_init: currentBuild.result 'SUCCESS' <NL> ===== ===== ===== ===== ====="}
{"timestamp_utc": "2024-07-31T05:10:34.813Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> running_in_k8s_flag : false"}
{"timestamp_utc": "2024-07-31T05:10:34.814Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] node"}
{"timestamp_utc": "2024-07-31T05:10:49.827Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Still waiting to schedule task"}
{"timestamp_utc": "2024-07-31T05:10:49.828Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Waiting for next available executor on \u2018regression-sanity-docker\u2019"}
{"timestamp_utc": "2024-07-31T08:06:50.585Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Running on node-rtxoialp79 in /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64"}
{"timestamp_utc": "2024-07-31T08:06:50.586Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:50.595Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:50.883Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ mkdir -p ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.003 <NL> + mkdir -p /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.003"}
{"timestamp_utc": "2024-07-31T08:06:50.889Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:50.899Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:51.169Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.003/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.003/node-info.json"}
{"timestamp_utc": "2024-07-31T08:06:51.174Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:06:51.175Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Init)"}
{"timestamp_utc": "2024-07-31T08:06:51.183Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] timeout <NL> Timeout set to expire in 1 hr 0 min <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:51.190Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:51.191Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:51.462Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64"}
{"timestamp_utc": "2024-07-31T08:06:51.467Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T08:06:51.474Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:06:51.480Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // timeout"}
{"timestamp_utc": "2024-07-31T08:06:51.487Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:06:51.494Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:06:51.501Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] timeout <NL> Timeout set to expire in 6 hr 0 min"}
{"timestamp_utc": "2024-07-31T08:06:51.502Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:51.509Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:51.510Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:51.785Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "++ hostname <NL> ++ hostname -i <NL> + echo '{ \"hostname\": \"rtxoialp79\", \"hostip\": \"167.254.217.189\" }' <NL> + cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/hostname.json <NL> { \"hostname\": \"rtxoialp79\", \"hostip\": \"167.254.217.189\" }"}
{"timestamp_utc": "2024-07-31T08:06:51.792Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] readFile"}
{"timestamp_utc": "2024-07-31T08:06:51.800Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> host_info_name_dict: { <NL> \"hostname\": \"rtxoialp79\", <NL> \"hostip\": \"167.254.217.189\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:06:51.810Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:51.820Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:51.822Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage <NL> [Pipeline] { (Execute)"}
{"timestamp_utc": "2024-07-31T08:06:51.830Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:51.831Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:52.110Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +ex <NL> cleaning out dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64"}
{"timestamp_utc": "2024-07-31T08:06:52.118Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] deleteDir"}
{"timestamp_utc": "2024-07-31T08:06:52.126Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv"}
{"timestamp_utc": "2024-07-31T08:06:52.127Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:52.135Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:52.142Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:52.150Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:06:52.157Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T08:06:52.158Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "running_in_k8s_flag: false"}
{"timestamp_utc": "2024-07-31T08:06:52.164Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:52.197Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] pwd"}
{"timestamp_utc": "2024-07-31T08:06:52.293Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] isUnix"}
{"timestamp_utc": "2024-07-31T08:06:52.294Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv <NL> [Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:06:52.302Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:52.577Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker pull harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest <NL> Trying to pull repository harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build ..."}
{"timestamp_utc": "2024-07-31T08:06:52.578Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "latest: Pulling from harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build <NL> Digest: sha256:f649c9d54a8d0322e20c4524897fb6d43164df14359f965f27d7fedcf395eb95 <NL> Status: Image is up to date for harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:06:52.844Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:06:52.852Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:06:52.861Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] isUnix"}
{"timestamp_utc": "2024-07-31T08:06:52.868Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:53.148Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker run -d --privileged --user root --cap-add NET_ADMIN --cap-add SYS_ADMIN --device /dev/kvm:/dev/kvm --device /dev/net/tun:/dev/net/tun --device /dev/vhost-net:/dev/vhost-net --publish :22 --workdir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64 --detach --volume /var/run/docker.sock:/var/run/docker.sock --volume /proj/bitbake:/proj/bitbake:shared --volume /proj/artifacts:/proj/artifacts:shared --volume /repo:/repo:ro,shared --volume /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64:shared harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:06:54.535Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:06:54.807Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ hostname <NL> rtxoialp79 <NL> + pwd <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64 <NL> + id"}
{"timestamp_utc": "2024-07-31T08:06:54.808Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "uid=51016(jenkins) gid=50063(common) groups=50063(common),36(kvm),990(dockerroot),548600513(domain users),548601197(9949 atp's-r),548601199(itgcd01),548601201(ontblan - prjfiles-r),548606239(qdc-c),548612341(106admin),548619018(itgfile3_marketing-r),548619025(itgfile3_procq_r),548619027(itgfile3_qdc-c),548619031(itgfile3_rel-r),548619037(itgfile3_svcq_r),548619041(itgfile3_tpubs-dvt$-r),548619046(itgfile3_tpubs-users),548619089(itgfile4_antivirus-r),548619106(itgfile4_corpq_r),548619129(itgfile4_fns_bp - r),548619134(itgfile4_fns-busmodel-r),548619154(itgfile4_markmfg-r),548619161(itgfile4_naprojects-c),548619164(itgfile4_net ops - r),548619167(itgfile4_networkdev_dev),548619170(itgfile4_networkdoc_prod-r),548619177(itgfile4_oracle-r),548619186(itgfile4_priso9001 - r),548619203(itgfile4_sapsuperusers-r),548619209(itgfile4_siebel docs - r),548619211(itgfile4_siebelitg-s),548619214(itgfile4_software-r),548619216(itgfile4_sw-iso9002-r),548619223(itgfile4_tech_ops-r),548619238(itgfile4_xeroxps-r),548619566(netval3admin),548619568(tsc_users),548650281(rchnetapp2_mobile_newsletters-r),548657500(rchnetapp2_coursera_sdn-002_r),548658825(rchfile2_techserv_r),548664859(fnc.engftp),548671195(g05_qdc_share_c),548671198(rtxnasop01_lr_toolkit-r),548671199(rtxnasop01_lr_output-c),548674493(mxl1400dhc-w10-admins),548677213(rtxnasop01_qdc-c) <NL> + '[' '!' -d continuous-integration ']' <NL> + git clone --branch fss3 --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration.git continuous-integration <NL> Cloning into 'continuous-integration'... <NL> + rm -rf continuous-integration/continuous-integration-common <NL> + cd continuous-integration <NL> + git log -1 <NL> + '[' '!' -d continuous-integration-common ']' <NL> + git clone --branch project_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/continuous-integration-common.git continuous-integration-common <NL> Cloning into 'continuous-integration-common'..."}
{"timestamp_utc": "2024-07-31T08:06:55.369Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd continuous-integration-common <NL> + git log -1 <NL> + rm -rf .git <NL> + cd .. <NL> + rm -rf .git <NL> + cd .. <NL> + '[' '!' -d network-topology ']' <NL> + git clone --branch ntp_latest --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/network-topology.git network-topology <NL> Cloning into 'network-topology'..."}
{"timestamp_utc": "2024-07-31T08:06:55.624Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out '9dd57f75190f0d255e5fd5a19408ee684d8e30fb'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> + cd network-topology <NL> + git log -1 <NL> + rm -rf .git <NL> + cd .. <NL> + '[' '!' -d repo ']' <NL> + git clone --branch master --depth 1 --single-branch ssh://git@bitbucket.fnc.fujitsu.com:7999/iprepo/repo.git repo <NL> Cloning into 'repo'..."}
{"timestamp_utc": "2024-07-31T08:06:55.880Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cd repo <NL> + rm -rf .git <NL> + cd .. <NL> + set +xe <NL> -- show continuous-integration/version.txt <NL> commit 46d558a518beb700cd21573f2815e8a9d270df94 <NL> Author: pmadiraj <pavankumar.madirajukeshavaraju@us.fujitsu.com> <NL> Date:   Thu Sep 19 09:40:06 2019 -0500 <NL> add missing recipe repo groovy links <NL> -- show continuous-integration/continuous-integration-common/version.txt <NL> commit 43c0b56f36cb45dd3c8377fd1f470a9e8901ae1a <NL> Author: Jenkins <jenkins_noreply@fnc.fujitsu.com> <NL> Date:   Tue Jul 30 04:49:43 2024 -0500 <NL> saving manifest for tag project_cd1474 <NL> -- show network-topology/version.txt <NL> commit 9dd57f75190f0d255e5fd5a19408ee684d8e30fb <NL> Author: Parween, Sagufta <sparween@localhost> <NL> Date:   Thu Jul 25 00:09:36 2024 -0500 <NL> saving manifest for tag ntp_cd118 <NL> -- done <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/jenkins-job-command-list.json <NL> [ <NL> \"ci-get-archive-artifacts\", <NL> \"--project-info-basename\", <NL> \"project-info.json\", <NL> \"--project-info-extended-basename\", <NL> \"project-info-extended.json\", <NL> \"--\", <NL> \"ci-job-info\", <NL> \"ci-project-sanity-tfwk\", <NL> \"--\", <NL> \"--testcases-project-name\", <NL> \"fss3\", <NL> \"--\", <NL> \"--test-engine\", <NL> \"Warrior\", <NL> \"--topology-tag-name\", <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\", <NL> \"--define-attr-defaults\", <NL> \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE1/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE1/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE2/main\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"shelf-num=2\", <NL> \"--define-instance-attr\", <NL> \"NE2/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE3/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE3/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"shelf-num=200\", <NL> \"--define-instance-attr\", <NL> \"NE4/main\", <NL> \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"shelf-num=1\", <NL> \"--define-instance-attr\", <NL> \"NE4/trib1\", <NL> \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\", <NL> \"--add-instance\", <NL> \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\", <NL> \"--device-wait-startup-timeout\", <NL> \"1200\", <NL> \"--test-engine-begin\", <NL> \"--no_logger\", <NL> \"--test-engine-end\", <NL> \"--\", <NL> \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\" <NL> ] <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/jenkins-job-environment-map.json <NL> { <NL> \"CI_BASE_BRANCH_NAME\": \"fss3\", <NL> \"CI_SUBMODULE_BRANCH_NAME\": \"project_latest\", <NL> \"PROJECT_INFO_BRANCH_NAME\": \"master_cd23138\","}
{"timestamp_utc": "2024-07-31T08:06:55.881Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"NETWORK_TOPOLOGY_BRANCH_NAME\": \"ntp_latest\", <NL> \"CI_BUILD_URL\": \"\", <NL> \"CI_JOB_PARENT_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\", <NL> \"JPARAM_JOB_JSON_STRING\": \"{\\\"job_type\\\":\\\"explicit\\\",\\\"job_timeout_unit\\\":\\\"HOURS\\\",\\\"job_timeout_amount\\\":6,\\\"job_propagate_flag\\\":true,\\\"job_template\\\":\\\"ci-pipeline-job.xml\\\",\\\"disable_flag.ci-release-recipe-repo\\\":true,\\\"disable_flag.ci-review\\\":true,\\\"disable_flag.ci-release-project\\\":true,\\\"job_command_list\\\":[\\\"ci-project-sanity-tfwk\\\",\\\"--\\\",\\\"--testcases-project-name\\\",\\\"fss3\\\",\\\"--\\\",\\\"--test-engine\\\",\\\"Warrior\\\",\\\"--topology-tag-name\\\",\\\"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\\\",\\\"--define-attr-defaults\\\",\\\"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\\\",\\\"--define-instance-attr\\\",\\\"NE1/main\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE1/main\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE1/trib1\\\",\\\"shelf-num=2\\\",\\\"--define-instance-attr\\\",\\\"NE1/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE2/main\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE2/main\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE2/trib1\\\",\\\"shelf-num=2\\\",\\\"--define-instance-attr\\\",\\\"NE2/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE3/main\\\",\\\"shelf-num=200\\\",\\\"--define-instance-attr\\\",\\\"NE3/main\\\",\\\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\\\",\\\"--define-instance-attr\\\",\\\"NE3/trib1\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE3/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--define-instance-attr\\\",\\\"NE4/main\\\",\\\"shelf-num=200\\\",\\\"--define-instance-attr\\\",\\\"NE4/main\\\",\\\"image-name=fss-aggr-image-validation-T,image-info-config-name=main\\\",\\\"--define-instance-attr\\\",\\\"NE4/trib1\\\",\\\"shelf-num=1\\\",\\\"--define-instance-attr\\\",\\\"NE4/trib1\\\",\\\"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\\\",\\\"--add-instance\\\",\\\"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\\\",\\\"--device-wait-startup-timeout\\\",\\\"1200\\\",\\\"--test-engine-begin\\\",\\\"--no_logger\\\",\\\"--test-engine-end\\\",\\\"--\\\",\\\"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\\\"],\\\"disable_flag.ci-update-manifest\\\":true,\\\"job_name\\\":\\\"nt-ddcn-4-node-natRedistribute-nat64\\\",\\\"job_quiet_period\\\":0,\\\"job_docker_container_flag\\\":true,\\\"job_wait_flag\\\":true,\\\"job_failure_handling\\\":\\\"pipeline-failure\\\",\\\"job_unstash_flag\\\":true,\\\"disable_flag.ci-update-manifest-recipe-repo\\\":true,\\\"disable_flag.ci-review-recipe-repo\\\":true,\\\"job_agent\\\":\\\"regression-sanity-docker\\\",\\\"previous_job_method\\\":\\\"previous-job\\\",\\\"job_stash_flag\\\":true,\\\"job_label\\\":\\\"nt-ddcn-4-node-natRedistribute-nat64\\\",\\\"job_docker_container_info\\\":null,\\\"job_kubernetes_info\\\":null,\\\"job_command_prefix\\\":[\\\"ci-get-archive-artifacts\\\",\\\"--project-info-basename\\\",\\\"project-info.json\\\",\\\"--project-info-extended-basename\\\",\\\"project-info-extended.json\\\",\\\"--\\\",\\\"ci-job-info\\\"],\\\"logstash_flag\\\":false,\\\"parent_info\\\":{\\\"jenkins_master\\\":\\\"jenkins.fnc.fujitsu.com\\\",\\\"jenkins_job_BUILD_URL\\\":\\\"https://jenkins.fnc.fujitsu.com/job/project/job/fss3/job/ci-regression/2999/\\\",\\\"jenkins_job_full_name\\\":\\\"project/fss3/ci-regression\\\",\\\"jenkins_job_name\\\":\\\"ci-regression\\\",\\\"jenkins_job_build_number\\\":2999,\\\"jenkins_job_full_build_name\\\":\\\"project/fss3/ci-regression/2999\\\"},\\\"parent_pipeline_context_info\\\":{\\\"pipeline_type\\\":\\\"ci-regression\\\",\\\"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\\\":\\\"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\\\"}}\", <NL> \"BUILD_NUMBER\": \"7\", <NL> \"CI_JENKINS_EXECUTOR_HOSTNAME\": \"rtxoialp79\", <NL> \"CI_JENKINS_EXECUTOR_HOSTIP\": \"167.254.217.189\", <NL> \"WORKSPACE\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64\", <NL> \"JOB_NAME\": \"project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64\", <NL> \"LANG\": \"en_US.UTF-8\", <NL> \"PARENT_PIPELINE_CONTEXT_INFO_MAP_JSON_FNAME\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/parent-pipeline-context-info-map.json\" <NL> } <NL> == cat /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/parent-pipeline-context-info-map.json <NL> { <NL> \"root_pipeline_CI_JOB_ARTIFACT_INFO_FNAME\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ci-regression.json\", <NL> \"pipeline_type\": \"ci-regression\" <NL> } <NL> == done <NL> user jenkins <NL> container.id 0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d"}
{"timestamp_utc": "2024-07-31T08:06:56.442Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ exec ci-execute-json-command-list --command-json-fname /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/jenkins-job-command-list.json"}
{"timestamp_utc": "2024-07-31T08:06:56.697Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-get-archive-artifacts: creating local_data_dir \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/ci-data\""}
{"timestamp_utc": "2024-07-31T08:06:56.978Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-get-archive-artifacts: started with parent info from CI_JOB_PARENT_ARTIFACT_INFO_FNAME \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.json\" <NL> ci-get-archive-artifacts: copying ci-data files from CI_JOB_ARTIFACT_CI_DATA_DIR \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/ri-fss3-protocol-DDCN-natRedistribute-build-ntt.ci-data\" into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/ci-data\" <NL> ./ <NL> ./manifest.json <NL> ./project-info-status.json <NL> ./gitscm-info.json <NL> ./data.json <NL> ./project-info-extended.json <NL> ./project-info.json <NL> ./project-info-complete.json"}
{"timestamp_utc": "2024-07-31T08:06:57.908Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info-recipe-repo.json <NL> ci-get-archive-artifacts: pwd \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64\" <NL> ci-get-archive-artifacts: calling command:  \"ci-job-info\" \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\" <NL> ci-job-info: started on Wed Jul 31 03:06:57 CDT 2024 <NL> start_job: Wed Jul 31 03:06:57 CDT 2024"}
{"timestamp_utc": "2024-07-31T08:06:58.468Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_subsequent_job <NL> ci-job-info: start_subsequent_job: ----- ----- ----- ----- -----"}
{"timestamp_utc": "2024-07-31T08:06:59.394Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_job: save existing info file into what will be the parent info file /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/data.parent.json"}
{"timestamp_utc": "2024-07-31T08:07:01.281Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: start_job: ----- ----- ----- ----- -----"}
{"timestamp_utc": "2024-07-31T08:07:01.537Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: calling command: \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\" <NL> ci-project-sanity-tfwk: starting"}
{"timestamp_utc": "2024-07-31T08:07:01.794Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ '[' 0 -eq 0 ']'"}
{"timestamp_utc": "2024-07-31T08:07:01.795Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ echo 'ci-project-sanity-tfwk: not setting up workspace' <NL> ci-project-sanity-tfwk: not setting up workspace <NL> + rm -rf /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts <NL> + mkdir -p /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts <NL> + '[' 0 -eq 1 ']' <NL> + cd /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts <NL> + '[' 67 -le 0 ']' <NL> + ci-project-sanity-tfwk.py --testcases-project-name fss3 -- --test-engine Warrior --topology-tag-name DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1 --define-attr-defaults machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute --define-instance-attr NE1/main shelf-num=1 --define-instance-attr NE1/main image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2 --define-instance-attr NE1/trib1 shelf-num=2 --define-instance-attr NE1/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE2/main shelf-num=1 --define-instance-attr NE2/main image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2 --define-instance-attr NE2/trib1 shelf-num=2 --define-instance-attr NE2/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE3/main shelf-num=200 --define-instance-attr NE3/main image-name=fss-aggr-image-validation-T,image-info-config-name=main --define-instance-attr NE3/trib1 shelf-num=1 --define-instance-attr NE3/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --define-instance-attr NE4/main shelf-num=200 --define-instance-attr NE4/main image-name=fss-aggr-image-validation-T,image-info-config-name=main --define-instance-attr NE4/trib1 shelf-num=1 --define-instance-attr NE4/trib1 image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2 --add-instance NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1 --device-wait-startup-timeout 1200 --test-engine-begin --no_logger --test-engine-end -- warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml"}
{"timestamp_utc": "2024-07-31T08:07:02.723Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Fetching project \"manifests\" <NL> Cloning into 'manifests'..."}
{"timestamp_utc": "2024-07-31T08:07:02.979Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "remote: Enumerating objects: 22649, done.\u001b[K"}
{"timestamp_utc": "2025-05-28T08:03:36.008Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "remote: Total 22649 (delta 3951), reused 100 (delta 98), pack-reused 17567\u001b[K"}
{"timestamp_utc": "2024-07-31T08:07:04.163Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch fss3 set up to track remote branch fss3 from origin. <NL> Switched to a new branch 'fss3'"}
{"timestamp_utc": "2024-07-31T08:07:04.421Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://bitbucket.fnc.fujitsu.com:7999/iprepo/testcase-manifests <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date."}
{"timestamp_utc": "2024-07-31T08:07:04.678Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# manifest_filename \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/.repo/manifests/default.xml\" <NL> Fetching project \"test_framework\" <NL> Warning: Permanently added '[rtx-swtl-git.fnc.net.local]:7999' (RSA) to the list of known hosts."}
{"timestamp_utc": "2024-07-31T08:07:12.767Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'tfwk_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c5a96c8... saving manifest for tag tfwk_cd101 <NL> Fetching project \"test_framework/network-topology\" <NL> Note: checking out 'ntp_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 9dd57f7... saving manifest for tag ntp_cd118 <NL> Fetching project \"test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:07:13.022Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'ntpd_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c580e72... saving manifest for tag ntpd_cd28 <NL> Fetching project \"test_framework/common_tools\""}
{"timestamp_utc": "2024-07-31T08:07:14.388Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'common-tools_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 6617d9d... saving manifest for tag common-tools_cd30 <NL> Fetching project \"test_framework/warrior-testcases/common\""}
{"timestamp_utc": "2024-07-31T08:07:14.949Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch DEVOPS-415_hw_sanity_tc_py3 set up to track remote branch DEVOPS-415_hw_sanity_tc_py3 from origin. <NL> Switched to a new branch 'DEVOPS-415_hw_sanity_tc_py3' <NL> Fetching project \"test_framework/testcase-config\""}
{"timestamp_utc": "2024-07-31T08:07:15.510Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Branch fss3 set up to track remote branch fss3 from origin. <NL> Switched to a new branch 'fss3' <NL> From ssh://rtx-swtl-git.fnc.net.local:7999/iprepo/testcase-config <NL> * branch            fss3       -> FETCH_HEAD"}
{"timestamp_utc": "2024-07-31T08:07:15.766Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Already up-to-date. <NL> Fetching project \"test_framework/warrior-testcases/1finity\""}
{"timestamp_utc": "2024-07-31T08:07:27.932Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-tseries_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 93cf8df... Pull request #1586: L1TC-2668-increasing-rang-for-pm-value <NL> Fetching project \"test_framework/warrior-testcases/trp_base\" <NL> Note: checking out 'proj-fss3-recipe-trp_base_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 0e5f339... Pull request #19: TRPBASE-1278 changed auto-negotiation disabled <NL> Fetching project \"test_framework/warrior-testcases/dcn\""}
{"timestamp_utc": "2024-07-31T08:07:43.799Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Checking out files:  44% (5592/12577) <NL> Checking out files:  45% (5660/12577) <NL> Checking out files:  46% (5786/12577) <NL> Checking out files:  47% (5912/12577) <NL> Checking out files:  48% (6037/12577) <NL> Checking out files:  49% (6163/12577) <NL> Checking out files:  50% (6289/12577) <NL> Checking out files:  51% (6415/12577) <NL> Checking out files:  52% (6541/12577) <NL> Checking out files:  53% (6666/12577) <NL> Checking out files:  54% (6792/12577) <NL> Checking out files:  55% (6918/12577) <NL> Checking out files:  56% (7044/12577) <NL> Checking out files:  57% (7169/12577) <NL> Checking out files:  58% (7295/12577) <NL> Checking out files:  59% (7421/12577) <NL> Checking out files:  60% (7547/12577) <NL> Checking out files:  61% (7672/12577) <NL> Checking out files:  62% (7798/12577) <NL> Checking out files:  63% (7924/12577) <NL> Checking out files:  64% (8050/12577) <NL> Checking out files:  65% (8176/12577) <NL> Checking out files:  66% (8301/12577) <NL> Checking out files:  67% (8427/12577) <NL> Checking out files:  68% (8553/12577) <NL> Checking out files:  69% (8679/12577) <NL> Checking out files:  70% (8804/12577) <NL> Checking out files:  71% (8930/12577) <NL> Checking out files:  72% (9056/12577) <NL> Checking out files:  73% (9182/12577) <NL> Checking out files:  74% (9307/12577) <NL> Checking out files:  75% (9433/12577) <NL> Checking out files:  76% (9559/12577) <NL> Checking out files:  77% (9685/12577) <NL> Checking out files:  78% (9811/12577) <NL> Checking out files:  79% (9936/12577) <NL> Checking out files:  80% (10062/12577) <NL> Checking out files:  81% (10188/12577) <NL> Checking out files:  82% (10314/12577) <NL> Checking out files:  82% (10412/12577) <NL> Checking out files:  83% (10439/12577) <NL> Checking out files:  84% (10565/12577) <NL> Checking out files:  85% (10691/12577) <NL> Checking out files:  86% (10817/12577) <NL> Checking out files:  87% (10942/12577) <NL> Checking out files:  88% (11068/12577) <NL> Checking out files:  89% (11194/12577) <NL> Checking out files:  90% (11320/12577) <NL> Checking out files:  91% (11446/12577) <NL> Checking out files:  92% (11571/12577) <NL> Checking out files:  93% (11697/12577) <NL> Checking out files:  94% (11823/12577) <NL> Checking out files:  95% (11949/12577) <NL> Checking out files:  96% (12074/12577) <NL> Checking out files:  97% (12200/12577) <NL> Checking out files:  98% (12326/12577) <NL> Checking out files:  99% (12452/12577) <NL> Checking out files: 100% (12577/12577) <NL> Checking out files: 100% (12577/12577), done."}
{"timestamp_utc": "2024-07-31T08:07:44.055Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-dcn_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 2dbf363... Pull request #579: DCN-10811 remove the dhcp process chcek <NL> Fetching project \"test_framework/warrior-testcases/snmp\""}
{"timestamp_utc": "2024-07-31T08:07:44.616Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-snmp_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 1c1d5c5... Pull request #63: FSS2SNMP-914 reduce TAT of SNMP L jobs <NL> Fetching project \"test_framework/warrior-testcases/ops\""}
{"timestamp_utc": "2024-07-31T08:07:51.176Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-ops_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name"}
{"timestamp_utc": "2024-07-31T08:07:51.177Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c8e9ba9... Pull request #170: OPS-8964: Updated the client IP after Kubernetes server patching <NL> Fetching project \"test_framework/pycit-testcases/cit/lseries_test_cases\""}
{"timestamp_utc": "2024-07-31T08:07:52.542Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-lseries_test_cases_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at ce78bba... PF-9776 rdm-service check after mcu-p reboot <NL> Fetching project \"test_framework/pycit-testcases/cit/cit_l1cc\""}
{"timestamp_utc": "2024-07-31T08:07:52.798Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-cit_l1cc_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 3801263... Pull request #80: L1TC-2661 restore-profile-attr-testcases-commented <NL> Fetching project \"test_framework/warrior-keywords/ops_1finity\""}
{"timestamp_utc": "2024-07-31T08:07:54.163Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-ops_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at b90c727... Pull request #9: OPS-7896 <NL> Fetching project \"test_framework/warrior-keywords/snmp_1finity\""}
{"timestamp_utc": "2024-07-31T08:07:55.553Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-snmp_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at d00ee1e... Pull request #1: OPS-7722 <NL> Fetching project \"test_framework/robot-testcases/webui_automation-py3\""}
{"timestamp_utc": "2024-07-31T08:08:00.818Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-webui_automation-py3_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at f9b2864... Pull request #9: FSSFWK-8781: Initial commit #1. <NL> Fetching project \"test_framework/warrior-keywords/dcn_1finity\" <NL> Note: checking out 'proj-fss3-recipe-dcn_1finity_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 8ea07fa... Pull request #21: DCN-10811 increase the retry and correct the renew sed cmd <NL> Fetching project \"test_framework/warrior-testcases/openconfig-t\""}
{"timestamp_utc": "2024-07-31T08:08:01.380Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-openconfig-t_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at c0f0ec8... Pull request #27: OPCG-323 <NL> Fetching project \"test_framework/warrior-keywords/kw_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:03.272Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-kw_1finity_latest_passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at e873a09... FSSVSW-1166 update pip conf file <NL> Fetching project \"test_framework/warrior-keywords/onefinity\""}
{"timestamp_utc": "2024-07-31T08:08:05.161Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-onefinity_latest_passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 93ebd8e... Pull request #60: Made the input text case insensitive for not-allowed <NL> Fetching project \"test_framework/robot_core\""}
{"timestamp_utc": "2024-07-31T08:08:05.724Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'robot-core_latest'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 5b56560... HOTFIX: Fix refactoring mistake (used 'alias' kwarg instead of 'session_name') <NL> Fetching project \"test_framework/robot_tests\""}
{"timestamp_utc": "2024-07-31T08:08:06.287Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-robot_tests_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 6adf37a... Pull request #143: RF-733 update for 24.2 changes <NL> Fetching project \"test_framework/warrior-testcases/owb_lseries_att\""}
{"timestamp_utc": "2024-07-31T08:08:07.652Z", "log_type_hint": "JENKINS_GIT_OUTPUT", "message_content": "Note: checking out 'proj-fss3-recipe-owb_lseries_att_latest-passed'. <NL> You are in 'detached HEAD' state. You can look around, make experimental <NL> changes and commit them, and you can discard any commits you make in this <NL> state without impacting any branches by performing another checkout. <NL> If you want to create a new branch to retain commits you create, you may <NL> do so (now or later) by using -b with the checkout command again. Example: <NL> git checkout -b new_branch_name <NL> HEAD is now at 78dd82a... Pull request #199: OWBSW-2496 <NL> # manifest_filename \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/.repo/manifests/default.xml\" <NL> Fetching project \"test_framework\""}
{"timestamp_utc": "2024-07-31T08:08:07.908Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c5a96c8... saving manifest for tag tfwk_cd101 <NL> Fetching project \"test_framework/network-topology\""}
{"timestamp_utc": "2024-07-31T08:08:08.163Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 9dd57f7... saving manifest for tag ntp_cd118 <NL> Fetching project \"test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:08:08.419Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c580e72... saving manifest for tag ntpd_cd28 <NL> Fetching project \"test_framework/common_tools\""}
{"timestamp_utc": "2024-07-31T08:08:08.676Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 6617d9d... saving manifest for tag common-tools_cd30 <NL> Fetching project \"test_framework/warrior-testcases/common\" <NL> Already on 'DEVOPS-415_hw_sanity_tc_py3' <NL> Fetching project \"test_framework/testcase-config\""}
{"timestamp_utc": "2024-07-31T08:08:09.261Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "From ssh://rtx-swtl-git.fnc.net.local:7999/iprepo/testcase-config <NL> * branch            fss3       -> FETCH_HEAD <NL> Already up-to-date. <NL> Fetching project \"test_framework/warrior-testcases/1finity\""}
{"timestamp_utc": "2024-07-31T08:08:09.823Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 93cf8df... Pull request #1586: L1TC-2668-increasing-rang-for-pm-value <NL> Fetching project \"test_framework/warrior-testcases/trp_base\""}
{"timestamp_utc": "2024-07-31T08:08:10.078Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 0e5f339... Pull request #19: TRPBASE-1278 changed auto-negotiation disabled <NL> Fetching project \"test_framework/warrior-testcases/dcn\""}
{"timestamp_utc": "2024-07-31T08:08:11.965Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 2dbf363... Pull request #579: DCN-10811 remove the dhcp process chcek <NL> Fetching project \"test_framework/warrior-testcases/snmp\""}
{"timestamp_utc": "2024-07-31T08:08:12.220Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 1c1d5c5... Pull request #63: FSS2SNMP-914 reduce TAT of SNMP L jobs <NL> Fetching project \"test_framework/warrior-testcases/ops\""}
{"timestamp_utc": "2024-07-31T08:08:13.147Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c8e9ba9... Pull request #170: OPS-8964: Updated the client IP after Kubernetes server patching <NL> Fetching project \"test_framework/pycit-testcases/cit/lseries_test_cases\""}
{"timestamp_utc": "2024-07-31T08:08:13.404Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at ce78bba... PF-9776 rdm-service check after mcu-p reboot <NL> Fetching project \"test_framework/pycit-testcases/cit/cit_l1cc\""}
{"timestamp_utc": "2024-07-31T08:08:13.659Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 3801263... Pull request #80: L1TC-2661 restore-profile-attr-testcases-commented <NL> Fetching project \"test_framework/warrior-keywords/ops_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:13.915Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at b90c727... Pull request #9: OPS-7896 <NL> Fetching project \"test_framework/warrior-keywords/snmp_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:14.170Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at d00ee1e... Pull request #1: OPS-7722 <NL> Fetching project \"test_framework/robot-testcases/webui_automation-py3\""}
{"timestamp_utc": "2024-07-31T08:08:14.426Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at f9b2864... Pull request #9: FSSFWK-8781: Initial commit #1. <NL> Fetching project \"test_framework/warrior-keywords/dcn_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:14.682Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 8ea07fa... Pull request #21: DCN-10811 increase the retry and correct the renew sed cmd <NL> Fetching project \"test_framework/warrior-testcases/openconfig-t\""}
{"timestamp_utc": "2024-07-31T08:08:14.937Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at c0f0ec8... Pull request #27: OPCG-323 <NL> Fetching project \"test_framework/warrior-keywords/kw_1finity\""}
{"timestamp_utc": "2024-07-31T08:08:15.194Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at e873a09... FSSVSW-1166 update pip conf file <NL> Fetching project \"test_framework/warrior-keywords/onefinity\""}
{"timestamp_utc": "2024-07-31T08:08:15.755Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 93ebd8e... Pull request #60: Made the input text case insensitive for not-allowed <NL> Fetching project \"test_framework/robot_core\" <NL> HEAD is now at 5b56560... HOTFIX: Fix refactoring mistake (used 'alias' kwarg instead of 'session_name') <NL> Fetching project \"test_framework/robot_tests\""}
{"timestamp_utc": "2024-07-31T08:08:16.011Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 6adf37a... Pull request #143: RF-733 update for 24.2 changes <NL> Fetching project \"test_framework/warrior-testcases/owb_lseries_att\""}
{"timestamp_utc": "2024-07-31T08:08:16.267Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "HEAD is now at 78dd82a... Pull request #199: OWBSW-2496 <NL> # fnc-init-test-env: TEST_FRAMEWORK_ROOT_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework\" <NL> ntpd-setup.sh: NETWORK_TOPOLOGY_DATA_ROOT_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data\""}
{"timestamp_utc": "2024-07-31T08:08:17.630Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:17 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__before_variables') <NL> # 03:08:17 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__variables') <NL> # 03:08:17 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__normal') <NL> # 03:08:17 tfwk-exec-test-agent INFO: args_derived_cl.add_topology_tag_name: arg_item_obj: { <NL> \"def_item_obj\": { <NL> \"const\": false, <NL> \"default\": null, <NL> \"dest\": \"discard_topology_tag_name\", <NL> \"input_type\": \"text\", <NL> \"name\": \"--topology-tag-name\", <NL> \"nargs\": 2, <NL> \"phase\": \"phase__normal\", <NL> \"required\": false, <NL> \"set_attributes_func\": \"<bound method args_derived_cl.add_topology_tag_name of <__main__.args_derived_cl object at 0x7f211c0538d0>>\", <NL> \"subtype\": null, <NL> \"type\": \"list\" <NL> }, <NL> \"item_list\": [ <NL> \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" <NL> ] <NL> } <NL> # 03:08:17 tfwk-exec-test-agent INFO: get_topology_tag_pre_and_post_file_lists: - checking topology_tag_name 'DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1' <NL> # 03:08:17 tfwk-exec-test-agent INFO: get_topology_tag_pre_and_post_file_lists:   topology_tag_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags' <NL> # 03:08:17 tfwk-exec-test-agent INFO: add_from_testcase_group_config_fname: testcase_group_config_fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/conf/local-config.json' <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148'] <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir'] <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json'] <NL> # 03:08:17 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-setup', '-v', '-v', '--work-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '--pid', '148', '--shared-store-tag', 'tag', '--out-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json']"}
{"timestamp_utc": "2024-07-31T08:08:17.886Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:17 ntp-topology-setup INFO: args: { <NL> \"container_local_base_dir\": null, <NL> \"out_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"parent_hostip\": null, <NL> \"parent_hostname\": null, <NL> \"pid\": \"148\", <NL> \"script_dir\": null, <NL> \"shared_store_base_dir\": null, <NL> \"shared_store_tag\": \"tag\", <NL> \"shared_store_type\": null, <NL> \"topology_options\": null, <NL> \"topology_type\": null, <NL> \"verbosity\": 2, <NL> \"work_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\", <NL> \"work_dir_tag\": null, <NL> \"work_dir_type\": null <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:18.447Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/docker: stdout b'/bin/docker\\n'"}
{"timestamp_utc": "2024-07-31T08:08:19.009Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:18 ntp-topology-setup INFO: get_have_docker_flag: sudo /bin/docker info --format {{.ID}}: stdout b'3NT7:U5OP:3EXF:HCMW:43ZR:PVZQ:L754:MIXL:ZLQU:ZPQ7:QM27:VKE2\\n' <NL> # 03:08:18 ntp-topology-setup INFO: get_in_docker_container_flag: /proc/1/cgroup: '12:memory:/system.slice/docker-0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d.scope\\n' <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/podman: stderr b'sudo: /bin/podman: command not found\\n' <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /bin/podman: returncode 1 <NL> # 03:08:18 ntp-topology-setup INFO: get_in_kubernetes_flag: KUBERNETES_SERVICE_HOST None <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /usr/local/bin/vmmng_interface.py: stderr b'sudo: /usr/local/bin/vmmng_interface.py: command not found\\n' <NL> # 03:08:18 ntp-topology-setup INFO: check_sudo_command: sudo --non-interactive --list /usr/local/bin/vmmng_interface.py: returncode 1 <NL> # 03:08:18 ntp-topology-setup INFO: main: have_docker_flag True <NL> # 03:08:18 ntp-topology-setup INFO: main: have_docker_socket_flag True <NL> # 03:08:18 ntp-topology-setup INFO: main: in_docker_container_flag True <NL> # 03:08:18 ntp-topology-setup INFO: main: have_podman_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: have_podman_socket_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: in_podman_container_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: in_kubernetes_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: have_sudo_vmmng_flag False <NL> # 03:08:18 ntp-topology-setup INFO: main: defaulting topology_type to 'single' <NL> # 03:08:18 ntp-topology-setup INFO: get_network_topology_tag: shared_store_tag = tag <NL> # 03:08:18 ntp-topology-setup INFO: get_network_topology_tag: network_topology_tag  'tag.20240731030818.df250eded7d34577b63247fd091bcb64' (len 51) <NL> # 03:08:18 ntp-topology-setup INFO: main: shared_store_mount_dir        '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64' <NL> # 03:08:18 ntp-topology-setup INFO: main: shared_store_dir              '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64' <NL> # 03:08:18 ntp-topology-setup INFO: main: container_workspace_basedir   '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace' <NL> # 03:08:18 ntp-topology-setup INFO: main: container_logs_basedir        '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs' <NL> # 03:08:18 ntp-topology-setup INFO: main: container_local_base_dir      None <NL> # 03:08:18 ntp-topology-setup INFO: main: container_fake_local_base_dir None (fake can only be used when using remote store) <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64'] <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace'] <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs'] <NL> # 03:08:18 ntp-topology-setup INFO: exec_cmd: ['chmod', 'a+rwx', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs'] <NL> # 03:08:18 ntp-topology-setup INFO: ntp_info_cl.write_json_dict: ntp_info_obj into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json': { <NL> \"_NETWORK_TOPOLOGY_TAG\": \"tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> \"_SHARED_STORE_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> \"_TOPOLOGY_TYPE\": \"container-docker-single\" <NL> } <NL> # 03:08:18 ntp-topology-setup INFO: shared_store_info_cl.write_json_dict: shared_store_info_dict into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json': { <NL> \"REMOTE_STORE_FLAG\": false, <NL> \"SHARED_STORE_MOUNT_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> \"UNIQUE_SHARED_SUBDIR\": \"ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\" <NL> } <NL> # 03:08:18 tfwk-exec-test-agent INFO: main: begin: calling set_attributes() to perform the delayed evaluation <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_cl.set_attributes(phase='phase__delayed') <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE1/device:main' <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: {"}
{"timestamp_utc": "2024-07-31T08:08:19.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:18 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json'"}
{"timestamp_utc": "2024-07-31T08:08:19.266Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ci-get-pipeline-image-location-info', '--project-name', '{#project_name#}', '--project-label', '{#project_label#}', '--branch-name', '{#branch_name#}', '--regression-group', '{#regression_group#}', '--machine-name', '{#machine_name#}', '--image-name', '{#image_name#}']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: {  \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\" } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_cl.get_image_location_info_dict: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\","}
{"timestamp_utc": "2024-07-31T08:08:19.267Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"2\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE2/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip"}
{"timestamp_utc": "2024-07-31T08:08:19.268Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"2\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE3/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"shelf-num\": \"200\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-aggr-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:19.527Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T': product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\","}
{"timestamp_utc": "2024-07-31T08:08:19.528Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE4/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"main\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"shelf-num\": \"200\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-aggr-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none"}
{"timestamp_utc": "2024-07-31T08:08:19.529Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T': product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: ===== <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: full_instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_type 'device' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add:   instance_name 'trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: instance_dict: { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"shelf-num\": \"1\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_info_template_path does not exist: '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags/image-info-template.json' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_variable_dictionary: { <NL> \"branch_name\": null, <NL> \"image_name\": \"fss-image-validation-T\", <NL> \"machine_name\": \"qemux86-64\", <NL> \"project_label\": null, <NL> \"project_name\": null, <NL> \"regression_group\": \"ri-fss3-protocol-ddcn-natRedistribute\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: image_location_info_dict: { <NL> \"CI_ARTIFACTS_PIPELINES_ROOT\": \"/proj/artifacts/projects\", <NL> \"CI_JOB_WORKSPACE_ARTIFACTS_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts\", <NL> \"CI_PIPELINE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression\", <NL> \"CI_PIPELINE_INSTANCE_ARTIFACT_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999\", <NL> \"CI_PIPELINE_INSTANCE_RELEASE_DIR\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release\", <NL> \"build_artifact_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"build_regression_image_zip_dir\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_artifact_image_zip_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_component_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/components/{#project_name#}/{#branch_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_artifact_image_zip_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.artifact/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\", <NL> \"generic_project_build_regression_group_machine_image_deploy_dir\": \"/proj/artifacts/projects/{#project_name#}/{#project_label#}/release/build.regression/GROUP.{#regression_group#}/MACHINE.{#machine_name#}/IMAGE.{#image_name#}\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product_artifactory_image_uri: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_product_artifactory: product: None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_build_dir: image_path is None <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_path: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: image_path is none <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output: command ['ls', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T']: <NL> # 03:08:19 tfwk-exec-test-agent INFO: get_output:   stdout: product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: contents of '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T': product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: line 'product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: image_location_cl.check_image_zip_dir: found pipeline_instance '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_config_defaults_dict: {} <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: end: calling set_attributes() to perform the delayed evaluation <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.non_explicit_instance_context_add: define_instance_attr_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null,"}
{"timestamp_utc": "2024-07-31T08:08:19.530Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"2\" <NL> } <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"2\" <NL> } <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"200\" <NL> } <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\", <NL> \"value\": { <NL> \"image-info-config-name\": \"main\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-aggr-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"200\" <NL> } <NL> }, <NL> \"network-element:NE4/device:trib1\": { <NL> \"name\": \"network-element:NE4/device:trib1\", <NL> \"value\": { <NL> \"image-info-config-name\": \"trib-L1-OTSG2\", <NL> \"image-info-tags-dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags\", <NL> \"image-name\": \"fss-image-validation-T\", <NL> \"image-zip-path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"product-name\": null, <NL> \"shelf-num\": \"1\" <NL> } <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\", <NL> \"network-element:NE4/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-attr\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: args_derived_cl.non_explicit_instance_context_add: define_instance_config_dict: { <NL> \"child_dict\": { <NL> \"network-element:NE1/device:main\": { <NL> \"name\": \"network-element:NE1/device:main\" <NL> }, <NL> \"network-element:NE1/device:trib1\": { <NL> \"name\": \"network-element:NE1/device:trib1\" <NL> }, <NL> \"network-element:NE2/device:main\": { <NL> \"name\": \"network-element:NE2/device:main\" <NL> }, <NL> \"network-element:NE2/device:trib1\": { <NL> \"name\": \"network-element:NE2/device:trib1\" <NL> }, <NL> \"network-element:NE3/device:main\": { <NL> \"name\": \"network-element:NE3/device:main\" <NL> }, <NL> \"network-element:NE3/device:trib1\": { <NL> \"name\": \"network-element:NE3/device:trib1\" <NL> }, <NL> \"network-element:NE4/device:main\": { <NL> \"name\": \"network-element:NE4/device:main\" <NL> }, <NL> \"network-element:NE4/device:trib1\": { <NL> \"name\": \"network-element:NE4/device:trib1\" <NL> } <NL> }, <NL> \"child_list\": [ <NL> \"network-element:NE1/device:main\", <NL> \"network-element:NE1/device:trib1\", <NL> \"network-element:NE2/device:main\", <NL> \"network-element:NE2/device:trib1\", <NL> \"network-element:NE3/device:main\", <NL> \"network-element:NE3/device:trib1\", <NL> \"network-element:NE4/device:main\", <NL> \"network-element:NE4/device:trib1\" <NL> ], <NL> \"name\": \"--define-instance-config\" <NL> } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: ntp_topology_run: [ <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE1/device:main\", <NL> \"main-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE1/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE1/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE1/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE1/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE1/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE1/device:trib1\", <NL> \"image-zip-path\","}
{"timestamp_utc": "2024-07-31T08:08:19.531Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE1/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE1/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE1/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE2/device:main\", <NL> \"main-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE2/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE2/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE2/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE2/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE2/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE2/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE2/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE2/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE2/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE3/device:main\", <NL> \"main\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE3/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE3/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE3/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE3/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE3/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE3/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE3/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE3/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE3/device:trib1\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE4/device:main\", <NL> \"main\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE4/device:main\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE4/device:main\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE4/device:main\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE4/device:main\", <NL> \"--ntp-instance-context-image-info-config-name\", <NL> \"network-element:NE4/device:trib1\", <NL> \"trib-L1-OTSG2\", <NL> \"--ntp-instance-context-image-location-type\", <NL> \"network-element:NE4/device:trib1\", <NL> \"image-zip-path\", <NL> \"--ntp-instance-context-image-zip-path\", <NL> \"network-element:NE4/device:trib1\", <NL> \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"--ntp-instance-context-configure-options-json\", <NL> \"network-element:NE4/device:trib1\", <NL> \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> \"--ntp-instance-context-add\", <NL> \"network-element:NE4/device:trib1\" <NL> ] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: - new exec status info: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   topology_active_flag=False <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   topology_state='initializing' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   topology info for work dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148': <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     topology_tag_name: ['DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1'] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     topology_pre_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json'] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     topology_post_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip'"}
{"timestamp_utc": "2024-07-31T08:08:19.532Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T'"}
{"timestamp_utc": "2024-07-31T08:08:19.533Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:trib1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:             } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:         } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main:     } <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: args_obj.execute_wait_for_devices_flag True <NL> # 03:08:19 tfwk-exec-test-agent INFO: main: local_exec_test_agent_flag True (defaulted from args_obj.execute_wait_for_devices_flag) <NL> # 03:08:19 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-run.py', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--services-legacy-env-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json', '--services-env-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--image-info-configuration-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-configuration.json', '--ntp-topology-pre-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--ntp-topology-post-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--parent-hostname', 'rtxoialp79', '--parent-hostip', '167.254.217.189', '--ntp-instance-context-image-info-config-name', 'network-element:NE1/device:main', 'main-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE1/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE1/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE1/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE1/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE1/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE1/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE1/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE1/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}', '--ntp-instance-context-add', 'network-element:NE1/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE2/device:main', 'main-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE2/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE2/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE2/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE2/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE2/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE2/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE2/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE2/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}', '--ntp-instance-context-add', 'network-element:NE2/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE3/device:main', 'main', '--ntp-instance-context-image-location-type', 'network-element:NE3/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE3/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE3/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}', '--ntp-instance-context-add', 'network-element:NE3/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE3/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE3/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE3/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE3/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE3/device:trib1', '--ntp-instance-context-image-info-config-name', 'network-element:NE4/device:main', 'main', '--ntp-instance-context-image-location-type', 'network-element:NE4/device:main', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE4/device:main', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE4/device:main', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}', '--ntp-instance-context-add', 'network-element:NE4/device:main', '--ntp-instance-context-image-info-config-name', 'network-element:NE4/device:trib1', 'trib-L1-OTSG2', '--ntp-instance-context-image-location-type', 'network-element:NE4/device:trib1', 'image-zip-path', '--ntp-instance-context-image-zip-path', 'network-element:NE4/device:trib1', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--ntp-instance-context-configure-options-json', 'network-element:NE4/device:trib1', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}', '--ntp-instance-context-add', 'network-element:NE4/device:trib1'] <NL> # 03:08:19 ntp-topology-run.py INFO: main: { <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"_instance_context_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE1/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         },"}
{"timestamp_utc": "2024-07-31T08:08:19.534Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE1/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE2/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE2/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE3/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE3/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:main\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE4/device:main\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:trib1\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"_data_dict\": { <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"configure_json\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_config_name\": \"trib-L1-OTSG2\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_location_type\": \"image-zip-path\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:                 \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:             }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"network-element:NE4/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         } <NL> # 03:08:19 ntp-topology-run.py INFO: main:     }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"_instance_context_list\": [ <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE1/device:trib1\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE2/device:trib1\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE3/device:trib1\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:main\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:         \"network-element:NE4/device:trib1\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:     ], <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"_ntp_topology_obj_list\": [ <NL> # 03:08:19 ntp-topology-run.py INFO: main:         { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"--ntp-topology-pre-fname\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"value\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         }, <NL> # 03:08:19 ntp-topology-run.py INFO: main:         { <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"name\": \"--ntp-topology-post-fname\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:             \"value\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\" <NL> # 03:08:19 ntp-topology-run.py INFO: main:         } <NL> # 03:08:19 ntp-topology-run.py INFO: main:     ], <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"abort_before_create_flag\": false, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"create_image_info_from_tag_command\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"get_image_location_info_command\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"image_info_configuration_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-configuration.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"ntp_topology_tag_dir\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"parent_hostip\": \"167.254.217.189\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"parent_hostname\": \"rtxoialp79\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_env_bash_fname\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_env_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\","}
{"timestamp_utc": "2024-07-31T08:08:19.535Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: main:     \"services_global_host_info_flag\": true, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_legacy_env_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json\", <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"services_ntp_json_fname\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"show_topology_flag\": true, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_flag\": false, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_image_info_path\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_kernel_path\": null, <NL> # 03:08:19 ntp-topology-run.py INFO: main:     \"verify_topology_rootfs_path\": null <NL> # 03:08:19 ntp-topology-run.py INFO: main: } <NL> # 03:08:19 ntp-topology-run.py INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/image-info'] <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file: - input_topology_json_fname_list: <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file:   item '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json' <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file: - input_topology_post_json_fname_list: <NL> # 03:08:19 ntp-topology-run.py INFO: create_flist_file:   item '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json' <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE1/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE2/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE3/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:  reference: network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.collect_instance_reference:       from: network-element:NE4/network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE1/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE1/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE2/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE2/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE3/network:osc2 referencing network:osc2"}
{"timestamp_utc": "2024-07-31T08:08:19.536Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE3/network:osc2 from referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lcn1 referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lcn1 from referencing network:lcn1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lcn2 referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lcn2 from referencing network:lcn2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:lmp referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:lmp from referencing network:lmp <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:osc1 referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:osc1 from referencing network:osc1 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: instance_obj network-element:NE4/network:osc2 referencing network:osc2 <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.parser.resolve_instance_reference: populating instance_obj network-element:NE4/network:osc2 from referencing network:osc2"}
{"timestamp_utc": "2024-07-31T08:08:19.792Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:19 ntp-topology-run.py INFO: operating_system_cl.get_current_operating_system_tag: PRETTY_NAME 'CentOS Linux 7 (Core)', ID 'centos', MAJOR_VERSION_ID '7' <NL> # 03:08:19 ntp-topology-run.py INFO: create_dynamic_defaults: operating_system_tag 'rhel-7' <NL> # 03:08:19 ntp-topology-run.py INFO: add_dynamic_defaults_for_qemu_defs: qemu_command None <NL> # 03:08:19 ntp-topology-run.py INFO: add_dynamic_defaults_for_docker_defs: docker_image_name None <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE1/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE2/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE3/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE3/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE4/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances: - instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:19 ntp-topology-run.py INFO: configure_instances:   configure_json: '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}' <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.instance.create_instance_new: \"definitions:instance-configure\" <NL> # 03:08:19 ntp-topology-run.py INFO: ntp.definitions_instance_configure.instance_configure_cl.write_amend_file: saved amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json' <NL> # 03:08:19 ntp-topology-run.py INFO: exec_cmd: ['rm', '-f', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json'] <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE1/device:main' <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:19 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main-L1-OTSG2' <NL> # 03:08:19 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE1/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'main-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:20.360Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE1/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE1/device:main\" <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE1/device.main/data/qemu'"}
{"timestamp_utc": "2024-07-31T08:08:20.361Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE1/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE1/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main-L1-OTSG2' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"08-qemu-main-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"main-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE1/device.main/data/qemu <NL> network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE1/device.main/data/qemu/cdrom <NL> network-element.NE1/device.main/data/qemu/cdrom/image <NL> network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\""}
{"timestamp_utc": "2024-07-31T08:08:20.647Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE1/device:trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2'"}
{"timestamp_utc": "2024-07-31T08:08:20.648Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE1/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE1/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE1/device:trib1\" <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE1/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE1/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE1/device.trib1/data/qemu <NL> network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE1/device.trib1/data/qemu/cdrom <NL> network-element.NE1/device.trib1/data/qemu/cdrom/image <NL> network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json"}
{"timestamp_utc": "2024-07-31T08:08:20.905Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\" <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE2/device:main'"}
{"timestamp_utc": "2024-07-31T08:08:20.906Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main-L1-OTSG2' <NL> # 03:08:20 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE2/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'main-L1-OTSG2'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE2/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE2/device:main\" <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE2/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE2/device.main/data/qemu'"}
{"timestamp_utc": "2024-07-31T08:08:21.163Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE2/device.main/data/qemu/cdrom/image' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main-L1-OTSG2' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"08-qemu-main-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"main-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE2/device.main/data/qemu <NL> network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE2/device.main/data/qemu/cdrom <NL> network-element.NE2/device.main/data/qemu/cdrom/image <NL> network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:20 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\" <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE2/device:trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:20 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE2/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2']"}
{"timestamp_utc": "2024-07-31T08:08:21.419Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\","}
{"timestamp_utc": "2024-07-31T08:08:21.420Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE2/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE2/device:trib1\" <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE2/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE2/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE2/device.trib1/data/qemu <NL> network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE2/device.trib1/data/qemu/cdrom <NL> network-element.NE2/device.trib1/data/qemu/cdrom/image <NL> network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\" <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE3/device:main' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main' <NL> # 03:08:21 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE3/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--image-info-configuration-name', 'main']"}
{"timestamp_utc": "2024-07-31T08:08:21.677Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"instance_context\": \"network-element:NE3/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE3/device:main\" <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True"}
{"timestamp_utc": "2024-07-31T08:08:21.678Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 18:00   cdrom/image/' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2568482816  07-26-2024 17:57   cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    32881  07-26-2024 17:58   cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE3/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> inflating: network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE3/device.main/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 32881 Jul 26 17:58 fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json': ['main-BDC2-C200', 'main_prot-BDC2-C200', 'main', 'main_prot'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"03-qemu-main-image-config-values.json\" <NL> ], <NL> \"configuration-name\": \"main\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE3/device.main/data/qemu <NL> network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> network-element.NE3/device.main/data/qemu/cdrom <NL> network-element.NE3/device.main/data/qemu/cdrom/image <NL> network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\" <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE3/device:trib1'"}
{"timestamp_utc": "2024-07-31T08:08:21.935Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:21 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE3/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE3/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE3/device:trib1\" <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE3/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE3/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'"}
{"timestamp_utc": "2024-07-31T08:08:22.191Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:21 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE3/device.trib1/data/qemu <NL> network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE3/device.trib1/data/qemu/cdrom <NL> network-element.NE3/device.trib1/data/qemu/cdrom/image <NL> network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\" <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE4/device:main' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'main' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'main'"}
{"timestamp_utc": "2024-07-31T08:08:22.192Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE4/device:main', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', '--image-info-configuration-name', 'main']"}
{"timestamp_utc": "2024-07-31T08:08:22.447Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"main\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"instance_context\": \"network-element:NE4/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE4/device:main\" <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True"}
{"timestamp_utc": "2024-07-31T08:08:22.448Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 18:00   cdrom/image/' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2568482816  07-26-2024 17:57   cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    32881  07-26-2024 17:58   cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE4/device.main/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip', 'cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> inflating: network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE4/device.main/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 32881 Jul 26 17:58 fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json': ['main-BDC2-C200', 'main_prot-BDC2-C200', 'main', 'main_prot'] <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'main' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict { <NL> \"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"03-qemu-main-image-config-values.json\" <NL> ], <NL> \"configuration-name\": \"main\", <NL> \"topology-dict-content-index-list\": [ <NL> \"01-qemu-main-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict' <NL> network-element.NE4/device.main/data/qemu <NL> network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip <NL> network-element.NE4/device.main/data/qemu/cdrom <NL> network-element.NE4/device.main/data/qemu/cdrom/image <NL> network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\""}
{"timestamp_utc": "2024-07-31T08:08:22.704Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-topology-run.py INFO: launch_network_topology: - instance_context 'network-element:NE4/device:trib1' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:    context_item_obj.instance_type 'device', context_item_obj.instance_name 'trib1' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_path '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_zip_dir None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   kernel_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   rootfs_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_info_path None <NL> # 03:08:22 ntp-topology-run.py INFO: launch_network_topology:   image_config_name 'trib-L1-OTSG2' <NL> # 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-device-qemu-from-image-info', '-v', '-v', '--amend-workspace-root-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--instance-context', 'network-element:NE4/device:trib1', '--instance-context-format', 'text', '--image-zip-path', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', '--image-info-configuration-name', 'trib-L1-OTSG2'] <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: arg_dict: { <NL> \"amend_workspace_root_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\", <NL> \"configure_options_json\": null, <NL> \"image_info_configuration_name\": \"trib-L1-OTSG2\", <NL> \"image_info_path\": null, <NL> \"image_zip_dir\": null, <NL> \"image_zip_path\": \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"instance_context\": \"network-element:NE4/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\" <NL> ], <NL> \"kernel_path\": null, <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"rootfs_path\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: container_context_list_text \"network-element:NE4/device:trib1\" <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main:   defaulted_device_type 'qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: device_type_is_qemu_flag True <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '        0  07-26-2024 17:51   cdrom/image/' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + ' 10567360  07-24-2024 19:45   cdrom/image/bzImage-qemux86-64.bin' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '2576215040  07-26-2024 17:47   cdrom/image/fss-image-validation-T-qemux86-64.ext3' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: content line + '    34094  07-26-2024 17:48   cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item: unzip_fname 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' into local_image_dir 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:   - exec ['unzip', '-d', 'network-element.NE4/device.trib1/data/qemu', '/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip', 'cdrom/image/fss-image-validation-T-qemux86-64.image-info.json'] <NL> Archive:  /proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> inflating: network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: unzip_single_item:     unzipped into dest_path 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: find: 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls -al 'network-element.NE4/device.trib1/data/qemu/cdrom/image' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'total 44' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 2 jenkins jenkins  4096 Jul 31 03:08 .' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: 'drwxr-xr-x 3 jenkins jenkins  4096 Jul 31 03:08 ..' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: get_qemu_image_info: ls: '-rw-r--r-- 1 jenkins jenkins 34094 Jul 26 17:48 fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.init_from_file: found image_info_version_string '2' in image_info_fname 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found these configurations in 'network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json': ['main-L1-ETH', 'trib-L1-ETH', 'main-L1-OCHOD', 'trib-L1-OCHOD', 'main-L1-OTSG2', 'trib-L1-OTSG2', 'main-L1-OTSI2', 'trib-L1-OTSI2', 'main-L1-OTSI', 'trib-L1-OTSI', 'main-FSS2-PD01', 'trib-FSS2-PD01', 'main-L1-FLEXZR', 'trib-L1-FLEXZR', 'main', 'trib'] <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: found configuration-name 'trib-L1-OTSG2' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: selected_configuration_item_dict {"}
{"timestamp_utc": "2024-07-31T08:08:22.705Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"command-options-list-content-index-list\": [ <NL> \"02-qemu-image-command-options.json\" <NL> ], <NL> \"config-values-dict-content-index-list\": [ <NL> \"09-qemu-trib-image-config-values.unit_name.L1-OTSG2.json\" <NL> ], <NL> \"configuration-name\": \"trib-L1-OTSG2\", <NL> \"topology-dict-content-index-list\": [ <NL> \"04-qemu-trib-image-topology.json\" <NL> ] <NL> } <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'command-options-list-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'command_options_list', field_type 'list' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'config-values-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'config_values_dict', field_type 'dict' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'configuration-name': found valid field '^configuration-name$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.select_configuration: key_name 'topology-dict-content-index-list': found valid field '^(.+-([^-]+))-content-index-list$' <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: image_info_cl.handle_json_field: found field_name 'topology_dict', field_type 'dict'"}
{"timestamp_utc": "2024-07-31T08:08:22.966Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "network-element.NE4/device.trib1/data/qemu <NL> network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip <NL> network-element.NE4/device.trib1/data/qemu/cdrom <NL> network-element.NE4/device.trib1/data/qemu/cdrom/image <NL> network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json <NL> # 03:08:22 ntp-configure-device-qemu-from-image-info INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\" <NL> # 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['cat', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json'] <NL> [ <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.967Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"1\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"1\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE1\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\","}
{"timestamp_utc": "2024-07-31T08:08:22.968Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.969Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE1\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.970Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"1\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"1\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE2\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\""}
{"timestamp_utc": "2024-07-31T08:08:22.971Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "} <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:22.972Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE2\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.973Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.974Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"{#cpu_model#}\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"cpu_model\\\": \\\"qemu64\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"redundancyMode\\\": \\\"WORK\\\", \\\"serialNum\\\": \\\"12345\\\", \\\"shelfNumber\\\": \\\"200\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"200\\\", \\\"smp\\\": \\\"1\\\", \\\"unitCode\\\": \\\"0xc200\\\", \\\"unitName\\\": \\\"BDC2-C200\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE3\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:22.975Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "}, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.976Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:22.977Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE3\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:22.978Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"main\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"{#cpu_model#}\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"MAIN_01_02\\\", \\\"cpu_model\\\": \\\"qemu64\\\", \\\"m_megs\\\": \\\"4096\\\", \\\"redundancyMode\\\": \\\"WORK\\\", \\\"serialNum\\\": \\\"12345\\\", \\\"shelfNumber\\\": \\\"200\\\", \\\"shelfRole\\\": \\\"MAIN\\\", \\\"simulatedRole\\\": \\\"MAIN\\\", \\\"simulatedShelf\\\": \\\"200\\\", \\\"smp\\\": \\\"1\\\", \\\"unitCode\\\": \\\"0xc200\\\", \\\"unitName\\\": \\\"BDC2-C200\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lmp\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lmp-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn1\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn1-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"lcn2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-lcn2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-external-osc2-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"cli\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-cli-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 22}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"netconf\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-netconf-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 830}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gnmi\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gnmi-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6030}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"snmp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-snmp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 161}, \\\"protocol\\\": \\\"udp\\\"}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"webui\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-webui-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 80}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"https\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-https-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 443}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"zmq\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-zmq-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 5555}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 10000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"gdb-ops-additional\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-gdb-ops-additional-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 32767}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ospl\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ospl-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 50000}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 21}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"sftp\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-sftp-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 2202}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"telnet\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"port_number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-telnet-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 23}}]}}}}\","}
{"timestamp_utc": "2024-07-31T08:08:22.979Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE4\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"main\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lmp\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lmp-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn1\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn1-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"lcn2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-lcn2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-external-osc2-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_options\": ["}
{"timestamp_utc": "2024-07-31T08:08:22.980Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"cli\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-cli-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 22 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"netconf\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-netconf-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 830 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gnmi\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gnmi-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6030 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"snmp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-snmp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 161 <NL> }, <NL> \"protocol\": \"udp\" <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"webui\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-webui-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 80 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"https\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-https-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 443 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"zmq\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-zmq-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 5555 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb\", <NL> \"instance_type\": \"service\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:22.981Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 10000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"gdb-ops-additional\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-gdb-ops-additional-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 32767 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ospl\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ospl-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 50000 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 21 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"sftp\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-sftp-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 2202 <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"telnet\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"port_number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-telnet-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 23 <NL> } <NL> } <NL> ] <NL> }, <NL> { <NL> \"image_info_configuration_json\": \"{\\\"configuration_name\\\": \\\"trib-L1-OTSG2\\\", \\\"content_dict\\\": {}, \\\"field_defs_dict\\\": {\\\"field_command_options_list\\\": {\\\"attr_name\\\": \\\"field_command_options_list\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"command_options_list\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": [{\\\"option_name\\\": \\\"-cpu\\\", \\\"option_value\\\": \\\"qemu64\\\"}, {\\\"option_name\\\": \\\"-nographic\\\"}, {\\\"option_name\\\": \\\"-enable-kvm\\\"}, {\\\"option_name\\\": \\\"-smp\\\", \\\"option_value\\\": \\\"{#smp#}\\\"}, {\\\"option_name\\\": \\\"-m\\\", \\\"option_value\\\": \\\"{#m_megs#}\\\"}, {\\\"option_name\\\": \\\"--append\\\", \\\"option_value\\\": [{\\\"option_name\\\": \\\"root\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"/dev/hda\\\"}, {\\\"option_name\\\": \\\"rw\\\"}, {\\\"option_name\\\": \\\"ip\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"dhcp\\\"}, {\\\"option_name\\\": \\\"console\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"ttyS0\\\"}, {\\\"option_name\\\": \\\"FSS_CARD_ID\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#FSS_CARD_ID#}\\\"}, {\\\"option_name\\\": \\\"OSPL_URI\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"file:///etc/config/ospl.xml\\\"}, {\\\"option_name\\\": \\\"unitCode\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitCode#}\\\"}, {\\\"option_name\\\": \\\"unitName\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#unitName#}\\\"}, {\\\"option_name\\\": \\\"shelfRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfRole#}\\\"}, {\\\"option_name\\\": \\\"shelfNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#shelfNumber#}\\\"}, {\\\"option_name\\\": \\\"simulatedRole\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedRole#}\\\"}, {\\\"option_name\\\": \\\"simulatedShelf\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#simulatedShelf#}\\\"}, {\\\"option_name\\\": \\\"serialNum\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#serialNum#}\\\"}, {\\\"option_name\\\": \\\"slotNumber\\\", \\\"option_separator\\\": \\\"=\\\", \\\"option_value\\\": \\\"{#slotNumber#}\\\"}]}]}, \\\"field_config_values_dict\\\": {\\\"attr_name\\\": \\\"field_config_values_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"config_values_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"FSS_CARD_ID\\\": \\\"TRIB_01_02\\\", \\\"m_megs\\\": \\\"1024\\\", \\\"serialNum\\\": \\\"sim_\\\", \\\"shelfNumber\\\": \\\"2\\\", \\\"shelfRole\\\": \\\"TRIB\\\", \\\"simulatedRole\\\": \\\"TRIB\\\", \\\"simulatedShelf\\\": \\\"2\\\", \\\"slotNumber\\\": \\\"0\\\", \\\"smp\\\": \\\"4\\\", \\\"unitCode\\\": \\\"0xf9fc\\\", \\\"unitName\\\": \\\"L1-OTSG2\\\"}}, \\\"field_topology_dict\\\": {\\\"attr_name\\\": \\\"field_topology_dict\\\", \\\"field_class\\\": null, \\\"field_name\\\": \\\"topology_dict\\\", \\\"field_type\\\": \\\"json\\\", \\\"json_value\\\": {\\\"interface-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug\\\", \\\"instance_type\\\": \\\"interface\\\", \\\"provision_type\\\": \\\"slirp\\\", \\\"qemu_debug_interface_flag\\\": true}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"ilan\\\", \\\"instance_type\\\": \\\"interface\\\"}, \\\"network_info\\\": {\\\"instance_info\\\": {\\\"instance_action\\\": \\\"reference\\\", \\\"instance_name\\\": {\\\"action\\\": \\\"reference-value\\\", \\\"name\\\": \\\"ne-internal-ilan-network-name\\\"}, \\\"instance_ref_parent_context_instance_type\\\": \\\"network-element\\\", \\\"instance_ref_parent_context_type\\\": \\\"ancestor\\\", \\\"instance_type\\\": \\\"network\\\"}}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc1\\\", \\\"instance_type\\\": \\\"interface\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"osc2\\\", \\\"instance_type\\\": \\\"interface\\\"}}], \\\"service-list\\\": [{\\\"instance_info\\\": {\\\"instance_name\\\": \\\"console\\\", \\\"instance_type\\\": \\\"service\\\"}}, {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"debug-ssh\\\", \\\"instance_type\\\": \\\"service\\\"}, \\\"internal-port-number\\\": {\\\"instance_info\\\": {\\\"instance_name\\\": \\\"internal-ssh-port\\\", \\\"instance_type\\\": \\\"port-number\\\", \\\"port_number_type\\\": \\\"internal\\\"}, \\\"port_number\\\": 6022}}]}}}}\", <NL> \"instance_info\": { <NL> \"instance_action\": \"modify\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"NE4\", <NL> \"instance_type\": \"network-element\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"trib1\", <NL> \"instance_type\": \"device\" <NL> }, <NL> \"interface-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug\", <NL> \"instance_type\": \"interface\", <NL> \"provision_type\": \"slirp\", <NL> \"qemu_debug_interface_flag\": true <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"ilan\", <NL> \"instance_type\": \"interface\" <NL> }, <NL> \"network_info\": { <NL> \"instance_info\": { <NL> \"instance_action\": \"reference\", <NL> \"instance_name\": { <NL> \"action\": \"reference-value\", <NL> \"name\": \"ne-internal-ilan-network-name\" <NL> }, <NL> \"instance_ref_parent_context_instance_type\": \"network-element\", <NL> \"instance_ref_parent_context_type\": \"ancestor\", <NL> \"instance_type\": \"network\" <NL> } <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc1\", <NL> \"instance_type\": \"interface\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"osc2\", <NL> \"instance_type\": \"interface\" <NL> } <NL> } <NL> ], <NL> \"qemu_config\": { <NL> \"kernel_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> },"}
{"timestamp_utc": "2024-07-31T08:08:22.982Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "{ <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> }, <NL> \"service-list\": [ <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"console\", <NL> \"instance_type\": \"service\" <NL> } <NL> }, <NL> { <NL> \"instance_info\": { <NL> \"instance_name\": \"debug-ssh\", <NL> \"instance_type\": \"service\" <NL> }, <NL> \"internal-port-number\": { <NL> \"instance_info\": { <NL> \"instance_name\": \"internal-ssh-port\", <NL> \"instance_type\": \"port-number\", <NL> \"port_number_type\": \"internal\" <NL> }, <NL> \"port_number\": 6022 <NL> } <NL> } <NL> ] <NL> } <NL> ]# 03:08:22 ntp-topology-run.py INFO: exec_cmd: ['ntp-amend-for-qemu', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json', '--out-mode', 'create', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json']"}
{"timestamp_utc": "2024-07-31T08:08:23.251Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:22 ntp-amend-for-qemu INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json\", <NL> \"out_mode\": \"create\", <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:23 ntp-amend-for-qemu INFO: handle_phase_1: - begin <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE1/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE1/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:trib1/serial-interface:serial-1\""}
{"timestamp_utc": "2024-07-31T08:08:23.252Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE1/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE2/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE2/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE2/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE3/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE3/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE3/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE4/device:main', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:main/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:main/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: find_device_interfaces: device_context_absolute_id 'network-element:NE4/device:trib1', device_type_is_qemu_flag True <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:trib1/serial-interface:serial-1\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: ntp.instance.create_instance_new: \"network-element:NE4/device:trib1/serial-interface:serial-2\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE1/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE1/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE1/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE2/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE2/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE2/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE3/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE3/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE3/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE4/device:main/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lmp\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lcn1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:lcn2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:main/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: skipping debug interface \"network-element:NE4/device:trib1/interface:debug\" <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:ilan\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:osc1\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: create_network_interface: interface \"network-element:NE4/device:trib1/interface:osc2\" already has a network defined <NL> # 03:08:23 ntp-amend-for-qemu INFO: handle_phase_1: ----- <NL> # 03:08:23 ntp-topology-run.py INFO: exec_cmd: ['ntp-amend-for-docker-containers', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json', '--out-mode', 'append', '--topology-tag', 'tag.20240731030818.df250eded7d34577b63247fd091bcb64', '--topology-type', 'container-docker-single', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json']"}
{"timestamp_utc": "2024-07-31T08:08:23.508Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json\", <NL> \"out_mode\": \"append\", <NL> \"topology_tag\": \"tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> \"topology_type\": \"container-docker-single\", <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: topology_definitions_cl.__init__: new_topology_type \"container-docker-single\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: topology_definitions_cl.__init__: new termination-signal 15(SIGTERM)"}
{"timestamp_utc": "2024-07-31T08:08:23.766Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: main: topology_type \"container-docker-single\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE1/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE1/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE2/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE2/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE3/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE3/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE4/device:main', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups: - device_context_absolute_id 'network-element:NE4/device:trib1', defaulted_device_type 'qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: map_devices_to_device_groups:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: create_group_instances: <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_new: \"definitions:topology/device_group:group-device-group-type-qemu-01\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: create_group_instances: get_instance_dict: { <NL> \"instance_info\": { <NL> \"group_type\": \"device-group-type-qemu\", <NL> \"instance_action\": \"create-new\", <NL> \"instance_my_parent_context_absolute_list\": [ <NL> { <NL> \"instance_name\": \"topology\", <NL> \"instance_type\": \"definitions\" <NL> } <NL> ], <NL> \"instance_my_parent_context_type\": \"absolute\", <NL> \"instance_name\": \"group-device-group-type-qemu-01\", <NL> \"instance_type\": \"device_group\" <NL> } <NL> } <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main\" (ref \"network-element:NE1/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1\" (ref \"network-element:NE1/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main\" (ref \"network-element:NE2/device:main\")"}
{"timestamp_utc": "2024-07-31T08:08:23.767Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1\" (ref \"network-element:NE2/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main\" (ref \"network-element:NE3/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1\" (ref \"network-element:NE3/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main\" (ref \"network-element:NE4/device:main\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1\" (ref \"network-element:NE4/device:trib1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: create_default_docker_bridge_networks: <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_new: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_interfaces: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/interface:debug/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-console\" (ref \"network-element:NE1/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-debug-ssh\" (ref \"network-element:NE1/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-cli\" (ref \"network-element:NE1/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-netconf\" (ref \"network-element:NE1/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gnmi\" (ref \"network-element:NE1/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-snmp\" (ref \"network-element:NE1/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-webui\" (ref \"network-element:NE1/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-https\" (ref \"network-element:NE1/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-zmq\" (ref \"network-element:NE1/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb\" (ref \"network-element:NE1/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb-ops-additional\" (ref \"network-element:NE1/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ospl\" (ref \"network-element:NE1/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ftp\" (ref \"network-element:NE1/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-sftp\" (ref \"network-element:NE1/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-telnet\" (ref \"network-element:NE1/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-console\" (ref \"network-element:NE1/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE1/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\")"}
{"timestamp_utc": "2024-07-31T08:08:23.768Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-debug-ssh\" (ref \"network-element:NE1/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-console\" (ref \"network-element:NE2/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-debug-ssh\" (ref \"network-element:NE2/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-cli\" (ref \"network-element:NE2/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-netconf\" (ref \"network-element:NE2/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gnmi\" (ref \"network-element:NE2/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-snmp\" (ref \"network-element:NE2/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-webui\" (ref \"network-element:NE2/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-https\" (ref \"network-element:NE2/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-zmq\" (ref \"network-element:NE2/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb\" (ref \"network-element:NE2/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb-ops-additional\" (ref \"network-element:NE2/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ospl\" (ref \"network-element:NE2/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ftp\" (ref \"network-element:NE2/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-sftp\" (ref \"network-element:NE2/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-telnet\" (ref \"network-element:NE2/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-console\" (ref \"network-element:NE2/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE2/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-debug-ssh\" (ref \"network-element:NE2/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-console\" (ref \"network-element:NE3/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-debug-ssh\" (ref \"network-element:NE3/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-cli\" (ref \"network-element:NE3/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-netconf\" (ref \"network-element:NE3/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gnmi\" (ref \"network-element:NE3/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-snmp\" (ref \"network-element:NE3/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-webui\" (ref \"network-element:NE3/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-https\" (ref \"network-element:NE3/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-zmq\" (ref \"network-element:NE3/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb\" (ref \"network-element:NE3/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb-ops-additional\" (ref \"network-element:NE3/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ospl\" (ref \"network-element:NE3/device:main/service:ospl\")"}
{"timestamp_utc": "2024-07-31T08:08:23.769Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ftp\" (ref \"network-element:NE3/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-sftp\" (ref \"network-element:NE3/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-telnet\" (ref \"network-element:NE3/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-console\" (ref \"network-element:NE3/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE3/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-debug-ssh\" (ref \"network-element:NE3/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-console\" (ref \"network-element:NE4/device:main/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-debug-ssh\" (ref \"network-element:NE4/device:main/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:cli/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-cli\" (ref \"network-element:NE4/device:main/service:cli\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:netconf/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-netconf\" (ref \"network-element:NE4/device:main/service:netconf\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gnmi/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gnmi\" (ref \"network-element:NE4/device:main/service:gnmi\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:snmp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-snmp\" (ref \"network-element:NE4/device:main/service:snmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:webui/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-webui\" (ref \"network-element:NE4/device:main/service:webui\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:https/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-https\" (ref \"network-element:NE4/device:main/service:https\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:zmq/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-zmq\" (ref \"network-element:NE4/device:main/service:zmq\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gdb/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb\" (ref \"network-element:NE4/device:main/service:gdb\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:gdb-ops-additional/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb-ops-additional\" (ref \"network-element:NE4/device:main/service:gdb-ops-additional\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:ospl/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ospl\" (ref \"network-element:NE4/device:main/service:ospl\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:ftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ftp\" (ref \"network-element:NE4/device:main/service:ftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:sftp/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-sftp\" (ref \"network-element:NE4/device:main/service:sftp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:main/service:telnet/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-telnet\" (ref \"network-element:NE4/device:main/service:telnet\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: collect_services: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/service:console/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-console\" (ref \"network-element:NE4/device:trib1/service:console\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"network-element:NE4/device:trib1/service:debug-ssh/network:bridge\" (ref \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-debug-ssh\" (ref \"network-element:NE4/device:trib1/service:debug-ssh\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: begin <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge', network_type 'external' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc1', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lmp', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lcn1', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:lcn2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE1/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc1-2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network:osc2-2', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE2/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE3/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: 1 children group users for resolved_network_instance_context_absolute_id 'network-element:NE4/network:ilan', network_type 'internal' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   child group_id 'group-device-group-type-qemu-01', group_type 'device-group-type-qemu' <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types: group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   external: resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     this is the container's default docker bridge network, do not create again <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge"}
{"timestamp_utc": "2024-07-31T08:08:23.770Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id None <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1\" (ref \"network:osc1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp\" (ref \"network:lmp\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1\" (ref \"network:lcn1\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2\" (ref \"network:lcn2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan\" (ref \"network-element:NE1/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2\" (ref \"network:osc2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2\" (ref \"network:osc1-2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2\" (ref \"network:osc2-2\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan\" (ref \"network-element:NE2/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan\" (ref \"network-element:NE3/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:   internal: resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: ntp.instance.create_instance_ref: \"definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan\" (ref \"network-element:NE4/network:ilan\") <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:     container_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: amend_network_types:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show: networks by group <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge"}
{"timestamp_utc": "2024-07-31T08:08:23.771Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id None <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show: groups by network <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:   group_id group-device-group-type-qemu-01 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id None <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:debug <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lmp <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc1-2"}
{"timestamp_utc": "2024-07-31T08:08:23.772Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:     resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:main/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: show:       interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:23 ntp-amend-for-docker-containers INFO: handle_phase_1: ----- ----- ----- ----- ----- <NL> # 03:08:23 ntp-topology-run.py INFO: exec_cmd: ['ntp-update-instance-sequence-numbers', '-v', '-v', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json', '--out-mode', 'append', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json']"}
{"timestamp_utc": "2024-07-31T08:08:24.027Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:23 ntp-update-instance-sequence-numbers INFO: arg_dict: { <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\","}
{"timestamp_utc": "2024-07-31T08:08:24.028Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json\" <NL> ], <NL> \"out_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json\", <NL> \"out_mode\": \"append\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:24.285Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: ----- collecting existing counts <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: ----- setting new counts <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:docker-container\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:docker-container\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"definitions:docker-network\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"definitions:docker-network\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"definitions:instance-configure\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"definitions:instance-configure\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"definitions:instance-defaults\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"definitions:instance-defaults\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"definitions:kubernetes-cluster\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"definitions:kubernetes-cluster\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"definitions:qemu-configuration\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"definitions:qemu-configuration\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"definitions:topology\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"definitions:topology\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network:osc1\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.286Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network:osc1-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network:osc1-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network:osc2-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network:osc2-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE1/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  1\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.287Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.288Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 61\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 62\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.289Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 63\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 64\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 65\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 66\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 67\": create-new instance_context_absolute_id \"network-element:NE1/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE1/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 68\": create-new instance_context_absolute_id \"network-element:NE2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  2\": create-new instance_context_absolute_id \"network-element:NE2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 69\": create-new instance_context_absolute_id \"network-element:NE2/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE2/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 70\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 71\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 72\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 73\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 74\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 75\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 76\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 77\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 78\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 79\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 80\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 81\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 82\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 83\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 17\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 84\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 85\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 18\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 86\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 87\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 88\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 89\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 90\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.290Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 91\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 92\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 93\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 94\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 95\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 96\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 97\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 98\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 99\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"100\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"101\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"102\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"103\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"104\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"105\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"106\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"107\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"108\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"109\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 19\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"110\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 20\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"111\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 21\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"112\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 22\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"113\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"114\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"115\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"116\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"117\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.291Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"118\": create-new instance_context_absolute_id \"network-element:NE2/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE2/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"119\": create-new instance_context_absolute_id \"network-element:NE3\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  3\": create-new instance_context_absolute_id \"network-element:NE3\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"120\": create-new instance_context_absolute_id \"network-element:NE3/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  5\": create-new instance_context_absolute_id \"network-element:NE3/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"121\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 23\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"122\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 24\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"123\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 25\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"124\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 26\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"125\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 27\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"126\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 28\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"127\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 29\": create-new instance_context_absolute_id \"network-element:NE3/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"128\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  9\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"129\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 10\": create-new instance_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"130\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"131\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"132\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"133\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"134\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"135\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"136\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"137\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"138\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"139\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"140\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"141\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"142\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"143\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.292Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"144\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"145\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"146\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"147\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"148\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"149\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"150\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"151\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"152\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"153\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"154\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"155\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"156\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"157\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"158\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"159\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  6\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"160\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 30\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"161\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 31\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"162\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 32\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"163\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 33\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"164\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.293Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"165\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"166\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"167\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"168\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 45\": create-new instance_context_absolute_id \"network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"169\": create-new instance_context_absolute_id \"network-element:NE3/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 11\": create-new instance_context_absolute_id \"network-element:NE3/network:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"170\": create-new instance_context_absolute_id \"network-element:NE4\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  4\": create-new instance_context_absolute_id \"network-element:NE4\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"171\": create-new instance_context_absolute_id \"network-element:NE4/device:main\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  7\": create-new instance_context_absolute_id \"network-element:NE4/device:main\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"172\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 34\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"173\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 35\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"174\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 36\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"175\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 37\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lcn2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"176\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 38\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:lmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"177\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 39\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"178\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 40\": create-new instance_context_absolute_id \"network-element:NE4/device:main/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"179\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 13\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"180\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 14\": create-new instance_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"181\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"182\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli/port-number:internal-cli-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 46\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:cli/port-number:internal-cli-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"183\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"184\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"185\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 47\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"186\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"187\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 48\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"188\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"189\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 49\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"190\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"191\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 50\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"192\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"193\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 51\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"194\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https\" (instance-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.294Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"195\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https/port-number:internal-https-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 52\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:https/port-number:internal-https-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"196\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"197\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 53\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"198\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 61\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"199\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 54\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"200\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 62\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"201\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 55\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"202\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 63\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"203\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 56\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"204\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 64\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"205\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 57\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"206\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 65\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"207\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui/port-number:internal-webui-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 58\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:webui/port-number:internal-webui-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"208\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 66\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"209\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 59\": create-new instance_context_absolute_id \"network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"210\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"  8\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"211\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:debug\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 41\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:debug\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"212\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 42\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:ilan\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"213\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 43\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"214\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 44\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/interface:osc2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"215\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 15\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"216\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 16\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"217\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:console\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 67\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:console\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"218\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 68\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"219\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 60\": create-new instance_context_absolute_id \"network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port\" (instance-by-type-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \"220\": create-new instance_context_absolute_id \"network-element:NE4/network:ilan\" (instance-sequence-number) <NL> # 03:08:24 ntp-update-instance-sequence-numbers INFO: main: value \" 12\": create-new instance_context_absolute_id \"network-element:NE4/network:ilan\" (instance-by-type-sequence-number)"}
{"timestamp_utc": "2024-07-31T08:08:24.295Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:24 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-json-flist', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--use-relative-path', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '--json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json'] <NL> # 03:08:24 ntp-create-json-flist INFO: arg_dict: { <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"json\": [ <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json\" <NL> ], <NL> \"use_absolute_path_flag\": false, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:24 ntp-create-json-flist DEBUG: json_flist ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/topology-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/docker-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/kubernetes-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/qemu-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/data/instance-defaults-defs.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-01-dynamic-defaults.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-02-config.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-03-user.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/amend-04-setup.json'] <NL> # 03:08:24 ntp-create-json-flist DEBUG: flist_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\" <NL> # 03:08:24 ntp-create-json-flist DEBUG: workspace_root_dir \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace\" <NL> # 03:08:24 ntp-create-json-flist DEBUG: flist_fpath \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\""}
{"timestamp_utc": "2024-07-31T08:08:32.393Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:31 ntp-topology-run.py INFO: exec_cmd: ['ntp-get-image-info-configuration-json', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--image-info-configuration-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-configuration.json'] <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration: container_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:32 ntp-get-image-info-configuration-json INFO: get_image_info_configuration:   device_context_absolute_id network-element:NE4/device:trib1"}
{"timestamp_utc": "2024-07-31T08:08:32.648Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:32 ntp-topology-run.py INFO: exec_cmd: ['ntp-configure-docker-containers', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--container-parent-hostip', '167.254.217.189', '--container-parent-hostname', 'rtxoialp79'] <NL> # 03:08:32 ntp-configure-docker-containers INFO: arg_dict: { <NL> \"container_parent_hostip\": \"167.254.217.189\", <NL> \"container_parent_hostname\": \"rtxoialp79\", <NL> \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:33.210Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:32 ntp-configure-docker-containers INFO: save_amend_changes: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.docker-container/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:32 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE1/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}'] <NL> # 03:08:33 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE1/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:33 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:33.465Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE1/device:main\" <NL> # 03:08:33 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:33 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE1/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:33.720Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE1/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:33.721Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"2\", <NL> \"simulatedShelf\": \"2\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:33.976Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:33 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE1/device:trib1\" <NL> # 03:08:33 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:33 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE2/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:34.231Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:34.232Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE2/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:34 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:34.487Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE2/device:main\" <NL> # 03:08:34 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:34 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE2/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"2\", \"simulatedShelf\": \"2\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:34.743Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"2\\\", \\\"simulatedShelf\\\": \\\"2\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE2/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:34 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"2\", <NL> \"simulatedShelf\": \"2\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:34.998Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:34 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE2/device:trib1\" <NL> # 03:08:34 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:34 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE3/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}'] <NL> # 03:08:34 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE3/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:34 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"200\", <NL> \"simulatedShelf\": \"200\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:35.559Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE3/device:main\" <NL> # 03:08:35 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:35 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE3/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}'] <NL> # 03:08:35 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE3/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:35 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:35.816Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE3/device:trib1\" <NL> # 03:08:35 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:36.071Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:35 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE4/device:main', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"200\", \"simulatedShelf\": \"200\"}}}'] <NL> # 03:08:35 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"200\\\", \\\"simulatedShelf\\\": \\\"200\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE4/device:main\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:35 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"200\", <NL> \"simulatedShelf\": \"200\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:36.345Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:36 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE4/device:main\" <NL> # 03:08:36 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:36 ntp-topology-run.py INFO: exec_cmd: ['ntp-instance-configure', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--instance-context', 'network-element:NE4/device:trib1', '--instance-context-format', 'text', '--json-field', '{\"qemu_config\": {\"variable_definitions\": {\"shelfNumber\": \"1\", \"simulatedShelf\": \"1\"}}}']"}
{"timestamp_utc": "2024-07-31T08:08:36.601Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:36 ntp-instance-configure INFO: arg_dict: { <NL> \"field_and_value\": [ <NL> { <NL> \"param\": \"--json-field\", <NL> \"value\": \"{\\\"qemu_config\\\": {\\\"variable_definitions\\\": {\\\"shelfNumber\\\": \\\"1\\\", \\\"simulatedShelf\\\": \\\"1\\\"}}}\" <NL> } <NL> ], <NL> \"flist_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json\", <NL> \"instance_context\": \"network-element:NE4/device:trib1\", <NL> \"instance_context_format\": \"text\", <NL> \"json_flist\": [], <NL> \"out_fname\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:08:36 ntp-instance-configure INFO: main: instance_dict: { <NL> \"qemu_config\": { <NL> \"variable_definitions\": { <NL> \"shelfNumber\": \"1\", <NL> \"simulatedShelf\": \"1\" <NL> } <NL> } <NL> }"}
{"timestamp_utc": "2024-07-31T08:08:36.857Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:36 ntp-instance-configure INFO: main: instance_context_list_text \"network-element:NE4/device:trib1\" <NL> # 03:08:36 ntp-instance-configure INFO: main: saved amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:36 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--action', 'prepare']"}
{"timestamp_utc": "2024-07-31T08:08:37.112Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace' <NL> # 03:08:37 ntp-topology INFO: main: starting action 'prepare'"}
{"timestamp_utc": "2024-07-31T08:08:37.677Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5000 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5000:None for 'network-element:NE1/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5000 for network-element:NE1/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5001 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5001:6022 for 'network-element:NE1/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5001 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5002 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5002:22 for 'network-element:NE1/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5002 for network-element:NE1/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE1/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5003 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5003:830 for 'network-element:NE1/device:main/service:netconf', device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:08:37.678Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5003 for network-element:NE1/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE1/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5004 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5004:6030 for 'network-element:NE1/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5004 for network-element:NE1/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE1/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5005 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5005:161/udp for 'network-element:NE1/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5005 for network-element:NE1/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE1/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5006 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5006:80 for 'network-element:NE1/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5006 for network-element:NE1/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE1/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5007 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5007:443 for 'network-element:NE1/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5007 for network-element:NE1/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE1/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5008 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5008:5555 for 'network-element:NE1/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5008 for network-element:NE1/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE1/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5009 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5009:10000 for 'network-element:NE1/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5009 for network-element:NE1/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE1/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5010 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5010:32767 for 'network-element:NE1/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5010 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5011 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5011:50000 for 'network-element:NE1/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5011 for network-element:NE1/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE1/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5012 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5012:21 for 'network-element:NE1/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5012 for network-element:NE1/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE1/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5013 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5013:2202 for 'network-element:NE1/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5013 for network-element:NE1/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE1/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5014 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5014:23 for 'network-element:NE1/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5014 for network-element:NE1/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE1/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5015 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5015:None for 'network-element:NE1/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5015 for network-element:NE1/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5016 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5016:6022 for 'network-element:NE1/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5016 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5017 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5017:None for 'network-element:NE2/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5017 for network-element:NE2/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5018 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5018:6022 for 'network-element:NE2/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5018 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE2/device:main/service:debug-ssh"}
{"timestamp_utc": "2024-07-31T08:08:37.679Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5019 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5019:22 for 'network-element:NE2/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5019 for network-element:NE2/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE2/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5020 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5020:830 for 'network-element:NE2/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5020 for network-element:NE2/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE2/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5021 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5021:6030 for 'network-element:NE2/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5021 for network-element:NE2/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE2/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5022 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5022:161/udp for 'network-element:NE2/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5022 for network-element:NE2/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE2/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5023 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5023:80 for 'network-element:NE2/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5023 for network-element:NE2/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE2/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5024 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5024:443 for 'network-element:NE2/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5024 for network-element:NE2/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE2/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5025 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5025:5555 for 'network-element:NE2/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5025 for network-element:NE2/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE2/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5026 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5026:10000 for 'network-element:NE2/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5026 for network-element:NE2/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE2/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5027 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5027:32767 for 'network-element:NE2/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5027 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5028 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5028:50000 for 'network-element:NE2/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5028 for network-element:NE2/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE2/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5029 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5029:21 for 'network-element:NE2/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5029 for network-element:NE2/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE2/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5030 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5030:2202 for 'network-element:NE2/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5030 for network-element:NE2/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE2/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5031 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5031:23 for 'network-element:NE2/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5031 for network-element:NE2/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE2/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5032 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5032:None for 'network-element:NE2/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5032 for network-element:NE2/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5033 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5033:6022 for 'network-element:NE2/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5033 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5034 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5034:None for 'network-element:NE3/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5034 for network-element:NE3/device:main/service:console"}
{"timestamp_utc": "2024-07-31T08:08:37.680Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5035 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5035:6022 for 'network-element:NE3/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5035 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5036 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5036:22 for 'network-element:NE3/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5036 for network-element:NE3/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE3/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5037 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5037:830 for 'network-element:NE3/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5037 for network-element:NE3/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE3/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5038 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5038:6030 for 'network-element:NE3/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5038 for network-element:NE3/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE3/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5039 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5039:161/udp for 'network-element:NE3/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5039 for network-element:NE3/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE3/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5040 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5040:80 for 'network-element:NE3/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5040 for network-element:NE3/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE3/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5041 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5041:443 for 'network-element:NE3/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5041 for network-element:NE3/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE3/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5042 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5042:5555 for 'network-element:NE3/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5042 for network-element:NE3/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE3/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5043 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5043:10000 for 'network-element:NE3/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5043 for network-element:NE3/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE3/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5044 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5044:32767 for 'network-element:NE3/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5044 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5045 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5045:50000 for 'network-element:NE3/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5045 for network-element:NE3/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE3/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5046 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5046:21 for 'network-element:NE3/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5046 for network-element:NE3/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE3/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5047 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5047:2202 for 'network-element:NE3/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5047 for network-element:NE3/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE3/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5048 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5048:23 for 'network-element:NE3/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5048 for network-element:NE3/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE3/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5049 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5049:None for 'network-element:NE3/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5049 for network-element:NE3/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5050 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5050:6022 for 'network-element:NE3/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5050 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE3/device:trib1/service:debug-ssh"}
{"timestamp_utc": "2024-07-31T08:08:37.681Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5051 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5051:None for 'network-element:NE4/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5051 for network-element:NE4/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5052 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5052:6022 for 'network-element:NE4/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5052 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5053 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5053:22 for 'network-element:NE4/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5053 for network-element:NE4/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 22 for network-element:NE4/device:main/service:cli <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5054 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5054:830 for 'network-element:NE4/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5054 for network-element:NE4/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 830 for network-element:NE4/device:main/service:netconf <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5055 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5055:6030 for 'network-element:NE4/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5055 for network-element:NE4/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6030 for network-element:NE4/device:main/service:gnmi <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5056 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5056:161/udp for 'network-element:NE4/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5056 for network-element:NE4/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 161 for network-element:NE4/device:main/service:snmp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5057 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5057:80 for 'network-element:NE4/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5057 for network-element:NE4/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 80 for network-element:NE4/device:main/service:webui <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5058 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5058:443 for 'network-element:NE4/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5058 for network-element:NE4/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 443 for network-element:NE4/device:main/service:https <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5059 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5059:5555 for 'network-element:NE4/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5059 for network-element:NE4/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 5555 for network-element:NE4/device:main/service:zmq <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5060 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5060:10000 for 'network-element:NE4/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5060 for network-element:NE4/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 10000 for network-element:NE4/device:main/service:gdb <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5061 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5061:32767 for 'network-element:NE4/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5061 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 32767 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5062 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5062:50000 for 'network-element:NE4/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5062 for network-element:NE4/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 50000 for network-element:NE4/device:main/service:ospl <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5063 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5063:21 for 'network-element:NE4/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5063 for network-element:NE4/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 21 for network-element:NE4/device:main/service:ftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5064 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5064:2202 for 'network-element:NE4/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5064 for network-element:NE4/device:main/service:sftp <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 2202 for network-element:NE4/device:main/service:sftp"}
{"timestamp_utc": "2024-07-31T08:08:37.682Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5065 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5065:23 for 'network-element:NE4/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5065 for network-element:NE4/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 23 for network-element:NE4/device:main/service:telnet <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5066 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5066:None for 'network-element:NE4/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5066 for network-element:NE4/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   assigned external port_number 5067 <NL> # 03:08:37 ntp-topology INFO: prepare_service_ports:   found port 5067:6022 for 'network-element:NE4/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending external_port_number to 5067 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: amending internal_port_number to 6022 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:37 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:08:37 ntp-topology INFO: handle_prepare_networks: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type external <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name eth0 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text a00000 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE1/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 9 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0002\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0002\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE1-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE2/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 10 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 3 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0003\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0003\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE2-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE3/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 11 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 4 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0004\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0004\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE3-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network-element:NE4/network:ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 12 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 5 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0005\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0005\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.NE4-ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lcn1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 6 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0006\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0006\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lcn2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 3 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 7 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0007\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0007\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:lmp"}
{"timestamp_utc": "2024-07-31T08:08:37.683Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 4 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 8 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0008\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0008\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 5 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 9 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-0009\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-0009\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc1-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 6 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 10 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000a\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000a\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc1-2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 7 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 11 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000b\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000b\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:   network_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     resolved_network_instance_context_absolute_id network:osc2-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_by_type_sequence_number 8 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     instance_sequence_number 12 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     network_type internal <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     text bdefinitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # brctl addbr \"br-000c\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     # ifconfig \"br-000c\" up <NL> # 03:08:37 ntp-topology INFO: prepare_qemu_device_networks:     saved internal network amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/network.osc2-2/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:37.942Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:trib1'"}
{"timestamp_utc": "2024-07-31T08:08:37.943Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1' <NL> # 03:08:37 ntp-topology INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:08:37 ntp-topology INFO: amend_device_host_info: unique device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:08:37 ntp-topology INFO: prepare_devices: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01', device_group_type 'device-group-type-qemu' <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE1/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE1/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\","}
{"timestamp_utc": "2024-07-31T08:08:37.944Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5000:None for service \"network-element:NE1/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5001:6022 for service \"network-element:NE1/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5002:22 for service \"network-element:NE1/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5003:830 for service \"network-element:NE1/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5004:6030 for service \"network-element:NE1/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5005:161/udp for service \"network-element:NE1/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5006:80 for service \"network-element:NE1/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5007:443 for service \"network-element:NE1/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5008:5555 for service \"network-element:NE1/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5009:10000 for service \"network-element:NE1/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5010:32767 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5011:50000 for service \"network-element:NE1/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5012:21 for service \"network-element:NE1/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5013:2202 for service \"network-element:NE1/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5014:23 for service \"network-element:NE1/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:01' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5000:None (network-element:NE1/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5001:6022 (network-element:NE1/device:main/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5002:22 (network-element:NE1/device:main/service:cli) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5003:830 (network-element:NE1/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5004:6030 (network-element:NE1/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5005:161 (network-element:NE1/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5006:80 (network-element:NE1/device:main/service:webui) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5007:443 (network-element:NE1/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5008:5555 (network-element:NE1/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5009:10000 (network-element:NE1/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5010:32767 (network-element:NE1/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5011:50000 (network-element:NE1/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5012:21 (network-element:NE1/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5013:2202 (network-element:NE1/device:main/service:sftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5014:23 (network-element:NE1/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5001-:6022,hostfwd=tcp::5002-:22,hostfwd=tcp::5003-:830,hostfwd=tcp::5004-:6030,hostfwd=udp::5005-:161,hostfwd=tcp::5006-:80,hostfwd=tcp::5007-:443,hostfwd=tcp::5008-:5555,hostfwd=tcp::5009-:10000,hostfwd=tcp::5010-:32767,hostfwd=tcp::5011-:50000,hostfwd=tcp::5012-:21,hostfwd=tcp::5013-:2202,hostfwd=tcp::5014-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:06' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0006,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:06\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:05' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0005,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:05\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006'"}
{"timestamp_utc": "2024-07-31T08:08:37.945Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:03' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0003,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:03\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:04' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-0004,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:04\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE1/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0002' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:02' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0002,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:02\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:main/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:07' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0007,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:07\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:main/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5000 for network-element:NE1/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0006\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0005\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\","}
{"timestamp_utc": "2024-07-31T08:08:37.946Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"link\", <NL> \"set\", <NL> \"tap-0003\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0004\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0002\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0007\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0006\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0006\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0005\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0005\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0003\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0003\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0004\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0004\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0002\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0002\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\","}
{"timestamp_utc": "2024-07-31T08:08:37.947Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"dev\", <NL> \"tap-0002\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0007\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0007\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE1/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE1/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5001-:6022,hostfwd=tcp::5002-:22,hostfwd=tcp::5003-:830,hostfwd=tcp::5004-:6030,hostfwd=udp::5005-:161,hostfwd=tcp::5006-:80,hostfwd=tcp::5007-:443,hostfwd=tcp::5008-:5555,hostfwd=tcp::5009-:10000,hostfwd=tcp::5010-:32767,hostfwd=tcp::5011-:50000,hostfwd=tcp::5012-:21,hostfwd=tcp::5013-:2202,hostfwd=tcp::5014-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0006,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:06\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0005,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:05\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0003,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:03\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-0004,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:04\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0002,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:02\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0007,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:07\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5000, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE1/device:trib1\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE1/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE1/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\""}
{"timestamp_utc": "2024-07-31T08:08:37.948Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "}, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5015:None for service \"network-element:NE1/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5016:6022 for service \"network-element:NE1/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:08' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5015:None (network-element:NE1/device:trib1/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5016:6022 (network-element:NE1/device:trib1/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5016-:6022\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE1/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0002' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:09' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0009,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:09\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-000a,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:0a\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE1/device:trib1/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-000b,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:0b\""}
{"timestamp_utc": "2024-07-31T08:08:38.212Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE1/device:trib1/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5015 for network-element:NE1/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:38.213Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0009\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE1/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0009\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"master\", <NL> \"br-0002\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0009\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE1/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000b\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE1/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE1/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE1/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5016-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0009,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:09\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-000a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:0a\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-000b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:0b\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5015, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:38.214Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE2/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE2/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"m_megs\": \"4096\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5017:None for service \"network-element:NE2/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5018:6022 for service \"network-element:NE2/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5019:22 for service \"network-element:NE2/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5020:830 for service \"network-element:NE2/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5021:6030 for service \"network-element:NE2/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5022:161/udp for service \"network-element:NE2/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5023:80 for service \"network-element:NE2/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5024:443 for service \"network-element:NE2/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5025:5555 for service \"network-element:NE2/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5026:10000 for service \"network-element:NE2/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5027:32767 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5028:50000 for service \"network-element:NE2/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5029:21 for service \"network-element:NE2/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5030:2202 for service \"network-element:NE2/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5031:23 for service \"network-element:NE2/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5017:None (network-element:NE2/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5018:6022 (network-element:NE2/device:main/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5019:22 (network-element:NE2/device:main/service:cli) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5020:830 (network-element:NE2/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5021:6030 (network-element:NE2/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5022:161 (network-element:NE2/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5023:80 (network-element:NE2/device:main/service:webui)"}
{"timestamp_utc": "2024-07-31T08:08:38.215Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5024:443 (network-element:NE2/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5025:5555 (network-element:NE2/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5026:10000 (network-element:NE2/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5027:32767 (network-element:NE2/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5028:50000 (network-element:NE2/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5029:21 (network-element:NE2/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5030:2202 (network-element:NE2/device:main/service:sftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5031:23 (network-element:NE2/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5018-:6022,hostfwd=tcp::5019-:22,hostfwd=tcp::5020-:830,hostfwd=tcp::5021-:6030,hostfwd=udp::5022-:161,hostfwd=tcp::5023-:80,hostfwd=tcp::5024-:443,hostfwd=tcp::5025-:5555,hostfwd=tcp::5026-:10000,hostfwd=tcp::5027-:32767,hostfwd=tcp::5028-:50000,hostfwd=tcp::5029-:21,hostfwd=tcp::5030-:2202,hostfwd=tcp::5031-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:11' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0011,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:11\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:10' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0010,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:10\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0e' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-000e,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:0e\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0f' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-000f,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:0f\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE2/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0003' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:0d' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-000d,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:0d\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:main/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:12' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0012,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:12\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-1\""}
{"timestamp_utc": "2024-07-31T08:08:38.216Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:main/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5017 for network-element:NE2/device:main/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0011\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0010\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000e\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000f\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000d\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0012\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0011\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0011\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\","}
{"timestamp_utc": "2024-07-31T08:08:38.217Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0010\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0010\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000e\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000e\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000f\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000f\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-000d\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-000d\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0012\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0012\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE2/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE2/device.main/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5018-:6022,hostfwd=tcp::5019-:22,hostfwd=tcp::5020-:830,hostfwd=tcp::5021-:6030,hostfwd=udp::5022-:161,hostfwd=tcp::5023-:80,hostfwd=tcp::5024-:443,hostfwd=tcp::5025-:5555,hostfwd=tcp::5026-:10000,hostfwd=tcp::5027-:32767,hostfwd=tcp::5028-:50000,hostfwd=tcp::5029-:21,hostfwd=tcp::5030-:2202,hostfwd=tcp::5031-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0011,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:11\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0010,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:10\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-000e,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:0e\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-000f,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:0f\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-000d,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:0d\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0012,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:12\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5017, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE2/device:trib1\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE2/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE2/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:38.218Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"2\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"2\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5032:None for service \"network-element:NE2/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5033:6022 for service \"network-element:NE2/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:13' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5032:None (network-element:NE2/device:trib1/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5033:6022 (network-element:NE2/device:trib1/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5033-:6022\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE2/network:ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0003' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:14' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0014,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:14\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:15' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0015,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:15\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE2/device:trib1/interface:osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2'"}
{"timestamp_utc": "2024-07-31T08:08:38.219Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:16' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0016,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:16\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-1\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE2/device:trib1/serial-interface:serial-2\" <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:37 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   found ports None:5032 for network-element:NE2/device:trib1/service:console <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0014\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0015\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0016\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE2/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0014\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"master\", <NL> \"br-0003\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0014\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0015\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0015\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE2/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0016\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0016\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE2/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\","}
{"timestamp_utc": "2024-07-31T08:08:38.220Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"network-element.NE2/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE2/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5033-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0014,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:14\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0015,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:15\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0016,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:16\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5032, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE3/device:main <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE3/device:main\" <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> } <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:37 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5034:None for service \"network-element:NE3/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5035:6022 for service \"network-element:NE3/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5036:22 for service \"network-element:NE3/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5037:830 for service \"network-element:NE3/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5038:6030 for service \"network-element:NE3/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5039:161/udp for service \"network-element:NE3/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5040:80 for service \"network-element:NE3/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5041:443 for service \"network-element:NE3/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5042:5555 for service \"network-element:NE3/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5043:10000 for service \"network-element:NE3/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5044:32767 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\""}
{"timestamp_utc": "2024-07-31T08:08:38.221Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5045:50000 for service \"network-element:NE3/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5046:21 for service \"network-element:NE3/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5047:2202 for service \"network-element:NE3/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: get_device_service_ports:   found port chain None:5048:23 for service \"network-element:NE3/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:17' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5034:None (network-element:NE3/device:main/service:console) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5035:6022 (network-element:NE3/device:main/service:debug-ssh) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5036:22 (network-element:NE3/device:main/service:cli) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5037:830 (network-element:NE3/device:main/service:netconf) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5038:6030 (network-element:NE3/device:main/service:gnmi) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5039:161 (network-element:NE3/device:main/service:snmp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5040:80 (network-element:NE3/device:main/service:webui) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5041:443 (network-element:NE3/device:main/service:https) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5042:5555 (network-element:NE3/device:main/service:zmq) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5043:10000 (network-element:NE3/device:main/service:gdb) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5044:32767 (network-element:NE3/device:main/service:gdb-ops-additional) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5045:50000 (network-element:NE3/device:main/service:ospl) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5046:21 (network-element:NE3/device:main/service:ftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5047:2202 (network-element:NE3/device:main/service:sftp) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5048:23 (network-element:NE3/device:main/service:telnet) <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5035-:6022,hostfwd=tcp::5036-:22,hostfwd=tcp::5037-:830,hostfwd=tcp::5038-:6030,hostfwd=udp::5039-:161,hostfwd=tcp::5040-:80,hostfwd=tcp::5041-:443,hostfwd=tcp::5042-:5555,hostfwd=tcp::5043-:10000,hostfwd=tcp::5044-:32767,hostfwd=tcp::5045-:50000,hostfwd=tcp::5046-:21,hostfwd=tcp::5047-:2202,hostfwd=tcp::5048-:23\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1c' <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-001c,script=no,downscript=no\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:1c\" <NL> # 03:08:37 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1b' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-001b,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:1b\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:19' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0019,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:19\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1a' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-001a,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:1a\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE3/network:ilan'"}
{"timestamp_utc": "2024-07-31T08:08:38.222Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0004' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:18' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0018,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:18\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:main/interface:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1d' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-001d,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:1d\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-1\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:main/serial-interface:serial-2\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   found ports None:5034 for network-element:NE3/device:main/service:console <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001c\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0019\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0018\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001d\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\""}
{"timestamp_utc": "2024-07-31T08:08:38.223Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001c\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001c\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001b\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0019\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0019\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0018\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0018\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001d\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001d\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE3/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE3/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5035-:6022,hostfwd=tcp::5036-:22,hostfwd=tcp::5037-:830,hostfwd=tcp::5038-:6030,hostfwd=udp::5039-:161,hostfwd=tcp::5040-:80,hostfwd=tcp::5041-:443,hostfwd=tcp::5042-:5555,hostfwd=tcp::5043-:10000,hostfwd=tcp::5044-:32767,hostfwd=tcp::5045-:50000,hostfwd=tcp::5046-:21,hostfwd=tcp::5047-:2202,hostfwd=tcp::5048-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-001c,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:1c\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-001b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:1b\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0019,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:19\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-001a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:1a\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0018,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:18\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-001d,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:1d\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5034, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE3/device:trib1\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE3/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE3/device.trib1/data/qemu\" <NL> }, <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:38.224Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5049:None for service \"network-element:NE3/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5050:6022 for service \"network-element:NE3/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1e' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5049:None (network-element:NE3/device:trib1/service:console) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5050:6022 (network-element:NE3/device:trib1/service:debug-ssh) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5050-:6022\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0004' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:1f' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-001f,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:1f\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:20' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0020,script=no,downscript=no\""}
{"timestamp_utc": "2024-07-31T08:08:38.225Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:20\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE3/device:trib1/interface:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:21' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0021,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:21\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-1\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE3/device:trib1/serial-interface:serial-2\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   found ports None:5049 for network-element:NE3/device:trib1/service:console <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001f\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0020\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0021\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE3/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-001f\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"master\", <NL> \"br-0004\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-001f\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0020\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0020\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE3/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0021\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0021\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE3/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\","}
{"timestamp_utc": "2024-07-31T08:08:38.226Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE3/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE3/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5050-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-001f,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:1f\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0020,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:20\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0021,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:21\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5049, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE4/device:main <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE4/device:main\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.main/data/qemu/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.main/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"{#cpu_model#}\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"MAIN_01_02\", <NL> \"cpu_model\": \"qemu64\", <NL> \"m_megs\": \"4096\", <NL> \"redundancyMode\": \"WORK\", <NL> \"serialNum\": \"12345\", <NL> \"shelfNumber\": \"200\", <NL> \"shelfRole\": \"MAIN\", <NL> \"simulatedRole\": \"MAIN\", <NL> \"simulatedShelf\": \"200\", <NL> \"smp\": \"1\", <NL> \"unitCode\": \"0xc200\", <NL> \"unitName\": \"BDC2-C200\" <NL> } <NL> } <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5051:None for service \"network-element:NE4/device:main/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5052:6022 for service \"network-element:NE4/device:main/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5053:22 for service \"network-element:NE4/device:main/service:cli\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5054:830 for service \"network-element:NE4/device:main/service:netconf\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5055:6030 for service \"network-element:NE4/device:main/service:gnmi\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5056:161/udp for service \"network-element:NE4/device:main/service:snmp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5057:80 for service \"network-element:NE4/device:main/service:webui\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5058:443 for service \"network-element:NE4/device:main/service:https\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5059:5555 for service \"network-element:NE4/device:main/service:zmq\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5060:10000 for service \"network-element:NE4/device:main/service:gdb\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5061:32767 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5062:50000 for service \"network-element:NE4/device:main/service:ospl\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5063:21 for service \"network-element:NE4/device:main/service:ftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5064:2202 for service \"network-element:NE4/device:main/service:sftp\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\""}
{"timestamp_utc": "2024-07-31T08:08:38.227Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5065:23 for service \"network-element:NE4/device:main/service:telnet\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:22' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5051:None (network-element:NE4/device:main/service:console) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5052:6022 (network-element:NE4/device:main/service:debug-ssh) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5053:22 (network-element:NE4/device:main/service:cli) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5054:830 (network-element:NE4/device:main/service:netconf) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5055:6030 (network-element:NE4/device:main/service:gnmi) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward udp:5056:161 (network-element:NE4/device:main/service:snmp) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5057:80 (network-element:NE4/device:main/service:webui) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5058:443 (network-element:NE4/device:main/service:https) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5059:5555 (network-element:NE4/device:main/service:zmq) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5060:10000 (network-element:NE4/device:main/service:gdb) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5061:32767 (network-element:NE4/device:main/service:gdb-ops-additional) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5062:50000 (network-element:NE4/device:main/service:ospl) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5063:21 (network-element:NE4/device:main/service:ftp) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5064:2202 (network-element:NE4/device:main/service:sftp) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5065:23 (network-element:NE4/device:main/service:telnet) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5052-:6022,hostfwd=tcp::5053-:22,hostfwd=tcp::5054-:830,hostfwd=tcp::5055-:6030,hostfwd=udp::5056-:161,hostfwd=tcp::5057-:80,hostfwd=tcp::5058-:443,hostfwd=tcp::5059-:5555,hostfwd=tcp::5060-:10000,hostfwd=tcp::5061-:32767,hostfwd=tcp::5062-:50000,hostfwd=tcp::5063-:21,hostfwd=tcp::5064-:2202,hostfwd=tcp::5065-:23\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0009' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:27' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-0027,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:27\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0008' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:26' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lmp,ifname=tap-0026,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lmp,mac=52:54:01:00:00:26\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.lmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0006' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:24' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn1,ifname=tap-0024,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn1,mac=52:54:01:00:00:24\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.lcn1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0007' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:25' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=lcn2,ifname=tap-0025,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=lcn2,mac=52:54:01:00:00:25\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.lcn2/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:08:38.228Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0005' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:23' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-0023,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:23\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:main/interface:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000b' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:28' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-0028,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:28\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-1\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:main/serial-interface:serial-2\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   found ports None:5051 for network-element:NE4/device:main/service:console <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lmp\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"lcn2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0027\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0026\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0024\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0025\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0023\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0028\", <NL> \"up\" <NL> ],"}
{"timestamp_utc": "2024-07-31T08:08:38.229Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "[ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.main/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0027\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"master\", <NL> \"br-0009\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0027\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lmp\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lmp\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0026\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"master\", <NL> \"br-0008\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0026\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn1\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0024\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"master\", <NL> \"br-0006\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0024\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:lcn2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:lcn2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0025\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"master\", <NL> \"br-0007\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0025\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0023\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0023\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:main/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-0028\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"master\", <NL> \"br-000b\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-0028\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.main/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE4/device.main/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE4/device.main/data/qemu/cdrom/image/fss-aggr-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"1\", <NL> \"-m\", <NL> \"4096\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5052-:6022,hostfwd=tcp::5053-:22,hostfwd=tcp::5054-:830,hostfwd=tcp::5055-:6030,hostfwd=udp::5056-:161,hostfwd=tcp::5057-:80,hostfwd=tcp::5058-:443,hostfwd=tcp::5059-:5555,hostfwd=tcp::5060-:10000,hostfwd=tcp::5061-:32767,hostfwd=tcp::5062-:50000,hostfwd=tcp::5063-:21,hostfwd=tcp::5064-:2202,hostfwd=tcp::5065-:23\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-0027,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:27\", <NL> \"-netdev\", <NL> \"tap,id=lmp,ifname=tap-0026,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lmp,mac=52:54:01:00:00:26\", <NL> \"-netdev\", <NL> \"tap,id=lcn1,ifname=tap-0024,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn1,mac=52:54:01:00:00:24\", <NL> \"-netdev\", <NL> \"tap,id=lcn2,ifname=tap-0025,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=lcn2,mac=52:54:01:00:00:25\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-0023,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:23\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-0028,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:28\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5051, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_devices:   device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: - internal device_context_absolute_id \"network-element:NE4/device:trib1\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   default_root_disk_interface_type 'virtio' <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_config_dict: { <NL> \"kernel_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"optimize_unzip_list\": [ <NL> {"}
{"timestamp_utc": "2024-07-31T08:08:38.230Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/bzImage-qemux86-64.bin\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"image_zip_path\": \"network-element.NE4/device.trib1/data/qemu/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip\", <NL> \"operation\": \"unzip\", <NL> \"unzip_fname\": \"cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"unzip_subdir\": \"network-element.NE4/device.trib1/data/qemu\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"mode\": \"a+w\", <NL> \"operation\": \"chmod\" <NL> }, <NL> { <NL> \"file_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.image-info.json\", <NL> \"operation\": \"relocate\" <NL> } <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_options\": [ <NL> { <NL> \"option_name\": \"-cpu\", <NL> \"option_value\": \"qemu64\" <NL> }, <NL> { <NL> \"option_name\": \"-nographic\" <NL> }, <NL> { <NL> \"option_name\": \"-enable-kvm\" <NL> }, <NL> { <NL> \"option_name\": \"-smp\", <NL> \"option_value\": \"{#smp#}\" <NL> }, <NL> { <NL> \"option_name\": \"-m\", <NL> \"option_value\": \"{#m_megs#}\" <NL> }, <NL> { <NL> \"option_name\": \"--append\", <NL> \"option_value\": [ <NL> { <NL> \"option_name\": \"root\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"/dev/hda\" <NL> }, <NL> { <NL> \"option_name\": \"rw\" <NL> }, <NL> { <NL> \"option_name\": \"ip\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"dhcp\" <NL> }, <NL> { <NL> \"option_name\": \"console\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"ttyS0\" <NL> }, <NL> { <NL> \"option_name\": \"FSS_CARD_ID\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#FSS_CARD_ID#}\" <NL> }, <NL> { <NL> \"option_name\": \"OSPL_URI\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"file:///etc/config/ospl.xml\" <NL> }, <NL> { <NL> \"option_name\": \"unitCode\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitCode#}\" <NL> }, <NL> { <NL> \"option_name\": \"unitName\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#unitName#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"shelfNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#shelfNumber#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedRole\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedRole#}\" <NL> }, <NL> { <NL> \"option_name\": \"simulatedShelf\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#simulatedShelf#}\" <NL> }, <NL> { <NL> \"option_name\": \"serialNum\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#serialNum#}\" <NL> }, <NL> { <NL> \"option_name\": \"slotNumber\", <NL> \"option_separator\": \"=\", <NL> \"option_value\": \"{#slotNumber#}\" <NL> } <NL> ] <NL> } <NL> ], <NL> \"rootfs_path\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"variable_definitions\": { <NL> \"FSS_CARD_ID\": \"TRIB_01_02\", <NL> \"m_megs\": \"1024\", <NL> \"serialNum\": \"sim_\", <NL> \"shelfNumber\": \"1\", <NL> \"shelfRole\": \"TRIB\", <NL> \"simulatedRole\": \"TRIB\", <NL> \"simulatedShelf\": \"1\", <NL> \"slotNumber\": \"0\", <NL> \"smp\": \"4\", <NL> \"unitCode\": \"0xf9fc\", <NL> \"unitName\": \"L1-OTSG2\" <NL> } <NL> } <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: option_control: {} <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list: - fix_root_device_type_flag True <NL> # 03:08:38 ntp-topology INFO: get_qemu_command_line_options_list:   replaced '/dev/hda' with '/dev/vda' at index ['--append', 'root'] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_disk_options_list: [ <NL> \"-drive\", <NL> \"file={#disk_fname#},if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   qemu_rootfs_options_list: [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5066:None for service \"network-element:NE4/device:trib1/service:console\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: get_device_service_ports:   found port chain None:5067:6022 for service \"network-element:NE4/device:trib1/service:debug-ssh\" on network \"definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'debug' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index 0 <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name 'eth0' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:29' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag True <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       skip: port forward tcp:5066:None (network-element:NE4/device:trib1/service:console) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:       take: port forward tcp:5067:6022 (network-element:NE4/device:trib1/service:debug-ssh) <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"user,id=debug,hostfwd=tcp::5067-:6022\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=debug\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.debug/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-0005' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2a' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=ilan,ifname=tap-002a,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=ilan,mac=52:54:01:00:00:2a\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.ilan/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc1' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc1-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000a' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2b' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False"}
{"timestamp_utc": "2024-07-31T08:08:38.231Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc1,ifname=tap-002b,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc1,mac=52:54:01:00:00:2b\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.osc1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps: saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   - device_interface_context_absolute_id 'network-element:NE4/device:trib1/interface:osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_instance_name 'osc2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_resolved_network_context_absolute_id 'network:osc2-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     container_network_instance_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     external_network_index None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     interface_name None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_bridge_name 'br-000c' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     linux_tap_mtu None <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     mac_address '52:54:01:00:00:2c' <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     default_docker_bridge_network_flag False <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -netdev \"tap,id=osc2,ifname=tap-002c,script=no,downscript=no\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:     -device \"e1000,netdev=osc2,mac=52:54:01:00:00:2c\" <NL> # 03:08:38 ntp-topology INFO: prepare_device_taps:   saved interface amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/interface.osc2/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-1\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"dev_string\": \"stdio\", <NL> \"device\": \"mon\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: device_interface_context_absolute_id \"network-element:NE4/device:trib1/serial-interface:serial-2\" <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_field_value { <NL> \"device\": \"null\" <NL> } <NL> # 03:08:38 ntp-topology INFO: get_serial_interface_list: qemu_serial_interface_list [ <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\" <NL> ] <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   found ports None:5066 for network-element:NE4/device:trib1/service:console <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"debug\", qemu_netdev_type \"user\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"ilan\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc1\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_qemu:   qemu_netdev_name \"osc2\", qemu_netdev_type \"tap\" <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu: qemu_info_dict { <NL> \"create_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002a\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002b\", <NL> \"up\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"add\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"mode\", <NL> \"tap\", <NL> \"group\", <NL> \"jenkins\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002c\", <NL> \"up\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> ], <NL> [ <NL> \"rm\", <NL> \"-f\", <NL> \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\" <NL> ] <NL> ], <NL> \"delete_command_list\": [ <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:ilan\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network-element:NE4/network:ilan\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002a\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"master\", <NL> \"br-0005\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002a\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc1\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc1-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002b\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"master\", <NL> \"br-000a\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002b\", <NL> \"mode\", <NL> \"tap\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: device_interface_context_absolute_id network-element:NE4/device:trib1/interface:osc2\" <NL> ], <NL> [ <NL> \"echo\", <NL> \"prepare_qemu: interface_resolved_network_context_absolute_id network:osc2-2\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"set\", <NL> \"tap-002c\", <NL> \"down\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"link\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"master\", <NL> \"br-000c\" <NL> ], <NL> [ <NL> \"sudo\", <NL> \"ip\", <NL> \"tuntap\", <NL> \"del\", <NL> \"dev\", <NL> \"tap-002c\", <NL> \"mode\", <NL> \"tap\" <NL> ] <NL> ], <NL> \"qemu_binary\": \"qemu-system-x86_64\", <NL> \"qemu_command_line_options_list\": [ <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\","}
{"timestamp_utc": "2024-07-31T08:08:38.232Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\" <NL> ], <NL> \"qemu_instance_fpath\": \"network-element.NE4/device.trib1/data/qemu\", <NL> \"qemu_kernel_fname\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"qemu_rootfs_fname\": \"network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3\", <NL> \"qemu_rootfs_options_list\": [ <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\" <NL> ], <NL> \"socket_daemon_command_list\": [ <NL> \"qemu-system-x86_64\", <NL> \"-kernel\", <NL> \"network-element.NE4/device.trib1/data/qemu/cdrom/image/bzImage-qemux86-64.bin\", <NL> \"-drive\", <NL> \"file=network-element.NE4/device.trib1/data/qemu/cdrom/image/fss-image-validation-T-qemux86-64.ext3,if=virtio,format=raw\", <NL> \"-cpu\", <NL> \"qemu64\", <NL> \"-nographic\", <NL> \"-enable-kvm\", <NL> \"-smp\", <NL> \"4\", <NL> \"-m\", <NL> \"1024\", <NL> \"--append\", <NL> \"root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0\", <NL> \"-serial\", <NL> \"mon:stdio\", <NL> \"-serial\", <NL> \"null\", <NL> \"-netdev\", <NL> \"user,id=debug,hostfwd=tcp::5067-:6022\", <NL> \"-device\", <NL> \"e1000,netdev=debug\", <NL> \"-netdev\", <NL> \"tap,id=ilan,ifname=tap-002a,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=ilan,mac=52:54:01:00:00:2a\", <NL> \"-netdev\", <NL> \"tap,id=osc1,ifname=tap-002b,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc1,mac=52:54:01:00:00:2b\", <NL> \"-netdev\", <NL> \"tap,id=osc2,ifname=tap-002c,script=no,downscript=no\", <NL> \"-device\", <NL> \"e1000,netdev=osc2,mac=52:54:01:00:00:2c\" <NL> ], <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_control_port\": null, <NL> \"socket_daemon_foreground_flag\": false, <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_port\": 5066, <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> # 03:08:38 ntp-topology INFO: prepare_for_qemu:   saved device amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: prepare_devices:   saved device_group amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:38 ntp-topology INFO: main: completed action 'prepare' <NL> # 03:08:38 ntp-topology INFO: done <NL> # 03:08:38 ntp-topology-run.py INFO: exec_cmd: ['ntp-show-current-topology', '-v', '-v', '--sort-instances', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json']"}
{"timestamp_utc": "2024-07-31T08:08:38.796Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 0) None      : <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:docker-container <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:docker-network <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:instance-configure <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:instance-defaults <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:kubernetes-cluster <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:qemu-configuration <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: definitions:topology <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:gnmi"}
{"timestamp_utc": "2024-07-31T08:08:38.797Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE1-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE2-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-sftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE3-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-cli <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ftp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-https <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-netconf <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-ospl <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-sftp"}
{"timestamp_utc": "2024-07-31T08:08:38.798Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-snmp <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-telnet <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-webui <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-main-zmq <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-console <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/service:NE4-trib1-debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: +            - refering: network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/interface:osc2"}
{"timestamp_utc": "2024-07-31T08:08:38.799Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE1/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE1/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE1/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE1/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:ilan"}
{"timestamp_utc": "2024-07-31T08:08:38.800Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE2/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE2/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE2/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE3 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:snmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:telnet/network:bridge"}
{"timestamp_utc": "2024-07-31T08:08:38.801Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE3/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE3/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE3/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE3/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network-element:NE4 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/device:main <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn1/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn2/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lmp/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc1/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc2/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:cli <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:cli/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:cli/port-number:internal-cli-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:ftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:ftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:ftp/port-number:internal-ftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gdb <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gdb/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gdb/port-number:internal-gdb-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gdb-ops-additional/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gdb-ops-additional/port-number:internal-gdb-ops-additional-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:gnmi <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:gnmi/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:gnmi/port-number:internal-gnmi-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:https <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:https/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:https/port-number:internal-https-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:netconf <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:netconf/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:netconf/port-number:internal-netconf-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:ospl <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:ospl/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:ospl/port-number:internal-ospl-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:sftp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:sftp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:sftp/port-number:internal-sftp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:snmp"}
{"timestamp_utc": "2024-07-31T08:08:38.802Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:snmp/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:snmp/port-number:internal-snmp-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:telnet <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:telnet/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:telnet/port-number:internal-telnet-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:webui <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:webui/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:webui/port-number:internal-webui-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:main/service:zmq <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:main/service:zmq/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:main/service:zmq/port-number:internal-zmq-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/device:trib1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:debug <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/interface:debug/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:ilan/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc1/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/interface:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc2/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: network-element:NE4/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/serial-interface:serial-1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/serial-interface:serial-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/service:console <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/service:console/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-new: network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-ref: network-element:NE4/device:trib1/service:debug-ssh/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: +              - refering: definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         create-new: network-element:NE4/device:trib1/service:debug-ssh/port-number:internal-ssh-port <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     reference : network-element:NE4/network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: +          - refering: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ----- ----- ----- ----- ----- <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lcn2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:lmp <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc1-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 1)   create-new: network:osc2-2 <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE1/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE2/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE3/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 2)     create-new: network-element:NE4/network:ilan <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan : 'network-element:NE1/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan : 'network-element:NE2/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan : 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan : 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1     : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2     : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp      : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1     : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2     : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 3)       create-ref: definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:ilan/network:ilan                      : 'network-element:NE1/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE1/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE1/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:ilan/network:ilan                      : 'network-element:NE2/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE2/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE2/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:ilan/network:ilan                      : 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc1/network:osc1                      : 'network:osc1'"}
{"timestamp_utc": "2024-07-31T08:08:38.803Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE3/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE3/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:ilan/network:ilan                      : 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn1/network:lcn1                      : 'network:lcn1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lcn2/network:lcn2                      : 'network:lcn2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:lmp/network:lmp                        : 'network:lmp' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc1/network:osc1                      : 'network:osc1' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:main/interface:osc2/network:osc2                      : 'network:osc2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:ilan/network:ilan                     : 'network-element:NE4/network:ilan' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc1/network:osc1-2                   : 'network:osc1-2' <NL> # 03:08:38 ntp-show-current-topology INFO: + ( 4)         reference : network-element:NE4/device:trib1/interface:osc2/network:osc2-2                   : 'network:osc2-2' <NL> # 03:08:38 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--action', 'create']"}
{"timestamp_utc": "2024-07-31T08:08:39.059Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:38 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace' <NL> # 03:08:38 ntp-topology INFO: main: starting action 'create'"}
{"timestamp_utc": "2024-07-31T08:08:40.004Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:39 ntp-topology INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01'] <NL> # 03:08:39 ntp-topology INFO: exec_cmd: ['chmod', 'a+rwx', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01'] <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: parent_hostname rtxoialp79 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: parent_hostip 167.254.217.189 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_context_names topology-group-device-group-type-qemu-01 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_context_absolute_id definitions:topology/device_group:group-device-group-type-qemu-01 <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: device_group_type device-group-type-qemu <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:bridge', network_type 'external', default_docker_bridge_network_flag True <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE1-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE2-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE3-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:NE4-ilan', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn1', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lcn2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:lmp', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc1-2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   network_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/network:osc2-2', network_type 'internal', default_docker_bridge_network_flag False <NL> # 03:08:39 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   container_network_name_list [] <NL> # 03:08:39 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'pull', 'harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest']"}
{"timestamp_utc": "2024-07-31T08:08:40.260Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-topology INFO: docker_command: stdout: Trying to pull repository harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build ... <NL> # 03:08:40 ntp-topology INFO: docker_command: stdout: latest: Pulling from harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build <NL> # 03:08:40 ntp-topology INFO: docker_command: stdout: Digest: sha256:f649c9d54a8d0322e20c4524897fb6d43164df14359f965f27d7fedcf395eb95 <NL> # 03:08:40 ntp-topology INFO: docker_command: stdout: Status: Image is up to date for harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest"}
{"timestamp_utc": "2024-07-31T08:08:40.516Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5000 for service \"network-element:NE1/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5001 for service \"network-element:NE1/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5002 for service \"network-element:NE1/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5003 for service \"network-element:NE1/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5004 for service \"network-element:NE1/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5005/udp for service \"network-element:NE1/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5006 for service \"network-element:NE1/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5007 for service \"network-element:NE1/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5008 for service \"network-element:NE1/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5009 for service \"network-element:NE1/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5010 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5011 for service \"network-element:NE1/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5012 for service \"network-element:NE1/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5013 for service \"network-element:NE1/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5014 for service \"network-element:NE1/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5015 for service \"network-element:NE1/device:trib1/service:console\""}
{"timestamp_utc": "2024-07-31T08:08:40.517Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5016 for service \"network-element:NE1/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5017 for service \"network-element:NE2/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5018 for service \"network-element:NE2/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5019 for service \"network-element:NE2/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5020 for service \"network-element:NE2/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5021 for service \"network-element:NE2/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5022/udp for service \"network-element:NE2/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5023 for service \"network-element:NE2/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5024 for service \"network-element:NE2/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5025 for service \"network-element:NE2/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5026 for service \"network-element:NE2/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5027 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5028 for service \"network-element:NE2/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5029 for service \"network-element:NE2/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5030 for service \"network-element:NE2/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5031 for service \"network-element:NE2/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5032 for service \"network-element:NE2/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5033 for service \"network-element:NE2/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5034 for service \"network-element:NE3/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5035 for service \"network-element:NE3/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5036 for service \"network-element:NE3/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5037 for service \"network-element:NE3/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5038 for service \"network-element:NE3/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5039/udp for service \"network-element:NE3/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5040 for service \"network-element:NE3/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5041 for service \"network-element:NE3/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5042 for service \"network-element:NE3/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5043 for service \"network-element:NE3/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5044 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5045 for service \"network-element:NE3/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5046 for service \"network-element:NE3/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5047 for service \"network-element:NE3/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5048 for service \"network-element:NE3/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5049 for service \"network-element:NE3/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5050 for service \"network-element:NE3/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5051 for service \"network-element:NE4/device:main/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5052 for service \"network-element:NE4/device:main/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5053 for service \"network-element:NE4/device:main/service:cli\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5054 for service \"network-element:NE4/device:main/service:netconf\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5055 for service \"network-element:NE4/device:main/service:gnmi\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5056/udp for service \"network-element:NE4/device:main/service:snmp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5057 for service \"network-element:NE4/device:main/service:webui\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5058 for service \"network-element:NE4/device:main/service:https\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5059 for service \"network-element:NE4/device:main/service:zmq\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5060 for service \"network-element:NE4/device:main/service:gdb\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5061 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5062 for service \"network-element:NE4/device:main/service:ospl\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5063 for service \"network-element:NE4/device:main/service:ftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5064 for service \"network-element:NE4/device:main/service:sftp\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5065 for service \"network-element:NE4/device:main/service:telnet\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5066 for service \"network-element:NE4/device:trib1/service:console\" <NL> # 03:08:40 ntp-topology INFO: create_single_docker_container: expose port None:5067 for service \"network-element:NE4/device:trib1/service:debug-ssh\" <NL> # 03:08:40 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'create', '--privileged', '--user', 'root', '--device', '/dev/kvm:/dev/kvm', '--device', '/dev/net/tun:/dev/net/tun', '--device', '/dev/vhost-net:/dev/vhost-net', '--volume', '/proj/artifacts:/proj/artifacts:ro,shared', '--volume', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64', '--volume', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology:ro', '--publish', ':5000', '--publish', ':5001', '--publish', ':5002', '--publish', ':5003', '--publish', ':5004', '--publish', ':5005/udp', '--publish', ':5006', '--publish', ':5007', '--publish', ':5008', '--publish', ':5009', '--publish', ':5010', '--publish', ':5011', '--publish', ':5012', '--publish', ':5013', '--publish', ':5014', '--publish', ':5015', '--publish', ':5016', '--publish', ':5017', '--publish', ':5018', '--publish', ':5019', '--publish', ':5020', '--publish', ':5021', '--publish', ':5022/udp', '--publish', ':5023', '--publish', ':5024', '--publish', ':5025', '--publish', ':5026', '--publish', ':5027', '--publish', ':5028', '--publish', ':5029', '--publish', ':5030', '--publish', ':5031', '--publish', ':5032', '--publish', ':5033', '--publish', ':5034', '--publish', ':5035', '--publish', ':5036', '--publish', ':5037', '--publish', ':5038', '--publish', ':5039/udp', '--publish', ':5040', '--publish', ':5041', '--publish', ':5042', '--publish', ':5043', '--publish', ':5044', '--publish', ':5045', '--publish', ':5046', '--publish', ':5047', '--publish', ':5048', '--publish', ':5049', '--publish', ':5050', '--publish', ':5051', '--publish', ':5052', '--publish', ':5053', '--publish', ':5054', '--publish', ':5055', '--publish', ':5056/udp', '--publish', ':5057', '--publish', ':5058', '--publish', ':5059', '--publish', ':5060', '--publish', ':5061', '--publish', ':5062', '--publish', ':5063', '--publish', ':5064', '--publish', ':5065', '--publish', ':5066', '--publish', ':5067', 'harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest']"}
{"timestamp_utc": "2024-07-31T08:08:43.029Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:42 ntp-topology INFO: docker_command: stdout: 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05 <NL> # 03:08:42 ntp-topology INFO: create_single_docker_container: create: \"085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05\" <NL> # 03:08:42 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'start', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05']"}
{"timestamp_utc": "2024-07-31T08:08:52.987Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_command: stdout: 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: running ['sudo', '/bin/docker', 'inspect', '--type', 'container', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05']"}
{"timestamp_utc": "2024-07-31T08:08:52.988Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout: [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Id\": \"085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Created\": \"2024-07-31T08:08:40.453118926Z\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Path\": \"/usr/bin/tini\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Args\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"--\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"/usr/sbin/sshd\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"-D\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"State\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Status\": \"running\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Running\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Paused\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Restarting\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OOMKilled\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Dead\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Pid\": 25058, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ExitCode\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Error\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"StartedAt\": \"2024-07-31T08:08:51.358218257Z\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"FinishedAt\": \"0001-01-01T00:00:00Z\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Image\": \"sha256:e6ab72684bf033e695847013b10678ea3fd26f1eb52d6ad59f865602619223ab\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"ResolvConfPath\": \"/var/lib/docker/containers/085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05/resolv.conf\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"HostnamePath\": \"/var/lib/docker/containers/085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05/hostname\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"HostsPath\": \"/var/lib/docker/containers/085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05/hosts\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"LogPath\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Name\": \"/hopeful_mirzakhani\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"RestartCount\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Driver\": \"devicemapper\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"MountLabel\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"ProcessLabel\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"AppArmorProfile\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"ExecIDs\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"HostConfig\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Binds\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/proj/artifacts:/proj/artifacts:ro,shared\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology:/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology:ro\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ContainerIDFile\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"LogConfig\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"journald\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Config\": {} <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"NetworkMode\": \"default\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PortBindings\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ],"}
{"timestamp_utc": "2024-07-31T08:08:52.989Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     {"}
{"timestamp_utc": "2024-07-31T08:08:52.990Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\","}
{"timestamp_utc": "2024-07-31T08:08:52.991Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\","}
{"timestamp_utc": "2024-07-31T08:08:52.992Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ] <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"RestartPolicy\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Name\": \"no\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"MaximumRetryCount\": 0 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AutoRemove\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"VolumeDriver\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"VolumesFrom\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CapAdd\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CapDrop\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Dns\": [], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"DnsOptions\": [], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"DnsSearch\": [], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ExtraHosts\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"GroupAdd\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IpcMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Cgroup\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Links\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OomScoreAdj\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PidMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Privileged\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PublishAllPorts\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ReadonlyRootfs\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SecurityOpt\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"label=disable\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"UTSMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"UsernsMode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ShmSize\": 67108864, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Runtime\": \"docker-runc\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ConsoleSize\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 0 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Isolation\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuShares\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Memory\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"NanoCpus\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CgroupParent\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioWeight\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioWeightDevice\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceReadBps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceWriteBps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceReadIOps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"BlkioDeviceWriteIOps\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuPeriod\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuQuota\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuRealtimePeriod\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuRealtimeRuntime\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpusetCpus\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpusetMems\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Devices\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/kvm\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/kvm\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/net/tun\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/net/tun\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathOnHost\": \"/dev/vhost-net\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"PathInContainer\": \"/dev/vhost-net\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"CgroupPermissions\": \"rwm\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"DiskQuota\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"KernelMemory\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MemoryReservation\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MemorySwap\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MemorySwappiness\": -1, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OomKillDisable\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"PidsLimit\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Ulimits\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuCount\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"CpuPercent\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IOMaximumIOps\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IOMaximumBandwidth\": 0 <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"GraphDriver\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Name\": \"devicemapper\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Data\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"DeviceId\": \"35464\","}
{"timestamp_utc": "2024-07-31T08:08:52.993Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"DeviceName\": \"docker-253:0-2235604-d91dc388cc83085291c3f88daf19279ebe28214f70984a9de7decc65f15c2b77\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"DeviceSize\": \"10737418240\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Mounts\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/proj/artifacts\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/proj/artifacts\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"ro,shared\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"shared\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"rprivate\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Type\": \"bind\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Source\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Destination\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Mode\": \"ro\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"RW\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"Propagation\": \"rprivate\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"Config\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Hostname\": \"085e23d3ac7c\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Domainname\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"User\": \"root\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStdin\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStdout\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"AttachStderr\": true, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"ExposedPorts\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"22/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": {},"}
{"timestamp_utc": "2024-07-31T08:08:52.994Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": {} <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Tty\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OpenStdin\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"StdinOnce\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Env\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"HOME=/home/jenkins\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"LC_ALL=en_US.UTF-8\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"LANG=en_US.UTF-8\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Cmd\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/usr/sbin/sshd\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"-D\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Image\": \"harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Volumes\": {}, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"WorkingDir\": \"/home/jenkins\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Entrypoint\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"/usr/bin/tini\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"--\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"OnBuild\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Labels\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"io.buildah.version\": \"1.31.3\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.build-date\": \"20201113\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.license\": \"GPLv2\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.name\": \"CentOS Base Image\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.schema-version\": \"1.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.label-schema.vendor\": \"CentOS\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.created\": \"2020-11-13 00:00:00+00:00\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.licenses\": \"GPL-2.0-only\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.title\": \"CentOS Base Image\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"org.opencontainers.image.vendor\": \"CentOS\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         \"NetworkSettings\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Bridge\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SandboxID\": \"b644da72c2d4b9efc155dd9e63f81771c85e63b79b52dd16c15aaf43a2e61e2f\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"HairpinMode\": false, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"LinkLocalIPv6Address\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"LinkLocalIPv6PrefixLen\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Ports\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"22/tcp\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5000/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37321\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5001/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37320\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5002/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37319\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5003/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37318\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5004/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37317\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5005/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32843\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5006/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37316\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5007/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37314\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5008/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37312\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5009/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37310\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5010/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37308\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     }"}
{"timestamp_utc": "2024-07-31T08:08:52.995Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5011/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37306\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5012/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37305\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5013/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37303\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5014/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37301\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5015/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37299\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5016/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37297\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5017/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37295\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5018/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37293\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5019/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37291\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5020/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37289\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5021/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37287\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5022/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32841\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5023/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37284\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5024/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37282\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5025/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37280\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5026/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37278\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5027/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37276\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5028/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37274\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5029/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37273\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     }"}
{"timestamp_utc": "2024-07-31T08:08:52.996Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5030/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37271\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5031/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37269\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5032/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37267\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5033/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37265\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5034/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37263\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5035/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37261\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5036/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37259\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5037/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37257\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5038/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37255\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5039/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32839\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5040/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37252\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5041/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37250\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5042/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37248\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5043/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37246\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5044/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37244\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5045/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37242\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5046/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37240\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5047/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37239\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5048/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37237\""}
{"timestamp_utc": "2024-07-31T08:08:52.997Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5049/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37235\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5050/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37233\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5051/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37231\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5052/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37229\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5053/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37227\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5054/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37225\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5055/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37223\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5056/udp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"32837\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5057/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37220\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5058/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37218\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5059/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37216\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5060/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37214\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5061/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37212\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5062/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37210\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5063/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37208\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5064/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37207\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5065/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37205\""}
{"timestamp_utc": "2024-07-31T08:08:52.998Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5066/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37203\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ], <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"5067/tcp\": [ <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostIp\": \"0.0.0.0\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                         \"HostPort\": \"37201\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 ] <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             }, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SandboxKey\": \"/var/run/docker/netns/b644da72c2d4\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SecondaryIPAddresses\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"SecondaryIPv6Addresses\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"EndpointID\": \"7b08598ffefb83c9608a494016d76637aebd8b6a54da4d7583b9a96abdedeb3a\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Gateway\": \"172.17.0.1\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"GlobalIPv6Address\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"GlobalIPv6PrefixLen\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IPAddress\": \"172.17.0.10\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IPPrefixLen\": 16, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"IPv6Gateway\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"MacAddress\": \"02:42:ac:11:00:0a\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             \"Networks\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 \"bridge\": { <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPAMConfig\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"Links\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"Aliases\": null, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"NetworkID\": \"4a45b0ef4cf13bd98e537829e6df02da9e283ef3232ced2d12f8023a8079d589\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"EndpointID\": \"7b08598ffefb83c9608a494016d76637aebd8b6a54da4d7583b9a96abdedeb3a\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"Gateway\": \"172.17.0.1\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPAddress\": \"172.17.0.10\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPPrefixLen\": 16, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"IPv6Gateway\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"GlobalIPv6Address\": \"\", <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"GlobalIPv6PrefixLen\": 0, <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                     \"MacAddress\": \"02:42:ac:11:00:0a\" <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:                 } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:             } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:         } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout:     } <NL> # 03:08:51 ntp-topology INFO: docker_inspect_command: stdout: ] <NL> # 03:08:51 ntp-topology INFO: create_single_docker_container: created actual_container_id \"085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05\"(name \"hopeful_mirzakhani\") for requested name \"topology-group-device-group-type-qemu-01\" <NL> # 03:08:51 ntp-topology INFO: handle_remote_create_in_new_device_group_containers:   saved container amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/definitions.topology/device_group.group-device-group-type-qemu-01/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', 'hopeful_mirzakhani'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5062/tcp -> 0.0.0.0:37210 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5066/tcp -> 0.0.0.0:37203 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5029/tcp -> 0.0.0.0:37273 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5040/tcp -> 0.0.0.0:37252 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5050/tcp -> 0.0.0.0:37233 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5052/tcp -> 0.0.0.0:37229 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5054/tcp -> 0.0.0.0:37225 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5002/tcp -> 0.0.0.0:37319 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5032/tcp -> 0.0.0.0:37267 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5055/tcp -> 0.0.0.0:37223 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5005/udp -> 0.0.0.0:32843 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5011/tcp -> 0.0.0.0:37306 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5022/udp -> 0.0.0.0:32841 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5059/tcp -> 0.0.0.0:37216 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5061/tcp -> 0.0.0.0:37212 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5001/tcp -> 0.0.0.0:37320 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5023/tcp -> 0.0.0.0:37284 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5041/tcp -> 0.0.0.0:37250 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5003/tcp -> 0.0.0.0:37318 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5021/tcp -> 0.0.0.0:37287 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5033/tcp -> 0.0.0.0:37265 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5056/udp -> 0.0.0.0:32837 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5007/tcp -> 0.0.0.0:37314 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5017/tcp -> 0.0.0.0:37295 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5060/tcp -> 0.0.0.0:37214 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5006/tcp -> 0.0.0.0:37316 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5019/tcp -> 0.0.0.0:37291 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5024/tcp -> 0.0.0.0:37282 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5027/tcp -> 0.0.0.0:37276 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5048/tcp -> 0.0.0.0:37237 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5009/tcp -> 0.0.0.0:37310 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5010/tcp -> 0.0.0.0:37308 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5036/tcp -> 0.0.0.0:37259 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5042/tcp -> 0.0.0.0:37248 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5008/tcp -> 0.0.0.0:37312 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5012/tcp -> 0.0.0.0:37305 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5053/tcp -> 0.0.0.0:37227 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5044/tcp -> 0.0.0.0:37244 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5058/tcp -> 0.0.0.0:37218 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5018/tcp -> 0.0.0.0:37293 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5026/tcp -> 0.0.0.0:37278 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5031/tcp -> 0.0.0.0:37269 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5035/tcp -> 0.0.0.0:37261 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5038/tcp -> 0.0.0.0:37255 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5043/tcp -> 0.0.0.0:37246 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5025/tcp -> 0.0.0.0:37280 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5045/tcp -> 0.0.0.0:37242 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5063/tcp -> 0.0.0.0:37208 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5065/tcp -> 0.0.0.0:37205 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5016/tcp -> 0.0.0.0:37297 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5028/tcp -> 0.0.0.0:37274 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5037/tcp -> 0.0.0.0:37257 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5051/tcp -> 0.0.0.0:37231 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5057/tcp -> 0.0.0.0:37220 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5064/tcp -> 0.0.0.0:37207 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5014/tcp -> 0.0.0.0:37301 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5020/tcp -> 0.0.0.0:37289 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5004/tcp -> 0.0.0.0:37317 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5013/tcp -> 0.0.0.0:37303 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5015/tcp -> 0.0.0.0:37299 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5047/tcp -> 0.0.0.0:37239 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5067/tcp -> 0.0.0.0:37201 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5000/tcp -> 0.0.0.0:37321 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5030/tcp -> 0.0.0.0:37271 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5034/tcp -> 0.0.0.0:37263 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5039/udp -> 0.0.0.0:32839"}
{"timestamp_utc": "2024-07-31T08:08:52.999Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:51 ntp-topology INFO: docker_command: stdout: 5046/tcp -> 0.0.0.0:37240 <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 5049/tcp -> 0.0.0.0:37235 <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5000'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37321 <NL> # 03:08:51 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37321 for service \"network-element:NE1/device:main/service:console\" <NL> # 03:08:51 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5001'] <NL> # 03:08:51 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37320 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37320 for service \"network-element:NE1/device:main/service:debug-ssh\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5002'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37319 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37319 for service \"network-element:NE1/device:main/service:cli\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5003'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37318 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37318 for service \"network-element:NE1/device:main/service:netconf\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5004'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37317 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37317 for service \"network-element:NE1/device:main/service:gnmi\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5005/udp'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32843 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32843 for service \"network-element:NE1/device:main/service:snmp\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5006'] <NL> # 03:08:52 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37316 <NL> # 03:08:52 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37316 for service \"network-element:NE1/device:main/service:webui\" <NL> # 03:08:52 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5007']"}
{"timestamp_utc": "2024-07-31T08:08:53.254Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37314 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37314 for service \"network-element:NE1/device:main/service:https\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5008'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37312 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37312 for service \"network-element:NE1/device:main/service:zmq\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5009'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37310 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37310 for service \"network-element:NE1/device:main/service:gdb\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5010']"}
{"timestamp_utc": "2024-07-31T08:08:53.510Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37308 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37308 for service \"network-element:NE1/device:main/service:gdb-ops-additional\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5011'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37306 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37306 for service \"network-element:NE1/device:main/service:ospl\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5012']"}
{"timestamp_utc": "2024-07-31T08:08:53.765Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37305 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37305 for service \"network-element:NE1/device:main/service:ftp\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5013'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37303 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37303 for service \"network-element:NE1/device:main/service:sftp\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5014'] <NL> # 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37301 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37301 for service \"network-element:NE1/device:main/service:telnet\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5015']"}
{"timestamp_utc": "2024-07-31T08:08:54.021Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:53 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37299 <NL> # 03:08:53 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37299 for service \"network-element:NE1/device:trib1/service:console\" <NL> # 03:08:53 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5016']"}
{"timestamp_utc": "2024-07-31T08:08:54.276Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37297 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37297 for service \"network-element:NE1/device:trib1/service:debug-ssh\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5017'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37295 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37295 for service \"network-element:NE2/device:main/service:console\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5018']"}
{"timestamp_utc": "2024-07-31T08:08:54.532Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37293 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37293 for service \"network-element:NE2/device:main/service:debug-ssh\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5019'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37291 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37291 for service \"network-element:NE2/device:main/service:cli\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5020']"}
{"timestamp_utc": "2024-07-31T08:08:54.788Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37289 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37289 for service \"network-element:NE2/device:main/service:netconf\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5021'] <NL> # 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37287 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37287 for service \"network-element:NE2/device:main/service:gnmi\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5022/udp']"}
{"timestamp_utc": "2024-07-31T08:08:55.044Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:54 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32841 <NL> # 03:08:54 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32841 for service \"network-element:NE2/device:main/service:snmp\" <NL> # 03:08:54 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5023']"}
{"timestamp_utc": "2024-07-31T08:08:55.301Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37284 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37284 for service \"network-element:NE2/device:main/service:webui\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5024'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37282 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37282 for service \"network-element:NE2/device:main/service:https\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5025']"}
{"timestamp_utc": "2024-07-31T08:08:55.556Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37280 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37280 for service \"network-element:NE2/device:main/service:zmq\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5026'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37278 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37278 for service \"network-element:NE2/device:main/service:gdb\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5027']"}
{"timestamp_utc": "2024-07-31T08:08:55.851Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37276 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37276 for service \"network-element:NE2/device:main/service:gdb-ops-additional\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5028'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37274 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37274 for service \"network-element:NE2/device:main/service:ospl\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5029']"}
{"timestamp_utc": "2024-07-31T08:08:56.108Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37273 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37273 for service \"network-element:NE2/device:main/service:ftp\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5030'] <NL> # 03:08:55 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37271 <NL> # 03:08:55 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37271 for service \"network-element:NE2/device:main/service:sftp\" <NL> # 03:08:55 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5031']"}
{"timestamp_utc": "2024-07-31T08:08:56.363Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37269 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37269 for service \"network-element:NE2/device:main/service:telnet\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5032'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37267 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37267 for service \"network-element:NE2/device:trib1/service:console\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5033']"}
{"timestamp_utc": "2024-07-31T08:08:56.619Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37265 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37265 for service \"network-element:NE2/device:trib1/service:debug-ssh\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5034'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37263 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37263 for service \"network-element:NE3/device:main/service:console\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5035']"}
{"timestamp_utc": "2024-07-31T08:08:56.874Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37261 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37261 for service \"network-element:NE3/device:main/service:debug-ssh\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5036'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37259"}
{"timestamp_utc": "2024-07-31T08:08:57.130Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37259 for service \"network-element:NE3/device:main/service:cli\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5037'] <NL> # 03:08:56 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37257 <NL> # 03:08:56 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37257 for service \"network-element:NE3/device:main/service:netconf\" <NL> # 03:08:56 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5038'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37255 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37255 for service \"network-element:NE3/device:main/service:gnmi\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5039/udp']"}
{"timestamp_utc": "2024-07-31T08:08:57.385Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32839 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32839 for service \"network-element:NE3/device:main/service:snmp\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5040']"}
{"timestamp_utc": "2024-07-31T08:08:57.386Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37252 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37252 for service \"network-element:NE3/device:main/service:webui\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5041']"}
{"timestamp_utc": "2024-07-31T08:08:57.642Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37250 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37250 for service \"network-element:NE3/device:main/service:https\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5042'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37248"}
{"timestamp_utc": "2024-07-31T08:08:57.899Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37248 for service \"network-element:NE3/device:main/service:zmq\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5043'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37246 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37246 for service \"network-element:NE3/device:main/service:gdb\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5044'] <NL> # 03:08:57 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37244 <NL> # 03:08:57 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37244 for service \"network-element:NE3/device:main/service:gdb-ops-additional\" <NL> # 03:08:57 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5045']"}
{"timestamp_utc": "2024-07-31T08:08:58.155Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37242 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37242 for service \"network-element:NE3/device:main/service:ospl\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5046']"}
{"timestamp_utc": "2024-07-31T08:08:58.410Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37240 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37240 for service \"network-element:NE3/device:main/service:ftp\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5047'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37239 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37239 for service \"network-element:NE3/device:main/service:sftp\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5048']"}
{"timestamp_utc": "2024-07-31T08:08:58.666Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37237 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37237 for service \"network-element:NE3/device:main/service:telnet\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5049'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37235 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37235 for service \"network-element:NE3/device:trib1/service:console\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5050']"}
{"timestamp_utc": "2024-07-31T08:08:58.922Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37233 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37233 for service \"network-element:NE3/device:trib1/service:debug-ssh\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5051'] <NL> # 03:08:58 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37231 <NL> # 03:08:58 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37231 for service \"network-element:NE4/device:main/service:console\" <NL> # 03:08:58 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5052']"}
{"timestamp_utc": "2024-07-31T08:08:59.187Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37229 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37229 for service \"network-element:NE4/device:main/service:debug-ssh\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5053']"}
{"timestamp_utc": "2024-07-31T08:08:59.449Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37227 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37227 for service \"network-element:NE4/device:main/service:cli\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5054']"}
{"timestamp_utc": "2024-07-31T08:08:59.705Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37225 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37225 for service \"network-element:NE4/device:main/service:netconf\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5055'] <NL> # 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37223 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37223 for service \"network-element:NE4/device:main/service:gnmi\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5056/udp']"}
{"timestamp_utc": "2024-07-31T08:08:59.961Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:32837 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 32837 for service \"network-element:NE4/device:main/service:snmp\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5057']"}
{"timestamp_utc": "2024-07-31T08:09:00.218Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:08:59 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37220 <NL> # 03:08:59 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37220 for service \"network-element:NE4/device:main/service:webui\" <NL> # 03:08:59 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5058'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37218 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37218 for service \"network-element:NE4/device:main/service:https\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5059']"}
{"timestamp_utc": "2024-07-31T08:09:00.476Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37216 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37216 for service \"network-element:NE4/device:main/service:zmq\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5060'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37214 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37214 for service \"network-element:NE4/device:main/service:gdb\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5061'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37212 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37212 for service \"network-element:NE4/device:main/service:gdb-ops-additional\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5062']"}
{"timestamp_utc": "2024-07-31T08:09:00.739Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37210 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37210 for service \"network-element:NE4/device:main/service:ospl\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5063']"}
{"timestamp_utc": "2024-07-31T08:09:00.995Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37208 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37208 for service \"network-element:NE4/device:main/service:ftp\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5064'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37207 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37207 for service \"network-element:NE4/device:main/service:sftp\""}
{"timestamp_utc": "2024-07-31T08:09:00.996Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5065'] <NL> # 03:09:00 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37205 <NL> # 03:09:00 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37205 for service \"network-element:NE4/device:main/service:telnet\" <NL> # 03:09:00 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5066']"}
{"timestamp_utc": "2024-07-31T08:09:01.255Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37203 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37203 for service \"network-element:NE4/device:trib1/service:console\" <NL> # 03:09:01 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'port', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '5067'] <NL> # 03:09:01 ntp-topology INFO: docker_command: stdout: 0.0.0.0:37201 <NL> # 03:09:01 ntp-topology INFO: get_container_external_service_ports_from_docker: actual_container_external_port_number 37201 for service \"network-element:NE4/device:trib1/service:debug-ssh\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37321 for network-element:NE1/device:main/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37320 for network-element:NE1/device:main/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37319 for network-element:NE1/device:main/service:cli <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37318 for network-element:NE1/device:main/service:netconf <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37317 for network-element:NE1/device:main/service:gnmi <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32843 for network-element:NE1/device:main/service:snmp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37316 for network-element:NE1/device:main/service:webui <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37314 for network-element:NE1/device:main/service:https <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37312 for network-element:NE1/device:main/service:zmq <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:09:01.256Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37310 for network-element:NE1/device:main/service:gdb <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37308 for network-element:NE1/device:main/service:gdb-ops-additional <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37306 for network-element:NE1/device:main/service:ospl <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37305 for network-element:NE1/device:main/service:ftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37303 for network-element:NE1/device:main/service:sftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37301 for network-element:NE1/device:main/service:telnet <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37299 for network-element:NE1/device:trib1/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37297 for network-element:NE1/device:trib1/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE1/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37295 for network-element:NE2/device:main/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37293 for network-element:NE2/device:main/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37291 for network-element:NE2/device:main/service:cli <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37289 for network-element:NE2/device:main/service:netconf <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37287 for network-element:NE2/device:main/service:gnmi <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32841 for network-element:NE2/device:main/service:snmp"}
{"timestamp_utc": "2024-07-31T08:09:01.257Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37284 for network-element:NE2/device:main/service:webui <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37282 for network-element:NE2/device:main/service:https <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37280 for network-element:NE2/device:main/service:zmq <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37278 for network-element:NE2/device:main/service:gdb <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37276 for network-element:NE2/device:main/service:gdb-ops-additional <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37274 for network-element:NE2/device:main/service:ospl <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37273 for network-element:NE2/device:main/service:ftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37271 for network-element:NE2/device:main/service:sftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37269 for network-element:NE2/device:main/service:telnet <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189"}
{"timestamp_utc": "2024-07-31T08:09:01.515Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37267 for network-element:NE2/device:trib1/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37265 for network-element:NE2/device:trib1/service:debug-ssh"}
{"timestamp_utc": "2024-07-31T08:09:01.516Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE2/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37263 for network-element:NE3/device:main/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37261 for network-element:NE3/device:main/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37259 for network-element:NE3/device:main/service:cli <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37257 for network-element:NE3/device:main/service:netconf <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37255 for network-element:NE3/device:main/service:gnmi <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32839 for network-element:NE3/device:main/service:snmp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37252 for network-element:NE3/device:main/service:webui <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37250 for network-element:NE3/device:main/service:https <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37248 for network-element:NE3/device:main/service:zmq <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37246 for network-element:NE3/device:main/service:gdb <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37244 for network-element:NE3/device:main/service:gdb-ops-additional <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37242 for network-element:NE3/device:main/service:ospl <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37240 for network-element:NE3/device:main/service:ftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189"}
{"timestamp_utc": "2024-07-31T08:09:01.517Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37239 for network-element:NE3/device:main/service:sftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37237 for network-element:NE3/device:main/service:telnet <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37235 for network-element:NE3/device:trib1/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37233 for network-element:NE3/device:trib1/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE3/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37231 for network-element:NE4/device:main/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37229 for network-element:NE4/device:main/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37227 for network-element:NE4/device:main/service:cli <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:cli hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.cli/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37225 for network-element:NE4/device:main/service:netconf <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:netconf hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.netconf/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37223 for network-element:NE4/device:main/service:gnmi <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gnmi hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gnmi/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 32837 for network-element:NE4/device:main/service:snmp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:snmp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.snmp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37220 for network-element:NE4/device:main/service:webui <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:webui hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.webui/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37218 for network-element:NE4/device:main/service:https <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:https hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.https/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37216 for network-element:NE4/device:main/service:zmq <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:zmq hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.zmq/ntp-json-topology/ntp-amend-instance.json\""}
{"timestamp_utc": "2024-07-31T08:09:01.518Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37214 for network-element:NE4/device:main/service:gdb <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gdb hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gdb/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37212 for network-element:NE4/device:main/service:gdb-ops-additional <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:gdb-ops-additional hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.gdb-ops-additional/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37210 for network-element:NE4/device:main/service:ospl <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:ospl hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.ospl/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37208 for network-element:NE4/device:main/service:ftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:ftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.ftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37207 for network-element:NE4/device:main/service:sftp <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:sftp hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.sftp/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37205 for network-element:NE4/device:main/service:telnet <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:main/service:telnet hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/service.telnet/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37203 for network-element:NE4/device:trib1/service:console <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:trib1/service:console hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/service.console/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: amending container_external_port_number to 37201 for network-element:NE4/device:trib1/service:debug-ssh <NL> # 03:09:01 ntp-topology INFO: amend_service_ports: saved port forward amend info into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json' <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: amending network-element:NE4/device:trib1/service:debug-ssh hostname rtxoialp79, hostip 167.254.217.189 <NL> # 03:09:01 ntp-topology INFO: amend_service_host_info: saved service host amend info into \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/service.debug-ssh/ntp-json-topology/ntp-amend-instance.json\" <NL> # 03:09:01 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: container_logs_command_log_fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.log' <NL> # 03:09:01 ntp-topology INFO: get_container_env_exec_command: network_topology_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology <NL> # 03:09:01 ntp-topology INFO: handle_remote_create_in_new_device_group_containers: start_command ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-create'] <NL> # 03:09:01 ntp-topology INFO: create_container_log_fname: name='command' type='created'): fname_data_dict { <NL> \"status_text\": \"from handle_remote_create_in_new_device_group_containers\" <NL> } <NL> # 03:09:01 ntp-topology INFO: exec_cmd: ['mv', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.created.tmp', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.created'] <NL> # 03:09:01 ntp-topology INFO: exec_cmd: ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-create']"}
{"timestamp_utc": "2024-07-31T08:09:02.081Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:01 ntp-topology INFO: wait_for_containers_command_started: - waiting max 600s for container_logs_command_started_fname files: <NL> # 03:09:01 ntp-topology INFO: wait_for_containers_command_started:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.started' <NL> # 03:09:01 ntp-topology INFO: wait_for_containers_command_started: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.started'] <NL> # 03:09:01 ntp-topology INFO: wait_for_containers_command_started: 0.000s of 600.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:03.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:02 ntp-topology INFO: wait_for_containers_command_started: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.started'] <NL> # 03:09:02 ntp-topology INFO: wait_for_containers_command_started: 1.001s of 600.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:03.939Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized: - waiting max 1800s for container_logs_command_initialized_fname files: <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized' <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error' <NL> # 03:09:03 ntp-topology INFO: ntp.retry.group_list_cl.show: json_list: [ <NL> { <NL> \"all_of_file_list\": [ <NL> [ <NL> \"initialized\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized\" <NL> ] <NL> ], <NL> \"any_of_file_list\": [ <NL> [ <NL> \"error\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error\" <NL> ] <NL> ], <NL> \"group_name\": \"topology-group-device-group-type-qemu-01\" <NL> } <NL> ] <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:03 ntp-topology INFO: wait_for_containers_command_initialized: 0.000s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:05.306Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:04 ntp-topology INFO: wait_for_containers_command_initialized: 1.001s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:06.233Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:05 ntp-topology INFO: wait_for_containers_command_initialized: 2.002s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:07.163Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:06 ntp-topology INFO: wait_for_containers_command_initialized: 3.003s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:08.090Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:07 ntp-topology INFO: wait_for_containers_command_initialized: 4.004s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:09.018Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:08 ntp-topology INFO: wait_for_containers_command_initialized: 5.006s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:09.946Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:09 ntp-topology INFO: wait_for_containers_command_initialized: 6.007s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:11.312Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:10 ntp-topology INFO: wait_for_containers_command_initialized: 7.008s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:12.239Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:11 ntp-topology INFO: wait_for_containers_command_initialized: 8.009s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:13.167Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:12 ntp-topology INFO: wait_for_containers_command_initialized: 9.010s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:14.108Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:13 ntp-topology INFO: wait_for_containers_command_initialized: 10.012s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:15.036Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:14 ntp-topology INFO: wait_for_containers_command_initialized: 11.013s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:15.964Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:15 ntp-topology INFO: wait_for_containers_command_initialized: 12.014s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:16.892Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:16 ntp-topology INFO: wait_for_containers_command_initialized: 13.015s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:18.258Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:17 ntp-topology INFO: wait_for_containers_command_initialized: 14.017s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:19.189Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:18 ntp-topology INFO: wait_for_containers_command_initialized: 15.017s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:20.117Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:19 ntp-topology INFO: wait_for_containers_command_initialized: 16.018s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:21.044Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:20 ntp-topology INFO: wait_for_containers_command_initialized: 17.019s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:21.973Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:21 ntp-topology INFO: wait_for_containers_command_initialized: 18.020s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:22.900Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:22 ntp-topology INFO: wait_for_containers_command_initialized: 19.021s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:24.266Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:23 ntp-topology INFO: wait_for_containers_command_initialized: 20.022s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:25.222Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:24 ntp-topology INFO: wait_for_containers_command_initialized: 21.023s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:26.158Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:25 ntp-topology INFO: wait_for_containers_command_initialized: 22.024s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:27.084Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:26 ntp-topology INFO: wait_for_containers_command_initialized: 23.025s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:28.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:09:28.011Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:27 ntp-topology INFO: wait_for_containers_command_initialized: 24.026s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:28.939Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:28 ntp-topology INFO: wait_for_containers_command_initialized: 25.027s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:30.303Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:29 ntp-topology INFO: wait_for_containers_command_initialized: 26.028s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:31.232Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:30 ntp-topology INFO: wait_for_containers_command_initialized: 27.030s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:32.158Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:31 ntp-topology INFO: wait_for_containers_command_initialized: 28.031s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:33.085Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:32 ntp-topology INFO: wait_for_containers_command_initialized: 29.032s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:34.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:33 ntp-topology INFO: wait_for_containers_command_initialized: 30.033s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:34.936Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:34 ntp-topology INFO: wait_for_containers_command_initialized: 31.034s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:36.300Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:35 ntp-topology INFO: wait_for_containers_command_initialized: 32.035s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:37.255Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:36 ntp-topology INFO: wait_for_containers_command_initialized: 33.036s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:38.180Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:37 ntp-topology INFO: wait_for_containers_command_initialized: 34.037s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:39.106Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:38 ntp-topology INFO: wait_for_containers_command_initialized: 35.038s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:40.032Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:39 ntp-topology INFO: wait_for_containers_command_initialized: 36.039s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:40.958Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:40 ntp-topology INFO: wait_for_containers_command_initialized: 37.040s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:42.322Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:41 ntp-topology INFO: wait_for_containers_command_initialized: 38.041s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:43.248Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:42 ntp-topology INFO: wait_for_containers_command_initialized: 39.042s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:44.173Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:43 ntp-topology INFO: wait_for_containers_command_initialized: 40.043s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:45.099Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:44 ntp-topology INFO: wait_for_containers_command_initialized: 41.044s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:46.062Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:45 ntp-topology INFO: wait_for_containers_command_initialized: 42.045s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:46.988Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:09:46.989Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:46 ntp-topology INFO: wait_for_containers_command_initialized: 43.046s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:48.350Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:47 ntp-topology INFO: wait_for_containers_command_initialized: 44.047s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:49.275Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:48 ntp-topology INFO: wait_for_containers_command_initialized: 45.048s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:50.211Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:49 ntp-topology INFO: wait_for_containers_command_initialized: 46.049s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:51.137Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:50 ntp-topology INFO: wait_for_containers_command_initialized: 47.050s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:52.065Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:51 ntp-topology INFO: wait_for_containers_command_initialized: 48.051s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:52.991Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:52 ntp-topology INFO: wait_for_containers_command_initialized: 49.052s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:54.356Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:53 ntp-topology INFO: wait_for_containers_command_initialized: 50.053s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:55.283Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:54 ntp-topology INFO: wait_for_containers_command_initialized: 51.054s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:56.211Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:55 ntp-topology INFO: wait_for_containers_command_initialized: 52.055s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:57.137Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:56 ntp-topology INFO: wait_for_containers_command_initialized: 53.056s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:58.063Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:57 ntp-topology INFO: wait_for_containers_command_initialized: 54.057s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:59.029Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:09:59.030Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:58 ntp-topology INFO: wait_for_containers_command_initialized: 55.058s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:09:59.959Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:09:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:09:59 ntp-topology INFO: wait_for_containers_command_initialized: 56.059s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:01.328Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:00 ntp-topology INFO: wait_for_containers_command_initialized: 57.060s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:02.259Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:01 ntp-topology INFO: wait_for_containers_command_initialized: 58.061s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:03.190Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:02 ntp-topology INFO: wait_for_containers_command_initialized: 59.062s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:04.117Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:03 ntp-topology INFO: wait_for_containers_command_initialized: 60.063s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:05.045Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:04 ntp-topology INFO: wait_for_containers_command_initialized: 61.064s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:05.971Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:05 ntp-topology INFO: wait_for_containers_command_initialized: 62.065s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:07.358Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:06 ntp-topology INFO: wait_for_containers_command_initialized: 63.066s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:08.284Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:07 ntp-topology INFO: wait_for_containers_command_initialized: 64.067s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:09.211Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:08 ntp-topology INFO: wait_for_containers_command_initialized: 65.068s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:10.137Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:09 ntp-topology INFO: wait_for_containers_command_initialized: 66.069s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:11.065Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:10 ntp-topology INFO: wait_for_containers_command_initialized: 67.070s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:11.991Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:11 ntp-topology INFO: wait_for_containers_command_initialized: 68.071s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:13.356Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:12 ntp-topology INFO: wait_for_containers_command_initialized: 69.072s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:14.282Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:13 ntp-topology INFO: wait_for_containers_command_initialized: 70.073s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:15.208Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:14 ntp-topology INFO: wait_for_containers_command_initialized: 71.074s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:16.135Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:10:16.136Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:15 ntp-topology INFO: wait_for_containers_command_initialized: 72.075s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:17.061Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:16 ntp-topology INFO: wait_for_containers_command_initialized: 73.076s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:17.989Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:17 ntp-topology INFO: wait_for_containers_command_initialized: 74.077s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:19.353Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:18 ntp-topology INFO: wait_for_containers_command_initialized: 75.078s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:20.281Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:19 ntp-topology INFO: wait_for_containers_command_initialized: 76.079s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:21.208Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:20 ntp-topology INFO: wait_for_containers_command_initialized: 77.080s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:22.135Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:21 ntp-topology INFO: wait_for_containers_command_initialized: 78.081s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:23.067Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:22 ntp-topology INFO: wait_for_containers_command_initialized: 79.082s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:23.994Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:23 ntp-topology INFO: wait_for_containers_command_initialized: 80.083s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:25.359Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:24 ntp-topology INFO: wait_for_containers_command_initialized: 81.084s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:26.286Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:25 ntp-topology INFO: wait_for_containers_command_initialized: 82.085s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:27.228Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:26 ntp-topology INFO: wait_for_containers_command_initialized: 83.086s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:28.153Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:27 ntp-topology INFO: wait_for_containers_command_initialized: 84.087s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:29.081Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:28 ntp-topology INFO: wait_for_containers_command_initialized: 85.088s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:30.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:29 ntp-topology INFO: wait_for_containers_command_initialized: 86.089s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:31.374Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:30 ntp-topology INFO: wait_for_containers_command_initialized: 87.091s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:32.300Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:31 ntp-topology INFO: wait_for_containers_command_initialized: 88.092s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:33.226Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:32 ntp-topology INFO: wait_for_containers_command_initialized: 89.093s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:34.152Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:33 ntp-topology INFO: wait_for_containers_command_initialized: 90.094s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:35.078Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:34 ntp-topology INFO: wait_for_containers_command_initialized: 91.095s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:36.004Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:35 ntp-topology INFO: wait_for_containers_command_initialized: 92.096s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:37.415Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:36 ntp-topology INFO: wait_for_containers_command_initialized: 93.097s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:37.975Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:10:37.976Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:37 ntp-topology INFO: wait_for_containers_command_initialized: 94.098s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:39.338Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:38 ntp-topology INFO: wait_for_containers_command_initialized: 95.099s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:40.265Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:39 ntp-topology INFO: wait_for_containers_command_initialized: 96.100s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:41.191Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:40 ntp-topology INFO: wait_for_containers_command_initialized: 97.101s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:42.119Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:41 ntp-topology INFO: wait_for_containers_command_initialized: 98.102s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:43.044Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:42 ntp-topology INFO: wait_for_containers_command_initialized: 99.103s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:44.406Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:43 ntp-topology INFO: wait_for_containers_command_initialized: 100.104s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:45.333Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:44 ntp-topology INFO: wait_for_containers_command_initialized: 101.105s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:46.276Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:45 ntp-topology INFO: wait_for_containers_command_initialized: 102.106s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:47.203Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:46 ntp-topology INFO: wait_for_containers_command_initialized: 103.107s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:48.130Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:47 ntp-topology INFO: wait_for_containers_command_initialized: 104.108s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:49.074Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:48 ntp-topology INFO: wait_for_containers_command_initialized: 105.109s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:50.010Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:49 ntp-topology INFO: wait_for_containers_command_initialized: 106.110s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:51.374Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:50 ntp-topology INFO: wait_for_containers_command_initialized: 107.111s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:52.301Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:51 ntp-topology INFO: wait_for_containers_command_initialized: 108.112s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:53.261Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:52 ntp-topology INFO: wait_for_containers_command_initialized: 109.113s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:54.192Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:53 ntp-topology INFO: wait_for_containers_command_initialized: 110.114s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:55.120Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:54 ntp-topology INFO: wait_for_containers_command_initialized: 111.115s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:56.048Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:55 ntp-topology INFO: wait_for_containers_command_initialized: 112.116s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:57.423Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:56 ntp-topology INFO: wait_for_containers_command_initialized: 113.117s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:58.351Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:57 ntp-topology INFO: wait_for_containers_command_initialized: 114.118s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:10:59.279Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:58 ntp-topology INFO: wait_for_containers_command_initialized: 115.119s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:00.207Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:10:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:10:59 ntp-topology INFO: wait_for_containers_command_initialized: 116.120s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:01.135Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:00 ntp-topology INFO: wait_for_containers_command_initialized: 117.121s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:02.081Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:01 ntp-topology INFO: wait_for_containers_command_initialized: 118.122s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:03.009Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:02 ntp-topology INFO: wait_for_containers_command_initialized: 119.123s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:04.371Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:03 ntp-topology INFO: wait_for_containers_command_initialized: 120.124s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:05.300Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:04 ntp-topology INFO: wait_for_containers_command_initialized: 121.125s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:06.246Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:05 ntp-topology INFO: wait_for_containers_command_initialized: 122.126s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:07.176Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:06 ntp-topology INFO: wait_for_containers_command_initialized: 123.127s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:08.105Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:07 ntp-topology INFO: wait_for_containers_command_initialized: 124.128s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:09.033Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:09 ntp-topology INFO: wait_for_containers_command_initialized: 125.129s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:10.400Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:10 ntp-topology INFO: wait_for_containers_command_initialized: 126.130s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:11.326Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:11 ntp-topology INFO: wait_for_containers_command_initialized: 127.131s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:12.254Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:12 ntp-topology INFO: wait_for_containers_command_initialized: 128.134s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:13.179Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:13 ntp-topology INFO: wait_for_containers_command_initialized: 129.135s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:14.110Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:14 ntp-topology INFO: wait_for_containers_command_initialized: 130.136s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:15.037Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:15 ntp-topology INFO: wait_for_containers_command_initialized: 131.137s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:16.404Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:16 ntp-topology INFO: wait_for_containers_command_initialized: 132.138s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:17.330Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:17 ntp-topology INFO: wait_for_containers_command_initialized: 133.139s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:18.256Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:18 ntp-topology INFO: wait_for_containers_command_initialized: 134.140s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:19.183Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:19 ntp-topology INFO: wait_for_containers_command_initialized: 135.141s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:20.109Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:20 ntp-topology INFO: wait_for_containers_command_initialized: 136.142s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:21.035Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:21 ntp-topology INFO: wait_for_containers_command_initialized: 137.143s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:22.400Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:22 ntp-topology INFO: wait_for_containers_command_initialized: 138.144s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:23.325Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:23 ntp-topology INFO: wait_for_containers_command_initialized: 139.145s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:24.253Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:24 ntp-topology INFO: wait_for_containers_command_initialized: 140.146s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:25.180Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:25 ntp-topology INFO: wait_for_containers_command_initialized: 141.147s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:26.125Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:26 ntp-topology INFO: wait_for_containers_command_initialized: 142.148s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:27.051Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:27 ntp-topology INFO: wait_for_containers_command_initialized: 143.149s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:28.417Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:28 ntp-topology INFO: wait_for_containers_command_initialized: 144.150s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:29.346Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:29 ntp-topology INFO: wait_for_containers_command_initialized: 145.151s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:30.293Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:30 ntp-topology INFO: wait_for_containers_command_initialized: 146.152s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:31.224Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:31 ntp-topology INFO: wait_for_containers_command_initialized: 147.153s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:32.150Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:32 ntp-topology INFO: wait_for_containers_command_initialized: 148.154s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:33.077Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:33 ntp-topology INFO: wait_for_containers_command_initialized: 149.155s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:34.443Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:34 ntp-topology INFO: wait_for_containers_command_initialized: 150.156s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:35.370Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:35 ntp-topology INFO: wait_for_containers_command_initialized: 151.157s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:36.297Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:36 ntp-topology INFO: wait_for_containers_command_initialized: 152.158s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:37.224Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:37 ntp-topology INFO: wait_for_containers_command_initialized: 153.159s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:38.150Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:38 ntp-topology INFO: wait_for_containers_command_initialized: 154.160s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:39.077Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:39 ntp-topology INFO: wait_for_containers_command_initialized: 155.161s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:40.442Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:40 ntp-topology INFO: wait_for_containers_command_initialized: 156.162s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:41.370Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:41 ntp-topology INFO: wait_for_containers_command_initialized: 157.163s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:42.297Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:42 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:42 ntp-topology INFO: wait_for_containers_command_initialized: 158.164s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:43.225Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:43 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:43 ntp-topology INFO: wait_for_containers_command_initialized: 159.165s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:44.153Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:44 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:44 ntp-topology INFO: wait_for_containers_command_initialized: 160.166s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:45.082Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:45 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:45 ntp-topology INFO: wait_for_containers_command_initialized: 161.167s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:46.449Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:46 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:46 ntp-topology INFO: wait_for_containers_command_initialized: 162.168s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:47.375Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:47 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:47 ntp-topology INFO: wait_for_containers_command_initialized: 163.169s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:48.303Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:48 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:48 ntp-topology INFO: wait_for_containers_command_initialized: 164.170s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:49.230Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:49 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:49 ntp-topology INFO: wait_for_containers_command_initialized: 165.171s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:50.159Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:50 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:50 ntp-topology INFO: wait_for_containers_command_initialized: 166.172s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:51.088Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:51 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:51 ntp-topology INFO: wait_for_containers_command_initialized: 167.173s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:52.455Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:52 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:11:52.456Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:52 ntp-topology INFO: wait_for_containers_command_initialized: 168.174s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:53.383Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:53 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:53 ntp-topology INFO: wait_for_containers_command_initialized: 169.175s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:54.313Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:54 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:54 ntp-topology INFO: wait_for_containers_command_initialized: 170.176s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:55.244Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:55 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:55 ntp-topology INFO: wait_for_containers_command_initialized: 171.177s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:56.175Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:56 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:56 ntp-topology INFO: wait_for_containers_command_initialized: 172.178s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:57.104Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:57 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:57 ntp-topology INFO: wait_for_containers_command_initialized: 173.179s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:58.471Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:58 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:58 ntp-topology INFO: wait_for_containers_command_initialized: 174.180s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:11:59.399Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:11:59 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:11:59 ntp-topology INFO: wait_for_containers_command_initialized: 175.181s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:00.328Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:00 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:00 ntp-topology INFO: wait_for_containers_command_initialized: 176.182s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:01.306Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:01 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:01 ntp-topology INFO: wait_for_containers_command_initialized: 177.183s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:02.237Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:02 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:02 ntp-topology INFO: wait_for_containers_command_initialized: 178.184s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:03.165Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:03 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:03 ntp-topology INFO: wait_for_containers_command_initialized: 179.185s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:04.132Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:04 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:04 ntp-topology INFO: wait_for_containers_command_initialized: 180.186s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:05.060Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:05 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:05 ntp-topology INFO: wait_for_containers_command_initialized: 181.187s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:06.428Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:06 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:06 ntp-topology INFO: wait_for_containers_command_initialized: 182.188s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:07.395Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:07 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:07 ntp-topology INFO: wait_for_containers_command_initialized: 183.189s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:08.323Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:08 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:08 ntp-topology INFO: wait_for_containers_command_initialized: 184.190s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:09.250Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:09 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:09 ntp-topology INFO: wait_for_containers_command_initialized: 185.191s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:10.180Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:10 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:10 ntp-topology INFO: wait_for_containers_command_initialized: 186.193s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:11.115Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:11 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:11 ntp-topology INFO: wait_for_containers_command_initialized: 187.194s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:12.480Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:12 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:12 ntp-topology INFO: wait_for_containers_command_initialized: 188.195s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:13.407Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:13 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:13 ntp-topology INFO: wait_for_containers_command_initialized: 189.196s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:14.334Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:14 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:14 ntp-topology INFO: wait_for_containers_command_initialized: 190.197s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:15.261Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:15 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:15 ntp-topology INFO: wait_for_containers_command_initialized: 191.198s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:16.188Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:16 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:16 ntp-topology INFO: wait_for_containers_command_initialized: 192.199s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:17.117Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:17 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:17 ntp-topology INFO: wait_for_containers_command_initialized: 193.200s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:18.509Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:18 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:18 ntp-topology INFO: wait_for_containers_command_initialized: 194.201s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:19.437Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:19 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:19 ntp-topology INFO: wait_for_containers_command_initialized: 195.202s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:20.364Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:20 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:20 ntp-topology INFO: wait_for_containers_command_initialized: 196.203s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:21.290Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:21 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:21 ntp-topology INFO: wait_for_containers_command_initialized: 197.204s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:22.216Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:22 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:22 ntp-topology INFO: wait_for_containers_command_initialized: 198.205s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:23.144Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:23 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:23 ntp-topology INFO: wait_for_containers_command_initialized: 199.206s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:24.510Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:24 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:24 ntp-topology INFO: wait_for_containers_command_initialized: 200.207s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:25.440Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:25 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:25 ntp-topology INFO: wait_for_containers_command_initialized: 201.208s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:26.367Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:26 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:26 ntp-topology INFO: wait_for_containers_command_initialized: 202.209s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:27.293Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:27 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:27 ntp-topology INFO: wait_for_containers_command_initialized: 203.210s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:28.225Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:28 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:28 ntp-topology INFO: wait_for_containers_command_initialized: 204.211s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:29.153Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:29 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:29 ntp-topology INFO: wait_for_containers_command_initialized: 205.212s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:30.516Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:30 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:30 ntp-topology INFO: wait_for_containers_command_initialized: 206.213s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:31.443Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:31 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:31 ntp-topology INFO: wait_for_containers_command_initialized: 207.214s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:32.380Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:32 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:32 ntp-topology INFO: wait_for_containers_command_initialized: 208.215s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:33.315Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:33 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:33 ntp-topology INFO: wait_for_containers_command_initialized: 209.216s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:34.242Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:34 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:34 ntp-topology INFO: wait_for_containers_command_initialized: 210.217s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:35.169Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:35 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:35 ntp-topology INFO: wait_for_containers_command_initialized: 211.218s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:36.097Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:36 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:36 ntp-topology INFO: wait_for_containers_command_initialized: 212.219s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:37.461Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:37 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}]"}
{"timestamp_utc": "2024-07-31T08:12:37.462Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:37 ntp-topology INFO: wait_for_containers_command_initialized: 213.220s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:38.388Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:38 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:38 ntp-topology INFO: wait_for_containers_command_initialized: 214.221s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:39.316Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:39 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:39 ntp-topology INFO: wait_for_containers_command_initialized: 215.222s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:40.243Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:40 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:40 ntp-topology INFO: wait_for_containers_command_initialized: 216.223s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:41.171Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:41 ntp-topology INFO: wait_for_containers_command_initialized: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.initialized']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:41 ntp-topology INFO: wait_for_containers_command_initialized: 217.224s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:42.098Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:42 ntp-topology INFO: wait_for_containers_command_initialized: ntp_container_name 'topology-group-device-group-type-qemu-01': error_file_present_flag False <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: - waiting max 1800s for socket daemon files, if we have any <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: container_workspace_basedir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace'"}
{"timestamp_utc": "2024-07-31T08:12:42.355Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error' <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: socket_daemon_info_list: [ <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE1/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE1/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE1/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE2/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE2/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE2/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE3/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE3/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE3/device.trib1/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE4/device:main\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-command.log\","}
{"timestamp_utc": "2024-07-31T08:12:42.356Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\"socket_daemon_info_fname\": \"network-element.NE4/device.main/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.main/data/qemu/qemu-prog.log\" <NL> }, <NL> { <NL> \"device_context_absolute_id\": \"network-element:NE4/device:trib1\", <NL> \"socket_daemon_command_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-command.log\", <NL> \"socket_daemon_info_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\", <NL> \"socket_daemon_prog_log_fname\": \"network-element.NE4/device.trib1/data/qemu/qemu-prog.log\" <NL> } <NL> ] <NL> # 03:12:42 ntp-topology INFO: ntp.retry.group_list_cl.show: json_list: [ <NL> { <NL> \"all_of_file_list\": [ <NL> [ <NL> \"socket-daemon-info:network-element:NE1/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE1/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE2/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE2/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE3/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE3/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE4/device:main\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json\" <NL> ], <NL> [ <NL> \"socket-daemon-info:network-element:NE4/device:trib1\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json\" <NL> ] <NL> ], <NL> \"any_of_file_list\": [ <NL> [ <NL> \"error\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error\" <NL> ] <NL> ], <NL> \"group_name\": \"topology-group-device-group-type-qemu-01\" <NL> } <NL> ] <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:42 ntp-topology INFO: wait_for_containers_socket_deamon_info: 0.000s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:43.313Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:43 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:43 ntp-topology INFO: wait_for_containers_socket_deamon_info: 1.001s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:44.253Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:44 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:44 ntp-topology INFO: wait_for_containers_socket_deamon_info: 2.003s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:45.181Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:45 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:45 ntp-topology INFO: wait_for_containers_socket_deamon_info: 3.004s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:46.545Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:46 ntp-topology INFO: wait_for_containers_socket_deamon_info: caught RetryFailedError exception, message: No such files or directories: [{'all_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_all_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE1/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE2/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE3/device.trib1/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.main/data/qemu/qemu-info-fname.json', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/network-element.NE4/device.trib1/data/qemu/qemu-info-fname.json']}]}, {'any_of_list': [{'group_name': 'topology-group-device-group-type-qemu-01', 'missing_any_of_flist': ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.error']}]}] <NL> # 03:12:46 ntp-topology INFO: wait_for_containers_socket_deamon_info: 4.005s of 1800.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:12:47.472Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': error_file_present_flag False <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE1/device:main': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE1/device:trib1': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE2/device:main': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE2/device:trib1': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE3/device:main': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE3/device:trib1': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE4/device:main': command_code 0 <NL> # 03:12:47 ntp-topology INFO: wait_for_containers_socket_deamon_info: ntp_container_name 'topology-group-device-group-type-qemu-01': 'network-element:NE4/device:trib1': command_code 0 <NL> # 03:12:47 ntp-topology INFO: main: completed action 'create' <NL> # 03:12:47 ntp-topology INFO: done <NL> # 03:12:47 ntp-topology-run.py INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--action', 'request-remote-create']"}
{"timestamp_utc": "2024-07-31T08:12:48.399Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace' <NL> # 03:12:48 ntp-topology INFO: main: starting action 'request-remote-create' <NL> # 03:12:48 ntp-topology INFO: main: completed action 'request-remote-create' <NL> # 03:12:48 ntp-topology INFO: done <NL> # 03:12:48 ntp-topology-run.py INFO: exec_cmd: ['ntp-get-service-details', '-v', '-v', '--flist-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace/topology-flist.json', '--out-format', 'json', '--out-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json']"}
{"timestamp_utc": "2024-07-31T08:12:48.961Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE1-trib1'"}
{"timestamp_utc": "2024-07-31T08:12:48.962Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE2-trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE3-trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: found device_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01/device:NE4-trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices:   resolved device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE1/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE1/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE2/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE2/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE3/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE3/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE4/device:main' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_obj_list_for_devices: unique device_context_absolute_id 'network-element:NE4/device:trib1' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:cli' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:netconf' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gnmi' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:snmp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:webui' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:https' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:zmq' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gdb' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:gdb-ops-additional' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:ospl' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:ftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:sftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:main/service:telnet' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:trib1/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE1/device:trib1/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:cli' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:netconf' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gnmi' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:snmp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:webui' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:https' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:zmq' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gdb' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:gdb-ops-additional' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:ospl' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:ftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:sftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:main/service:telnet' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:trib1/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE2/device:trib1/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:cli' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:netconf' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gnmi' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:snmp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:webui' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:https' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:zmq' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gdb' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:gdb-ops-additional' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:ospl' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:ftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:sftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:main/service:telnet' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:trib1/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE3/device:trib1/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:cli' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:netconf' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gnmi' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:snmp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:webui' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:https' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:zmq' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gdb' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:gdb-ops-additional' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:ospl' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:ftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:sftp' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:main/service:telnet' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:trib1/service:console' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: overall service_context_absolute_id 'network-element:NE4/device:trib1/service:debug-ssh' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list: device_group_context_absolute_id 'definitions:topology/device_group:group-device-group-type-qemu-01' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gnmi', device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:48.963Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE1/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE2/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE3/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:cli', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:netconf', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gnmi', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:snmp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:webui', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:https', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:zmq', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gdb', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:gdb-ops-additional', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:ospl', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:ftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:sftp', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:main/service:telnet', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:trib1/service:console', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   existing device_group service_context_absolute_id 'network-element:NE4/device:trib1/service:debug-ssh', device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37321:5000:None for network-element:NE1/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37320:5001:6022 for network-element:NE1/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37319:5002:22 for network-element:NE1/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37318:5003:830 for network-element:NE1/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37317:5004:6030 for network-element:NE1/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32843:5005:161/udp for network-element:NE1/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37316:5006:80 for network-element:NE1/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37314:5007:443 for network-element:NE1/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37312:5008:5555 for network-element:NE1/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37310:5009:10000 for network-element:NE1/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37308:5010:32767 for network-element:NE1/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu'"}
{"timestamp_utc": "2024-07-31T08:12:48.964Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37306:5011:50000 for network-element:NE1/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37305:5012:21 for network-element:NE1/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37303:5013:2202 for network-element:NE1/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37301:5014:23 for network-element:NE1/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37299:5015:None for network-element:NE1/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37297:5016:6022 for network-element:NE1/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37295:5017:None for network-element:NE2/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37293:5018:6022 for network-element:NE2/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37291:5019:22 for network-element:NE2/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37289:5020:830 for network-element:NE2/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37287:5021:6030 for network-element:NE2/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32841:5022:161/udp for network-element:NE2/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37284:5023:80 for network-element:NE2/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37282:5024:443 for network-element:NE2/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37280:5025:5555 for network-element:NE2/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37278:5026:10000 for network-element:NE2/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37276:5027:32767 for network-element:NE2/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37274:5028:50000 for network-element:NE2/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37273:5029:21 for network-element:NE2/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37271:5030:2202 for network-element:NE2/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37269:5031:23 for network-element:NE2/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37267:5032:None for network-element:NE2/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37265:5033:6022 for network-element:NE2/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37263:5034:None for network-element:NE3/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37261:5035:6022 for network-element:NE3/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37259:5036:22 for network-element:NE3/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37257:5037:830 for network-element:NE3/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37255:5038:6030 for network-element:NE3/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32839:5039:161/udp for network-element:NE3/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37252:5040:80 for network-element:NE3/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37250:5041:443 for network-element:NE3/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37248:5042:5555 for network-element:NE3/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37246:5043:10000 for network-element:NE3/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37244:5044:32767 for network-element:NE3/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37242:5045:50000 for network-element:NE3/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37240:5046:21 for network-element:NE3/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37239:5047:2202 for network-element:NE3/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37237:5048:23 for network-element:NE3/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37235:5049:None for network-element:NE3/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37233:5050:6022 for network-element:NE3/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37231:5051:None for network-element:NE4/device:main/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37229:5052:6022 for network-element:NE4/device:main/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37227:5053:22 for network-element:NE4/device:main/service:cli, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37225:5054:830 for network-element:NE4/device:main/service:netconf, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37223:5055:6030 for network-element:NE4/device:main/service:gnmi, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 32837:5056:161/udp for network-element:NE4/device:main/service:snmp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37220:5057:80 for network-element:NE4/device:main/service:webui, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37218:5058:443 for network-element:NE4/device:main/service:https, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37216:5059:5555 for network-element:NE4/device:main/service:zmq, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37214:5060:10000 for network-element:NE4/device:main/service:gdb, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37212:5061:32767 for network-element:NE4/device:main/service:gdb-ops-additional, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37210:5062:50000 for network-element:NE4/device:main/service:ospl, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37208:5063:21 for network-element:NE4/device:main/service:ftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37207:5064:2202 for network-element:NE4/device:main/service:sftp, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37205:5065:23 for network-element:NE4/device:main/service:telnet, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37203:5066:None for network-element:NE4/device:trib1/service:console, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-get-service-details INFO: get_service_info_list:   found [rtxoialp79|167.254.217.189] on ports 37201:5067:6022 for network-element:NE4/device:trib1/service:debug-ssh, device_group_type 'device-group-type-qemu' <NL> # 03:12:48 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-legacy-service-info-environment', '-v', '-v', '--service-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json', '--environment-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json', '--map-service-name', 'debug-ssh', 'dip'] <NL> # 03:12:48 ntp-create-legacy-service-info-environment INFO: arg_dict: { <NL> \"environment_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json\", <NL> \"global_host_info_flag\": true, <NL> \"map_service_name\": [ <NL> [ <NL> \"debug-ssh\", <NL> \"dip\" <NL> ] <NL> ], <NL> \"service_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json\", <NL> \"verbosity\": 2 <NL> } <NL> create-service-info-environment-json: service_info_json_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json\" <NL> create-service-info-environment-json: environment_json_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json\""}
{"timestamp_utc": "2024-07-31T08:12:48.965Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:48 ntp-topology-run.py INFO: exec_cmd: ['ntp-create-service-info-environment', '-v', '-v', '--input-file', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json', '--output-file', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--output-format', 'json']"}
{"timestamp_utc": "2024-07-31T08:12:49.222Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-create-service-info-environment INFO: Called with arguments: Namespace(input_file='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json', output_file='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', output_format='json', verbosity=2) <NL> # 03:12:49 ntp-create-service-info-environment DEBUG: Writing: /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json <NL> # 03:12:49 ntp-topology-run.py INFO: exec_cmd: ['rm', '-f', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/services-ntp.852.json'] <NL> # 03:12:49 ntp-topology-run.py INFO: done <NL> # 03:12:49 tfwk-exec-test-agent INFO: create_autop_json_fname: device_list: []"}
{"timestamp_utc": "2024-07-31T08:12:49.223Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 tfwk-exec-test-agent INFO: create_autop_json_fname: saving device_list into '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/image-info-autop.json' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs: - from fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-legacy-env.json' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CLI_PORT'=37319 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.CONSOLE_PORT'=37321 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.DIP_PORT'=37320 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.FTP_PORT'=37305 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_OPS_ADDITIONAL_PORT'=37308 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GDB_PORT'=37310 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.GNMI_PORT'=37317 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.HTTPS_PORT'=37314 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.NETCONF_PORT'=37318 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.OSPL_PORT'=37306 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SFTP_PORT'=37303 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.SNMP_PORT'=32843 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.TELNET_PORT'=37301 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.WEBUI_PORT'=37316 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.MAIN.ZMQ_PORT'=37312 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.CONSOLE_PORT'=37299 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.DIP_PORT'=37297 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CLI_PORT'=37291 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.CONSOLE_PORT'=37295 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.DIP_PORT'=37293 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.FTP_PORT'=37273 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_OPS_ADDITIONAL_PORT'=37276 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GDB_PORT'=37278 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.GNMI_PORT'=37287 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.HTTPS_PORT'=37282 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.NETCONF_PORT'=37289 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.OSPL_PORT'=37274 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SFTP_PORT'=37271 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.SNMP_PORT'=32841 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.TELNET_PORT'=37269 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.WEBUI_PORT'=37284 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_HOSTNAME'='rtxoialp79'"}
{"timestamp_utc": "2024-07-31T08:12:49.224Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.MAIN.ZMQ_PORT'=37280 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.CONSOLE_PORT'=37267 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.DIP_PORT'=37265 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CLI_PORT'=37259 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.CONSOLE_PORT'=37263 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.DIP_PORT'=37261 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.FTP_PORT'=37240 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_OPS_ADDITIONAL_PORT'=37244 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GDB_PORT'=37246 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.GNMI_PORT'=37255 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.HTTPS_PORT'=37250 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.NETCONF_PORT'=37257 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.OSPL_PORT'=37242 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SFTP_PORT'=37239 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.SNMP_PORT'=32839 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.TELNET_PORT'=37237 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.WEBUI_PORT'=37252 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.MAIN.ZMQ_PORT'=37248 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.CONSOLE_PORT'=37235 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.DIP_PORT'=37233 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CLI_PORT'=37227 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.CONSOLE_PORT'=37231 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.DIP_PORT'=37229 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.FTP_PORT'=37208 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_OPS_ADDITIONAL_PORT'=37212 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GDB_PORT'=37214 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.GNMI_PORT'=37223 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.HTTPS_PORT'=37218 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.NETCONF_PORT'=37225 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.OSPL_PORT'=37210 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SFTP_PORT'=37207 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.SNMP_PORT'=32837 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.TELNET_PORT'=37205 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.WEBUI_PORT'=37220 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_HOSTNAME'='rtxoialp79'"}
{"timestamp_utc": "2024-07-31T08:12:49.225Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.MAIN.ZMQ_PORT'=37216 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.CONSOLE_PORT'=37203 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.DIP_PORT'=37201 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.HOSTIP'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4.TRIB1.HOSTNAME'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs: - from fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli'=37319 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_cli_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console'=37321 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh'=37320 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp'=37305 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb'=37310 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional'=37308 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi'=37317 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https'=37314 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_https_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf'=37318 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl'=37306 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp'=37303 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp'=32843 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet'=37301 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui'=37316 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_webui_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq'=37312 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console'=37299 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh'=37297 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE1_trib1_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli'=37291 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_cli_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console'=37295 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh'=37293 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp'=37273 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb'=37278 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional'=37276 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi'=37287 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https'=37282 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_https_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf'=37289 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl'=37274 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp'=37271 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp'=32841 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet'=37269 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui'=37284 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui_hostip'='167.254.217.189'"}
{"timestamp_utc": "2024-07-31T08:12:49.226Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_webui_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq'=37280 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console'=37267 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh'=37265 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE2_trib1_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli'=37259 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_cli_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console'=37263 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh'=37261 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp'=37240 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb'=37246 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional'=37244 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi'=37255 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https'=37250 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_https_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf'=37257 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl'=37242 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp'=37239 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp'=32839 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet'=37237 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui'=37252 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_webui_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq'=37248 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console'=37235 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh'=37233 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE3_trib1_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli'=37227 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_cli_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console'=37231 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh'=37229 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp'=37208 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb'=37214 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional'=37212 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gdb_ops_additional_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi'=37223 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_gnmi_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https'=37218 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_https_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf'=37225 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_netconf_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl'=37210 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_ospl_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp'=37207 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_sftp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp'=32837 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_snmp_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet'=37205"}
{"timestamp_utc": "2024-07-31T08:12:49.227Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_telnet_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui'=37220 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_webui_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq'=37216 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_main_zmq_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console'=37203 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_console_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh'=37201 <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_debug_ssh_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_hostip'='167.254.217.189' <NL> # 03:12:49 tfwk-exec-test-agent INFO: export_service_defs:   env 'NE4_trib1_hostname'='rtxoialp79' <NL> # 03:12:49 tfwk-exec-test-agent INFO: exec_cmd: ['mkdir', '-p', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test-engine-output-dir'] <NL> # 03:12:49 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json', '--cmd-end', '--job-end']"}
{"timestamp_utc": "2024-07-31T08:12:49.495Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-wait-for-devices INFO: arg_dict: { <NL> \"autop_json_fname\": null, <NL> \"autop_processing\": null, <NL> \"flist_fname\": null, <NL> \"ntp_info_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"overall_timeout\": 28800, <NL> \"startup_timeout\": \"1200\", <NL> \"trailer_command\": [ <NL> \"--\", <NL> \"--job-begin-command\", <NL> \"--name\", <NL> \"Warrior\", <NL> \"--cmd-begin\", <NL> \"run_init\", <NL> \"--runinit_venv_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\", <NL> \"--services_env\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\", <NL> \"--work_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\", <NL> \"-v\", <NL> \"-e\", <NL> \"warrior\", <NL> \"--test_engine_venv_dir\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\", <NL> \"--test_engine\", <NL> \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json\", <NL> \"--cmd-end\", <NL> \"--job-end\" <NL> ], <NL> \"verbosity\": 2, <NL> \"virtualenv_dir\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\", <NL> \"wait_period\": null, <NL> \"wait_time\": null <NL> } <NL> # 03:12:49 ntp-wait-for-devices INFO: main: ntp_info_obj: { <NL> \"_NETWORK_TOPOLOGY_TAG\": \"tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> \"_SHARED_STORE_DIR\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64\", <NL> \"_TOPOLOGY_TYPE\": \"container-docker-single\" <NL> }"}
{"timestamp_utc": "2024-07-31T08:12:49.806Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE1/device:main <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-console\": [rtxoialp79] 37321 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-debug-ssh\": [rtxoialp79] 37320 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-cli\": [rtxoialp79] 37319 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE1-main-cli\": [rtxoialp79] 37319 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE1/device:trib1 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE1-trib1-console\": [rtxoialp79] 37299 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE1-trib1-debug-ssh\": [rtxoialp79] 37297 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE2/device:main <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-console\": [rtxoialp79] 37295 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-debug-ssh\": [rtxoialp79] 37293 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-cli\": [rtxoialp79] 37291 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE2-main-cli\": [rtxoialp79] 37291 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE2/device:trib1 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE2-trib1-console\": [rtxoialp79] 37267 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE2-trib1-debug-ssh\": [rtxoialp79] 37265 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE3/device:main <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-console\": [rtxoialp79] 37263 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-debug-ssh\": [rtxoialp79] 37261 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-cli\": [rtxoialp79] 37259 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE3-main-cli\": [rtxoialp79] 37259 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE3/device:trib1 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE3-trib1-console\": [rtxoialp79] 37235 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE3-trib1-debug-ssh\": [rtxoialp79] 37233 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE4/device:main <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-console\": [rtxoialp79] 37231 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-debug-ssh\": [rtxoialp79] 37229 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-cli\": [rtxoialp79] 37227 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: {'main': True, 'main-mcu-w': True} <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE4-main-cli\": [rtxoialp79] 37227 <NL> # 03:12:49 ntp-wait-for-devices INFO: main: - device_context_absolute_id network-element:NE4/device:trib1 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE4-trib1-console\": [rtxoialp79] 37203 <NL> # 03:12:49 ntp-wait-for-devices INFO: target_device_instance_name_dict: None <NL> # 03:12:49 ntp-wait-for-devices INFO: main:     take job_name \"NE4-trib1-debug-ssh\": [rtxoialp79] 37201"}
{"timestamp_utc": "2024-07-31T08:12:50.097Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: installing into VIRTUALENV_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\" <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"venv\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\""}
{"timestamp_utc": "2024-07-31T08:13:00.043Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"ensurepip\""}
{"timestamp_utc": "2024-07-31T08:13:01.935Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Requirement already satisfied: setuptools in ./.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib/python3.6/site-packages <NL> Requirement already satisfied: pip in ./.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib/python3.6/site-packages <NL> pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"pip\" \"install\" \"--upgrade\" \"pip\""}
{"timestamp_utc": "2024-07-31T08:13:03.302Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Collecting pip"}
{"timestamp_utc": "2024-07-31T08:13:03.817Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hInstalling collected packages: pip <NL> Found existing installation: pip 9.0.3"}
{"timestamp_utc": "2024-07-31T08:13:04.379Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Uninstalling pip-9.0.3:"}
{"timestamp_utc": "2024-07-31T08:13:04.635Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Successfully uninstalled pip-9.0.3"}
{"timestamp_utc": "2024-07-31T08:13:06.539Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Successfully installed pip-21.3.1 <NL> \u001b[33mYou are using pip version 21.3.1, however version 24.2 is available. <NL> You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m"}
{"timestamp_utc": "2024-07-31T08:13:06.794Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"python3\" \"-m\" \"pip\" \"install\" \"paramiko\""}
{"timestamp_utc": "2024-07-31T08:13:07.721Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Looking in indexes: https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/simple"}
{"timestamp_utc": "2024-07-31T08:13:07.978Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Collecting paramiko <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/ad/50/8792484502c8141c20c996b802fefa8435a9c018a2bb440a06b172782118/paramiko-3.4.0-py3-none-any.whl (225 kB)"}
{"timestamp_utc": "2024-07-31T08:13:08.234Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting bcrypt>=3.2 <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/aa/48/fd2b197a9741fa790ba0b88a9b10b5e88e62ff5cf3e1bc96d8354d7ce613/bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (593 kB)"}
{"timestamp_utc": "2024-07-31T08:13:10.398Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\u001b[?25hCollecting cryptography>=3.3"}
{"timestamp_utc": "2024-07-31T08:13:10.400Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "\u001b[?25hCollecting pynacl>=1.5"}
{"timestamp_utc": "2024-07-31T08:13:11.331Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting cffi>=1.12 <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/3a/12/d6066828014b9ccb2bbb8e1d9dc28872d20669b65aeb4a86806a0757813f/cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)"}
{"timestamp_utc": "2024-07-31T08:13:11.587Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hCollecting pycparser <NL> Downloading https://artifactory.fnc.fujitsu.com/artifactory/api/pypi/pypi/packages/packages/62/d5/5f610ebe421e85889f2e55e33b7f9a6795bd982198517d912eb1c76e1a53/pycparser-2.21-py2.py3-none-any.whl (118 kB)"}
{"timestamp_utc": "2024-07-31T08:13:11.843Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "\u001b[?25hInstalling collected packages: pycparser, cffi, pynacl, cryptography, bcrypt, paramiko"}
{"timestamp_utc": "2024-07-31T08:13:12.770Z", "log_type_hint": "PIP_INSTALL_INFO", "message_content": "Successfully installed bcrypt-4.0.1 cffi-1.15.1 cryptography-40.0.2 paramiko-3.4.0 pycparser-2.21 pynacl-1.5.0"}
{"timestamp_utc": "2024-07-31T08:13:13.332Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: execute: \"exec-job-tree --timeout 28800 --job-begin-parallel --name all (p) --job-begin-command --name NE1-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37321 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE1-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37299 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE2-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37295 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE2-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37267 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE3-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37263 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE3-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37235 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE4-main-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37231 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-command --name NE4-trib1-console --ignore-termination-failures --force-failure --parallel-siblings-terminate-on-my-completion --cmd-begin socket_monitor --host rtxoialp79 --port 37203 --retry-interval 5 --max-wait-time 0 --cmd-end --job-end --job-begin-serial --name start+user (s) --parallel-siblings-terminate-on-my-completion --job-begin-parallel --name startup (p) --timeout 1200 --job-begin-serial --name main-startup (s) --job-begin-command --name NE1-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37320 --delay 5 --cmd-end --job-end --job-begin-command --name NE1-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37319 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE1-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37297 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE2-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37293 --delay 5 --cmd-end --job-end --job-begin-command --name NE2-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37291 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE2-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37265 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE3-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37261 --delay 5 --cmd-end --job-end --job-begin-command --name NE3-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37259 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE3-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37233 --delay 5 --cmd-end --job-end --job-begin-serial --name main-startup (s) --job-begin-command --name NE4-main-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37229 --delay 5 --cmd-end --job-end --job-begin-command --name NE4-main-cli --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37227 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name NE4-trib1-debug-ssh --cmd-begin retry-ssh-command -v -v -v --hostname rtxoialp79 --port 37201 --delay 5 --cmd-end --job-end --job-end --job-begin-command --name Warrior --cmd-begin run_init --runinit_venv_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir --services_env /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json --work_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148 -v -e warrior --test_engine_venv_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir --test_engine /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json --cmd-end --job-end --job-end --job-end\""}
{"timestamp_utc": "2024-07-31T08:13:13.333Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pip3-virtualenv-install-and-execute-cmd: calling command: \"exec-job-tree\" \"--timeout\" \"28800\" \"--job-begin-parallel\" \"--name\" \"all (p)\" \"--job-begin-command\" \"--name\" \"NE1-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37321\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37299\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37295\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37267\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37263\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37235\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37231\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37203\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"start+user (s)\" \"--parallel-siblings-terminate-on-my-completion\" \"--job-begin-parallel\" \"--name\" \"startup (p)\" \"--timeout\" \"1200\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE1-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37320\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37319\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37297\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE2-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37293\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37291\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37265\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE3-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37261\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37259\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37233\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE4-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37229\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37227\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37201\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"Warrior\" \"--cmd-begin\" \"run_init\" \"--runinit_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\" \"--services_env\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\" \"--work_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\" \"-v\" \"-e\" \"warrior\" \"--test_engine_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\" \"--test_engine\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-end\""}
{"timestamp_utc": "2024-07-31T08:13:13.590Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: parse_arguments: ( 0) arg timeout=\"28800\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 0) \"--job-begin-parallel\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   arg name=\"all (p)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE1-main-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37321', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE1-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37299', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE2-main-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37295', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE2-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37267', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE3-main-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37263', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE3-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37235', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE4-main-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37231', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"NE4-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg ignore_termination_failures_flag=\"True\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg adjust_exit_code=\"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37203', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-begin-serial\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg name=\"start+user (s)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     arg parallel_siblings_action=\"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-begin-parallel\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       arg name=\"startup (p)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       arg timeout=\"1200\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE1-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37320', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE1-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37319', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE1-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37297', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE2-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37293', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE2-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37291', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE2-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37265', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE3-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37261', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE3-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37259', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\""}
{"timestamp_utc": "2024-07-31T08:13:13.591Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE3-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37233', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-serial\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE4-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37229', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           arg name=\"NE4-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37227', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 5)           \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         arg name=\"NE4-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37201', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 4)         \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-begin-command\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       arg name=\"Warrior\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       command ['run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json'] <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 3)       \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 2)     \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: parse_arguments: ( 1)   \"--job-end\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 0){ <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 0)  type \"none\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 0)  name \"none\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 0)  child_index None <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 0)  option \"timeout\" = \"28800\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 1)  { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 1)    type \"parallel\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 1)    name \"n01.all (p)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 1)    child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 1)    option \"name\" = \"all (p)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p01.NE1-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE1-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37321', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p02.NE1-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 1 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE1-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37299', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p03.NE2-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 2 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE2-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37295', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p04.NE2-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 3 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE2-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37267', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p05.NE3-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 4 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE3-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37263', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p06.NE3-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 5 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE3-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37235', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p07.NE4-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 6 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE4-main-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37231', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p08.NE4-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 7 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"adjust_exit_code\" = \"force-failure\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"ignore_termination_failures_flag\" = \"True\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"NE4-trib1-console\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37203', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      name \"n01.p09.start+user (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      child_index 8 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"name\" = \"start+user (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)      option \"parallel_siblings_action\" = \"terminate-always\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)      { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        type \"parallel\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        name \"n01.p09.s01.startup (p)\""}
{"timestamp_utc": "2024-07-31T08:13:13.592Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        option \"name\" = \"startup (p)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        option \"timeout\" = \"1200\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p01.main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE1-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37320', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p01.s02.NE1-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE1-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37319', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 1 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE1-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37297', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p03.main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 2 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE2-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37293', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p03.s02.NE2-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE2-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37291', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 3"}
{"timestamp_utc": "2024-07-31T08:13:13.593Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE2-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37265', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p05.main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 4 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE3-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37261', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p05.s02.NE3-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE3-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37259', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 5 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE3-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37233', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p07.main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 6 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"main-startup (s)\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 0 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE4-main-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37229', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            name \"n01.p09.s01.p07.s02.NE4-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            child_index 1 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            option \"name\" = \"NE4-main-cli\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)            command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37227', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 5)          } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          child_index 7 <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          option \"name\" = \"NE4-trib1-debug-ssh\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)          command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37201', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 4)        } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)      } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)      { <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        type \"command\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        name \"n01.p09.s02.Warrior\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        child_index 1"}
{"timestamp_utc": "2024-07-31T08:13:13.594Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        option \"name\" = \"Warrior\" <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)        command ['run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 3)      } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 2)    } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 1)  } <NL> # 03:13:13 exec-job-tree INFO: job_cl::show: ##( 0)} <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::__enter__ <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37321', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p01.NE1-main-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p01.NE1-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37321', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p01.NE1-main-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37299', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p02.NE1-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p02.NE1-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37299', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p02.NE1-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37295', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p03.NE2-main-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p03.NE2-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37295', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p03.NE2-main-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37267', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p04.NE2-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p04.NE2-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37267', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p04.NE2-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37263', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p05.NE3-main-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p05.NE3-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37263', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p05.NE3-main-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37235', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p06.NE3-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p06.NE3-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37235', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p06.NE3-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37231', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p07.NE4-main-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p07.NE4-main-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37231', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p07.NE4-main-console)"}
{"timestamp_utc": "2024-07-31T08:13:13.595Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (unexecuted) type \"command\": command ['socket_monitor', '--host', 'rtxoialp79', '--port', '37203', '--retry-interval', '5', '--max-wait-time', '0'] (n01.p08.NE4-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p08.NE4-trib1-console\", command: ['socket_monitor', '--host', 'rtxoialp79', '--port', '37203', '--retry-interval', '5', '--max-wait-time', '0'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"command\": started (n01.p08.NE4-trib1-console) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37320', '--delay', '5'] (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37320', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37297', '--delay', '5'] (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37297', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37293', '--delay', '5'] (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37293', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p03.main-startup (s))"}
{"timestamp_utc": "2024-07-31T08:13:13.596Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37265', '--delay', '5'] (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37265', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37261', '--delay', '5'] (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37261', '--delay', '5']"}
{"timestamp_utc": "2024-07-31T08:13:13.852Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37233', '--delay', '5'] (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37233', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37229', '--delay', '5'] (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37229', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"serial\": started child #0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37201', '--delay', '5'] (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37201', '--delay', '5'] <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 4)          (executing) type \"command\": started (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 3)        (executing) type \"parallel\": started 8 children (n01.p09.s01.startup (p)) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 2)      (executing) type \"serial\": started child #0 (n01.p09.start+user (s)) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 1)    (executing) type \"parallel\": started 9 children (n01.all (p)) <NL> # 03:13:13 exec-job-tree INFO: job_cl::start:  ( 0)  (executing) type \"none\": started child #0 (none) <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p01.NE1-main-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p02.NE1-trib1-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p03.NE2-main-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p04.NE2-trib1-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p05.NE3-main-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p06.NE3-trib1-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p07.NE4-main-console\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p08.NE4-trib1-console\", type \"command\""}
{"timestamp_utc": "2024-07-31T08:13:13.853Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.main-startup (s)\", type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.main-startup (s)\", type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"command\""}
{"timestamp_utc": "2024-07-31T08:13:14.113Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "# 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.main-startup (s)\", type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.main-startup (s)\", type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"command\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.startup (p)\", type \"parallel\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.start+user (s)\", type \"serial\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.all (p)\", type \"parallel\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"none\", type \"none\" <NL> # 03:13:13 exec-job-tree INFO: process_list_cl::wait: begin, timeout 28800.0 <NL> (process:683): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80"}
{"timestamp_utc": "2024-07-31T08:13:14.114Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 124254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 6053992767 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000025] tsc: Detected 2095.076 MHz processor <NL> [    0.005798] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.005907] x86/PAT: PAT not supported by the CPU. <NL> [    0.005919] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.005940] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.039528] found SMP MP-table at [mem 0x000f6340-0x000f634f] <NL> [    0.039673] check: Scanning 1 areas for low memory corruption <NL> [    0.040032] ACPI: Early table checksum verification disabled <NL> [    0.040080] ACPI: RSDP 0x00000000000F6110 000014 (v00 BOCHS ) <NL> [    0.040099] ACPI: RSDT 0x00000000BFFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.040119] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.040141] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.040151] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.040159] ACPI: SSDT 0x00000000BFFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.040168] ACPI: APIC 0x00000000BFFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.040176] ACPI: HPET 0x00000000BFFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.040183] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.040186] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.040188] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.040190] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffc33] <NL> [    0.040192] ACPI: Reserving APIC table memory at [mem 0xbffffc34-0xbffffcc3] <NL> [    0.040194] ACPI: Reserving HPET table memory at [mem 0xbffffcc4-0xbffffcfb] <NL> [    0.040342] Zone ranges: <NL> [    0.040356]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.040359]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.040362]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.040366] Movable zone start for each node <NL> [    0.040367] Early memory node ranges <NL> [    0.040370]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.040373]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.040375]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.040379] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.040452] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.040763] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.825982] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.826698] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.826722] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.826775] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.826782] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.826786] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.826788] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.826800] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.826803] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.826819] Using ACPI (MADT) for SMP configuration information <NL> [    0.826822] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.826833] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.826879] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.826882] Booting paravirtualized kernel on KVM <NL> [    0.826889] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.826907] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.829538] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.829601] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.829618] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.829622] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.835205] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.892633] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.892762] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    1.120663] Memory: 4026268K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 167368K reserved, 0K cma-reserved) <NL> [    1.120812] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    1.120841] Kernel/User page tables isolation: enabled <NL> [    1.121005] ftrace: allocating 47967 entries in 188 pages <NL> [    1.193784] ftrace: allocated 188 pages with 5 groups <NL> [    1.215607] rcu: Preemptible hierarchical RCU implementation. <NL> [    1.215624] rcu: \tRCU event tracing is enabled. <NL> [    1.215627] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    1.215629] \tTrampoline variant of Tasks RCU enabled. <NL> [    1.215630] \tRude variant of Tasks RCU enabled. <NL> [    1.215632] \tTracing variant of Tasks RCU enabled. <NL> [    1.215634] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    1.215637] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    1.223469] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    1.230033] Console: colour VGA+ 80x25 <NL> [    1.498336] printk: console [ttyS0] enabled <NL> [    1.500622] ACPI: Core revision 20200925 <NL> [    1.501373] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    1.506686] APIC: Switch to symmetric I/O mode setup <NL> [    1.508442] x2apic enabled <NL> [    1.510432] Switched APIC routing to physical x2apic. <NL> [    1.514261] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    1.517230] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    1.520679] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    1.521859] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    1.522690] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    1.523706] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    1.524683] Spectre V2 : Mitigation: Retpolines <NL> [    1.525221] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    1.525687] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT"}
{"timestamp_utc": "2024-07-31T08:13:14.115Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    1.526684] Speculative Store Bypass: Vulnerable <NL> [    1.527403] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    1.527681] MMIO Stale Data: Unknown: No mitigations <NL> [    1.528685] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.560825] Freeing SMP alternatives memory: 48K <NL> [    1.562685] pid_max: default: 32768 minimum: 301 <NL> [    1.564702] LSM: Security Framework initializing <NL> [    1.566701] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.567719] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.653675] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.654084] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.656735] rcu: Hierarchical SRCU implementation. <NL> [    1.658142] smp: Bringing up secondary CPUs ... <NL> [    1.658889] x86: Booting SMP configuration: <NL> [    1.659686] .... node  #0, CPUs:      #1 <NL> [    0.292823] kvm-clock: cpu 1, msr 124254041, secondary cpu clock <NL> [    0.292823] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    1.675771] kvm-guest: stealtime: cpu 1, msr 13bc9b600 <NL> [    1.677715]  #2 <NL> [    0.292823] kvm-clock: cpu 2, msr 124254081, secondary cpu clock <NL> [    0.292823] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    1.685760] kvm-guest: stealtime: cpu 2, msr 13bd1b600 <NL> [    1.687934]  #3 <NL> [    0.292823] kvm-clock: cpu 3, msr 1242540c1, secondary cpu clock <NL> [    0.292823] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.692769] kvm-guest: stealtime: cpu 3, msr 13bd9b600 <NL> [    1.695710] smp: Brought up 1 node, 4 CPUs <NL> [    1.696737] smpboot: Max logical packages: 4 <NL> [    1.697681] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    1.705729] devtmpfs: initialized <NL> [    1.707022] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.707692] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.708787] pinctrl core: initialized pinctrl subsystem <NL> [    1.712831] NET: Registered protocol family 16 <NL> [    1.714810] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.714813] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.717844] cpuidle: using governor menu <NL> [    1.720829] ACPI: bus type PCI registered <NL> [    1.722723] PCI: Using configuration type 1 for base access <NL> [    1.728505] Kprobes globally optimized <NL> [    1.980688] raid6: sse2x4   gen()  5071 MB/s <NL> [    1.997692] raid6: sse2x4   xor()  1867 MB/s <NL> [    2.015706] raid6: sse2x2   gen()  3109 MB/s <NL> [    2.033686] raid6: sse2x2   xor()  1782 MB/s <NL> [    2.051687] raid6: sse2x1   gen()  2383 MB/s <NL> [    2.069690] raid6: sse2x1   xor()  2200 MB/s <NL> [    2.070716] raid6: using algorithm sse2x4 gen() 5071 MB/s <NL> [    2.071700] raid6: .... xor() 1867 MB/s, rmw enabled <NL> [    2.072691] raid6: using intx1 recovery algorithm <NL> [    2.074761] ACPI: Added _OSI(Module Device) <NL> [    2.075720] ACPI: Added _OSI(Processor Device) <NL> [    2.076691] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    2.077458] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    2.077692] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    2.078686] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    2.079684] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    2.084870] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    2.088472] ACPI: Interpreter enabled <NL> [    2.088715] ACPI: (supports S0 S3 S5) <NL> [    2.089688] ACPI: Using IOAPIC for interrupt routing <NL> [    2.090800] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    2.093010] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    2.100505] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    2.100730] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    2.101715] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    2.103834] PCI host bridge to bus 0000:00 <NL> [    2.104690] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    2.105688] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    2.106686] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    2.107693] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    2.108689] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    2.110687] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    2.111691] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    2.112688] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    2.113778] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    2.117336] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    2.120079] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    2.126689] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    2.129719] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    2.130693] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    2.131694] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    2.132692] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    2.134387] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    2.136711] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    2.137703] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    2.139917] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    2.142799] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    2.145786] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    2.160822] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    2.163053] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    2.165525] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    2.167696] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    2.177690] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    2.180013] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    2.183689] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    2.186689] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    2.196690] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    2.199711] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    2.202691] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    2.205690] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    2.217690] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    2.220265] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    2.223698] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    2.226690] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    2.236710] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    2.238923] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    2.241689] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    2.245574] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    2.254689] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    2.256076] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    2.258687] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    2.261690] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    2.273691] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    2.275717] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    2.278690] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    2.281691] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    2.292690] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    2.295733] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    2.298692] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    2.301691] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    2.318747] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    2.319869] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    2.320898] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    2.322863] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    2.323805] ACPI: PCI Interrupt Link [LNKS] (IRQs *9)"}
{"timestamp_utc": "2024-07-31T08:13:14.116Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[    2.329732] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    2.330675] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    2.330694] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    2.331686] vgaarb: loaded <NL> [    2.333728] SCSI subsystem initialized <NL> [    2.338797] ACPI: bus type USB registered <NL> [    2.339788] usbcore: registered new interface driver usbfs <NL> [    2.340723] usbcore: registered new interface driver hub <NL> [    2.341512] usbcore: registered new device driver usb <NL> [    2.341753] pps_core: LinuxPPS API ver. 1 registered <NL> [    2.342688] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    2.343707] PTP clock support registered <NL> [    2.347782] Bluetooth: Core ver 2.22 <NL> [    2.348736] NET: Registered protocol family 31 <NL> [    2.349683] Bluetooth: HCI device and connection manager initialized <NL> [    2.350706] Bluetooth: HCI socket layer initialized <NL> [    2.352690] Bluetooth: L2CAP socket layer initialized <NL> [    2.353705] Bluetooth: SCO socket layer initialized <NL> [    2.358738] PCI: Using ACPI for IRQ routing <NL> [    2.360249] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    2.360711] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    2.361679] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    2.375966] clocksource: Switched to clocksource kvm-clock <NL> [    3.155544] pnp: PnP ACPI init <NL> [    3.177659] pnp: PnP ACPI: found 7 devices <NL> [    3.193849] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    3.203385] NET: Registered protocol family 2 <NL> [    3.211944] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    3.220685] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    3.232740] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    3.238981] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    3.247578] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    3.260183] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    3.261102] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    3.262134] NET: Registered protocol family 1 <NL> [    3.294056] RPC: Registered named UNIX socket transport module. <NL> [    3.294817] RPC: Registered udp transport module. <NL> [    3.295432] RPC: Registered tcp transport module. <NL> [    3.296053] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    3.296821] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    3.297557] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    3.298281] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    3.299002] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    3.299710] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    3.300473] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    3.314133] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    3.317850] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    3.320891] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    3.323232] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    3.324116] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    3.325273] PCI: CLS 0 bytes, default 64 <NL> [    3.325921] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    3.326749] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    3.353112] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    3.369950] check: Scanning for low memory corruption every 60 seconds <NL> [    3.373772] Initialise system trusted keyrings <NL> [    3.390212] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    3.414157] NFS: Registering the id_resolver key type <NL> [    3.419317] Key type id_resolver registered <NL> [    3.423120] Key type id_legacy registered <NL> [    3.448009] Key type cifs.idmap registered <NL> [    3.452211] 9p: Installing v9fs 9p2000 file system support <NL> [    3.457412] xor: measuring software checksum speed <NL> [    3.463109]    prefetch64-sse  : 10784 MB/sec <NL> [    3.474690]    generic_sse     :  7778 MB/sec <NL> [    3.484665] xor: using function: prefetch64-sse (10784 MB/sec) <NL> [    3.489036] Key type asymmetric registered <NL> [    3.490866] Asymmetric key parser 'x509' registered <NL> [    3.493498] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    3.507194] io scheduler mq-deadline registered <NL> [    3.509489] io scheduler kyber registered <NL> [    3.512533] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    3.527921] ACPI: Power Button [PWRF] <NL> [    3.529617] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    3.530295] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    3.534249] N_HDLC line discipline registered with maxframe=4096 <NL> [    3.539184] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    3.540378] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    3.541748] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    3.543580] Linux agpgart interface v0.103 <NL> [    3.548760] ACPI: bus type drm_connector registered <NL> [    3.570061] brd: module loaded <NL> [    3.576440] loop: module loaded <NL> [    3.586627] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    3.594285] vda: detected capacity change from 0 to 2576215040 <NL> [    3.612334] Uniform Multi-Platform E-IDE driver <NL> [    3.616879] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    3.623576] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    3.629929] legacy IDE will be removed in 2021, please switch to libata <NL> [    3.629929] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    3.639290]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    3.658222]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.911036] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    5.555102] hdc: MWDMA2 mode selected <NL> [    5.555936] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    5.556646] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    5.557607] ide-gd driver 1.18 <NL> [    5.571330] e100: Intel(R) PRO/100 Network Driver <NL> [    5.572092] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    5.572939] e1000: Intel(R) PRO/1000 Network Driver <NL> [    5.573644] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.575056] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    6.129940] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    6.130914] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    6.136382] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    6.727874] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:06 <NL> [    6.739682] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.761720] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.401364] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:05 <NL> [    7.411238] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    7.985172] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:03 <NL> [    7.992365] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    8.565999] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:04 <NL> [    8.592230] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    9.549604] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:02 <NL> [    9.561037] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [   10.163238] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:07 <NL> [   10.164248] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [   10.165367] e1000e: Intel(R) PRO/1000 Network Driver <NL> [   10.166070] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [   10.180125] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [   10.205946] igb: Copyright (c) 2007-2014 Intel Corporation."}
{"timestamp_utc": "2024-07-31T08:13:14.117Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   10.214518] PPP generic driver version 2.4.2 <NL> [   10.256257] PPP BSD Compression module registered <NL> [   10.258074] PPP Deflate Compression module registered <NL> [   10.260189] NET: Registered protocol family 24 <NL> [   10.261856] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [   10.297806] CSLIP: code copyright 1989 Regents of the University of California. <NL> [   10.298814] SLIP linefill/keepalive option. <NL> [   10.299544] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [   10.331149] ehci-pci: EHCI PCI platform driver <NL> [   10.332468] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [   10.343288] ohci-pci: OHCI PCI platform driver <NL> [   10.343811] uhci_hcd: USB Universal Host Controller Interface driver <NL> [   10.344660] usbcore: registered new interface driver usb-storage <NL> [   10.345469] usbcore: registered new interface driver usbserial_generic <NL> [   10.356606] usbserial: USB Serial support registered for generic <NL> [   10.357405] usbcore: registered new interface driver ftdi_sio <NL> [   10.361168] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [   10.362191] usbcore: registered new interface driver pl2303 <NL> [   10.363732] usbserial: USB Serial support registered for pl2303 <NL> [   10.366069] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [   10.376457] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [   10.390891] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [   10.393990] mousedev: PS/2 mouse device common for all mice <NL> [   10.395297] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [   10.396944] rtc_cmos 00:00: RTC can wake from S4 <NL> [   10.398582] rtc_cmos 00:00: registered as rtc0 <NL> [   10.399819] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:06 UTC (1722413586) <NL> [   10.400838] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [   10.413932] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [   10.425025] intel_pstate: CPU model not supported <NL> [   10.425609] sdhci: Secure Digital Host Controller Interface driver <NL> [   10.426267] sdhci: Copyright(c) Pierre Ossman <NL> [   10.426784] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [   10.427682] usbcore: registered new interface driver usbhid <NL> [   10.428436] usbhid: USB HID core driver <NL> [   10.429367] u32 classifier <NL> [   10.429723]     input device check on <NL> [   10.430195]     Actions configured <NL> [   10.431817] xt_time: kernel timezone is -0000 <NL> [   10.438327] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [   10.439255] gre: GRE over IPv4 demultiplexor driver <NL> [   10.439857] ip_gre: GRE over IPv4 tunneling driver <NL> [   10.441138] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [   10.465775] NET: Registered protocol family 10 <NL> [   10.471175] Segment Routing with IPv6 <NL> [   10.471998] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [   10.473246] ip6_gre: GRE over IPv6 tunneling driver <NL> [   10.474163] NET: Registered protocol family 17 <NL> [   10.479116] Bridge firewalling registered <NL> [   10.491770] 8021q: 802.1Q VLAN Support v1.8 <NL> [   10.494009] 9pnet: Installing 9P2000 support <NL> [   10.504915] Key type dns_resolver registered <NL> [   10.505667] NET: Registered protocol family 40 <NL> [   10.523633] IPI shorthand broadcast: enabled <NL> [   10.524471] sched_clock: Marking stable (10232403866, 291823486)->(11812008018, -1287780666) <NL> [   10.534020] registered taskstats version 1 <NL> [   10.535323] Loading compiled-in X.509 certificates <NL> [   10.566004] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [   10.578243] Key type .fscrypt registered <NL> [   10.583016] Key type fscrypt-provisioning registered <NL> [   10.601260] Btrfs loaded, crc32c=crc32c-generic <NL> [   10.636074] Key type encrypted registered <NL> [   10.638068] printk: console [netcon0] enabled <NL> [   10.639548] netconsole: network logging started <NL> [   11.256752] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   11.315193] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   11.353202] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   11.375939] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   11.394283] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   11.441561] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   11.474447] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   11.494722] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   11.504062] IP-Config: Failed to open gretap0 <NL> [   11.515582] IP-Config: Failed to open erspan0 <NL> [   11.535922] Sending DHCP requests . <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37321; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37321 <NL> (process:678): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024"}
{"timestamp_utc": "2024-07-31T08:13:14.118Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 10c54001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 2834339580 cycles <NL> [    0.000010] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000023] tsc: Detected 2095.076 MHz processor <NL> [    0.002396] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.002496] x86/PAT: PAT not supported by the CPU. <NL> [    0.002509] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.014817] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.015518] check: Scanning 1 areas for low memory corruption <NL> [    0.015917] ACPI: Early table checksum verification disabled <NL> [    0.015949] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.015962] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.015982] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.015994] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.016002] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.016009] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.016016] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.016023] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.016031] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.016033] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.016036] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.016038] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.016040] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.016042] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.016144] Zone ranges: <NL> [    0.016147]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.016150]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.016154]   Normal   empty <NL> [    0.016156] Movable zone start for each node <NL> [    0.016158] Early memory node ranges <NL> [    0.016161]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.016163]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.016167] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.017335] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.017368] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.025952] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.026605] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.026628] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.026675] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.026681] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.026685] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.026687] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.026698] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.026701] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.026715] Using ACPI (MADT) for SMP configuration information <NL> [    0.026718] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.026728] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.026773] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.026776] Booting paravirtualized kernel on KVM <NL> [    0.026783] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.026800] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.027887] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.027940] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.027951] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.027956] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.028443] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.028610] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.028721] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.033202] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.033287] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.033300] Kernel/User page tables isolation: enabled <NL> [    0.033342] ftrace: allocating 47967 entries in 188 pages <NL> [    0.088936] ftrace: allocated 188 pages with 5 groups <NL> [    0.089899] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.089902] rcu: \tRCU event tracing is enabled. <NL> [    0.089904] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.089906] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.089908] \tRude variant of Tasks RCU enabled. <NL> [    0.089909] \tTracing variant of Tasks RCU enabled. <NL> [    0.089912] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.089914] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.096820] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.104661] Console: colour VGA+ 80x25 <NL> [    0.442793] printk: console [ttyS0] enabled <NL> [    0.444276] ACPI: Core revision 20200925 <NL> [    0.445757] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.453784] APIC: Switch to symmetric I/O mode setup <NL> [    0.455823] x2apic enabled <NL> [    0.462548] Switched APIC routing to physical x2apic. <NL> [    0.465146] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.470106] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.471507] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.472679] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.473509] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.474521] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.475521] Spectre V2 : Mitigation: Retpolines <NL> [    0.476516] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.477514] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.478510] Speculative Store Bypass: Vulnerable <NL> [    0.479598] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.481508] MMIO Stale Data: Unknown: No mitigations <NL> [    0.482144] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.525094] Freeing SMP alternatives memory: 48K <NL> [    0.525528] pid_max: default: 32768 minimum: 301 <NL> [    0.526183] LSM: Security Framework initializing <NL> [    0.527407] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.527530] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.559504] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.559873] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.562524] rcu: Hierarchical SRCU implementation. <NL> [    0.564923] smp: Bringing up secondary CPUs ... <NL> [    0.566761] x86: Booting SMP configuration: <NL> [    0.567516] .... node  #0, CPUs:      #1 <NL> [    0.369342] kvm-clock: cpu 1, msr 10c54041, secondary cpu clock"}
{"timestamp_utc": "2024-07-31T08:13:14.119Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    0.369342] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.579602] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.580788]  #2 <NL> [    0.369342] kvm-clock: cpu 2, msr 10c54081, secondary cpu clock <NL> [    0.369342] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.591543] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.593791]  #3 <NL> [    0.369342] kvm-clock: cpu 3, msr 10c540c1, secondary cpu clock <NL> [    0.369342] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.604588] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.606518] smp: Brought up 1 node, 4 CPUs <NL> [    0.607980] smpboot: Max logical packages: 4 <NL> [    0.608515] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    0.614793] devtmpfs: initialized <NL> [    0.617675] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.618559] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.619635] pinctrl core: initialized pinctrl subsystem <NL> [    0.621948] NET: Registered protocol family 16 <NL> [    0.622854] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.622856] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.625514] cpuidle: using governor menu <NL> [    0.627620] ACPI: bus type PCI registered <NL> [    0.628619] PCI: Using configuration type 1 for base access <NL> [    0.636015] Kprobes globally optimized <NL> [    0.781514] raid6: sse2x4   gen()  4693 MB/s <NL> [    0.799515] raid6: sse2x4   xor()  2397 MB/s <NL> [    0.817513] raid6: sse2x2   gen()  4857 MB/s <NL> [    0.835513] raid6: sse2x2   xor()  1831 MB/s <NL> [    0.853515] raid6: sse2x1   gen()  3767 MB/s <NL> [    0.871517] raid6: sse2x1   xor()  2635 MB/s <NL> [    0.873527] raid6: using algorithm sse2x2 gen() 4857 MB/s <NL> [    0.874524] raid6: .... xor() 1831 MB/s, rmw enabled <NL> [    0.875517] raid6: using intx1 recovery algorithm <NL> [    0.876627] ACPI: Added _OSI(Module Device) <NL> [    0.877519] ACPI: Added _OSI(Processor Device) <NL> [    0.878519] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.879514] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.880517] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.881511] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.882511] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.887117] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.888974] ACPI: Interpreter enabled <NL> [    0.890531] ACPI: (supports S0 S3 S5) <NL> [    0.891511] ACPI: Using IOAPIC for interrupt routing <NL> [    0.892550] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.894504] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.900236] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.900530] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.901541] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.903572] PCI host bridge to bus 0000:00 <NL> [    0.904518] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.905511] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.906518] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.907515] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.908515] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.909513] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.910518] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    0.911517] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    0.912587] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.916149] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.918800] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.925518] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    0.928985] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.929521] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.930522] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.931522] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.932854] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.934517] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.935510] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.936917] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.939567] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.942579] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    0.954574] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    0.956822] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.959517] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.962518] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.971520] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    0.972873] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    0.976522] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.980388] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    0.990519] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    0.991889] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    0.994518] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    0.997517] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.007519] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.009649] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.012520] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.015517] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.024519] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.025934] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.029308] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.031520] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.044898] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.045737] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.046714] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.047706] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.048607] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.051617] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.052504] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.052524] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.053516] vgaarb: loaded <NL> [    1.054776] SCSI subsystem initialized <NL> [    1.062591] ACPI: bus type USB registered <NL> [    1.063586] usbcore: registered new interface driver usbfs <NL> [    1.064574] usbcore: registered new interface driver hub <NL> [    1.066558] usbcore: registered new device driver usb <NL> [    1.067565] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.068511] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.069542] PTP clock support registered <NL> [    1.073065] Bluetooth: Core ver 2.22 <NL> [    1.073577] NET: Registered protocol family 31 <NL> [    1.074513] Bluetooth: HCI device and connection manager initialized <NL> [    1.075532] Bluetooth: HCI socket layer initialized <NL> [    1.076526] Bluetooth: L2CAP socket layer initialized <NL> [    1.077541] Bluetooth: SCO socket layer initialized <NL> [    1.080579] PCI: Using ACPI for IRQ routing <NL> [    1.082614] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.083543] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.084512] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.093508] clocksource: Switched to clocksource kvm-clock <NL> [    2.165248] pnp: PnP ACPI init <NL> [    2.171694] pnp: PnP ACPI: found 7 devices <NL> [    2.194456] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.209371] NET: Registered protocol family 2 <NL> [    2.210082] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.211691] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear)"}
{"timestamp_utc": "2024-07-31T08:13:14.120Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    2.212922] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.213912] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.214878] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.215809] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.216649] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.217637] NET: Registered protocol family 1 <NL> [    2.255969] RPC: Registered named UNIX socket transport module. <NL> [    2.259157] RPC: Registered udp transport module. <NL> [    2.259861] RPC: Registered tcp transport module. <NL> [    2.260508] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.272020] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.272903] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.273746] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.274585] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.275524] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.276302] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.277228] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.278239] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.279035] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.279818] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.280677] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.281793] PCI: CLS 0 bytes, default 64 <NL> [    2.353010] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.397914] check: Scanning for low memory corruption every 60 seconds <NL> [    2.399294] Initialise system trusted keyrings <NL> [    2.420190] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.433712] NFS: Registering the id_resolver key type <NL> [    2.445955] Key type id_resolver registered <NL> [    2.450236] Key type id_legacy registered <NL> [    2.481884] Key type cifs.idmap registered <NL> [    2.483997] 9p: Installing v9fs 9p2000 file system support <NL> [    2.488304] xor: measuring software checksum speed <NL> [    2.491179]    prefetch64-sse  : 12280 MB/sec <NL> [    2.492547]    generic_sse     : 13264 MB/sec <NL> [    2.493200] xor: using function: generic_sse (13264 MB/sec) <NL> [    2.494026] Key type asymmetric registered <NL> [    2.494667] Asymmetric key parser 'x509' registered <NL> [    2.495474] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.509505] io scheduler mq-deadline registered <NL> [    2.514439] io scheduler kyber registered <NL> [    2.519534] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.534439] ACPI: Power Button [PWRF] <NL> [    2.551977] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.557699] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.565998] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.572383] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.578498] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.583131] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.587914] Linux agpgart interface v0.103 <NL> [    2.589903] ACPI: bus type drm_connector registered <NL> [    2.613941] brd: module loaded <NL> [    2.621427] loop: module loaded <NL> [    2.626230] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.634970] vda: detected capacity change from 0 to 2576215040 <NL> [    2.664051] Uniform Multi-Platform E-IDE driver <NL> [    2.669057] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.676059] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.681705] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.681705] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.721744]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.722339]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.983555] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.627446] hdc: MWDMA2 mode selected <NL> [    4.628111] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.628754] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.629573] ide-gd driver 1.18 <NL> [    4.639205] e100: Intel(R) PRO/100 Network Driver <NL> [    4.641519] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.646863] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.647391] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.210130] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.218510] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.227542] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    5.823391] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:09 <NL> [    5.836681] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.851502] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.773477] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:0a <NL> [    6.775610] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.778300] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    7.401735] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:0b <NL> [    7.408803] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    7.415491] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    7.418625] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    7.421932] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    7.424701] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    7.427358] PPP generic driver version 2.4.2 <NL> [    7.429828] PPP BSD Compression module registered <NL> [    7.432272] PPP Deflate Compression module registered <NL> [    7.435203] NET: Registered protocol family 24 <NL> [    7.437513] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    7.442513] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    7.445680] SLIP linefill/keepalive option. <NL> [    7.447822] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    7.451248] ehci-pci: EHCI PCI platform driver <NL> [    7.453335] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    7.456253] ohci-pci: OHCI PCI platform driver <NL> [    7.458464] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    7.461887] usbcore: registered new interface driver usb-storage <NL> [    7.463335] usbcore: registered new interface driver usbserial_generic <NL> [    7.464202] usbserial: USB Serial support registered for generic <NL> [    7.464957] usbcore: registered new interface driver ftdi_sio <NL> [    7.465715] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    7.473806] usbcore: registered new interface driver pl2303 <NL> [    7.476378] usbserial: USB Serial support registered for pl2303 <NL> [    7.480088] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    7.490869] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    7.491713] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    7.493765] mousedev: PS/2 mouse device common for all mice <NL> [    7.496449] rtc_cmos 00:00: RTC can wake from S4 <NL> [    7.499115] rtc_cmos 00:00: registered as rtc0 <NL> [    7.508735] rtc_cmos 00:00: setting system clock to 2024-07-31T08:12:59 UTC (1722413579) <NL> [    7.515393] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    7.522491] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    7.522523] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    7.534695] intel_pstate: CPU model not supported <NL> [    7.537608] sdhci: Secure Digital Host Controller Interface driver <NL> [    7.541176] sdhci: Copyright(c) Pierre Ossman <NL> [    7.543881] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    7.552199] usbcore: registered new interface driver usbhid <NL> [    7.555680] usbhid: USB HID core driver <NL> [    7.558639] u32 classifier <NL> [    7.560611]     input device check on <NL> [    7.567420]     Actions configured <NL> [    7.569238] xt_time: kernel timezone is -0000"}
{"timestamp_utc": "2024-07-31T08:13:14.121Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[    7.570124] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.571118] gre: GRE over IPv4 demultiplexor driver <NL> [    7.571804] ip_gre: GRE over IPv4 tunneling driver <NL> [    7.573002] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    7.586769] NET: Registered protocol family 10 <NL> [    7.596795] Segment Routing with IPv6 <NL> [    7.598249] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.599970] ip6_gre: GRE over IPv6 tunneling driver <NL> [    7.604121] NET: Registered protocol family 17 <NL> [    7.606929] Bridge firewalling registered <NL> [    7.609201] 8021q: 802.1Q VLAN Support v1.8 <NL> [    7.612206] 9pnet: Installing 9P2000 support <NL> [    7.614680] Key type dns_resolver registered <NL> [    7.617383] NET: Registered protocol family 40 <NL> [    7.629490] IPI shorthand broadcast: enabled <NL> [    7.632009] sched_clock: Marking stable (7263617835, 368342975)->(8637061673, -1005100863) <NL> [    7.640730] registered taskstats version 1 <NL> [    7.643309] Loading compiled-in X.509 certificates <NL> [    7.669414] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    7.675920] Key type .fscrypt registered <NL> [    7.676769] Key type fscrypt-provisioning registered <NL> [    7.684478] Btrfs loaded, crc32c=crc32c-generic <NL> [    7.696807] Key type encrypted registered <NL> [    7.698762] printk: console [netcon0] enabled <NL> [    7.699312] netconsole: network logging started <NL> [    8.232797] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    8.295261] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    8.345800] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    8.371302] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    8.385199] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    8.395064] IP-Config: Failed to open gretap0 <NL> [    8.399289] IP-Config: Failed to open erspan0 <NL> [    8.419422] Sending DHCP requests . <NL> [   10.356906] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.359445] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.360958] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   10.369926] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.417937] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.428881] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.431842] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.440084] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   10.478391] ., OK <NL> [   10.482844] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.483790] IP-Config: Complete: <NL> [   10.484206]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.486948]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.487710]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.487712]      nameserver0=10.0.2.3 <NL> [   10.688871] md: Waiting for all devices to be available before autodetect <NL> [   10.695652] md: If you don't use raid, use raid=noautodetect <NL> [   10.702458] md: Autodetecting RAID arrays. <NL> [   10.706882] md: autorun ... <NL> [   10.710050] md: ... autorun DONE. <NL> [   10.722887] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   10.764817] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   10.771411] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   10.773289] devtmpfs: mounted <NL> [   10.778449] Freeing unused kernel image (initmem) memory: 1964K <NL> [   10.780511] Write protecting the kernel read-only data: 22528k <NL> [   10.806368] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   10.816252] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   10.820346] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.342388] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.351976] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   12.076444] #####FSS INIT: Running on host <NL> [   12.349313] #####FSS INIT: FSS system init pre startup script <NL> [   12.390011] random: python3: uninitialized urandom read (24 bytes read) <NL> [   16.056448] random: crng init done <NL> [   16.751894] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   16.767153] #####FSS INIT: FSS no slotRole found <NL> [   16.772756] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   16.779474] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   16.816309] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   16.822420] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   16.827951] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   16.829130] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> sh: -d: unknown operand <NL> [   16.841082] #####FSS INIT:systemd will take it from here! <NL> [   16.896937] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   16.908977] systemd[1]: Detected virtualization kvm. <NL> [   16.914141] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   16.955712] systemd[1]: Hostname set to <fujitsu>. <NL> [   16.971704] systemd[1]: Initializing machine ID from random generator. <NL> [   17.077250] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   17.162142] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   17.719904] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.762657] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.810159] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.851931] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.923148] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.962644] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.969604] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.000006] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.002935] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:14.122Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   18.062238] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.079605] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.103620] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.118825] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.121178] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.128357] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.135717] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.161407] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.163826] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.185604] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.192840] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.226264] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.240904] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   18.243889] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   18.274451] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.281268] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.301375] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.304375] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.321195] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.340510] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.356209] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.365867] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.395440] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.405251] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.438446] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.449266] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.467146] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.477993] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.505677] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.529691] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.666551] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.698908] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.702141] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.749451] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.802847] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.881508] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.920552] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.926717] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.944253] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.955138] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.961502] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.965455] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.986685] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.990577] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.032114] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.036016] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.069787] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   19.203612] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   19.218583] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   19.234228] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   19.250881] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   19.284239] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   19.290286] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   19.299056] systemd[1]: Started Dispatch Password Requests to Console Directory Watch."}
{"timestamp_utc": "2024-07-31T08:13:14.123Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   19.311754] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   19.326752] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   19.336591] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   19.337970] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   19.346570] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   19.347939] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   19.381629] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   19.393627] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   19.431567] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   19.450214] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37299; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37299 <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37295; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37295 <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37267; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37267 <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37263; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37263 <NL> (process:680): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 16c54001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 3500570762 cycles <NL> [    0.000007] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000021] tsc: Detected 2095.076 MHz processor <NL> [    0.010754] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.010847] x86/PAT: PAT not supported by the CPU. <NL> [    0.010858] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.010873] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.049162] found SMP MP-table at [mem 0x000f6340-0x000f634f] <NL> [    0.049270] check: Scanning 1 areas for low memory corruption <NL> [    0.050100] ACPI: Early table checksum verification disabled <NL> [    0.050126] ACPI: RSDP 0x00000000000F6110 000014 (v00 BOCHS ) <NL> [    0.050140] ACPI: RSDT 0x00000000BFFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.050155] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.050165] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.050173] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.050179] ACPI: SSDT 0x00000000BFFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.050187] ACPI: APIC 0x00000000BFFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.050194] ACPI: HPET 0x00000000BFFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.050201] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.050203] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.050206] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.050208] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffc33] <NL> [    0.050210] ACPI: Reserving APIC table memory at [mem 0xbffffc34-0xbffffcc3] <NL> [    0.050212] ACPI: Reserving HPET table memory at [mem 0xbffffcc4-0xbffffcfb] <NL> [    0.050302] Zone ranges: <NL> [    0.050304]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.050307]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.050309]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.050311] Movable zone start for each node"}
{"timestamp_utc": "2024-07-31T08:13:14.124Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    0.050312] Early memory node ranges <NL> [    0.050314]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.050316]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.050318]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.050320] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.050834] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.050869] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.119557] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.120183] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.120204] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.120249] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.120255] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.120258] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.120260] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.120269] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.120272] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.120295] Using ACPI (MADT) for SMP configuration information <NL> [    0.120300] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.120309] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.120350] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.120352] Booting paravirtualized kernel on KVM <NL> [    0.120358] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.120372] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.121016] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.121064] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.121073] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.121076] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=MAIN shelfNumber=1 simulatedRole=MAIN simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.133654] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.134212] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.134328] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.242439] Memory: 4026256K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 167380K reserved, 0K cma-reserved) <NL> [    0.242519] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.242530] Kernel/User page tables isolation: enabled <NL> [    0.242566] ftrace: allocating 47967 entries in 188 pages <NL> [    0.460686] ftrace: allocated 188 pages with 5 groups <NL> [    0.461302] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.461305] rcu: \tRCU event tracing is enabled. <NL> [    0.461308] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.461310] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.461311] \tRude variant of Tasks RCU enabled. <NL> [    0.461312] \tTracing variant of Tasks RCU enabled. <NL> [    0.461315] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.461317] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.488629] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.505926] Console: colour VGA+ 80x25 <NL> [    0.863508] printk: console [ttyS0] enabled <NL> [    0.864066] ACPI: Core revision 20200925 <NL> [    0.864739] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.874120] APIC: Switch to symmetric I/O mode setup <NL> [    0.875133] x2apic enabled <NL> [    0.875791] Switched APIC routing to physical x2apic. <NL> [    0.889162] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.889935] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.891390] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.892547] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.893399] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.894396] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.895395] Spectre V2 : Mitigation: Retpolines <NL> [    0.896394] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.897395] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.898396] Speculative Store Bypass: Vulnerable <NL> [    0.898990] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.899388] MMIO Stale Data: Unknown: No mitigations <NL> [    0.899388] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.914388] Freeing SMP alternatives memory: 48K <NL> [    0.914388] pid_max: default: 32768 minimum: 301 <NL> [    0.914432] LSM: Security Framework initializing <NL> [    0.916396] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.917397] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.966506] APIC calibration not consistent with PM-Timer: 105ms instead of 100ms <NL> [    0.967388] APIC delta adjusted to PM-Timer: 6250041 (6622979) <NL> [    0.967444] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.971402] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.974520] rcu: Hierarchical SRCU implementation. <NL> [    0.976393] smp: Bringing up secondary CPUs ... <NL> [    0.977613] x86: Booting SMP configuration: <NL> [    0.978398] .... node  #0, CPUs:      #1 <NL> [    0.399437] kvm-clock: cpu 1, msr 16c54041, secondary cpu clock <NL> [    0.399437] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.984467] kvm-guest: stealtime: cpu 1, msr 13bc9b600 <NL> [    0.988404]  #2 <NL> [    0.399437] kvm-clock: cpu 2, msr 16c54081, secondary cpu clock <NL> [    0.399437] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.994445] kvm-guest: stealtime: cpu 2, msr 13bd1b600 <NL> [    0.999636]  #3 <NL> [    0.399437] kvm-clock: cpu 3, msr 16c540c1, secondary cpu clock <NL> [    0.399437] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.014451] kvm-guest: stealtime: cpu 3, msr 13bd9b600 <NL> [    1.015401] smp: Brought up 1 node, 4 CPUs <NL> [    1.016406] smpboot: Max logical packages: 4 <NL> [    1.017394] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    1.025698] devtmpfs: initialized <NL> [    1.027569] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.028406] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.029467] pinctrl core: initialized pinctrl subsystem <NL> [    1.034497] NET: Registered protocol family 16 <NL> [    1.036403] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.036405] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.038412] cpuidle: using governor menu <NL> [    1.040479] ACPI: bus type PCI registered <NL> [    1.042502] PCI: Using configuration type 1 for base access <NL> [    1.047676] Kprobes globally optimized <NL> [    1.173400] raid6: sse2x4   gen()  4687 MB/s <NL> [    1.191395] raid6: sse2x4   xor()  2994 MB/s <NL> [    1.209396] raid6: sse2x2   gen()  4965 MB/s <NL> [    1.227394] raid6: sse2x2   xor()  3279 MB/s <NL> [    1.245399] raid6: sse2x1   gen()  3836 MB/s <NL> [    1.263396] raid6: sse2x1   xor()  2550 MB/s <NL> [    1.264395] raid6: using algorithm sse2x2 gen() 4965 MB/s <NL> [    1.265396] raid6: .... xor() 3279 MB/s, rmw enabled <NL> [    1.266396] raid6: using intx1 recovery algorithm <NL> [    1.267475] ACPI: Added _OSI(Module Device) <NL> [    1.268398] ACPI: Added _OSI(Processor Device) <NL> [    1.269397] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.270392] ACPI: Added _OSI(Processor Aggregator Device)"}
{"timestamp_utc": "2024-07-31T08:13:14.125Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    1.271401] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.272399] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.273398] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.277065] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.280620] ACPI: Interpreter enabled <NL> [    1.281413] ACPI: (supports S0 S3 S5) <NL> [    1.282392] ACPI: Using IOAPIC for interrupt routing <NL> [    1.283425] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.285588] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.291335] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.291408] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.292410] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.294452] PCI host bridge to bus 0000:00 <NL> [    1.295399] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.296395] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.297397] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.298396] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.299396] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.300394] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.301396] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    1.302395] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.303476] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.306824] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.309475] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.316339] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    1.318424] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.319399] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.321397] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.322395] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.324414] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.326459] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.327406] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.328824] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.331446] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.334470] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    1.345478] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    1.347454] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.351286] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    1.353301] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.363398] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    1.364822] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.367399] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    1.370382] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.380400] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    1.381776] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.385398] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.388399] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.399414] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    1.400764] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.403408] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.406396] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.415399] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    1.416722] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    1.419402] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.422396] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    1.432398] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.434711] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    1.437402] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.439394] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    1.449254] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.450525] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    1.452401] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    1.455394] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    1.464398] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.466541] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.469261] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    1.471402] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.483507] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.484562] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.486410] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.487555] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.488491] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.492751] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.493388] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.493419] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.494392] vgaarb: loaded <NL> [    1.496596] SCSI subsystem initialized"}
{"timestamp_utc": "2024-07-31T08:13:14.386Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    1.499495] ACPI: bus type USB registered <NL> [    1.500451] usbcore: registered new interface driver usbfs <NL> [    1.501431] usbcore: registered new interface driver hub <NL> [    1.502432] usbcore: registered new device driver usb <NL> [    1.503426] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.504396] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.505416] PTP clock support registered <NL> [    1.507910] Bluetooth: Core ver 2.22 <NL> [    1.508411] NET: Registered protocol family 31 <NL> [    1.509394] Bluetooth: HCI device and connection manager initialized <NL> [    1.510404] Bluetooth: HCI socket layer initialized <NL> [    1.511402] Bluetooth: L2CAP socket layer initialized <NL> [    1.512411] Bluetooth: SCO socket layer initialized <NL> [    1.514426] PCI: Using ACPI for IRQ routing <NL> [    1.517416] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.518429] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.519392] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.548343] clocksource: Switched to clocksource kvm-clock <NL> [    2.246642] pnp: PnP ACPI init <NL> [    2.248458] pnp: PnP ACPI: found 7 devices <NL> [    2.278816] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.289828] NET: Registered protocol family 2 <NL> [    2.300651] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    2.316149] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    2.319169] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    2.326293] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    2.338927] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    2.368468] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.370621] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.379894] NET: Registered protocol family 1 <NL> [    2.390639] RPC: Registered named UNIX socket transport module. <NL> [    2.393701] RPC: Registered udp transport module. <NL> [    2.395907] RPC: Registered tcp transport module. <NL> [    2.413366] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.416736] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.424177] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.427126] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.433519] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.440479] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.441258] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.446146] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    2.454949] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.457848] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.463333] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.469979] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.478970] PCI: CLS 0 bytes, default 64 <NL> [    2.481059] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    2.488294] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    2.492488] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.551377] check: Scanning for low memory corruption every 60 seconds <NL> [    2.558603] Initialise system trusted keyrings"}
{"timestamp_utc": "2024-07-31T08:13:14.387Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[    2.561863] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    2.616560] NFS: Registering the id_resolver key type <NL> [    2.621881] Key type id_resolver registered <NL> [    2.631106] Key type id_legacy registered <NL> [    2.685533] Key type cifs.idmap registered <NL> [    2.694302] 9p: Installing v9fs 9p2000 file system support <NL> [    2.708539] xor: measuring software checksum speed <NL> [    2.718190]    prefetch64-sse  :  9677 MB/sec <NL> [    2.729357]    generic_sse     :  7107 MB/sec <NL> [    2.739921] xor: using function: prefetch64-sse (9677 MB/sec) <NL> [    2.748813] Key type asymmetric registered <NL> [    2.750993] Asymmetric key parser 'x509' registered <NL> [    2.753476] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.787422] io scheduler mq-deadline registered <NL> [    2.789969] io scheduler kyber registered <NL> [    2.800419] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.827352] ACPI: Power Button [PWRF] <NL> [    2.835995] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    2.837714] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    2.843723] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.847074] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.849144] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.869661] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.874776] Linux agpgart interface v0.103 <NL> [    2.879346] ACPI: bus type drm_connector registered <NL> [    2.913851] brd: module loaded <NL> [    2.924664] loop: module loaded <NL> [    2.928095] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.938103] vda: detected capacity change from 0 to 2576215040 <NL> [    3.000324] Uniform Multi-Platform E-IDE driver <NL> [    3.002530] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    3.017640] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    3.034705] legacy IDE will be removed in 2021, please switch to libata <NL> [    3.034705] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    3.044776]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    3.048607]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.303636] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.930692] hdc: MWDMA2 mode selected <NL> [    4.931403] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.932075] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.932940] ide-gd driver 1.18 <NL> [    4.938133] e100: Intel(R) PRO/100 Network Driver <NL> [    4.939429] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.941334] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.941925] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.943078] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    6.099125] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    6.116677] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    6.126868] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    6.976462] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:11 <NL> [    6.984827] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.986291] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    7.592618] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:10 <NL> [    7.594666] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    8.069329] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:0e <NL> [    8.070227] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    8.523472] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:0f <NL> [    8.530528] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    9.243404] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:0d <NL> [    9.245547] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    9.793331] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:12 <NL> [    9.800534] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    9.815304] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    9.816084] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    9.817007] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    9.817708] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    9.821502] PPP generic driver version 2.4.2 <NL> [    9.822251] PPP BSD Compression module registered <NL> [    9.822871] PPP Deflate Compression module registered <NL> [    9.823527] NET: Registered protocol family 24 <NL> [    9.824140] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    9.830748] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    9.831882] SLIP linefill/keepalive option. <NL> [    9.832512] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    9.833497] ehci-pci: EHCI PCI platform driver <NL> [    9.834948] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    9.835816] ohci-pci: OHCI PCI platform driver <NL> [    9.840913] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    9.841832] usbcore: registered new interface driver usb-storage <NL> [    9.842674] usbcore: registered new interface driver usbserial_generic <NL> [    9.843525] usbserial: USB Serial support registered for generic <NL> [    9.856383] usbcore: registered new interface driver ftdi_sio <NL> [    9.857187] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    9.858129] usbcore: registered new interface driver pl2303 <NL> [    9.863047] usbserial: USB Serial support registered for pl2303 <NL> [    9.863934] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    9.889959] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    9.891868] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    9.894223] mousedev: PS/2 mouse device common for all mice <NL> [    9.916532] rtc_cmos 00:00: RTC can wake from S4 <NL> [    9.920866] rtc_cmos 00:00: registered as rtc0 <NL> [    9.924057] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:03 UTC (1722413583) <NL> [    9.928487] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    9.933078] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    9.938240] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    9.950045] intel_pstate: CPU model not supported <NL> [    9.952258] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.953058] sdhci: Copyright(c) Pierre Ossman <NL> [    9.958733] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.961835] usbcore: registered new interface driver usbhid <NL> [    9.967170] usbhid: USB HID core driver <NL> [    9.978374] u32 classifier <NL> [    9.981301]     input device check on <NL> [    9.985062]     Actions configured <NL> [    9.987207] xt_time: kernel timezone is -0000 <NL> [    9.987862] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [   10.006499] gre: GRE over IPv4 demultiplexor driver <NL> [   10.007134] ip_gre: GRE over IPv4 tunneling driver <NL> [   10.031041] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [   10.032096] NET: Registered protocol family 10 <NL> [   10.043072] Segment Routing with IPv6 <NL> [   10.043747] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [   10.044894] ip6_gre: GRE over IPv6 tunneling driver <NL> [   10.045685] NET: Registered protocol family 17 <NL> [   10.069531] Bridge firewalling registered <NL> [   10.070127] 8021q: 802.1Q VLAN Support v1.8 <NL> [   10.070767] 9pnet: Installing 9P2000 support <NL> [   10.071353] Key type dns_resolver registered"}
{"timestamp_utc": "2024-07-31T08:13:14.388Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   10.072153] NET: Registered protocol family 40 <NL> [   10.085761] IPI shorthand broadcast: enabled <NL> [   10.086360] sched_clock: Marking stable (9687223725, 398437560)->(11590662835, -1505001550) <NL> [   10.087597] registered taskstats version 1 <NL> [   10.088134] Loading compiled-in X.509 certificates <NL> [   10.110704] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [   10.112144] Key type .fscrypt registered <NL> [   10.112812] Key type fscrypt-provisioning registered <NL> [   10.115896] Btrfs loaded, crc32c=crc32c-generic <NL> [   10.124977] Key type encrypted registered <NL> [   10.126616] printk: console [netcon0] enabled <NL> [   10.127174] netconsole: network logging started <NL> [   10.752853] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   10.776233] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   10.789299] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   10.818239] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   10.824208] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   10.830085] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   10.845094] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   10.886140] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> (process:684): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80 <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 123254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 3280225117 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000021] tsc: Detected 2095.076 MHz processor <NL> [    0.001724] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.001813] x86/PAT: PAT not supported by the CPU. <NL> [    0.001823] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.001835] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.013468] found SMP MP-table at [mem 0x000f6380-0x000f638f] <NL> [    0.013575] check: Scanning 1 areas for low memory corruption <NL> [    0.013957] ACPI: Early table checksum verification disabled <NL> [    0.013982] ACPI: RSDP 0x00000000000F61D0 000014 (v00 BOCHS ) <NL> [    0.013996] ACPI: RSDT 0x00000000BFFFFBC1 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.014012] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.014022] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.014029] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.014036] ACPI: SSDT 0x00000000BFFFF234 0008DD (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.014043] ACPI: APIC 0x00000000BFFFFB11 000078 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.014051] ACPI: HPET 0x00000000BFFFFB89 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.014057] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.014060] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.014062] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.014064] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffb10] <NL> [    0.014066] ACPI: Reserving APIC table memory at [mem 0xbffffb11-0xbffffb88] <NL> [    0.014068] ACPI: Reserving HPET table memory at [mem 0xbffffb89-0xbffffbc0] <NL> [    0.014628] Zone ranges: <NL> [    0.014630]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.014634]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.014637]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.014640] Movable zone start for each node <NL> [    0.014641] Early memory node ranges <NL> [    0.014644]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.014646]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.014649]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.014651] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.015207] On node 0, zone DMA: 1 pages in unavailable ranges"}
{"timestamp_utc": "2024-07-31T08:13:14.389Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    0.015240] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.039968] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.040630] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.040651] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.040697] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.040703] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.040707] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.040709] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.040718] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.040720] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.040731] Using ACPI (MADT) for SMP configuration information <NL> [    0.040735] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.040743] smpboot: Allowing 1 CPUs, 0 hotplug CPUs <NL> [    0.040782] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.040785] Booting paravirtualized kernel on KVM <NL> [    0.040791] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.040804] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:1 nr_node_ids:1 <NL> [    0.041518] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u2097152 <NL> [    0.041562] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.041571] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.041574] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.042988] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.043596] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.043645] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.076662] Memory: 4026952K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 166684K reserved, 0K cma-reserved) <NL> [    0.076730] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1 <NL> [    0.076741] Kernel/User page tables isolation: enabled <NL> [    0.076778] ftrace: allocating 47967 entries in 188 pages <NL> [    0.130124] ftrace: allocated 188 pages with 5 groups <NL> [    0.130737] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.130739] rcu: \tRCU event tracing is enabled. <NL> [    0.130742] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=1. <NL> [    0.130744] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.130746] \tRude variant of Tasks RCU enabled. <NL> [    0.130748] \tTracing variant of Tasks RCU enabled. <NL> [    0.130750] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.130752] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1 <NL> [    0.137411] NR_IRQS: 4352, nr_irqs: 256, preallocated irqs: 16 <NL> [    0.144086] Console: colour VGA+ 80x25 <NL> [    0.455950] printk: console [ttyS0] enabled <NL> [    0.456506] ACPI: Core revision 20200925 <NL> [    0.457202] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.458494] APIC: Switch to symmetric I/O mode setup <NL> [    0.459425] x2apic enabled <NL> [    0.476107] Switched APIC routing to physical x2apic. <NL> [    0.478106] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.478921] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.489878] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.491033] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.491875] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.491884] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.492883] Spectre V2 : Mitigation: Retpolines <NL> [    0.493880] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.494880] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.495881] Speculative Store Bypass: Vulnerable <NL> [    0.496881] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.497880] MMIO Stale Data: Unknown: No mitigations <NL> [    0.498464] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.526875] Freeing SMP alternatives memory: 48K <NL> [    0.526875] pid_max: default: 32768 minimum: 301 <NL> [    0.526875] LSM: Security Framework initializing <NL> [    0.527484] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.527902] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    0.557863] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.558230] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.561010] rcu: Hierarchical SRCU implementation. <NL> [    0.562979] smp: Bringing up secondary CPUs ... <NL> [    0.563622] smp: Brought up 1 node, 1 CPU <NL> [    0.563879] smpboot: Max logical packages: 1 <NL> [    0.564475] smpboot: Total of 1 processors activated (4190.15 BogoMIPS) <NL> [    0.566118] devtmpfs: initialized <NL> [    0.568107] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.568883] futex hash table entries: 256 (order: 2, 16384 bytes, linear) <NL> [    0.569920] pinctrl core: initialized pinctrl subsystem <NL> [    0.571250] NET: Registered protocol family 16 <NL> [    0.572193] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.572195] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.572959] cpuidle: using governor menu <NL> [    0.574512] ACPI: bus type PCI registered <NL> [    0.576021] PCI: Using configuration type 1 for base access <NL> [    0.579322] Kprobes globally optimized <NL> [    0.711889] raid6: sse2x4   gen()  4691 MB/s <NL> [    0.729893] raid6: sse2x4   xor()  2577 MB/s <NL> [    0.747883] raid6: sse2x2   gen()  4098 MB/s <NL> [    0.765882] raid6: sse2x2   xor()  2752 MB/s <NL> [    0.783881] raid6: sse2x1   gen()  3489 MB/s <NL> [    0.801882] raid6: sse2x1   xor()  2395 MB/s <NL> [    0.802887] raid6: using algorithm sse2x4 gen() 4691 MB/s"}
{"timestamp_utc": "2024-07-31T08:13:14.390Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    0.803887] raid6: .... xor() 2577 MB/s, rmw enabled <NL> [    0.804881] raid6: using intx1 recovery algorithm <NL> [    0.806095] ACPI: Added _OSI(Module Device) <NL> [    0.806886] ACPI: Added _OSI(Processor Device) <NL> [    0.807885] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    0.808881] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    0.809882] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    0.810454] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    0.810879] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    0.814416] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    0.816452] ACPI: Interpreter enabled <NL> [    0.816893] ACPI: (supports S0 S3 S5) <NL> [    0.817336] ACPI: Using IOAPIC for interrupt routing <NL> [    0.817898] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    0.819176] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    0.824868] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    0.824886] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    0.825888] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    0.827040] PCI host bridge to bus 0000:00 <NL> [    0.827883] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    0.828885] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    0.829880] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    0.830879] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    0.831879] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    0.832892] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    0.833881] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    0.834798] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    0.834939] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    0.838005] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    0.839586] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    0.844885] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    0.847919] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    0.848882] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    0.849891] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    0.850890] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    0.852161] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    0.853385] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    0.853889] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    0.855982] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    0.858924] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    0.861933] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    0.876928] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    0.878417] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    0.880886] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    0.883890] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    0.893891] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    0.895203] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    0.897885] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    0.900885] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    0.909885] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    0.911221] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    0.913731] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    0.915884] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    0.925886] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    0.927207] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    0.929884] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    0.932885] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    0.942886] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    0.945155] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    0.947885] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    0.949886] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    0.958887] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    0.960163] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    0.962885] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    0.965681] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    0.974704] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    0.975930] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    0.977884] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    0.980889] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    0.990695] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    0.991975] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    0.994889] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    0.997887] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.010596] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.011002] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.012014] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.013055] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.013984] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.015477] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.015875] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.015881] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.016887] vgaarb: loaded <NL> [    1.017443] SCSI subsystem initialized <NL> [    1.018036] ACPI: bus type USB registered <NL> [    1.018589] usbcore: registered new interface driver usbfs <NL> [    1.018903] usbcore: registered new interface driver hub <NL> [    1.021911] usbcore: registered new device driver usb <NL> [    1.022560] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.022880] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.023887] PTP clock support registered <NL> [    1.025380] Bluetooth: Core ver 2.22 <NL> [    1.025911] NET: Registered protocol family 31 <NL> [    1.026476] Bluetooth: HCI device and connection manager initialized"}
{"timestamp_utc": "2024-07-31T08:13:14.391Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    1.026893] Bluetooth: HCI socket layer initialized <NL> [    1.027880] Bluetooth: L2CAP socket layer initialized <NL> [    1.028517] Bluetooth: SCO socket layer initialized <NL> [    1.028981] PCI: Using ACPI for IRQ routing <NL> [    1.030257] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.030899] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.031551] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.034932] clocksource: Switched to clocksource kvm-clock <NL> [    1.955732] pnp: PnP ACPI init <NL> [    1.957125] pnp: PnP ACPI: found 7 devices <NL> [    1.980468] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.014029] NET: Registered protocol family 2 <NL> [    2.026202] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    2.044592] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    2.052241] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    2.053389] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    2.292908] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    2.309291] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.322139] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.337492] NET: Registered protocol family 1 <NL> [    2.343838] RPC: Registered named UNIX socket transport module. <NL> [    2.356991] RPC: Registered udp transport module. <NL> [    2.362551] RPC: Registered tcp transport module. <NL> [    2.364799] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.366137] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.366897] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.367692] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.368493] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.385414] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.386212] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.387079] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    2.388014] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.388725] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.406196] pci 0000:00:00.0: quirk_natoma+0x0/0x20 took 17057 usecs <NL> [    2.413353] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.414160] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.422946] PCI: CLS 0 bytes, default 64 <NL> [    2.424367] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    2.430520] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    2.431639] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.433078] check: Scanning for low memory corruption every 60 seconds <NL> [    2.445833] Initialise system trusted keyrings <NL> [    2.451726] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    2.466662] NFS: Registering the id_resolver key type <NL> [    2.475125] Key type id_resolver registered <NL> [    2.480661] Key type id_legacy registered <NL> [    2.483261] Key type cifs.idmap registered <NL> [    2.485942] 9p: Installing v9fs 9p2000 file system support <NL> [    2.489281] xor: measuring software checksum speed <NL> [    2.492942]    prefetch64-sse  :  9406 MB/sec <NL> [    2.498397]    generic_sse     :  6664 MB/sec <NL> [    2.502339] xor: using function: prefetch64-sse (9406 MB/sec) <NL> [    2.505203] Key type asymmetric registered <NL> [    2.505744] Asymmetric key parser 'x509' registered <NL> [    2.506427] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.507471] io scheduler mq-deadline registered <NL> [    2.508045] io scheduler kyber registered <NL> [    2.515421] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.524147] ACPI: Power Button [PWRF] <NL> [    2.528840] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    2.534420] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    2.539720] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.543704] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.546470] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.550891] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.555374] Linux agpgart interface v0.103 <NL> [    2.558629] ACPI: bus type drm_connector registered <NL> [    2.595891] brd: module loaded <NL> [    2.606159] loop: module loaded <NL> [    2.615004] virtio_blk virtio0: [vda] 5016568 512-byte logical blocks (2.57 GB/2.39 GiB) <NL> [    2.626539] vda: detected capacity change from 0 to 2568482816 <NL> [    2.677329] Uniform Multi-Platform E-IDE driver <NL> [    2.690365] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.701881] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.726660] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.726660] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.759680]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    2.762982]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.046236] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.691254] hdc: MWDMA2 mode selected <NL> [    4.692643] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.694164] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.695943] ide-gd driver 1.18 <NL> [    4.698182] e100: Intel(R) PRO/100 Network Driver <NL> [    4.699721] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.700682] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.701629] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.704162] PCI Interrupt Link [LNKC] enabled at IRQ 11"}
{"timestamp_utc": "2024-07-31T08:13:14.392Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    5.375586] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.376481] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.382431] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    6.146154] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:1c <NL> [    6.148156] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.152338] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.725435] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:1b <NL> [    6.732193] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    7.398004] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:19 <NL> [    7.409500] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    7.983890] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:1a <NL> [    7.994816] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    8.642514] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:18 <NL> [    8.644832] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    9.132144] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:1d <NL> [    9.134406] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    9.137153] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    9.138488] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    9.139500] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    9.140195] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    9.140924] PPP generic driver version 2.4.2 <NL> [    9.141781] PPP BSD Compression module registered <NL> [    9.142383] PPP Deflate Compression module registered <NL> [    9.143072] NET: Registered protocol family 24 <NL> [    9.143658] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    9.144842] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    9.145963] SLIP linefill/keepalive option. <NL> [    9.146526] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    9.147404] ehci-pci: EHCI PCI platform driver <NL> [    9.147993] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    9.148757] ohci-pci: OHCI PCI platform driver <NL> [    9.149896] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    9.150784] usbcore: registered new interface driver usb-storage <NL> [    9.151657] usbcore: registered new interface driver usbserial_generic <NL> [    9.152816] usbserial: USB Serial support registered for generic <NL> [    9.153621] usbcore: registered new interface driver ftdi_sio <NL> [    9.154355] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    9.155405] usbcore: registered new interface driver pl2303 <NL> [    9.156352] usbserial: USB Serial support registered for pl2303 <NL> [    9.157283] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    9.159210] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    9.159899] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    9.160741] mousedev: PS/2 mouse device common for all mice <NL> [    9.161859] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    9.164968] rtc_cmos 00:00: RTC can wake from S4 <NL> [    9.167799] rtc_cmos 00:00: registered as rtc0 <NL> [    9.168583] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:02 UTC (1722413582) <NL> [    9.179557] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    9.183526] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    9.184814] intel_pstate: CPU model not supported <NL> [    9.186942] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.188294] sdhci: Copyright(c) Pierre Ossman <NL> [    9.189433] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.190431] usbcore: registered new interface driver usbhid <NL> [    9.191133] usbhid: USB HID core driver <NL> [    9.191686] u32 classifier <NL> [    9.192033]     input device check on <NL> [    9.192991]     Actions configured <NL> [    9.195320] xt_time: kernel timezone is -0000 <NL> [    9.196511] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.197863] gre: GRE over IPv4 demultiplexor driver <NL> [    9.198897] ip_gre: GRE over IPv4 tunneling driver <NL> [    9.201078] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    9.216612] NET: Registered protocol family 10 <NL> [    9.218126] Segment Routing with IPv6 <NL> [    9.218668] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.219882] ip6_gre: GRE over IPv6 tunneling driver <NL> [    9.220756] NET: Registered protocol family 17 <NL> [    9.221412] Bridge firewalling registered <NL> [    9.222025] 8021q: 802.1Q VLAN Support v1.8 <NL> [    9.222651] 9pnet: Installing 9P2000 support <NL> [    9.223262] Key type dns_resolver registered <NL> [    9.223868] NET: Registered protocol family 40 <NL> [    9.224662] IPI shorthand broadcast: enabled <NL> [    9.225449] sched_clock: Marking stable (8876313147, 349090093)->(11002725794, -1777322554) <NL> [    9.226619] registered taskstats version 1 <NL> [    9.227172] Loading compiled-in X.509 certificates"}
{"timestamp_utc": "2024-07-31T08:13:14.393Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[    9.229509] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    9.230790] Key type .fscrypt registered <NL> [    9.245225] Key type fscrypt-provisioning registered <NL> [    9.246995] Btrfs loaded, crc32c=crc32c-generic <NL> [    9.248265] Key type encrypted registered <NL> [    9.248977] printk: console [netcon0] enabled <NL> [    9.283358] netconsole: network logging started <NL> [    9.785382] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    9.794673] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    9.812108] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    9.831771] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    9.841101] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    9.989954] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   10.016720] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   10.033794] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   10.044387] IP-Config: Failed to open gretap0 <NL> [   10.053078] IP-Config: Failed to open erspan0 <NL> [   10.084747] Sending DHCP requests . <NL> [   11.847626] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.853597] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.855587] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.866361] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   11.872268] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   11.873214] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   11.874081] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   11.874959] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   12.040620] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.052223] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.060891] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.084285] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   12.096916] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   12.100228] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   12.975349] ., OK <NL> [   12.976960] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   12.978027] IP-Config: Complete: <NL> [   12.978468]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   12.979701]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   12.980382]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   12.980384]      nameserver0=10.0.2.3 <NL> [   13.427927] md: Waiting for all devices to be available before autodetect <NL> [   13.428836] md: If you don't use raid, use raid=noautodetect <NL> [   13.429618] md: Autodetecting RAID arrays. <NL> [   13.430185] md: autorun ... <NL> [   13.430568] md: ... autorun DONE. <NL> [   13.437234] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   13.466962] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   13.467973] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   13.468990] devtmpfs: mounted <NL> [   13.472554] Freeing unused kernel image (initmem) memory: 1964K <NL> [   13.481731] Write protecting the kernel read-only data: 22528k <NL> [   13.484563] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   13.489671] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   13.490535] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   13.825484] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   13.835723] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   13.908975] #####FSS INIT: Running on host <NL> [   14.030170] #####FSS INIT: FSS system init pre startup script <NL> [   14.067032] random: python3: uninitialized urandom read (24 bytes read) <NL> [   16.285121] random: crng init done <NL> [   17.639638] #####FSS INIT: UnitCode:c200  ShelfRole:MAIN <NL> [   17.658439] #####FSS INIT: FSS no slotRole found <NL> [   17.669297] #####FSS INIT: FSS system init get inputs from PSI c200 : MAIN <NL> [   17.680961] #####FSS INIT:PI data: unitCode=c200 Role=MAIN <NL> [   17.703686] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   17.730361] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-C200-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   17.770253] #####FSS INIT:Specific Target File found : /lib/systemd/system/FSS-C200-MAIN.target"}
{"timestamp_utc": "2024-07-31T08:13:14.394Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   17.771483] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-C200-MAIN.target <NL> sh: -d: unknown operand <NL> [   17.796186] #####FSS INIT:systemd will take it from here! <NL> [   17.873670] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   17.892216] systemd[1]: Detected virtualization kvm. <NL> [   17.892885] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   17.949136] systemd[1]: Hostname set to <fujitsu>. <NL> [   17.966569] systemd[1]: Initializing machine ID from random generator. <NL> [   18.190448] systemd-sysv-generator[310]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   18.257635] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   18.743337] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.806235] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.877394] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.936169] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.973142] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.076249] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.114078] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.155955] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.190840] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.220376] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.235044] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.278325] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.299256] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.325594] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.346727] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.382078] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.410152] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.413312] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.473466] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.490209] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.535422] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.545824] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.561961] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37203; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37203 <NL> # 03:13:13 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37235; retry every 5 seconds, waiting forever <NL> # 03:13:13 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37235 <NL> (process:685): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7)"}
{"timestamp_utc": "2024-07-31T08:13:14.395Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 12054001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4735728063 cycles <NL> [    0.000010] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000023] tsc: Detected 2095.076 MHz processor <NL> [    0.002462] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.002553] x86/PAT: PAT not supported by the CPU. <NL> [    0.002565] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.075042] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.075172] check: Scanning 1 areas for low memory corruption <NL> [    0.075468] ACPI: Early table checksum verification disabled <NL> [    0.075497] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.075511] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.075528] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.075539] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.075547] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.075554] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.075561] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.075568] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.075576] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.075579] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.075581] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.075583] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.075585] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.075588] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.075675] Zone ranges: <NL> [    0.075677]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]"}
{"timestamp_utc": "2024-07-31T08:13:14.396Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    0.075681]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.075684]   Normal   empty <NL> [    0.075687] Movable zone start for each node <NL> [    0.075689] Early memory node ranges <NL> [    0.075691]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.075694]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.075698] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.076528] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.076563] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.208727] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.235312] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.235344] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.235396] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.235403] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.235407] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.235410] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.235421] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.235423] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.235436] Using ACPI (MADT) for SMP configuration information <NL> [    0.235441] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.235453] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.235498] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.235501] Booting paravirtualized kernel on KVM <NL> [    0.235508] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.235524] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.238425] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.238485] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.238498] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.238504] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.239003] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.239166] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.239297] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.265332] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.265417] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.265429] Kernel/User page tables isolation: enabled <NL> [    0.265471] ftrace: allocating 47967 entries in 188 pages <NL> [    0.443600] ftrace: allocated 188 pages with 5 groups <NL> [    0.444573] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.444576] rcu: \tRCU event tracing is enabled. <NL> [    0.444578] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.444581] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.444582] \tRude variant of Tasks RCU enabled. <NL> [    0.444584] \tTracing variant of Tasks RCU enabled. <NL> [    0.444586] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.444588] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.461682] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.510273] Console: colour VGA+ 80x25 <NL> [    1.010020] printk: console [ttyS0] enabled <NL> [    1.024284] ACPI: Core revision 20200925 <NL> [    1.032939] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    1.041673] APIC: Switch to symmetric I/O mode setup <NL> [    1.043939] x2apic enabled <NL> [    1.045267] Switched APIC routing to physical x2apic. <NL> [    1.053534] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    1.064419] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    1.069908] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    1.073064] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    1.073914] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    1.074924] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    1.075919] Spectre V2 : Mitigation: Retpolines <NL> [    1.076517] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    1.076914] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    1.077915] Speculative Store Bypass: Vulnerable <NL> [    1.078925] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    1.079913] MMIO Stale Data: Unknown: No mitigations <NL> [    1.080545] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.109398] Freeing SMP alternatives memory: 48K <NL> [    1.109937] pid_max: default: 32768 minimum: 301 <NL> [    1.110961] LSM: Security Framework initializing <NL> [    1.112033] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    1.112947] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    1.131574] APIC calibration not consistent with PM-Timer: 105ms instead of 100ms <NL> [    1.131904] APIC delta adjusted to PM-Timer: 6250017 (6612827) <NL> [    1.132915] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.134458] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.137072] rcu: Hierarchical SRCU implementation. <NL> [    1.139475] smp: Bringing up secondary CPUs ... <NL> [    1.141206] x86: Booting SMP configuration: <NL> [    1.141924] .... node  #0, CPUs:      #1 <NL> [    0.603864] kvm-clock: cpu 1, msr 12054041, secondary cpu clock <NL> [    0.603864] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    1.159982] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    1.161343]  #2 <NL> [    0.603864] kvm-clock: cpu 2, msr 12054081, secondary cpu clock"}
{"timestamp_utc": "2024-07-31T08:13:14.397Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    0.603864] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    1.165955] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    1.172357]  #3 <NL> [    0.603864] kvm-clock: cpu 3, msr 120540c1, secondary cpu clock <NL> [    0.603864] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.187955] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    1.193942] smp: Brought up 1 node, 4 CPUs <NL> [    1.194935] smpboot: Max logical packages: 4 <NL> [    1.195917] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    1.206039] devtmpfs: initialized <NL> [    1.208102] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.208930] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.210077] pinctrl core: initialized pinctrl subsystem <NL> [    1.214058] NET: Registered protocol family 16 <NL> [    1.216980] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.216982] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.218949] cpuidle: using governor menu <NL> [    1.221170] ACPI: bus type PCI registered <NL> [    1.222229] PCI: Using configuration type 1 for base access <NL> [    1.226738] Kprobes globally optimized <NL> [    1.374227] raid6: sse2x4   gen()  3487 MB/s <NL> [    1.392223] raid6: sse2x4   xor()  1620 MB/s <NL> [    1.413225] raid6: sse2x2   gen()  4445 MB/s <NL> [    1.432914] raid6: sse2x2   xor()  2606 MB/s <NL> [    1.451224] raid6: sse2x1   gen()  2443 MB/s <NL> [    1.499914] raid6: sse2x1   xor()  1851 MB/s <NL> [    1.500919] raid6: using algorithm sse2x2 gen() 4445 MB/s <NL> [    1.501918] raid6: .... xor() 2606 MB/s, rmw enabled <NL> [    1.502921] raid6: using intx1 recovery algorithm <NL> [    1.504064] ACPI: Added _OSI(Module Device) <NL> [    1.504916] ACPI: Added _OSI(Processor Device) <NL> [    1.505916] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.506535] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.506915] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.507908] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.508919] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.512634] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.514682] ACPI: Interpreter enabled <NL> [    1.514925] ACPI: (supports S0 S3 S5) <NL> [    1.515913] ACPI: Using IOAPIC for interrupt routing <NL> [    1.516946] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.519199] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.524810] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.525926] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.526935] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.528095] PCI host bridge to bus 0000:00 <NL> [    1.528916] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.529913] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.530922] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.531922] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.532918] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.533909] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.534921] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.535914] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.536685] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.538119] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.539698] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.546721] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.548786] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.548921] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.549918] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.550916] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.552987] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.554420] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.554938] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.556313] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.558994] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.562022] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.572969] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.575696] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.577918] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.580917] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.591918] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.594211] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.596916] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.599915] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.608917] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.611269] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.613917] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.616938] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.625961] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.627336] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.629914] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.632916] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.642918] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.645063] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.648783] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.650915] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.663791] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.664107] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.665102] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.666242] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.667204] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.669549] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.669904] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.669920] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.670913] vgaarb: loaded <NL> [    1.673184] SCSI subsystem initialized <NL> [    1.674044] ACPI: bus type USB registered <NL> [    1.675032] usbcore: registered new interface driver usbfs <NL> [    1.676962] usbcore: registered new interface driver hub <NL> [    1.677946] usbcore: registered new device driver usb <NL> [    1.678953] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.679908] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.680916] PTP clock support registered <NL> [    1.684148] Bluetooth: Core ver 2.22 <NL> [    1.684668] NET: Registered protocol family 31 <NL> [    1.684908] Bluetooth: HCI device and connection manager initialized <NL> [    1.685918] Bluetooth: HCI socket layer initialized <NL> [    1.686542] Bluetooth: L2CAP socket layer initialized <NL> [    1.686921] Bluetooth: SCO socket layer initialized <NL> [    1.688972] PCI: Using ACPI for IRQ routing <NL> [    1.690243] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.690930] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.691909] hpet0: 3 comparators, 64-bit 100.000000 MHz counter"}
{"timestamp_utc": "2024-07-31T08:13:14.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    1.700600] clocksource: Switched to clocksource kvm-clock <NL> [    2.418099] pnp: PnP ACPI init <NL> [    2.420078] pnp: PnP ACPI: found 7 devices <NL> [    2.434899] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.437650] NET: Registered protocol family 2 <NL> [    2.443354] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.445255] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    2.448040] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.450358] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.452825] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.458567] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.460660] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.462010] NET: Registered protocol family 1 <NL> [    2.464127] RPC: Registered named UNIX socket transport module. <NL> [    2.464953] RPC: Registered udp transport module. <NL> [    2.465556] RPC: Registered tcp transport module. <NL> [    2.466238] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.481745] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.482589] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.483390] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.484191] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.485084] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.485886] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.486780] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.487761] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.488585] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.489335] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.494343] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.495470] PCI: CLS 0 bytes, default 64 <NL> [    2.496260] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.519808] check: Scanning for low memory corruption every 60 seconds <NL> [    2.521248] Initialise system trusted keyrings <NL> [    2.522049] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.534847] NFS: Registering the id_resolver key type <NL> [    2.535560] Key type id_resolver registered <NL> [    2.536083] Key type id_legacy registered <NL> [    2.556216] Key type cifs.idmap registered <NL> [    2.556937] 9p: Installing v9fs 9p2000 file system support <NL> [    2.557764] xor: measuring software checksum speed <NL> [    2.559379]    prefetch64-sse  : 10341 MB/sec <NL> [    2.561001]    generic_sse     :  9720 MB/sec <NL> [    2.561543] xor: using function: prefetch64-sse (10341 MB/sec) <NL> [    2.562303] Key type asymmetric registered <NL> [    2.562828] Asymmetric key parser 'x509' registered <NL> [    2.563480] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.575709] io scheduler mq-deadline registered <NL> [    2.576346] io scheduler kyber registered <NL> [    2.583359] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.590751] ACPI: Power Button [PWRF] <NL> [    2.595303] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.596028] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.598071] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.598815] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.599850] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.601102] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.602759] Linux agpgart interface v0.103 <NL> [    2.603421] ACPI: bus type drm_connector registered <NL> [    2.624120] brd: module loaded <NL> [    2.634204] loop: module loaded <NL> [    2.635548] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.636514] vda: detected capacity change from 0 to 2576215040 <NL> [    2.670270] Uniform Multi-Platform E-IDE driver <NL> [    2.671201] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.672729] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.673653] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.673653] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.680152]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.680774]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    4.017818] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.656116] hdc: MWDMA2 mode selected <NL> [    4.656798] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.657446] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.658211] ide-gd driver 1.18 <NL> [    4.669050] e100: Intel(R) PRO/100 Network Driver <NL> [    4.669707] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.670440] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.671076] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.300240] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.301275] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.310725] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    6.033505] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:2a <NL> [    6.038523] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.039885] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.457627] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:2b <NL> [    6.468675] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.485233] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    6.933197] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:2c <NL> [    6.940184] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.941108] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    6.941824] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    6.943034] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    6.944212] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    6.950529] PPP generic driver version 2.4.2 <NL> [    6.952120] PPP BSD Compression module registered <NL> [    6.953637] PPP Deflate Compression module registered <NL> [    6.955110] NET: Registered protocol family 24 <NL> [    6.960095] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    6.961276] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    6.962188] SLIP linefill/keepalive option. <NL> [    6.962749] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    6.963570] ehci-pci: EHCI PCI platform driver <NL> [    6.964175] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    6.969284] ohci-pci: OHCI PCI platform driver <NL> [    6.970381] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    6.971339] usbcore: registered new interface driver usb-storage <NL> [    6.972129] usbcore: registered new interface driver usbserial_generic <NL> [    6.972945] usbserial: USB Serial support registered for generic <NL> [    6.973680] usbcore: registered new interface driver ftdi_sio <NL> [    6.974436] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    6.979446] usbcore: registered new interface driver pl2303 <NL> [    6.980162] usbserial: USB Serial support registered for pl2303 <NL> [    6.985043] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    7.018262] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    7.021059] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    7.023555] mousedev: PS/2 mouse device common for all mice <NL> [    7.047834] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    7.061742] rtc_cmos 00:00: RTC can wake from S4 <NL> [    7.063207] rtc_cmos 00:00: registered as rtc0 <NL> [    7.068731] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:00 UTC (1722413580) <NL> [    7.072166] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs"}
{"timestamp_utc": "2024-07-31T08:13:14.399Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[    7.077697] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    7.082522] intel_pstate: CPU model not supported <NL> [    7.083288] sdhci: Secure Digital Host Controller Interface driver <NL> [    7.084983] sdhci: Copyright(c) Pierre Ossman <NL> [    7.086204] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    7.087241] usbcore: registered new interface driver usbhid <NL> [    7.091994] usbhid: USB HID core driver <NL> [    7.133910] u32 classifier <NL> [    7.138449]     input device check on <NL> [    7.142602]     Actions configured <NL> [    7.148105] xt_time: kernel timezone is -0000 <NL> [    7.162295] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.170752] gre: GRE over IPv4 demultiplexor driver <NL> [    7.176369] ip_gre: GRE over IPv4 tunneling driver <NL> [    7.181394] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    7.187319] NET: Registered protocol family 10 <NL> [    7.194046] Segment Routing with IPv6 <NL> [    7.199652] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.205426] ip6_gre: GRE over IPv6 tunneling driver <NL> [    7.212933] NET: Registered protocol family 17 <NL> [    7.219321] Bridge firewalling registered <NL> [    7.219943] 8021q: 802.1Q VLAN Support v1.8 <NL> [    7.220553] 9pnet: Installing 9P2000 support <NL> [    7.221165] Key type dns_resolver registered <NL> [    7.221765] NET: Registered protocol family 40 <NL> [    7.233047] IPI shorthand broadcast: enabled <NL> [    7.235492] sched_clock: Marking stable (6632566300, 602864918)->(8381770277, -1146339059) <NL> [    7.239733] registered taskstats version 1 <NL> [    7.241975] Loading compiled-in X.509 certificates <NL> [    7.261270] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    7.267317] Key type .fscrypt registered <NL> [    7.267833] Key type fscrypt-provisioning registered <NL> [    7.278464] Btrfs loaded, crc32c=crc32c-generic <NL> [    7.295364] Key type encrypted registered <NL> [    7.299172] printk: console [netcon0] enabled <NL> [    7.302305] netconsole: network logging started <NL> [    7.828032] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    7.838417] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    7.850225] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    7.864093] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    7.881145] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    7.887696] IP-Config: Failed to open gretap0 <NL> [    7.896986] IP-Config: Failed to open erspan0 <NL> [    7.911700] Sending DHCP requests . <NL> [    9.865441] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.867979] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.872009] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.875137] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [    9.877458] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    9.879386] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [    9.932198] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.935218] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   10.805975] ., OK <NL> [   10.812221] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.813747] IP-Config: Complete: <NL> [   10.814202]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.815981]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.816719]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.816720]      nameserver0=10.0.2.3 <NL> [   11.083641] md: Waiting for all devices to be available before autodetect <NL> [   11.085287] md: If you don't use raid, use raid=noautodetect <NL> [   11.094427] md: Autodetecting RAID arrays. <NL> [   11.103697] md: autorun ... <NL> [   11.112209] md: ... autorun DONE. <NL> [   11.121622] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   11.194388] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   11.207909] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   11.216801] devtmpfs: mounted <NL> [   11.227801] Freeing unused kernel image (initmem) memory: 1964K <NL> [   11.244425] Write protecting the kernel read-only data: 22528k <NL> [   11.253561] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   11.269177] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   11.270520] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.478246] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.495863] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.593320] #####FSS INIT: Running on host <NL> [   11.735112] #####FSS INIT: FSS system init pre startup script <NL> [   11.791419] random: python3: uninitialized urandom read (24 bytes read) <NL> [   14.426898] random: crng init done <NL> [   16.050461] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   16.065741] #####FSS INIT: FSS no slotRole found <NL> [   16.066538] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   16.067489] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   16.091364] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   16.109118] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   16.111368] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   16.120012] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   16.169122] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   16.217111] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   16.261543] systemd[1]: Detected virtualization kvm. <NL> [   16.268145] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m!"}
{"timestamp_utc": "2024-07-31T08:13:14.663Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   16.290151] systemd[1]: Hostname set to <fujitsu>. <NL> [   16.299619] systemd[1]: Initializing machine ID from random generator. <NL> [   16.466933] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   16.531283] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   17.047041] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> (process:679): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 3a254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 4554034205 cycles <NL> [    0.000009] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000022] tsc: Detected 2095.076 MHz processor <NL> [    0.002357] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.002458] x86/PAT: PAT not supported by the CPU. <NL> [    0.002469] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.029252] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.029390] check: Scanning 1 areas for low memory corruption <NL> [    0.029630] ACPI: Early table checksum verification disabled <NL> [    0.029660] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.029674] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.029690] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.029701] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.029708] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.029715] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.029722] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.029729] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.029736] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.029738] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.029740] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.029742] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.029744] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.029745] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.029832] Zone ranges: <NL> [    0.029835]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.029839]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.029842]   Normal   empty <NL> [    0.029845] Movable zone start for each node <NL> [    0.029846] Early memory node ranges <NL> [    0.029849]   node   0: [mem 0x0000000000001000-0x000000000009efff]"}
{"timestamp_utc": "2024-07-31T08:13:14.664Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    0.029851]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.029855] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.030687] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.030716] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.040340] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.040972] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.040995] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.041042] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.041048] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.041052] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.041054] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.041064] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.041066] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.041079] Using ACPI (MADT) for SMP configuration information <NL> [    0.041082] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.041092] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.041136] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.041139] Booting paravirtualized kernel on KVM <NL> [    0.041145] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.041161] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.042368] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.042431] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.042441] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.042445] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=1 simulatedRole=TRIB simulatedShelf=1 serialNum=sim_ slotNumber=0 <NL> [    0.043006] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.043154] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.043265] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.051136] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.051222] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.051234] Kernel/User page tables isolation: enabled <NL> [    0.051272] ftrace: allocating 47967 entries in 188 pages <NL> [    0.151682] ftrace: allocated 188 pages with 5 groups <NL> [    0.152767] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.152771] rcu: \tRCU event tracing is enabled. <NL> [    0.152773] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.152776] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.152777] \tRude variant of Tasks RCU enabled. <NL> [    0.152778] \tTracing variant of Tasks RCU enabled. <NL> [    0.152781] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.152782] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.167909] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.188897] Console: colour VGA+ 80x25 <NL> [    0.544712] printk: console [ttyS0] enabled <NL> [    0.545325] ACPI: Core revision 20200925 <NL> [    0.546206] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.564723] APIC: Switch to symmetric I/O mode setup <NL> [    0.565774] x2apic enabled <NL> [    0.566465] Switched APIC routing to physical x2apic. <NL> [    0.568698] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.569492] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.570826] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.572019] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.572827] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.573564] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.573830] Spectre V2 : Mitigation: Retpolines <NL> [    0.574362] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.574827] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.575827] Speculative Store Bypass: Vulnerable <NL> [    0.576839] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.577650] MMIO Stale Data: Unknown: No mitigations <NL> [    0.577840] x86/fpu: x87 FPU will use FXSAVE <NL> [    0.622879] Freeing SMP alternatives memory: 48K <NL> [    0.623847] pid_max: default: 32768 minimum: 301 <NL> [    0.624875] LSM: Security Framework initializing <NL> [    0.625944] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.626871] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    0.697904] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    0.701098] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    0.702991] rcu: Hierarchical SRCU implementation. <NL> [    0.704438] smp: Bringing up secondary CPUs ... <NL> [    0.705168] x86: Booting SMP configuration: <NL> [    0.705828] .... node  #0, CPUs:      #1 <NL> [    0.384915] kvm-clock: cpu 1, msr 3a254041, secondary cpu clock <NL> [    0.384915] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    0.709869] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    0.714051]  #2 <NL> [    0.384915] kvm-clock: cpu 2, msr 3a254081, secondary cpu clock <NL> [    0.384915] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    0.718909] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    0.720253]  #3 <NL> [    0.384915] kvm-clock: cpu 3, msr 3a2540c1, secondary cpu clock <NL> [    0.384915] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    0.730894] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    0.732844] smp: Brought up 1 node, 4 CPUs <NL> [    0.733843] smpboot: Max logical packages: 4 <NL> [    0.734411] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    0.739940] devtmpfs: initialized <NL> [    0.742869] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    0.743855] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    0.745018] pinctrl core: initialized pinctrl subsystem <NL> [    0.750085] NET: Registered protocol family 16 <NL> [    0.751259] thermal_sys: Registered thermal governor 'step_wise' <NL> [    0.751260] thermal_sys: Registered thermal governor 'user_space' <NL> [    0.753866] cpuidle: using governor menu <NL> [    0.755955] ACPI: bus type PCI registered <NL> [    0.757843] PCI: Using configuration type 1 for base access <NL> [    0.764974] Kprobes globally optimized <NL> [    0.958832] raid6: sse2x4   gen()  6518 MB/s <NL> [    0.976832] raid6: sse2x4   xor()  3002 MB/s <NL> [    0.994830] raid6: sse2x2   gen()  4215 MB/s <NL> [    1.012832] raid6: sse2x2   xor()  4090 MB/s <NL> [    1.030831] raid6: sse2x1   gen()  3893 MB/s"}
{"timestamp_utc": "2024-07-31T08:13:14.665Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    1.048834] raid6: sse2x1   xor()  3106 MB/s <NL> [    1.049842] raid6: using algorithm sse2x4 gen() 6518 MB/s <NL> [    1.050837] raid6: .... xor() 3002 MB/s, rmw enabled <NL> [    1.051834] raid6: using intx1 recovery algorithm <NL> [    1.052940] ACPI: Added _OSI(Module Device) <NL> [    1.053835] ACPI: Added _OSI(Processor Device) <NL> [    1.054835] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.055834] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.056835] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.057416] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.057827] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.062484] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.065931] ACPI: Interpreter enabled <NL> [    1.066849] ACPI: (supports S0 S3 S5) <NL> [    1.067836] ACPI: Using IOAPIC for interrupt routing <NL> [    1.068869] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.070131] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.074965] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.075850] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.076854] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.079003] PCI host bridge to bus 0000:00 <NL> [    1.079831] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.080831] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.081830] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.082829] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.083828] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.084829] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.085828] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.086832] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.087902] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.091179] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.094086] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.100831] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.103908] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.104837] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.105833] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.106832] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.108142] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.109343] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.109847] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.112129] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.114881] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.117879] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.129882] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.131507] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.133679] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.135834] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.146836] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.148211] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.150690] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.152834] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.161835] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.163953] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.166834] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.169832] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.180834] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.182199] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.185834] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.188837] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.197836] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.199086] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.201836] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.204834] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.217334] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.217937] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.219007] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.220878] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.221928] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.225902] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.226822] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.226837] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.227833] vgaarb: loaded <NL> [    1.229100] SCSI subsystem initialized <NL> [    1.231925] ACPI: bus type USB registered <NL> [    1.232898] usbcore: registered new interface driver usbfs <NL> [    1.233845] usbcore: registered new interface driver hub <NL> [    1.234528] usbcore: registered new device driver usb <NL> [    1.234858] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.235826] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.236858] PTP clock support registered <NL> [    1.241206] Bluetooth: Core ver 2.22 <NL> [    1.241866] NET: Registered protocol family 31 <NL> [    1.242831] Bluetooth: HCI device and connection manager initialized <NL> [    1.243850] Bluetooth: HCI socket layer initialized <NL> [    1.244840] Bluetooth: L2CAP socket layer initialized <NL> [    1.245846] Bluetooth: SCO socket layer initialized <NL> [    1.246894] PCI: Using ACPI for IRQ routing <NL> [    1.249117] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.249870] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.250832] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.260581] clocksource: Switched to clocksource kvm-clock <NL> [    1.757883] pnp: PnP ACPI init <NL> [    1.762941] pnp: PnP ACPI: found 7 devices <NL> [    1.786273] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    1.797136] NET: Registered protocol family 2 <NL> [    1.802475] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    1.812391] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    1.820987] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.824803] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    1.828500] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    1.830308] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.831135] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    1.832089] NET: Registered protocol family 1"}
{"timestamp_utc": "2024-07-31T08:13:14.666Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    1.868006] RPC: Registered named UNIX socket transport module. <NL> [    1.871732] RPC: Registered udp transport module. <NL> [    1.872371] RPC: Registered tcp transport module. <NL> [    1.873013] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    1.873894] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    1.874746] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    1.882062] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    1.883929] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    1.884715] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    1.885555] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    1.886448] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    1.887428] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    1.895752] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    1.898671] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    1.899528] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    1.900676] PCI: CLS 0 bytes, default 64 <NL> [    1.906114] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    1.933382] check: Scanning for low memory corruption every 60 seconds <NL> [    1.937154] Initialise system trusted keyrings <NL> [    1.946955] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    1.959778] NFS: Registering the id_resolver key type <NL> [    1.964755] Key type id_resolver registered <NL> [    1.967789] Key type id_legacy registered <NL> [    2.009809] Key type cifs.idmap registered <NL> [    2.013791] 9p: Installing v9fs 9p2000 file system support <NL> [    2.016949] xor: measuring software checksum speed <NL> [    2.022750]    prefetch64-sse  :  9215 MB/sec <NL> [    2.030043]    generic_sse     :  6735 MB/sec <NL> [    2.034385] xor: using function: prefetch64-sse (9215 MB/sec) <NL> [    2.037602] Key type asymmetric registered <NL> [    2.039819] Asymmetric key parser 'x509' registered <NL> [    2.041857] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.045636] io scheduler mq-deadline registered <NL> [    2.049798] io scheduler kyber registered <NL> [    2.062623] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.073003] ACPI: Power Button [PWRF] <NL> [    2.094356] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.095104] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.111659] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.118777] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.129593] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.137652] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.147366] Linux agpgart interface v0.103 <NL> [    2.151181] ACPI: bus type drm_connector registered <NL> [    2.162918] brd: module loaded <NL> [    2.173284] loop: module loaded <NL> [    2.177228] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.187797] vda: detected capacity change from 0 to 2576215040 <NL> [    2.198095] Uniform Multi-Platform E-IDE driver <NL> [    2.203480] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.213034] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.218482] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.218482] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.232164]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.234848]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.475778] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.100675] hdc: MWDMA2 mode selected <NL> [    4.101394] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.103386] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.104249] ide-gd driver 1.18 <NL> [    4.108628] e100: Intel(R) PRO/100 Network Driver <NL> [    4.110549] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    4.111361] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.113969] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    4.744778] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    4.746474] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    4.748015] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    5.343802] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:1f <NL> [    5.346311] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    5.350784] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.011335] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:20 <NL> [    6.012190] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.016940] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    6.662762] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:21 <NL> [    6.665000] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    6.667149] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    6.668138] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    6.669126] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    6.669812] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    6.671084] PPP generic driver version 2.4.2 <NL> [    6.672739] PPP BSD Compression module registered <NL> [    6.673478] PPP Deflate Compression module registered <NL> [    6.674147] NET: Registered protocol family 24"}
{"timestamp_utc": "2024-07-31T08:13:14.667Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[    6.674743] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    6.675951] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    6.676876] SLIP linefill/keepalive option. <NL> [    6.677426] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    6.678261] ehci-pci: EHCI PCI platform driver <NL> [    6.678869] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    6.679676] ohci-pci: OHCI PCI platform driver <NL> [    6.680266] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    6.681143] usbcore: registered new interface driver usb-storage <NL> [    6.681949] usbcore: registered new interface driver usbserial_generic <NL> [    6.682791] usbserial: USB Serial support registered for generic <NL> [    6.683559] usbcore: registered new interface driver ftdi_sio <NL> [    6.684291] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    6.685228] usbcore: registered new interface driver pl2303 <NL> [    6.699172] usbserial: USB Serial support registered for pl2303 <NL> [    6.701110] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    6.721445] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    6.736767] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    6.738685] mousedev: PS/2 mouse device common for all mice <NL> [    6.747611] rtc_cmos 00:00: RTC can wake from S4 <NL> [    6.754077] rtc_cmos 00:00: registered as rtc0 <NL> [    6.761146] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    6.770627] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:00 UTC (1722413580) <NL> [    6.773387] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    6.795856] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    6.803677] intel_pstate: CPU model not supported <NL> [    6.805197] sdhci: Secure Digital Host Controller Interface driver <NL> [    6.811178] sdhci: Copyright(c) Pierre Ossman <NL> [    6.812311] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    6.818231] usbcore: registered new interface driver usbhid <NL> [    6.818978] usbhid: USB HID core driver <NL> [    6.823666] u32 classifier <NL> [    6.824527]     input device check on <NL> [    6.825314]     Actions configured <NL> [    6.827291] xt_time: kernel timezone is -0000 <NL> [    6.828697] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.833940] gre: GRE over IPv4 demultiplexor driver <NL> [    6.838238] ip_gre: GRE over IPv4 tunneling driver <NL> [    6.844051] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    6.848804] NET: Registered protocol family 10 <NL> [    6.865903] Segment Routing with IPv6 <NL> [    6.866656] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    6.867844] ip6_gre: GRE over IPv6 tunneling driver <NL> [    6.873976] NET: Registered protocol family 17 <NL> [    6.874637] Bridge firewalling registered <NL> [    6.875230] 8021q: 802.1Q VLAN Support v1.8 <NL> [    6.875834] 9pnet: Installing 9P2000 support <NL> [    6.876418] Key type dns_resolver registered <NL> [    6.877059] NET: Registered protocol family 40 <NL> [    6.883996] IPI shorthand broadcast: enabled <NL> [    6.884614] sched_clock: Marking stable (6500010230, 383915812)->(8032767036, -1148840994) <NL> [    6.885744] registered taskstats version 1 <NL> [    6.886289] Loading compiled-in X.509 certificates <NL> [    6.941919] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    6.943290] Key type .fscrypt registered <NL> [    6.943817] Key type fscrypt-provisioning registered <NL> [    6.945131] Btrfs loaded, crc32c=crc32c-generic <NL> [    6.990468] Key type encrypted registered <NL> [    6.992168] printk: console [netcon0] enabled <NL> [    6.993739] netconsole: network logging started <NL> [    7.502943] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    7.539654] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    7.557202] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    7.570443] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    7.587872] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    7.589895] IP-Config: Failed to open gretap0 <NL> [    7.591344] IP-Config: Failed to open erspan0 <NL> [    7.611618] Sending DHCP requests . <NL> [    9.570560] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.573357] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.575061] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [    9.576095] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [    9.623793] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.641911] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [    9.659129] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [    9.663223] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   10.244589] ., OK <NL> [   10.246266] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   10.247137] IP-Config: Complete: <NL> [   10.247526]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   10.250639]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   10.251710]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   10.251712]      nameserver0=10.0.2.3 <NL> [   10.467374] md: Waiting for all devices to be available before autodetect <NL> [   10.471393] md: If you don't use raid, use raid=noautodetect <NL> [   10.482845] md: Autodetecting RAID arrays. <NL> [   10.483458] md: autorun ... <NL> [   10.483875] md: ... autorun DONE. <NL> [   10.488708] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   10.552872] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   10.555979] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   10.558298] devtmpfs: mounted <NL> [   10.576695] Freeing unused kernel image (initmem) memory: 1964K <NL> [   10.585315] Write protecting the kernel read-only data: 22528k <NL> [   10.596190] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   10.628192] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   10.636716] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   11.132021] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   11.151793] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   11.321212] #####FSS INIT: Running on host <NL> [   11.608965] #####FSS INIT: FSS system init pre startup script <NL> [   11.640565] random: python3: uninitialized urandom read (24 bytes read)"}
{"timestamp_utc": "2024-07-31T08:13:14.668Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   14.075951] random: crng init done <NL> [   15.308834] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   15.311751] #####FSS INIT: FSS no slotRole found <NL> [   15.312412] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   15.313320] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   15.321167] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   15.328377] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   15.330491] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   15.335975] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   15.340899] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   15.393277] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   15.413217] systemd[1]: Detected virtualization kvm. <NL> [   15.414744] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   15.419458] systemd[1]: Hostname set to <fujitsu>. <NL> [   15.420901] systemd[1]: Initializing machine ID from random generator. <NL> [   15.548008] systemd-sysv-generator[344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   15.633486] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   16.600790] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.613213] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.657433] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.735033] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.803415] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.850341] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.859377] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.896121] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.905318] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   16.997660] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.000468] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.027647] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.050720] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.061941] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.076714] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.088288] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.180271] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.203659] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.236504] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.244795] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.285124] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.297409] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.311890] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.329590] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.347290] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.365267] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.384515] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.418038] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.443037] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.454897] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.472145] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.518119] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.539042] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.566289] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.582493] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.627119] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.631238] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.654980] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.673059] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.750219] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.840995] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:14.669Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   17.844101] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.862208] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.930797] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.938847] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.970645] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.989212] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.052675] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.066743] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.131481] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.195189] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.262089] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.299763] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.356383] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.365726] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.441803] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   18.541867] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   18.561478] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   18.616332] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   18.645445] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   18.741502] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   18.761983] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   18.770980] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   18.785399] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   18.787291] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   18.799735] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   18.812247] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   18.825647] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   18.847818] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   18.906760] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   18.914220] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   18.923910] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   18.958167] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [   17.095089] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.131762] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.207813] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.268760] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.324828] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.359929] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.402899] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.440786] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:14.670Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   17.527581] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.541044] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.575977] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.586301] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.590846] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.615013] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.624952] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.659348] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.689770] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.714636] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.732204] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.763355] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.779527] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.782707] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   17.834774] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.859796] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.892807] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.924051] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.982684] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   17.997568] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.026551] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.034189] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.051898] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.060149] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.089639] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.104591] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.148942] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.163560] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.211692] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.231822] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.294768] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.346477] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.372763] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.395656] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:14.671Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   18.427919] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.447280] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.482853] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.486044] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.518306] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.541776] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.561459] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.582819] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.621771] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.632401] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.653692] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.674091] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   18.732548] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   18.834556] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   18.837588] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   18.897268] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   18.977524] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   19.011898] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   19.014526] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   19.027024] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   19.037037] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   19.039306] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   19.052675] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   19.054001] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   19.073640] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   19.075036] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   19.158313] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   19.161142] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   19.177457] systemd[1]: Listening on Process Core Dump Socket. <NL> (process:682): GLib-WARNING **: 03:12:48.157: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+3FF944D0+3FED44D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM 3FF944D0 3FED44D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.000000] BIOS-provided physical RAM map:"}
{"timestamp_utc": "2024-07-31T08:13:14.672Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000003fffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000003fffc000-0x000000003fffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 23e54001, primary cpu clock <NL> [    0.000000] kvm-clock: using sched offset of 4377268691 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000024] tsc: Detected 2095.076 MHz processor <NL> [    0.001788] last_pfn = 0x3fffc max_arch_pfn = 0x400000000 <NL> [    0.001882] x86/PAT: PAT not supported by the CPU. <NL> [    0.001894] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.014858] found SMP MP-table at [mem 0x000f6360-0x000f636f] <NL> [    0.015326] check: Scanning 1 areas for low memory corruption <NL> [    0.015654] ACPI: Early table checksum verification disabled <NL> [    0.015686] ACPI: RSDP 0x00000000000F6150 000014 (v00 BOCHS ) <NL> [    0.015700] ACPI: RSDT 0x000000003FFFFCFC 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.015718] ACPI: FACP 0x000000003FFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.015729] ACPI: DSDT 0x000000003FFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.015737] ACPI: FACS 0x000000003FFFE000 000040 <NL> [    0.015744] ACPI: SSDT 0x000000003FFFF234 000A00 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.015752] ACPI: APIC 0x000000003FFFFC34 000090 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.015759] ACPI: HPET 0x000000003FFFFCC4 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.015766] ACPI: Reserving FACP table memory at [mem 0x3ffff1c0-0x3ffff233] <NL> [    0.015769] ACPI: Reserving DSDT table memory at [mem 0x3fffe040-0x3ffff1bf] <NL> [    0.015771] ACPI: Reserving FACS table memory at [mem 0x3fffe000-0x3fffe03f] <NL> [    0.015773] ACPI: Reserving SSDT table memory at [mem 0x3ffff234-0x3ffffc33] <NL> [    0.015775] ACPI: Reserving APIC table memory at [mem 0x3ffffc34-0x3ffffcc3] <NL> [    0.015777] ACPI: Reserving HPET table memory at [mem 0x3ffffcc4-0x3ffffcfb] <NL> [    0.015867] Zone ranges: <NL> [    0.015870]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.015874]   DMA32    [mem 0x0000000001000000-0x000000003fffbfff] <NL> [    0.015877]   Normal   empty <NL> [    0.015879] Movable zone start for each node <NL> [    0.015881] Early memory node ranges <NL> [    0.015884]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.015886]   node   0: [mem 0x0000000000100000-0x000000003fffbfff] <NL> [    0.015890] Initmem setup node 0 [mem 0x0000000000001000-0x000000003fffbfff] <NL> [    0.016748] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.016780] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.032852] On node 0, zone DMA32: 4 pages in unavailable ranges <NL> [    0.033508] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.033532] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.033579] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.033585] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.033590] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.033592] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.033601] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.033604] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.033616] Using ACPI (MADT) for SMP configuration information <NL> [    0.033620] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.033631] smpboot: Allowing 4 CPUs, 0 hotplug CPUs <NL> [    0.033675] [mem 0x40000000-0xfeffbfff] available for PCI devices <NL> [    0.033678] Booting paravirtualized kernel on KVM <NL> [    0.033711] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.033728] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:4 nr_node_ids:1 <NL> [    0.034899] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u524288 <NL> [    0.034958] kvm-guest: stealtime: cpu 0, msr 3ec1b600 <NL> [    0.034969] Built 1 zonelists, mobility grouping on.  Total pages: 257925 <NL> [    0.034972] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=TRIB_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xf9fc unitName=L1-OTSG2 shelfRole=TRIB shelfNumber=2 simulatedRole=TRIB simulatedShelf=2 serialNum=sim_ slotNumber=0 <NL> [    0.035528] Dentry cache hash table entries: 131072 (order: 8, 1048576 bytes, linear) <NL> [    0.035688] Inode-cache hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    0.035850] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    0.040483] Memory: 1000220K/1048168K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 47688K reserved, 0K cma-reserved) <NL> [    0.040571] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=4, Nodes=1 <NL> [    0.040584] Kernel/User page tables isolation: enabled <NL> [    0.040628] ftrace: allocating 47967 entries in 188 pages <NL> [    0.186179] ftrace: allocated 188 pages with 5 groups <NL> [    0.189461] rcu: Preemptible hierarchical RCU implementation. <NL> [    0.189467] rcu: \tRCU event tracing is enabled. <NL> [    0.189470] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=4. <NL> [    0.189473] \tTrampoline variant of Tasks RCU enabled. <NL> [    0.189475] \tRude variant of Tasks RCU enabled. <NL> [    0.189476] \tTracing variant of Tasks RCU enabled. <NL> [    0.189479] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    0.189481] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=4 <NL> [    0.213303] NR_IRQS: 4352, nr_irqs: 456, preallocated irqs: 16 <NL> [    0.231047] Console: colour VGA+ 80x25 <NL> [    0.875709] printk: console [ttyS0] enabled <NL> [    0.879447] ACPI: Core revision 20200925 <NL> [    0.883436] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    0.889662] APIC: Switch to symmetric I/O mode setup <NL> [    0.894739] x2apic enabled <NL> [    0.898509] Switched APIC routing to physical x2apic. <NL> [    0.908653] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    0.911070] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    0.936267] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    0.938429] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    0.939269] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    0.940277] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    0.941271] Spectre V2 : Mitigation: Retpolines <NL> [    0.942267] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    0.943269] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    0.944272] Speculative Store Bypass: Vulnerable <NL> [    0.945281] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    0.947267] MMIO Stale Data: Unknown: No mitigations <NL> [    0.949266] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.022280] Freeing SMP alternatives memory: 48K <NL> [    1.022922] pid_max: default: 32768 minimum: 301 <NL> [    1.023262] LSM: Security Framework initializing <NL> [    1.023407] Mount-cache hash table entries: 2048 (order: 2, 16384 bytes, linear)"}
{"timestamp_utc": "2024-07-31T08:13:14.673Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    1.024308] Mountpoint-cache hash table entries: 2048 (order: 2, 16384 bytes, linear) <NL> [    1.065358] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.067581] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.070488] rcu: Hierarchical SRCU implementation. <NL> [    1.071909] smp: Bringing up secondary CPUs ... <NL> [    1.072682] x86: Booting SMP configuration: <NL> [    1.073278] .... node  #0, CPUs:      #1 <NL> [    0.717803] kvm-clock: cpu 1, msr 23e54041, secondary cpu clock <NL> [    0.717803] smpboot: CPU 1 Converting physical 0 to logical die 1 <NL> [    1.089346] kvm-guest: stealtime: cpu 1, msr 3ec9b600 <NL> [    1.091695]  #2 <NL> [    0.717803] kvm-clock: cpu 2, msr 23e54081, secondary cpu clock <NL> [    0.717803] smpboot: CPU 2 Converting physical 0 to logical die 2 <NL> [    1.096363] kvm-guest: stealtime: cpu 2, msr 3ed1b600 <NL> [    1.100553]  #3 <NL> [    0.717803] kvm-clock: cpu 3, msr 23e540c1, secondary cpu clock <NL> [    0.717803] smpboot: CPU 3 Converting physical 0 to logical die 3 <NL> [    1.105322] kvm-guest: stealtime: cpu 3, msr 3ed9b600 <NL> [    1.107287] smp: Brought up 1 node, 4 CPUs <NL> [    1.107858] smpboot: Max logical packages: 4 <NL> [    1.108287] smpboot: Total of 4 processors activated (16760.60 BogoMIPS) <NL> [    1.118363] devtmpfs: initialized <NL> [    1.120513] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.121277] futex hash table entries: 1024 (order: 4, 65536 bytes, linear) <NL> [    1.123330] pinctrl core: initialized pinctrl subsystem <NL> [    1.127420] NET: Registered protocol family 16 <NL> [    1.129518] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.129521] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.132295] cpuidle: using governor menu <NL> [    1.134379] ACPI: bus type PCI registered <NL> [    1.135464] PCI: Using configuration type 1 for base access <NL> [    1.142305] Kprobes globally optimized <NL> [    1.317273] raid6: sse2x4   gen()  4245 MB/s <NL> [    1.334273] raid6: sse2x4   xor()  2262 MB/s <NL> [    1.352276] raid6: sse2x2   gen()  5554 MB/s <NL> [    1.370272] raid6: sse2x2   xor()  3314 MB/s <NL> [    1.388274] raid6: sse2x1   gen()  3874 MB/s <NL> [    1.406283] raid6: sse2x1   xor()  2316 MB/s <NL> [    1.407300] raid6: using algorithm sse2x2 gen() 5554 MB/s <NL> [    1.407994] raid6: .... xor() 3314 MB/s, rmw enabled <NL> [    1.408276] raid6: using intx1 recovery algorithm <NL> [    1.409376] ACPI: Added _OSI(Module Device) <NL> [    1.409919] ACPI: Added _OSI(Processor Device) <NL> [    1.410270] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.411286] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.412268] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.412893] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.413266] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.416564] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.419219] ACPI: Interpreter enabled <NL> [    1.419317] ACPI: (supports S0 S3 S5) <NL> [    1.420268] ACPI: Using IOAPIC for interrupt routing <NL> [    1.421301] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.422567] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.430859] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.431275] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.432301] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.433434] PCI host bridge to bus 0000:00 <NL> [    1.434268] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.434979] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.435268] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.436273] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.437269] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.438268] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.439176] pci_bus 0000:00: root bus resource [mem 0x40000000-0xfebfffff window] <NL> [    1.439268] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.440345] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.442524] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.443801] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.449276] pci 0000:00:01.1: reg 0x20: [io  0xc140-0xc14f] <NL> [    1.452746] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.453277] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.454274] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.455273] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.456592] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.458625] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.459287] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.461443] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.464331] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref] <NL> [    1.467330] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff] <NL> [    1.478329] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref] <NL> [    1.480138] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.482275] pci 0000:00:03.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.485275] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.494276] pci 0000:00:03.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.496321] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000"}
{"timestamp_utc": "2024-07-31T08:13:14.674Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    1.499276] pci 0000:00:04.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.502275] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.512276] pci 0000:00:04.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.513621] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.516276] pci 0000:00:05.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.519276] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.528276] pci 0000:00:05.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.530283] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.533274] pci 0000:00:06.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.536273] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.548277] pci 0000:00:06.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref] <NL> [    1.550472] pci 0000:00:07.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.553278] pci 0000:00:07.0: reg 0x10: [io  0xc100-0xc13f] <NL> [    1.556281] pci 0000:00:07.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff] <NL> [    1.570141] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.570470] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.571391] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.573414] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    1.574395] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    1.576341] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    1.577262] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    1.577281] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    1.578275] vgaarb: loaded <NL> [    1.581303] SCSI subsystem initialized <NL> [    1.585351] ACPI: bus type USB registered <NL> [    1.587290] usbcore: registered new interface driver usbfs <NL> [    1.588318] usbcore: registered new interface driver hub <NL> [    1.589307] usbcore: registered new device driver usb <NL> [    1.590339] pps_core: LinuxPPS API ver. 1 registered <NL> [    1.591270] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    1.592291] PTP clock support registered <NL> [    1.595476] Bluetooth: Core ver 2.22 <NL> [    1.596300] NET: Registered protocol family 31 <NL> [    1.597270] Bluetooth: HCI device and connection manager initialized <NL> [    1.598286] Bluetooth: HCI socket layer initialized <NL> [    1.599275] Bluetooth: L2CAP socket layer initialized <NL> [    1.600297] Bluetooth: SCO socket layer initialized <NL> [    1.602439] PCI: Using ACPI for IRQ routing <NL> [    1.604443] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    1.606284] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    1.607270] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    1.617265] clocksource: Switched to clocksource kvm-clock <NL> [    2.084308] pnp: PnP ACPI init <NL> [    2.088576] pnp: PnP ACPI: found 7 devices <NL> [    2.103007] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.110028] NET: Registered protocol family 2 <NL> [    2.119474] IP idents hash table entries: 16384 (order: 5, 131072 bytes, linear) <NL> [    2.126274] tcp_listen_portaddr_hash hash table entries: 512 (order: 1, 8192 bytes, linear) <NL> [    2.128070] TCP established hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    2.135195] TCP bind hash table entries: 8192 (order: 5, 131072 bytes, linear) <NL> [    2.136319] TCP: Hash tables configured (established 8192 bind 8192) <NL> [    2.140643] UDP hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.141615] UDP-Lite hash table entries: 512 (order: 2, 16384 bytes, linear) <NL> [    2.142698] NET: Registered protocol family 1 <NL> [    2.150488] RPC: Registered named UNIX socket transport module. <NL> [    2.152270] RPC: Registered udp transport module. <NL> [    2.153863] RPC: Registered tcp transport module. <NL> [    2.155076] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.156071] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    2.156952] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    2.169178] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    2.172544] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    2.177062] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    2.177865] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    2.178742] pci_bus 0000:00: resource 10 [mem 0x40000000-0xfebfffff window] <NL> [    2.179710] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    2.180469] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    2.181239] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    2.198393] pci 0000:00:01.0: quirk_isa_dma_hangs+0x0/0x20 took 16739 usecs <NL> [    2.202118] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    2.204040] PCI: CLS 0 bytes, default 64 <NL> [    2.204866] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    2.252379] check: Scanning for low memory corruption every 60 seconds <NL> [    2.254828] Initialise system trusted keyrings <NL> [    2.269764] workingset: timestamp_bits=46 max_order=18 bucket_order=0 <NL> [    2.277574] NFS: Registering the id_resolver key type <NL> [    2.279591] Key type id_resolver registered <NL> [    2.280916] Key type id_legacy registered <NL> [    2.311970] Key type cifs.idmap registered <NL> [    2.316601] 9p: Installing v9fs 9p2000 file system support <NL> [    2.317904] xor: measuring software checksum speed <NL> [    2.323872]    prefetch64-sse  :  9848 MB/sec <NL> [    2.331488]    generic_sse     :  7581 MB/sec <NL> [    2.335654] xor: using function: prefetch64-sse (9848 MB/sec) <NL> [    2.336313] Key type asymmetric registered <NL> [    2.339221] Asymmetric key parser 'x509' registered <NL> [    2.345532] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    2.361598] io scheduler mq-deadline registered <NL> [    2.362283] io scheduler kyber registered <NL> [    2.366507] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    2.393401] ACPI: Power Button [PWRF] <NL> [    2.414162] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    2.415857] virtio-pci 0000:00:07.0: virtio_pci: leaving for legacy driver <NL> [    2.421096] N_HDLC line discipline registered with maxframe=4096 <NL> [    2.425861] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    2.426893] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    2.440574] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    2.442295] Linux agpgart interface v0.103 <NL> [    2.442992] ACPI: bus type drm_connector registered <NL> [    2.462582] brd: module loaded <NL> [    2.466822] loop: module loaded <NL> [    2.469320] virtio_blk virtio0: [vda] 5031670 512-byte logical blocks (2.58 GB/2.40 GiB) <NL> [    2.474062] vda: detected capacity change from 0 to 2576215040 <NL> [    2.486074] Uniform Multi-Platform E-IDE driver <NL> [    2.491634] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00) <NL> [    2.499360] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    2.506832] legacy IDE will be removed in 2021, please switch to libata <NL> [    2.506832] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    2.509899]     ide0: BM-DMA at 0xc140-0xc147 <NL> [    2.510442]     ide1: BM-DMA at 0xc148-0xc14f <NL> [    3.760516] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    4.389051] hdc: MWDMA2 mode selected <NL> [    4.391635] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    4.393655] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    4.395927] ide-gd driver 1.18 <NL> [    4.398215] e100: Intel(R) PRO/100 Network Driver <NL> [    4.398869] e100: Copyright(c) 1999-2006 Intel Corporation"}
{"timestamp_utc": "2024-07-31T08:13:14.675Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[    4.399598] e1000: Intel(R) PRO/1000 Network Driver <NL> [    4.400224] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.300028] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.302304] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.304876] PCI Interrupt Link [LNKD] enabled at IRQ 10 <NL> [    6.150429] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:14 <NL> [    6.162287] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.166593] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.659500] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:15 <NL> [    6.671142] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    6.682145] PCI Interrupt Link [LNKB] enabled at IRQ 11 <NL> [    7.493135] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:16 <NL> [    7.498727] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    7.499698] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    7.500349] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    7.501096] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    7.509893] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    7.510658] PPP generic driver version 2.4.2 <NL> [    7.515330] PPP BSD Compression module registered <NL> [    7.520148] PPP Deflate Compression module registered <NL> [    7.529309] NET: Registered protocol family 24 <NL> [    7.540009] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    7.541462] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    7.542397] SLIP linefill/keepalive option. <NL> [    7.542946] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    7.543775] ehci-pci: EHCI PCI platform driver <NL> [    7.544403] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    7.545192] ohci-pci: OHCI PCI platform driver <NL> [    7.565591] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    7.568594] usbcore: registered new interface driver usb-storage <NL> [    7.572137] usbcore: registered new interface driver usbserial_generic <NL> [    7.574942] usbserial: USB Serial support registered for generic <NL> [    7.583128] usbcore: registered new interface driver ftdi_sio <NL> [    7.586765] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    7.589175] usbcore: registered new interface driver pl2303 <NL> [    7.592386] usbserial: USB Serial support registered for pl2303 <NL> [    7.595484] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    7.605359] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    7.607910] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    7.614323] mousedev: PS/2 mouse device common for all mice <NL> [    7.617935] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    7.621050] rtc_cmos 00:00: RTC can wake from S4 <NL> [    7.621774] rtc_cmos 00:00: registered as rtc0 <NL> [    7.634575] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:01 UTC (1722413581) <NL> [    7.677955] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    7.681192] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    7.694340] intel_pstate: CPU model not supported <NL> [    7.699666] sdhci: Secure Digital Host Controller Interface driver <NL> [    7.706562] sdhci: Copyright(c) Pierre Ossman <NL> [    7.708759] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    7.719457] usbcore: registered new interface driver usbhid <NL> [    7.722932] usbhid: USB HID core driver <NL> [    7.725301] u32 classifier <NL> [    7.737645]     input device check on <NL> [    7.739511]     Actions configured <NL> [    7.741925] xt_time: kernel timezone is -0000 <NL> [    7.754823] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.766156] gre: GRE over IPv4 demultiplexor driver <NL> [    7.770903] ip_gre: GRE over IPv4 tunneling driver <NL> [    7.775476] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    7.781553] NET: Registered protocol family 10 <NL> [    7.800834] Segment Routing with IPv6 <NL> [    7.805999] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    7.813267] ip6_gre: GRE over IPv6 tunneling driver <NL> [    7.816546] NET: Registered protocol family 17 <NL> [    7.819903] Bridge firewalling registered <NL> [    7.823562] 8021q: 802.1Q VLAN Support v1.8 <NL> [    7.826484] 9pnet: Installing 9P2000 support <NL> [    7.830593] Key type dns_resolver registered <NL> [    7.833137] NET: Registered protocol family 40 <NL> [    7.837710] IPI shorthand broadcast: enabled <NL> [    7.841194] sched_clock: Marking stable (7124297484, 716803604)->(9091803817, -1250702729) <NL> [    7.847690] registered taskstats version 1 <NL> [    7.850976] Loading compiled-in X.509 certificates <NL> [    7.890533] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    7.898373] Key type .fscrypt registered <NL> [    7.899909] Key type fscrypt-provisioning registered <NL> [    7.901157] Btrfs loaded, crc32c=crc32c-generic <NL> [    7.909052] Key type encrypted registered <NL> [    7.910270] printk: console [netcon0] enabled <NL> [    7.910850] netconsole: network logging started <NL> [    8.501582] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [    8.520665] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [    8.529233] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [    8.551305] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [    8.571578] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [    8.572483] IP-Config: Failed to open gretap0 <NL> [    8.573051] IP-Config: Failed to open erspan0 <NL> [    8.587339] Sending DHCP requests . <NL> [   10.563470] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.604176] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.611241] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.614566] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   10.615792] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   10.616752] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   10.627387] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   10.629043] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   11.545298] ., OK <NL> [   11.547892] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   11.548761] IP-Config: Complete: <NL> [   11.549194]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   11.560490]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   11.561206]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   11.561209]      nameserver0=10.0.2.3 <NL> [   11.795877] md: Waiting for all devices to be available before autodetect <NL> [   11.806959] md: If you don't use raid, use raid=noautodetect <NL> [   11.813173] md: Autodetecting RAID arrays. <NL> [   11.818919] md: autorun ... <NL> [   11.824958] md: ... autorun DONE. <NL> [   11.839200] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   11.865954] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   11.872600] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   11.880829] devtmpfs: mounted <NL> [   11.886322] Freeing unused kernel image (initmem) memory: 1964K <NL> [   11.895467] Write protecting the kernel read-only data: 22528k <NL> [   11.910795] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   11.937163] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   11.945591] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   12.345790] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   12.367499] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   12.457074] #####FSS INIT: Running on host <NL> [   12.608168] #####FSS INIT: FSS system init pre startup script"}
{"timestamp_utc": "2024-07-31T08:13:14.676Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   12.640100] random: python3: uninitialized urandom read (24 bytes read) <NL> [   15.419298] random: crng init done <NL> [   17.296340] #####FSS INIT: UnitCode:f9fc  ShelfRole:TRIB <NL> [   17.305516] #####FSS INIT: FSS no slotRole found <NL> # 03:13:14 socket_monitor INFO: trying to connect to socket on host 'rtxoialp79', port 37231; retry every 5 seconds, waiting forever <NL> # 03:13:14 socket_monitor INFO: connected to socket on host 'rtxoialp79', port 37231 <NL> (process:681): GLib-WARNING **: 03:12:48.160: gmem.c:489: custom memory allocation vtable not supported <NL> \u001bc\u001b[?7l\u001b[2J\u001b[0mSeaBIOS (version 1.11.0-2.el7) <NL> iPXE (http://ipxe.org) 00:03.0 C980 PCI2.10 PnP PMM+BFF943D0+BFED43D0 C980 <NL> Press Ctrl-B to configure iPXE (PCI 00:03.0)... <NL> iPXE (http://ipxe.org) 00:04.0 CA80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CA80 <NL> Press Ctrl-B to configure iPXE (PCI 00:04.0)... <NL> iPXE (http://ipxe.org) 00:05.0 CB80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CB80 <NL> Press Ctrl-B to configure iPXE (PCI 00:05.0)... <NL> iPXE (http://ipxe.org) 00:06.0 CC80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CC80 <NL> Press Ctrl-B to configure iPXE (PCI 00:06.0)... <NL> iPXE (http://ipxe.org) 00:07.0 CD80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CD80 <NL> Press Ctrl-B to configure iPXE (PCI 00:07.0)... <NL> iPXE (http://ipxe.org) 00:08.0 CE80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CE80 <NL> Press Ctrl-B to configure iPXE (PCI 00:08.0)... <NL> iPXE (http://ipxe.org) 00:09.0 CF80 PCI2.10 PnP PMM BFF943D0 BFED43D0 CF80\u001b[25;75H <NL> Press Ctrl-B to configure iPXE (PCI 00:09.0)... <NL> Booting from ROM... <NL> \u001bc\u001b[?7l\u001b[2J[    0.000000] Linux version 5.10.209-yocto-standard (oe-user@oe-host) (x86_64-enea-linux-gcc (GCC) 11.4.0, GNU ld (GNU Binutils) 2.38.20220708) #1 SMP PREEMPT Wed Feb 21 01:23:24 UTC 2024 <NL> [    0.000000] Command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.000000] BIOS-provided physical RAM map: <NL> [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable <NL> [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000bfffbfff] usable <NL> [    0.000000] BIOS-e820: [mem 0x00000000bfffc000-0x00000000bfffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved <NL> [    0.000000] BIOS-e820: [mem 0x0000000100000000-0x000000013fffffff] usable <NL> [    0.000000] NX (Execute Disable) protection: active <NL> [    0.000000] SMBIOS 2.4 present. <NL> [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.5.1 01/01/2011 <NL> [    0.000000] Hypervisor detected: KVM <NL> [    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 <NL> [    0.000000] kvm-clock: cpu 0, msr 128254001, primary cpu clock <NL> [    0.000001] kvm-clock: using sched offset of 7398684304 cycles <NL> [    0.000008] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns <NL> [    0.000021] tsc: Detected 2095.076 MHz processor <NL> [    0.006930] last_pfn = 0x140000 max_arch_pfn = 0x400000000 <NL> [    0.007045] x86/PAT: PAT not supported by the CPU. <NL> [    0.007056] x86/PAT: Configuration [0-7]: WB  WT  UC- UC  WB  WT  UC- UC <NL> [    0.007075] last_pfn = 0xbfffc max_arch_pfn = 0x400000000 <NL> [    0.041969] found SMP MP-table at [mem 0x000f6380-0x000f638f] <NL> [    0.042101] check: Scanning 1 areas for low memory corruption <NL> [    0.042486] ACPI: Early table checksum verification disabled <NL> [    0.042529] ACPI: RSDP 0x00000000000F61D0 000014 (v00 BOCHS ) <NL> [    0.042547] ACPI: RSDT 0x00000000BFFFFBC1 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001) <NL> [    0.042565] ACPI: FACP 0x00000000BFFFF1C0 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001) <NL> [    0.042580] ACPI: DSDT 0x00000000BFFFE040 001180 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001) <NL> [    0.042588] ACPI: FACS 0x00000000BFFFE000 000040 <NL> [    0.042594] ACPI: SSDT 0x00000000BFFFF234 0008DD (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001) <NL> [    0.042602] ACPI: APIC 0x00000000BFFFFB11 000078 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001) <NL> [    0.042609] ACPI: HPET 0x00000000BFFFFB89 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001) <NL> [    0.042616] ACPI: Reserving FACP table memory at [mem 0xbffff1c0-0xbffff233] <NL> [    0.042619] ACPI: Reserving DSDT table memory at [mem 0xbfffe040-0xbffff1bf] <NL> [    0.042621] ACPI: Reserving FACS table memory at [mem 0xbfffe000-0xbfffe03f] <NL> [    0.042623] ACPI: Reserving SSDT table memory at [mem 0xbffff234-0xbffffb10] <NL> [    0.042625] ACPI: Reserving APIC table memory at [mem 0xbffffb11-0xbffffb88] <NL> [    0.042627] ACPI: Reserving HPET table memory at [mem 0xbffffb89-0xbffffbc0] <NL> [    0.103541] Zone ranges: <NL> [    0.103558]   DMA      [mem 0x0000000000001000-0x0000000000ffffff] <NL> [    0.103563]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff] <NL> [    0.103566]   Normal   [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.103570] Movable zone start for each node <NL> [    0.103572] Early memory node ranges <NL> [    0.103574]   node   0: [mem 0x0000000000001000-0x000000000009efff] <NL> [    0.103577]   node   0: [mem 0x0000000000100000-0x00000000bfffbfff] <NL> [    0.103579]   node   0: [mem 0x0000000100000000-0x000000013fffffff] <NL> [    0.103583] Initmem setup node 0 [mem 0x0000000000001000-0x000000013fffffff] <NL> [    0.196884] On node 0, zone DMA: 1 pages in unavailable ranges <NL> [    0.197200] On node 0, zone DMA: 97 pages in unavailable ranges <NL> [    0.702135] On node 0, zone Normal: 4 pages in unavailable ranges <NL> [    0.702844] ACPI: PM-Timer IO Port: 0x608 <NL> [    0.702867] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1]) <NL> [    0.702918] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23 <NL> [    0.702925] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl) <NL> [    0.702929] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level) <NL> [    0.702931] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level) <NL> [    0.702941] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level) <NL> [    0.702944] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level) <NL> [    0.702960] Using ACPI (MADT) for SMP configuration information <NL> [    0.702964] ACPI: HPET id: 0x8086a201 base: 0xfed00000 <NL> [    0.702976] smpboot: Allowing 1 CPUs, 0 hotplug CPUs"}
{"timestamp_utc": "2024-07-31T08:13:14.677Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    0.703020] [mem 0xc0000000-0xfeffbfff] available for PCI devices <NL> [    0.703023] Booting paravirtualized kernel on KVM <NL> [    0.703036] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns <NL> [    0.703052] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:1 nr_node_ids:1 <NL> [    0.729407] percpu: Embedded 57 pages/cpu s193816 r8192 d31464 u2097152 <NL> [    0.729471] kvm-guest: stealtime: cpu 0, msr 13bc1b600 <NL> [    0.729482] Built 1 zonelists, mobility grouping on.  Total pages: 1032069 <NL> [    0.729486] Kernel command line: root=/dev/vda rw ip=dhcp console=ttyS0 FSS_CARD_ID=MAIN_01_02 OSPL_URI=file:///etc/config/ospl.xml unitCode=0xc200 unitName=BDC2-C200 shelfRole=MAIN shelfNumber=200 simulatedRole=MAIN simulatedShelf=200 serialNum=12345 <NL> [    0.769106] Dentry cache hash table entries: 524288 (order: 10, 4194304 bytes, linear) <NL> [    0.778575] Inode-cache hash table entries: 262144 (order: 9, 2097152 bytes, linear) <NL> [    0.778667] mem auto-init: stack:off, heap alloc:off, heap free:off <NL> [    1.179140] Memory: 4026952K/4193896K available (16396K kernel code, 2202K rwdata, 3924K rodata, 1964K init, 1816K bss, 166684K reserved, 0K cma-reserved) <NL> [    1.179218] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1 <NL> [    1.179230] Kernel/User page tables isolation: enabled <NL> [    1.179271] ftrace: allocating 47967 entries in 188 pages <NL> [    1.241061] ftrace: allocated 188 pages with 5 groups <NL> [    1.256024] rcu: Preemptible hierarchical RCU implementation. <NL> [    1.256045] rcu: \tRCU event tracing is enabled. <NL> [    1.256047] rcu: \tRCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=1. <NL> [    1.256050] \tTrampoline variant of Tasks RCU enabled. <NL> [    1.256051] \tRude variant of Tasks RCU enabled. <NL> [    1.256053] \tTracing variant of Tasks RCU enabled. <NL> [    1.256055] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies. <NL> [    1.256057] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1 <NL> [    1.263606] NR_IRQS: 4352, nr_irqs: 256, preallocated irqs: 16 <NL> [    1.270114] Console: colour VGA+ 80x25 <NL> [    1.411950] printk: console [ttyS0] enabled <NL> [    1.412499] ACPI: Core revision 20200925 <NL> [    1.413239] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns <NL> [    1.414521] APIC: Switch to symmetric I/O mode setup <NL> [    1.415456] x2apic enabled <NL> [    1.416173] Switched APIC routing to physical x2apic. <NL> [    1.422470] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1 <NL> [    1.423997] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    1.425738] Calibrating delay loop (skipped) preset value.. 4190.15 BogoMIPS (lpj=2095076) <NL> [    1.426735] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0 <NL> [    1.426771] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0 <NL> [    1.427674] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization <NL> [    1.427735] Spectre V2 : Mitigation: Retpolines <NL> [    1.427735] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch <NL> [    1.427735] Spectre V2 : Spectre v2 / SpectreRSB : Filling RSB on VMEXIT <NL> [    1.427735] Speculative Store Bypass: Vulnerable <NL> [    1.427735] MDS: Vulnerable: Clear CPU buffers attempted, no microcode <NL> [    1.427735] MMIO Stale Data: Unknown: No mitigations <NL> [    1.427749] x86/fpu: x87 FPU will use FXSAVE <NL> [    1.462960] Freeing SMP alternatives memory: 48K <NL> [    1.463619] pid_max: default: 32768 minimum: 301 <NL> [    1.463772] LSM: Security Framework initializing <NL> [    1.467828] Mount-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.468839] Mountpoint-cache hash table entries: 8192 (order: 4, 65536 bytes, linear) <NL> [    1.544735] smpboot: CPU0: Intel QEMU Virtual CPU version 2.0.0 (family: 0x6, model: 0x6, stepping: 0x3) <NL> [    1.546077] Performance Events: PMU not available due to virtualization, using software events only. <NL> [    1.549793] rcu: Hierarchical SRCU implementation. <NL> [    1.552213] smp: Bringing up secondary CPUs ... <NL> [    1.552745] smp: Brought up 1 node, 1 CPU <NL> [    1.553750] smpboot: Max logical packages: 1 <NL> [    1.554746] smpboot: Total of 1 processors activated (4190.15 BogoMIPS) <NL> [    1.557962] devtmpfs: initialized <NL> [    1.558903] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns <NL> [    1.559744] futex hash table entries: 256 (order: 2, 16384 bytes, linear) <NL> [    1.560837] pinctrl core: initialized pinctrl subsystem <NL> [    1.562875] NET: Registered protocol family 16 <NL> [    1.565738] thermal_sys: Registered thermal governor 'step_wise' <NL> [    1.565741] thermal_sys: Registered thermal governor 'user_space' <NL> [    1.566880] cpuidle: using governor menu <NL> [    1.568856] ACPI: bus type PCI registered <NL> [    1.569900] PCI: Using configuration type 1 for base access <NL> [    1.574086] Kprobes globally optimized <NL> [    1.690764] raid6: sse2x4   gen()  7583 MB/s <NL> [    1.708759] raid6: sse2x4   xor()  3359 MB/s <NL> [    1.726745] raid6: sse2x2   gen()  5266 MB/s <NL> [    1.744744] raid6: sse2x2   xor()  3394 MB/s <NL> [    1.762744] raid6: sse2x1   gen()  3196 MB/s <NL> [    1.780743] raid6: sse2x1   xor()  1788 MB/s <NL> [    1.781748] raid6: using algorithm sse2x4 gen() 7583 MB/s <NL> [    1.782746] raid6: .... xor() 3359 MB/s, rmw enabled <NL> [    1.783748] raid6: using intx1 recovery algorithm <NL> [    1.784840] ACPI: Added _OSI(Module Device) <NL> [    1.785748] ACPI: Added _OSI(Processor Device) <NL> [    1.786752] ACPI: Added _OSI(3.0 _SCP Extensions) <NL> [    1.787749] ACPI: Added _OSI(Processor Aggregator Device) <NL> [    1.788748] ACPI: Added _OSI(Linux-Dell-Video) <NL> [    1.790613] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio) <NL> [    1.791752] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics) <NL> [    1.796188] ACPI: 2 ACPI AML tables successfully acquired and loaded <NL> [    1.797870] ACPI: Interpreter enabled <NL> [    1.798765] ACPI: (supports S0 S3 S5) <NL> [    1.799744] ACPI: Using IOAPIC for interrupt routing <NL> [    1.800784] PCI: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug <NL> [    1.802025] ACPI: Enabled 16 GPEs in block 00 to 0F <NL> [    1.807460] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff]) <NL> [    1.807764] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3] <NL> [    1.808764] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge. <NL> [    1.810926] PCI host bridge to bus 0000:00 <NL> [    1.811746] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window] <NL> [    1.812744] pci_bus 0000:00: root bus resource [io  0x0d00-0xadff window] <NL> [    1.813743] pci_bus 0000:00: root bus resource [io  0xae0f-0xaeff window] <NL> [    1.814751] pci_bus 0000:00: root bus resource [io  0xaf20-0xafdf window] <NL> [    1.815748] pci_bus 0000:00: root bus resource [io  0xafe4-0xffff window] <NL> [    1.816747] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window] <NL> [    1.817748] pci_bus 0000:00: root bus resource [mem 0xc0000000-0xfebfffff window] <NL> [    1.818747] pci_bus 0000:00: root bus resource [bus 00-ff] <NL> [    1.819819] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000 <NL> [    1.822108] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100 <NL> [    1.825021] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180 <NL> [    1.831284] pci 0000:00:01.1: reg 0x20: [io  0xc200-0xc20f] <NL> [    1.833778] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7] <NL> [    1.834751] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6] <NL> [    1.835750] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177] <NL> [    1.836750] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376] <NL> [    1.838744] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000 <NL> [    1.840878] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI <NL> [    1.841758] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB <NL> [    1.844091] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000 <NL> [    1.846862] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref]"}
{"timestamp_utc": "2024-07-31T08:13:14.678Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    1.850862] pci 0000:00:02.0: reg 0x14: [mem 0xfebf0000-0xfebf0fff] <NL> [    1.863852] pci 0000:00:02.0: reg 0x30: [mem 0xfebe0000-0xfebeffff pref] <NL> [    1.865652] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000 <NL> [    1.867747] pci 0000:00:03.0: reg 0x10: [mem 0xfeb00000-0xfeb1ffff] <NL> [    1.870756] pci 0000:00:03.0: reg 0x14: [io  0xc000-0xc03f] <NL> [    1.880580] pci 0000:00:03.0: reg 0x30: [mem 0xfe940000-0xfe97ffff pref] <NL> [    1.881084] pci 0000:00:04.0: [8086:100e] type 00 class 0x020000 <NL> [    1.883747] pci 0000:00:04.0: reg 0x10: [mem 0xfeb20000-0xfeb3ffff] <NL> [    1.886747] pci 0000:00:04.0: reg 0x14: [io  0xc040-0xc07f] <NL> [    1.896747] pci 0000:00:04.0: reg 0x30: [mem 0xfe980000-0xfe9bffff pref] <NL> [    1.899020] pci 0000:00:05.0: [8086:100e] type 00 class 0x020000 <NL> [    1.901748] pci 0000:00:05.0: reg 0x10: [mem 0xfeb40000-0xfeb5ffff] <NL> [    1.904746] pci 0000:00:05.0: reg 0x14: [io  0xc080-0xc0bf] <NL> [    1.913481] pci 0000:00:05.0: reg 0x30: [mem 0xfe9c0000-0xfe9fffff pref] <NL> [    1.914086] pci 0000:00:06.0: [8086:100e] type 00 class 0x020000 <NL> [    1.916585] pci 0000:00:06.0: reg 0x10: [mem 0xfeb60000-0xfeb7ffff] <NL> [    1.918746] pci 0000:00:06.0: reg 0x14: [io  0xc0c0-0xc0ff] <NL> [    1.927782] pci 0000:00:06.0: reg 0x30: [mem 0xfea00000-0xfea3ffff pref] <NL> [    1.929803] pci 0000:00:07.0: [8086:100e] type 00 class 0x020000 <NL> [    1.932747] pci 0000:00:07.0: reg 0x10: [mem 0xfeb80000-0xfeb9ffff] <NL> [    1.935582] pci 0000:00:07.0: reg 0x14: [io  0xc100-0xc13f] <NL> [    1.943748] pci 0000:00:07.0: reg 0x30: [mem 0xfea40000-0xfea7ffff pref] <NL> [    1.945084] pci 0000:00:08.0: [8086:100e] type 00 class 0x020000 <NL> [    1.947747] pci 0000:00:08.0: reg 0x10: [mem 0xfeba0000-0xfebbffff] <NL> [    1.950745] pci 0000:00:08.0: reg 0x14: [io  0xc140-0xc17f] <NL> [    1.959749] pci 0000:00:08.0: reg 0x30: [mem 0xfea80000-0xfeabffff pref] <NL> [    1.962015] pci 0000:00:09.0: [8086:100e] type 00 class 0x020000 <NL> [    1.964747] pci 0000:00:09.0: reg 0x10: [mem 0xfebc0000-0xfebdffff] <NL> [    1.967747] pci 0000:00:09.0: reg 0x14: [io  0xc180-0xc1bf] <NL> [    1.977751] pci 0000:00:09.0: reg 0x30: [mem 0xfeac0000-0xfeafffff pref] <NL> [    1.979122] pci 0000:00:0a.0: [1af4:1001] type 00 class 0x010000 <NL> [    1.981555] pci 0000:00:0a.0: reg 0x10: [io  0xc1c0-0xc1ff] <NL> [    1.983750] pci 0000:00:0a.0: reg 0x14: [mem 0xfebf1000-0xfebf1fff] <NL> [    1.995378] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11) <NL> [    1.995919] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11) <NL> [    1.996960] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11) <NL> [    1.998830] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11) <NL> [    2.000744] ACPI: PCI Interrupt Link [LNKS] (IRQs *9) <NL> [    2.003468] pci 0000:00:02.0: vgaarb: setting as boot VGA device <NL> [    2.003735] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none <NL> [    2.003750] pci 0000:00:02.0: vgaarb: bridge control possible <NL> [    2.004748] vgaarb: loaded <NL> [    2.006043] SCSI subsystem initialized <NL> [    2.007891] ACPI: bus type USB registered <NL> [    2.008836] usbcore: registered new interface driver usbfs <NL> [    2.009779] usbcore: registered new interface driver hub <NL> [    2.010768] usbcore: registered new device driver usb <NL> [    2.011826] pps_core: LinuxPPS API ver. 1 registered <NL> [    2.012461] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it> <NL> [    2.012759] PTP clock support registered <NL> [    2.014744] Bluetooth: Core ver 2.22 <NL> [    2.015226] NET: Registered protocol family 31 <NL> [    2.015738] Bluetooth: HCI device and connection manager initialized <NL> [    2.016538] Bluetooth: HCI socket layer initialized <NL> [    2.016743] Bluetooth: L2CAP socket layer initialized <NL> [    2.017778] Bluetooth: SCO socket layer initialized <NL> [    2.018879] PCI: Using ACPI for IRQ routing <NL> [    2.020271] hpet: 3 channels of 0 reserved for per-cpu timers <NL> [    2.020769] hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0 <NL> [    2.021740] hpet0: 3 comparators, 64-bit 100.000000 MHz counter <NL> [    2.024808] clocksource: Switched to clocksource kvm-clock <NL> [    2.826006] pnp: PnP ACPI init <NL> [    2.832834] pnp: PnP ACPI: found 7 devices <NL> [    2.855786] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns <NL> [    2.863947] NET: Registered protocol family 2 <NL> [    2.868177] IP idents hash table entries: 65536 (order: 7, 524288 bytes, linear) <NL> [    2.882911] tcp_listen_portaddr_hash hash table entries: 2048 (order: 3, 32768 bytes, linear) <NL> [    2.884103] TCP established hash table entries: 32768 (order: 6, 262144 bytes, linear) <NL> [    2.890371] TCP bind hash table entries: 32768 (order: 7, 524288 bytes, linear) <NL> [    2.921318] TCP: Hash tables configured (established 32768 bind 32768) <NL> [    2.940628] UDP hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.953198] UDP-Lite hash table entries: 2048 (order: 4, 65536 bytes, linear) <NL> [    2.960721] NET: Registered protocol family 1 <NL> [    2.965172] RPC: Registered named UNIX socket transport module. <NL> [    2.973410] RPC: Registered udp transport module. <NL> [    2.982181] RPC: Registered tcp transport module. <NL> [    2.995587] RPC: Registered tcp NFSv4.1 backchannel transport module. <NL> [    2.999182] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window] <NL> [    3.002047] pci_bus 0000:00: resource 5 [io  0x0d00-0xadff window] <NL> [    3.004367] pci_bus 0000:00: resource 6 [io  0xae0f-0xaeff window] <NL> [    3.005106] pci_bus 0000:00: resource 7 [io  0xaf20-0xafdf window] <NL> [    3.005829] pci_bus 0000:00: resource 8 [io  0xafe4-0xffff window] <NL> [    3.006558] pci_bus 0000:00: resource 9 [mem 0x000a0000-0x000bffff window] <NL> [    3.007362] pci_bus 0000:00: resource 10 [mem 0xc0000000-0xfebfffff window] <NL> [    3.014989] pci 0000:00:01.0: PIIX3: Enabling Passive Release <NL> [    3.018334] pci 0000:00:00.0: Limiting direct PCI/PCI transfers <NL> [    3.020891] pci 0000:00:01.0: Activating ISA DMA hang workarounds <NL> [    3.023758] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff] <NL> [    3.024874] PCI: CLS 0 bytes, default 64 <NL> [    3.025474] PCI-DMA: Using software bounce buffering for IO (SWIOTLB) <NL> [    3.026279] software IO TLB: mapped [mem 0x00000000bbffc000-0x00000000bfffc000] (64MB) <NL> [    3.027332] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1e33052aadd, max_idle_ns: 440795310221 ns <NL> [    3.036292] check: Scanning for low memory corruption every 60 seconds <NL> [    3.040115] Initialise system trusted keyrings <NL> [    3.042887] workingset: timestamp_bits=46 max_order=20 bucket_order=0 <NL> [    3.049242] NFS: Registering the id_resolver key type <NL> [    3.054218] Key type id_resolver registered <NL> [    3.057006] Key type id_legacy registered <NL> [    3.059700] Key type cifs.idmap registered <NL> [    3.064221] 9p: Installing v9fs 9p2000 file system support <NL> [    3.067235] xor: measuring software checksum speed <NL> [    3.072679]    prefetch64-sse  :  9069 MB/sec <NL> [    3.078060]    generic_sse     :  8004 MB/sec <NL> [    3.081633] xor: using function: prefetch64-sse (9069 MB/sec) <NL> [    3.084443] Key type asymmetric registered <NL> [    3.086717] Asymmetric key parser 'x509' registered <NL> [    3.088902] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250) <NL> [    3.092695] io scheduler mq-deadline registered <NL> [    3.095033] io scheduler kyber registered <NL> [    3.098065] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0 <NL> [    3.112839] ACPI: Power Button [PWRF] <NL> [    3.117762] PCI Interrupt Link [LNKB] enabled at IRQ 10 <NL> [    3.132073] virtio-pci 0000:00:0a.0: virtio_pci: leaving for legacy driver <NL> [    3.137455] N_HDLC line discipline registered with maxframe=4096 <NL> [    3.141626] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled <NL> [    3.144955] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A <NL> [    3.149089] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A <NL> [    3.153873] Linux agpgart interface v0.103 <NL> [    3.169979] ACPI: bus type drm_connector registered <NL> [    3.201086] brd: module loaded <NL> [    3.207008] loop: module loaded <NL> [    3.211080] virtio_blk virtio0: [vda] 5016568 512-byte logical blocks (2.57 GB/2.39 GiB) <NL> [    3.218957] vda: detected capacity change from 0 to 2568482816 <NL> [    3.241228] Uniform Multi-Platform E-IDE driver <NL> [    3.245564] piix 0000:00:01.1: IDE controller (0x8086:0x7010 rev 0x00)"}
{"timestamp_utc": "2024-07-31T08:13:14.679Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[    3.261389] piix 0000:00:01.1: not 100% native mode: will probe irqs later <NL> [    3.268897] legacy IDE will be removed in 2021, please switch to libata <NL> [    3.268897] Report any missing HW support to linux-ide@vger.kernel.org <NL> [    3.280716]     ide0: BM-DMA at 0xc200-0xc207 <NL> [    3.301180]     ide1: BM-DMA at 0xc208-0xc20f <NL> [    4.561178] hdc: QEMU DVD-ROM, ATAPI CD/DVD-ROM drive <NL> [    5.208114] hdc: MWDMA2 mode selected <NL> [    5.208834] ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 <NL> [    5.209465] ide1 at 0x170-0x177,0x376 on irq 15 <NL> [    5.210294] ide-gd driver 1.18 <NL> [    5.211351] e100: Intel(R) PRO/100 Network Driver <NL> [    5.221060] e100: Copyright(c) 1999-2006 Intel Corporation <NL> [    5.221796] e1000: Intel(R) PRO/1000 Network Driver <NL> [    5.222419] e1000: Copyright (c) 1999-2006 Intel Corporation. <NL> [    5.223599] PCI Interrupt Link [LNKC] enabled at IRQ 11 <NL> [    5.738005] e1000 0000:00:03.0 eth0: (PCI:33MHz:32-bit) 52:54:00:12:34:56 <NL> [    5.740093] e1000 0000:00:03.0 eth0: Intel(R) PRO/1000 Network Connection <NL> [    5.742847] PCI Interrupt Link [LNKD] enabled at IRQ 11 <NL> [    6.247508] e1000 0000:00:04.0 eth1: (PCI:33MHz:32-bit) 52:54:01:00:00:27 <NL> [    6.255049] e1000 0000:00:04.0 eth1: Intel(R) PRO/1000 Network Connection <NL> [    6.259656] PCI Interrupt Link [LNKA] enabled at IRQ 10 <NL> [    6.951512] e1000 0000:00:05.0 eth2: (PCI:33MHz:32-bit) 52:54:01:00:00:26 <NL> [    6.963167] e1000 0000:00:05.0 eth2: Intel(R) PRO/1000 Network Connection <NL> [    7.488013] e1000 0000:00:06.0 eth3: (PCI:33MHz:32-bit) 52:54:01:00:00:24 <NL> [    7.502954] e1000 0000:00:06.0 eth3: Intel(R) PRO/1000 Network Connection <NL> [    8.168815] e1000 0000:00:07.0 eth4: (PCI:33MHz:32-bit) 52:54:01:00:00:25 <NL> [    8.175245] e1000 0000:00:07.0 eth4: Intel(R) PRO/1000 Network Connection <NL> [    8.605423] e1000 0000:00:08.0 eth5: (PCI:33MHz:32-bit) 52:54:01:00:00:23 <NL> [    8.618522] e1000 0000:00:08.0 eth5: Intel(R) PRO/1000 Network Connection <NL> [    9.391175] e1000 0000:00:09.0 eth6: (PCI:33MHz:32-bit) 52:54:01:00:00:28 <NL> [    9.413984] e1000 0000:00:09.0 eth6: Intel(R) PRO/1000 Network Connection <NL> [    9.425473] e1000e: Intel(R) PRO/1000 Network Driver <NL> [    9.426644] e1000e: Copyright(c) 1999 - 2015 Intel Corporation. <NL> [    9.427701] igb: Intel(R) Gigabit Ethernet Network Driver <NL> [    9.440320] igb: Copyright (c) 2007-2014 Intel Corporation. <NL> [    9.452409] PPP generic driver version 2.4.2 <NL> [    9.455834] PPP BSD Compression module registered <NL> [    9.467327] PPP Deflate Compression module registered <NL> [    9.471687] NET: Registered protocol family 24 <NL> [    9.474708] SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256) (6 bit encapsulation enabled). <NL> [    9.479368] CSLIP: code copyright 1989 Regents of the University of California. <NL> [    9.480389] SLIP linefill/keepalive option. <NL> [    9.480969] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver <NL> [    9.481731] ehci-pci: EHCI PCI platform driver <NL> [    9.493237] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver <NL> [    9.498553] ohci-pci: OHCI PCI platform driver <NL> [    9.499440] uhci_hcd: USB Universal Host Controller Interface driver <NL> [    9.506972] usbcore: registered new interface driver usb-storage <NL> [    9.510330] usbcore: registered new interface driver usbserial_generic <NL> [    9.516672] usbserial: USB Serial support registered for generic <NL> [    9.519216] usbcore: registered new interface driver ftdi_sio <NL> [    9.522442] usbserial: USB Serial support registered for FTDI USB Serial Device <NL> [    9.525061] usbcore: registered new interface driver pl2303 <NL> [    9.525849] usbserial: USB Serial support registered for pl2303 <NL> [    9.526917] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12 <NL> [    9.529178] serio: i8042 KBD port at 0x60,0x64 irq 1 <NL> [    9.535912] serio: i8042 AUX port at 0x60,0x64 irq 12 <NL> [    9.540235] mousedev: PS/2 mouse device common for all mice <NL> [    9.544350] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1 <NL> [    9.550310] rtc_cmos 00:00: RTC can wake from S4 <NL> [    9.557449] rtc_cmos 00:00: registered as rtc0 <NL> [    9.561686] rtc_cmos 00:00: setting system clock to 2024-07-31T08:13:05 UTC (1722413585) <NL> [    9.563011] rtc_cmos 00:00: alarms up to one day, 114 bytes nvram, hpet irqs <NL> [    9.564653] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com <NL> [    9.573985] intel_pstate: CPU model not supported <NL> [    9.575850] sdhci: Secure Digital Host Controller Interface driver <NL> [    9.583151] sdhci: Copyright(c) Pierre Ossman <NL> [    9.584776] sdhci-pltfm: SDHCI platform and OF driver helper <NL> [    9.587105] usbcore: registered new interface driver usbhid <NL> [    9.588627] usbhid: USB HID core driver <NL> [    9.589475] u32 classifier <NL> [    9.591817]     input device check on <NL> [    9.593044]     Actions configured <NL> [    9.631436] xt_time: kernel timezone is -0000 <NL> [    9.633317] ipip: IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.639042] gre: GRE over IPv4 demultiplexor driver <NL> [    9.643812] ip_gre: GRE over IPv4 tunneling driver <NL> [    9.648804] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully <NL> [    9.656358] NET: Registered protocol family 10 <NL> [    9.662244] Segment Routing with IPv6 <NL> [    9.666510] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver <NL> [    9.673091] ip6_gre: GRE over IPv6 tunneling driver <NL> [    9.677031] NET: Registered protocol family 17 <NL> [    9.680204] Bridge firewalling registered <NL> [    9.682029] 8021q: 802.1Q VLAN Support v1.8 <NL> [    9.683955] 9pnet: Installing 9P2000 support <NL> [    9.685962] Key type dns_resolver registered <NL> [    9.688194] NET: Registered protocol family 40 <NL> [    9.691349] IPI shorthand broadcast: enabled <NL> [    9.694101] sched_clock: Marking stable (9534187825, 159800943)->(10566134192, -872145424) <NL> [    9.695470] registered taskstats version 1 <NL> [    9.696122] Loading compiled-in X.509 certificates <NL> [    9.703179] Loaded X.509 cert 'Build time autogenerated kernel key: 8de55cdb0b8d2fcfaff59e69816c84b624de6870' <NL> [    9.710342] Key type .fscrypt registered <NL> [    9.712194] Key type fscrypt-provisioning registered <NL> [    9.713702] Btrfs loaded, crc32c=crc32c-generic <NL> [    9.715163] Key type encrypted registered <NL> [    9.720264] printk: console [netcon0] enabled <NL> [    9.724127] netconsole: network logging started <NL> [   10.178583] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8042/serio1/input/input3 <NL> [   10.201179] 8021q: adding VLAN 0 to HW filter on device eth0 <NL> [   10.277426] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   10.347167] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   10.381500] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   10.394456] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   10.405339] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   10.416331] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   10.422496] IP-Config: Failed to open gretap0 <NL> [   10.426988] IP-Config: Failed to open erspan0 <NL> [   10.442960] Sending DHCP requests . <NL> [   12.213491] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.226152] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   12.338489] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.340179] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   12.403729] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.406078] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.408528] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:13:14.680Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   12.412350] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   12.413376] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   12.418072] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   19.478508] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   19.488209] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   19.543693] systemd[1]: Starting Journal Socket... <NL> [   19.544663] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   19.604788] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   19.618870] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   19.630829] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   19.658700] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   19.682194] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   19.733146] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   19.781981] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   19.801960] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   19.835217] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   19.854048] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   19.916123] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   19.949765] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   20.071628] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   20.208195] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   20.302560] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   20.329655] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   20.387010] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kern[   20.422179] fuse: init (API version 7.32) <NL> el File Systems\u001b[0m... <NL> [   20.468576] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   20.541034] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   20.559776] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   20.576742] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   20.639491] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   20.646047] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   20.661342] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   20.662900] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   20.686952] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   20.712002] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   20.749952] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   20.763971] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.805414] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   20.809626] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   20.862542] systemd[1]: Mounting FUSE Control File System... <NL> [   20.868827] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   20.914888] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   20.952158] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   20.977793] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   20.978086] dcn_phantom_drv: VIF Support v1.0 <NL> [   20.991705] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   21.018173] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   21.033606] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   21.056952] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   21.109483] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   21.176750] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   21.212872] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   21.221215] packet_injector_class: driver registered correctly with major number 246 <NL> [   21.232022] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway."}
{"timestamp_utc": "2024-07-31T08:13:14.681Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   21.244507] Packet_injector 257949696: minor device creation 246:0 <NL> [   21.252576] systemd[1]: Mounting /var/log... <NL> [   21.252761] Packet_injector 257949697: minor device creation 246:1 <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   21.266939] Packet_injector 257949698: minor device creation 246:2 <NL> [   21.270050] Packet_injector 257949699: minor device creation 246:3 <NL> [   21.273652] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   21.303182] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   21.328331] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   21.421759] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   21.495936] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   21.515832] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   21.534299] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   21.546809] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   21.552313] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   21.567225] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   21.592050] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   21.639845] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   21.674185] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   17.306872] #####FSS INIT: FSS system init get inputs from PSI f9fc : TRIB <NL> [   17.309124] #####FSS INIT:PI data: unitCode=f9fc Role=TRIB <NL> [   17.367776] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   17.380613] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-TRIB.target : /lib/systemd/system/FSS-CORE.target <NL> [   17.403145] #####FSS INIT:FSS TRIB Target File found : /lib/systemd/system/FSS-TRIB.target <NL> [   17.408417] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-TRIB.target <NL> [   17.498392] #####FSS INIT:systemd will take it from here! <NL> sh: -d: unknown operand <NL> [   17.707583] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   17.754574] systemd[1]: Detected virtualization kvm. <NL> [   17.755329] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   17.811642] systemd[1]: Hostname set to <fujitsu>. <NL> [   17.818017] systemd[1]: Initializing machine ID from random generator. <NL> [   17.975557] systemd-sysv-generator[343]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   18.112362] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   19.037501] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.053249] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.104388] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.150450] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.196379] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.230602] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.240254] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.251386] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.267753] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.388053] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.422006] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.448864] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.501748] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.516063] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.569147] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.573786] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.671965] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.682979] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.704414] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.714312] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.826796] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.861586] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.893565] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   19.939446] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.944018] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37320, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',) <NL> [   19.598377] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:14.682Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   19.609187] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.630618] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.633576] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.671362] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.683391] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.694721] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.715680] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.754150] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.757024] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.823190] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.836363] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.889886] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.906565] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.980371] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.014671] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.084297] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.093531] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.124363] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.131690] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.153427] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.156430] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.179692] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.182260] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.235722] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   20.344640] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   20.371008] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   20.396588] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   20.419734] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   20.449568] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   20.476622] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   20.485875] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   20.506343] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   20.520485] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   20.522125] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   20.543437] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   20.553856] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   20.617902] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   20.641416] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   20.678777] systemd[1]: Listening on Process Core Dump Socket. <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37293, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37293, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37293\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:14.939Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37261, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37229, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37297, with username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:15.195Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "# 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37297, username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37233, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37233, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37233\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37201, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37201, username 'fujitsu', password '1finity', key_filename None <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:14 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37265, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:14 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37201\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37297\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37265, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:15 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37265\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:16.124Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   19.953029] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.962546] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   19.997613] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.001288] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.032435] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.036601] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.104290] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.125236] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.205439] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.229711] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.279073] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.282013] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.327840] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.331023] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.475906] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.534010] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.569568] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.623404] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.746424] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.812958] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.912946] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   20.999717] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.066092] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.102625] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.145191] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.148071] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.192084] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.194678] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.268704] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.287718] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.394883] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample TRIB -. <NL> [   21.489704] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   21.578473] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   21.676383] systemd[1]: Created slice Slice /system/modprobe. <NL> [   10.887028] IP-Config: Failed to open gretap0 <NL> [   10.887578] IP-Config: Failed to open erspan0 <NL> [   10.900351] Sending DHCP requests . <NL> [   12.826698] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.835664] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.841378] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.868330] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   12.876787] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   12.878069] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   12.917854] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.924682] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:13:16.125Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   12.938635] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.949889] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.961928] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   12.974325] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   12.982654] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   12.986132] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   13.474329] ., OK <NL> [   13.481494] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   13.508453] IP-Config: Complete: <NL> [   13.511881]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   13.529836]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   13.532500]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   13.532502]      nameserver0=10.0.2.3 <NL> [   14.074030] md: Waiting for all devices to be available before autodetect <NL> [   14.092738] md: If you don't use raid, use raid=noautodetect <NL> [   14.094009] md: Autodetecting RAID arrays. <NL> [   14.102366] md: autorun ... <NL> [   14.104061] md: ... autorun DONE. <NL> [   14.124964] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   14.182983] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   14.187409] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   14.189190] devtmpfs: mounted <NL> [   14.200461] Freeing unused kernel image (initmem) memory: 1964K <NL> [   14.208417] Write protecting the kernel read-only data: 22528k <NL> [   14.211620] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   14.218974] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   14.219942] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   14.598125] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   14.620231] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   14.744204] #####FSS INIT: Running on host <NL> [   14.919388] #####FSS INIT: FSS system init pre startup script <NL> [   14.978415] random: python3: uninitialized urandom read (24 bytes read) <NL> [   17.811457] random: crng init done <NL> [   20.551685] #####FSS INIT: UnitCode:f9fc  ShelfRole:MAIN <NL> [   20.645817] #####FSS INIT: FSS no slotRole found <NL> [   20.663042] #####FSS INIT: FSS system init get inputs from PSI f9fc : MAIN <NL> [   20.700980] #####FSS INIT:PI data: unitCode=f9fc Role=MAIN <NL> [   20.769542] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   20.794123] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   20.831144] #####FSS INIT:FSS MAIN Target File found : /lib/systemd/system/FSS-MAIN.target <NL> [   20.835573] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-MAIN.target <NL> sh: -d: unknown operand <NL> [   20.851177] #####FSS INIT:systemd will take it from here! <NL> [   20.886294] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   20.935721] systemd[1]: Detected virtualization kvm. <NL> [   20.938938] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   20.951511] systemd[1]: Hostname set to <fujitsu>. <NL> [   20.963692] systemd[1]: Initializing machine ID from random generator. <NL> [   21.139610] systemd-sysv-generator[344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   21.236666] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   21.883656] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.886815] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.906237] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   21.965597] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.014364] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.034633] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.046931] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.094040] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.097063] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.130817] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.134500] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.156814] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.173197] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:16.382Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   19.191134] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   19.253680] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   19.255647] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   19.283786] systemd[1]: Starting Journal Socket... <NL> [   19.284762] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   19.306584] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   19.308386] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   19.320457] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   19.333861] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   19.346356] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   19.385938] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   19.498801] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   19.554816] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   19.593795] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   19.674569] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   19.716343] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   19.762343] systemd[1]: Starting Load Kernel Module fuse..."}
{"timestamp_utc": "2024-07-31T08:13:16.383Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   19.879844] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   20.005907] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   20.049215] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   20.085480] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   20.222100] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   20.275196] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   20.333938] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   20.361389] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   20.379901] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   20.397350] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   20.460726] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   20.470381] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   20.472343] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   20.507141] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   20.532551] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   20.556472] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   20.559445] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   20.566213] systemd[1]: Mounting Kernel Configuration File System... <NL> [   20.568385] fuse: init (API version 7.32) <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   20.651959] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   20.659144] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   20.669045] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   20.684294] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> [   20.720782] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   20.753278] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   20.801985] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.813154] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   20.840996] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   20.865636] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   20.911446] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   20.965584] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   20.985787] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   21.017143] dcn_phantom_drv: VIF Support v1.0 <NL> [   21.019993] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   21.065759] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   21.075321] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   21.252709] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   21.476163] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   21.537178] systemd[1]: Finished Coldplug All udev Devices. <NL> [   21.545790] packet_injector_class: driver registered correctly with major number 246 <NL> [   21.568940] Packet_injector 257949696: minor device creation 246:0 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   21.569322] Packet_injector 257949697: minor device creation 246:1 <NL> [   21.579190] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   21.583333] systemd[1]: Mounted /var/ftp. <NL> [   21.584927] Packet_injector 257949698: minor device creation 246:2 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   21.598186] systemd[1]: Mounted /var/log. <NL> [   21.601735] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   21.609373] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   21.614403] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   21.629207] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   21.644205] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:17.310Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   19.004719] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   19.025127] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   19.064779] systemd[1]: Starting Journal Socket... <NL> [   19.065926] systemd[350]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   19.098824] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   19.108818] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   19.118612] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   19.136101] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   19.198493] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   19.259273] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   19.347111] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   19.398353] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   19.483945] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   19.526751] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   19.732754] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   19.818548] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   19.867148] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   19.959219] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   20.088586] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   20.160277] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   20.253911] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   20.337337] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   20.383861] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   20.471984] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   20.623879] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   20.690104] systemd[1]: Mounted Kernel Trace File System. <NL> [   20.695626] fuse: init (API version 7.32) <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   20.726071] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   20.793677] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   20.806581] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   20.844112] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   20.858599] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   20.908596] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   20.920940] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   20.935621] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   21.031716] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   21.080379] systemd[1]: Mounting FUSE Control File System..."}
{"timestamp_utc": "2024-07-31T08:13:17.311Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   21.085467] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   21.120175] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   21.131110] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   21.161594] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   21.175789] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   21.191289] dcn_phantom_drv: VIF Support v1.0 <NL> [   21.205499] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   21.241259] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   21.263629] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   21.529508] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   21.617637] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   21.625268] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   21.689245] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   21.748279] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   21.774451] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   21.809481] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   21.841627] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   21.874308] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   22.069127] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   22.145776] packet_injector_class: driver registered correctly with major number 246 <NL> [   22.146984] Packet_injector 257949696: minor device creation 246:0 <NL> [   22.153713] Packet_injector 257949697: minor device creation 246:1 <NL> [   22.167549] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   22.190265] Packet_injector 257949698: minor device creation 246:2 <NL> [   22.214243] systemd[1]: Mounted /var/log. <NL> [   22.259267] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   22.276528] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:17.312Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   22.186038] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.190747] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.246192] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.253408] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.280683] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.327177] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.471541] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.510820] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.538430] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.564742] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.573897] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.630711] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.717666] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   22.728181] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   22.841548] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.844176] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.920647] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.923725] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.940593] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.962112] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   22.978137] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.016635] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.068610] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.071759] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.105062] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.109525] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.166364] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.212654] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.285234] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.317747] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.450531] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:18.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   21.699875] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   21.742033] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   21.758463] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   21.768657] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   21.822423] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   21.851683] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   21.863009] systemd[1]: Reached target Path Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [   21.878957] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   21.896388] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   21.910612] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   22.005287] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   22.020347] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   22.030298] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   22.109558] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   22.164356] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   22.166122] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   22.177000] systemd[1]: Starting Journal Socket... <NL> [   22.186312] systemd[349]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   22.234696] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   22.244620] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   22.250653] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   22.260893] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   22.273966] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   22.282168] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   22.298570] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   22.319642] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   22.364375] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   22.396930] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   22.429671] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   22.465953] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   22.551272] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   22.646366] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   22.669404] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   22.677573] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   22.703686] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   22.774100] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   22.819519] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   22.872889] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   22.890706] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   22.901950] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   22.919517] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   22.962540] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   22.999297] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   23.038951] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   23.063581] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   23.097547] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   23.109494] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [   23.122684] fuse: init (API version 7.32)"}
{"timestamp_utc": "2024-07-31T08:13:18.242Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   23.150193] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   23.247606] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   23.249035] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   23.253343] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   23.272329] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   23.280488] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   23.282343] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   23.359670] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   23.415206] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   23.430008] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   23.469728] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   23.490235] dcn_phantom_drv: VIF Support v1.0 <NL> [   23.502309] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   23.531666] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   23.600205] systemd[1]: Mounting /var/ftp..."}
{"timestamp_utc": "2024-07-31T08:13:19.606Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:19 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37293, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:19 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37293\" SSHException('Error reading SSH protocol banner',) <NL> [   23.481602] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.527242] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.548824] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.615348] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.622030] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.685668] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.698997] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.750923] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.790832] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.839742] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.852893] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   23.923767] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   24.063758] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   24.129846] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   24.218656] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   24.282966] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   24.327117] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   24.388542] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   24.402175] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   24.412741] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   24.450880] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   24.468621] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   24.479629] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   24.483181] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   24.552262] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   24.568167] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   24.590607] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   24.599775] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   24.635719] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   24.664888] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   24.704860] systemd[1]: Starting Journal Socket... <NL> [   24.705329] systemd[350]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   24.742853] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   24.747264] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   24.786536] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   24.837114] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:19.607Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   24.847859] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   24.918592] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:19.862Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   24.955591] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   24.983221] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   25.051767] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   25.143363] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:19.863Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   25.178581] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   25.227086] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   25.276921] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   25.401082] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   25.407899] fuse: init (API version 7.32) <NL> [   25.416429] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   25.455683] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   25.478162] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   25.532362] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   25.581894] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   25.588386] systemd[1]: Mounted POSIX Message Queue File System. <NL> # 03:13:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:19 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:19 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:20.119Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p06", "keyword_name": "NE3-trib1-debug-ssh", "step_id": "NE3-trib1-debug-ssh", "message_content": "# 03:13:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37233, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37233\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37201, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37297, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37201\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37297\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37265, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:20 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37265\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:20.696Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   20.705672] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:20.697Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   20.726492] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   20.746360] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   20.785964] systemd[1]: Starting Journal Socket... <NL> [   20.799452] systemd[316]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   20.848856] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   20.858431] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   20.895822] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   20.942676] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   20.995583] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   21.015476] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   21.050830] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   21.139089] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   21.216985] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   21.320083] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   21.429370] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   21.531517] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   21.623069] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   21.758270] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   21.863077] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   21.917372] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   22.147663] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   22.310608] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   22.397378] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   22.442898] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   22.519307] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   22.580089] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   22.686162] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   22.761203] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   22.838157] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   22.844432] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   22.889245] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   23.127796] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   23.161802] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   23.195804] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   23.220518] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   23.326469] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   23.475950] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   23.614827] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m.[   23.703180] fuse: init (API version 7.32) <NL> [   23.839321] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   23.910695] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   24.096769] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   24.302463] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   24.521286] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   24.564722] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   24.593940] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   24.683741] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   24.806334] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   24.839082] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   24.954711] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   25.088815] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   25.329581] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   25.428719] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   25.535968] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   25.604458] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   25.782021] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   25.925477] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   25.998835] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   26.123287] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   26.248533] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   26.315928] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   26.443857] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   26.457266] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:22.585Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   12.465476] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.468938] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   12.486593] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   12.497711] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   13.162234] ., OK <NL> [   13.165250] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   13.186162] IP-Config: Complete: <NL> [   13.189339]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   13.192929]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   13.193517]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   13.193518]      nameserver0=10.0.2.3 <NL> [   13.670723] md: Waiting for all devices to be available before autodetect <NL> [   13.684114] md: If you don't use raid, use raid=noautodetect <NL> [   13.710428] md: Autodetecting RAID arrays. <NL> [   13.731052] md: autorun ... <NL> [   13.731401] md: ... autorun DONE. <NL> [   13.739093] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   13.801371] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   13.813650] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   13.826106] devtmpfs: mounted <NL> [   13.835499] Freeing unused kernel image (initmem) memory: 1964K <NL> [   13.857872] Write protecting the kernel read-only data: 22528k <NL> [   13.869225] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   13.878139] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   13.881863] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   14.247073] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   14.269453] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   14.385028] #####FSS INIT: Running on host <NL> [   14.654193] #####FSS INIT: FSS system init pre startup script <NL> [   14.760242] random: python3: uninitialized urandom read (24 bytes read) <NL> [   19.142827] random: crng init done <NL> [   22.109320] #####FSS INIT: UnitCode:c200  ShelfRole:MAIN <NL> [   22.118600] #####FSS INIT: FSS no slotRole found <NL> [   22.160632] #####FSS INIT: FSS system init get inputs from PSI c200 : MAIN <NL> [   22.170138] #####FSS INIT:PI data: unitCode=c200 Role=MAIN <NL> [   22.227227] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   22.248976] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-C200-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   22.319576] #####FSS INIT:Specific Target File found : /lib/systemd/system/FSS-C200-MAIN.target <NL> [   22.348283] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-C200-MAIN.target <NL> sh: -d: unknown operand <NL> [   22.402612] #####FSS INIT:systemd will take it from here! <NL> [   22.510535] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   22.641153] systemd[1]: Detected virtualization kvm. <NL> [   22.646415] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   22.681074] systemd[1]: Hostname set to <fujitsu>. <NL> [   22.698612] systemd[1]: Initializing machine ID from random generator. <NL> [   23.128311] systemd-sysv-generator[309]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   23.320703] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   24.342488] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.503394] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.648699] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.665297] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.726404] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.851548] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.866305] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.875550] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.879585] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.933465] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   24.969206] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.024175] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:22.586Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   25.047047] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.073569] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.114163] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.129779] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:23.513Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   25.156060] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.178633] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.217063] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.237816] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.271202] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.295211] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   25.314784] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   25.342434] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.362893] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.393131] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.415539] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.436271] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.457019] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.489144] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.509844] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.535096] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.552406] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.558293] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.561128] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.568586] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:23.514Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   25.571503] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.651958] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.687294] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.732989] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.752541] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.777493] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.797670] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.822570] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.842708] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.867977] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.887345] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   25.917832] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -."}
{"timestamp_utc": "2024-07-31T08:13:24.440Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:24 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:24.696Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "# 03:13:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37293, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:24 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37293\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:24.952Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:24 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:24 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:25.209Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p06", "keyword_name": "NE3-trib1-debug-ssh", "step_id": "NE3-trib1-debug-ssh", "message_content": "# 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37233, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37233\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37201, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:25.210Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "# 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37297, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37297\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37265, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:25 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37265\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:25.773Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   25.625871] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   25.637492] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   25.677101] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   25.691842] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   25.702717] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   25.722346] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   25.723807] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   25.764011] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   25.766889] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   25.815023] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   25.875341] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   26.010025] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   26.081235] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   26.121812] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   26.127628] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   26.142087] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   26.144728] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> [   26.171941] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   26.239477] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   26.242908] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   26.319974] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [   26.325971] dcn_phantom_drv: VIF Support v1.0 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   26.342133] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   26.351700] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   26.384359] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   26.395825] packet_injector_class: driver registered correctly with major number 246 <NL> [   26.397128] systemd[1]: Mounting /var/log... <NL> [   26.406837] Packet_injector 257949696: minor device creation 246:0 <NL> [   26.419277] Packet_injector 257949697: minor device creation 246:1 <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   26.498582] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   26.506533] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   26.536611] Packet_injector 257949698: minor device creation 246:2 <NL> [   26.546486] Packet_injector 257949699: minor device creation 246:3 <NL> [   26.558978] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   26.628780] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   26.645511] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   26.658964] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   26.675126] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   26.686357] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   26.690679] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   26.696953] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   26.716996] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   26.799026] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   26.950582] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   26.965767] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   26.993581] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   27.023086] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   27.035887] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   27.049062] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   27.089663] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   27.440558] systemd-journald[359]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (6s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6namic Linker Cache (6s / no limit) <NL> [   31.022092] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   31.042042] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   31.048361] Floppy drive(s): fd0 is 1.44M <NL> [   31.100585] Console: switching to colour dummy device 80x25 <NL> [   31.127254] FDC 0 is a S82078B"}
{"timestamp_utc": "2024-07-31T08:13:25.774Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "\u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> \u001b[K[   31.155298] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   31.188466] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   31.212531] Console: switching to colour frame buffer device 128x48 <NL> [   31.250115] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [   31.279494] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   31.283194] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)]"}
{"timestamp_utc": "2024-07-31T08:13:26.031Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   25.946460] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   26.017083] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   26.038089] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   26.057968] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   26.074458] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   26.094456] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   26.103996] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   26.142091] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   26.166904] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   26.208137] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   26.221010] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   26.234598] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   26.277791] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   26.285789] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   26.300392] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   26.317417] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   26.331030] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   26.332773] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   26.346740] systemd[1]: Starting Journal Socket... <NL> [   26.360477] systemd[315]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   26.373206] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   26.389933] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   26.401700] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   26.432926] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   26.443836] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   26.461409] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   26.477781] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   26.556806] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   26.630962] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   26.653164] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   26.723050] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   26.775064] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   26.826235] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   26.874445] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   26.907756] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:26.032Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   26.940944] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   27.001587] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   27.079840] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   27.173027] systemd[1]: Mounted POSIX Message Queue File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m. <NL> [   27.242615] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   27.312149] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   27.326203] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   27.396087] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   27.406405] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   27.461109] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   27.500469] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   27.571983] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   27.573686] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   27.612072] systemd[1]: Mounted Kernel Configuration File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   27.729194] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   27.803361] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   27.824041] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   27.898118] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   28.128659] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   28.188493] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   28.324323] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   28.445278] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   28.556414] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   28.682033] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   28.864962] fuse: init (API version 7.32) <NL> [   28.877488] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   28.910411] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   28.931021] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:26.593Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p08.NE4-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p08", "keyword_name": "NE4-trib1-debug-ssh", "step_id": "NE4-trib1-debug-ssh", "message_content": "# 03:13:26 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:26 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:13:26.848Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:26 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:26 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:26 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\": process 3339 terminated with exitcode 0 <NL> # 03:13:26 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p08.NE4-trib1-debug-ssh)"}
{"timestamp_utc": "2024-07-31T08:13:26.849Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "# 03:13:26 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #7 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:26 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 7 children running (n01.p09.s01.startup (p)) <NL> # 03:13:26 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p08.NE4-trib1-debug-ssh\", exit_code 0 <NL> [   13.325417] e1000: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.327317] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready <NL> [   13.391420] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.393541] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.401614] IPv6: ADDRCONF(NETDEV_CHANGE): eth2: link becomes ready <NL> [   13.402535] IPv6: ADDRCONF(NETDEV_CHANGE): eth1: link becomes ready <NL> [   13.452421] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.454016] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.461250] IPv6: ADDRCONF(NETDEV_CHANGE): eth4: link becomes ready <NL> [   13.468304] IPv6: ADDRCONF(NETDEV_CHANGE): eth3: link becomes ready <NL> [   13.518405] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.520417] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   13.523740] IPv6: ADDRCONF(NETDEV_CHANGE): eth6: link becomes ready <NL> [   13.524645] IPv6: ADDRCONF(NETDEV_CHANGE): eth5: link becomes ready <NL> [   14.460672] ., OK <NL> [   14.465185] IP-Config: Got DHCP answer from 10.0.2.2, my address is 10.0.2.15 <NL> [   14.466114] IP-Config: Complete: <NL> [   14.466544]      device=eth0, hwaddr=52:54:00:12:34:56, ipaddr=10.0.2.15, mask=255.255.255.0, gw=10.0.2.2 <NL> [   14.467783]      host=10.0.2.15, domain=, nis-domain=(none) <NL> [   14.468519]      bootserver=10.0.2.2, rootserver=10.0.2.2, rootpath= <NL> [   14.468521]      nameserver0=10.0.2.3 <NL> [   14.981638] md: Waiting for all devices to be available before autodetect <NL> [   14.990526] md: If you don't use raid, use raid=noautodetect <NL> [   14.991798] md: Autodetecting RAID arrays. <NL> [   14.992377] md: autorun ... <NL> [   14.992773] md: ... autorun DONE. <NL> [   14.999461] EXT4-fs (vda): mounting ext3 file system using the ext4 subsystem <NL> [   15.233056] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null) <NL> [   15.234126] VFS: Mounted root (ext3 filesystem) on device 253:0. <NL> [   15.252394] devtmpfs: mounted <NL> [   15.270233] Freeing unused kernel image (initmem) memory: 1964K <NL> [   15.284641] Write protecting the kernel read-only data: 22528k <NL> [   15.315224] Freeing unused kernel image (text/rodata gap) memory: 2032K <NL> [   15.333106] Freeing unused kernel image (rodata/data gap) memory: 172K <NL> [   15.340271] Run /sbin/init as init process <NL> mount: /dev: none already mounted on /proc. <NL> mount: /var/shared: can't find in /etc/fstab. <NL> [   16.199972] ##### BOOTCOUNT: Currently running Bank : /dev/vda <NL> [   16.203554] #### BOOTCOUNT: creating the bootcount file <NL> mount: /proc/sys: mount point not mounted or bad option. <NL> [   16.785031] #####FSS INIT: Running on host <NL> [   17.187617] #####FSS INIT: FSS system init pre startup script <NL> [   17.436361] random: python3: uninitialized urandom read (24 bytes read) <NL> [   24.298991] random: crng init done <NL> [   27.222239] #####FSS INIT: UnitCode:f9fc  ShelfRole:MAIN <NL> [   27.261131] #####FSS INIT: FSS no slotRole found <NL> [   27.280363] #####FSS INIT: FSS system init get inputs from PSI f9fc : MAIN <NL> [   27.308096] #####FSS INIT:PI data: unitCode=f9fc Role=MAIN <NL> [   27.430978] #####FSS INIT: Calling pf_fsck for SATA disk checking... <NL> [   27.465238] #####FSS INIT:Looking for Target Files : /lib/systemd/system/FSS-F9FC-MAIN.target : /lib/systemd/system/FSS-CORE.target <NL> [   27.495634] #####FSS INIT:FSS MAIN Target File found : /lib/systemd/system/FSS-MAIN.target <NL> [   27.496859] #####FSS INIT:Creating softlink /etc/systemd/system/default.target to /lib/systemd/system/FSS-MAIN.target <NL> sh: -d: unknown operand <NL> [   27.561332] #####FSS INIT:systemd will take it from here! <NL> [   27.818953] systemd[1]: systemd 250.5+ running in system mode (+PAM -AUDIT -SELINUX -APPARMOR +IMA -SMACK +SECCOMP -GCRYPT -GNUTLS -OPENSSL +ACL +BLKID -CURL +ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -BZIP2 -LZ4 -XZ -ZLIB +ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=hybrid) <NL> [   27.825169] systemd[1]: Detected virtualization kvm. <NL> [   27.826877] systemd[1]: Detected architecture x86-64. <NL> Welcome to \u001b[1mEnea Linux 8.3 (kirkstone)\u001b[0m! <NL> [   27.851926] systemd[1]: Hostname set to <fujitsu>. <NL> [   27.878359] systemd[1]: Initializing machine ID from random generator. <NL> [   28.150046] systemd-sysv-generator[344]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [   28.331803] systemd[1]: systemd-journald.socket: Dependency After=systemd-journald.socket dropped <NL> [   29.316756] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.354748] systemd[1]: /etc/systemd/system/validation-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.399079] systemd[1]: /etc/systemd/system/user-mgmt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.473213] systemd[1]: /etc/systemd/system/temp-acct-clean.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.528296] systemd[1]: /etc/systemd/system/sync-evt.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.567030] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.604954] systemd[1]: /etc/systemd/system/router-ext-intf.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.633635] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.659427] systemd[1]: /etc/systemd/system/router-controller.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.733652] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.758418] systemd[1]: /etc/systemd/system/ops-tacacs.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.799712] systemd[1]: /etc/systemd/system/ops-service.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.817693] systemd[1]: /etc/systemd/system/ops-security.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:27.776Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   21.682349] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   21.708509] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   21.732914] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   21.759188] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   21.776495] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   21.810514] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   21.826932] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   21.844973] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   21.871342] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   21.901515] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   21.938647] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   21.982447] systemd[1]: Finished Load/Save Random Seed. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   22.027729] systemd[1]: First Boot Complete was skipped because of a failed condition check (ConditionFirstBoot=yes). <NL> [   22.054401] systemd[1]: Commit a transient machine-id on disk was skipped because of a failed condition check (ConditionPathIsMountPoint=/etc/machine-id). <NL> [   22.207588] systemd[1]: Finished Apply Kernel Variables. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [   22.350139] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   22.545462] systemd-journald[360]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [   24.429027] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   24.468358] Console: switching to colour dummy device 80x25 <NL> [   24.476433] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   24.504808] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   24.556899] Floppy drive(s): fd0 is 1.44M <NL> [   24.571114] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   24.644329] Console: switching to colour frame buffer device 128x48 <NL> [   24.654226] FDC 0 is a S82078B <NL> [   24.730712] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   25.293398] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   25.322210] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:27.777Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:52506)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [   31.345711] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   32.512593] pktHandler[586]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg"}
{"timestamp_utc": "2024-07-31T08:13:28.033Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   23.607040] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   23.659090] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   23.752649] packet_injector_class: driver registered correctly with major number 246 <NL> [   23.753074] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   23.788142] Packet_injector 257949696: minor device creation 246:0 <NL> [   23.804346] Packet_injector 257949697: minor device creation 246:1 <NL> [   23.862430] Packet_injector 257949698: minor device creation 246:2 <NL> [   23.863999] systemd[1]: Mounting /var/telemetry... <NL> [   23.882019] Packet_injector 257949699: minor device creation 246:3 <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   23.957444] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   24.079412] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   24.118891] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   24.153455] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   24.163511] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   24.176901] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   24.194712] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   24.207778] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   24.224227] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   24.236215] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   24.268803] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   24.336015] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   24.348991] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   24.410359] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   24.414079] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   24.446787] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   24.472801] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   24.489092] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:28.034Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   24.742625] systemd-journald[358]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6guration filesystem (6s / 4min 2s) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6guration filesystem (6s / 4min 2s) <NL> [   28.461161] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   28.476757] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   28.488509] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 3) A start job is running for\\xe2\\x80\\xa6guration filesystem (7s / 4min 2s) <NL> [   28.604873] Floppy drive(s): fd0 is 1.44M <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> \u001b[K[   28.660943] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   28.670024] FDC 0 is a S82078B <NL> [   28.690906] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   28.755176] Console: switching to colour frame buffer device 128x48 <NL> [   28.852596] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [   28.959646] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   28.981735] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:28.290Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   29.871773] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.889334] systemd[1]: /etc/systemd/system/ops-radius.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.919954] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   29.933296] systemd[1]: /etc/systemd/system/opr-data-handler.service.d/platform_default_opr_data_handler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.023566] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.036513] systemd[1]: /etc/systemd/system/dcn-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.224886] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.269336] systemd[1]: /etc/systemd/system/dcn-lldp-controller-trib.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.338618] systemd[1]: /etc/systemd/system/dcn-ipdcc-agent.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.401198] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.409519] systemd[1]: /etc/systemd/system/hook-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.497386] systemd[1]: /etc/systemd/system/eth-sub-app.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.531228] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:18: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   30.545778] systemd[1]: /lib/systemd/system/factory-user-shell-audit.service:19: Standard output type syslog+console is obsolete, automatically updating to journal+console. Please update your unit file, and consider removing the setting altogether. <NL> [   30.625038] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.637753] systemd[1]: /etc/systemd/system/dcn-proxy-ndp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.672451] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:10: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.675462] systemd[1]: /etc/systemd/system/dcn-lldp-controller.service.d/platform_default_override.conf:11: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.752259] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:28.291Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   30.768517] systemd[1]: /etc/systemd/system/dcn-ipdcc.service.d/platform_default_override.conf:7: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.841357] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.844417] systemd[1]: /etc/systemd/system/dcn-gret-controller.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.929526] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:8: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.933265] systemd[1]: /etc/systemd/system/dcn-dhcp-client.service.d/platform_default_override.conf:9: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.969044] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:2: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   30.997133] systemd[1]: /etc/systemd/system/dcn-cmn-config.service.d/platform_default_override.conf:3: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.007395] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.010249] systemd[1]: /etc/systemd/system/dcn-acl.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.054264] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:4: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.070945] systemd[1]: /etc/systemd/system/cdb-sub-data-handler.service.d/platform_default_datahandler_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.120953] systemd[1]: /etc/systemd/system/zeroization-mgr.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.151651] systemd[1]: /etc/systemd/system/rasis-util.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:29.656Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:29 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37293, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:29 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37293\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:29.927Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:29 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:29 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> [   21.704840] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   21.760397] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   21.783956] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   21.789706] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   21.794976] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   21.808460] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   21.848474] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   21.913335] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   21.991984] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   22.065486] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   22.213847] systemd-journald[358]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   24.924120] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [   24.958768] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   25.167255] Floppy drive(s): fd0 is 1.44M <NL> [   25.226287] FDC 0 is a S82078B <NL> [   25.335660] Console: switching to colour dummy device 80x25 <NL> [   25.432531] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   25.463395] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   25.549294] Console: switching to colour frame buffer device 128x48 <NL> [   25.604972] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [   25.722134] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   25.765074] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   26.458040] hrtimer: interrupt took 11193719 ns <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:29.928Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [   36.471432] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   36.923829] pktHandler[572]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg"}
{"timestamp_utc": "2024-07-31T08:13:30.193Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p06", "keyword_name": "NE3-trib1-debug-ssh", "step_id": "NE3-trib1-debug-ssh", "message_content": "# 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37233, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37297, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37265, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:30.754Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   31.182709] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.230672] systemd[1]: /etc/systemd/system/dcn-ppp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.297837] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.344452] systemd[1]: /etc/systemd/system/dcn-pl-te.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.419423] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.460481] systemd[1]: /etc/systemd/system/dcn-network-pm.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.518117] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.553432] systemd[1]: /etc/systemd/system/dcn-nat.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether."}
{"timestamp_utc": "2024-07-31T08:13:30.755Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   31.626811] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:5: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.662643] systemd[1]: /etc/systemd/system/dcn-int-rstp.service.d/platform_default_override.conf:6: Standard output type syslog is obsolete, automatically updating to journal. Please update your unit file, and consider removing the setting altogether. <NL> [   31.733334] systemd[1]: Queued start job for default target FSS EXAMPLE Product Target - sample MAIN -. <NL> [   31.808267] systemd[1]: cgroup compatibility translation between legacy and unified hierarchy settings activated. See cgroup-compat debug messages for details. <NL> [   31.845761] systemd[1]: Created slice Slice /system/getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/getty\u001b[0m. <NL> [   31.852057] systemd[1]: Created slice Slice /system/modprobe. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/modprobe\u001b[0m. <NL> [   31.868637] systemd[1]: Created slice Slice /system/serial-getty. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/serial-getty\u001b[0m. <NL> [   31.907381] systemd[1]: Created slice Slice /system/syslog-ng. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/syslog-ng\u001b[0m. <NL> [   31.941468] systemd[1]: Created slice User and Session Slice. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser and Session Slice\u001b[0m. <NL> [   31.974753] systemd[1]: Started Dispatch Password Requests to Console Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDispatch Password \\xe2\\x80\\xa6ts to Console Directory Watch\u001b[0m. <NL> [   31.993090] systemd[1]: Started Forward Password Requests to Wall Directory Watch. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mForward Password R\\xe2\\x80\\xa6uests to Wall Directory Watch\u001b[0m. <NL> [   32.037400] systemd[1]: Reached target Host and Network Name Lookups. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mHost and Network Name Lookups\u001b[0m. <NL> [   32.042291] systemd[1]: Reached target Remote File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRemote File Systems\u001b[0m. <NL> [   32.050672] systemd[1]: Reached target Slice Units. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSlice Units\u001b[0m. <NL> [   32.058766] systemd[1]: Reached target Swaps. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSwaps\u001b[0m. <NL> [   32.108193] systemd[1]: Listening on RPCbind Server Activation Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mRPCbind Server Activation Socket\u001b[0m. <NL> [   32.162019] systemd[1]: Reached target RPC Port Mapper. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mRPC Port Mapper\u001b[0m. <NL> [   32.188353] systemd[1]: Listening on Process Core Dump Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mProcess Core Dump Socket\u001b[0m. <NL> [   32.245552] systemd[1]: Listening on initctl Compatibility Named Pipe. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39minitctl Compatibility Named Pipe\u001b[0m. <NL> [   32.333122] systemd[1]: Journal Audit Socket was skipped because of a failed condition check (ConditionSecurity=audit). <NL> [   32.343465] systemd[1]: Listening on Journal Socket (/dev/log). <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket (/dev/log)\u001b[0m. <NL> [   32.370811] systemd[350]: systemd-journald.socket: Failed to connect stdout to the journal socket, ignoring: No such file or directory <NL> [   32.377330] systemd[1]: Starting Journal Socket... <NL> Starting \u001b[0;1;39mJournal Socket\u001b[0m... <NL> [   32.395441] systemd[1]: Listening on udev Control Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Control Socket\u001b[0m. <NL> [   32.411764] systemd[1]: Listening on udev Kernel Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mudev Kernel Socket\u001b[0m. <NL> [   32.425405] systemd[1]: Listening on User Database Manager Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mUser Database Manager Socket\u001b[0m. <NL> [   32.483639] systemd[1]: Listening on Journal Socket. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mJournal Socket\u001b[0m. <NL> [   32.522364] systemd[1]: Huge Pages File System was skipped because of a failed condition check (ConditionPathExists=/sys/kernel/mm/hugepages). <NL> [   32.582952] systemd[1]: Mounting POSIX Message Queue File System... <NL> Mounting \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m... <NL> [   32.643690] systemd[1]: Mounting Kernel Debug File System... <NL> Mounting \u001b[0;1;39mKernel Debug File System\u001b[0m... <NL> [   32.664780] systemd[1]: Mounting Kernel Trace File System... <NL> Mounting \u001b[0;1;39mKernel Trace File System\u001b[0m... <NL> [   32.708063] systemd[1]: Starting Create List of Static Device Nodes... <NL> Starting \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m... <NL> [   32.786470] systemd[1]: Starting Load Kernel Module configfs... <NL> Starting \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m... <NL> [   32.886484] systemd[1]: Starting Load Kernel Module drm... <NL> Starting \u001b[0;1;39mLoad Kernel Module drm\u001b[0m... <NL> [   32.939269] systemd[1]: Starting Load Kernel Module fuse... <NL> Starting \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m... <NL> [   33.020549] systemd[1]: Starting RPC Bind... <NL> Starting \u001b[0;1;39mRPC Bind\u001b[0m... <NL> [   33.228683] systemd[1]: Starting Journal Service... <NL> Starting \u001b[0;1;39mJournal Service\u001b[0m... <NL> [   33.329727] systemd[1]: Starting Load Kernel Modules... <NL> Starting \u001b[0;1;39mLoad Kernel Modules\u001b[0m... <NL> [   33.382562] systemd[1]: Starting Generate network units from Kernel command line... <NL> Starting \u001b[0;1;39mGenerate network \\xe2\\x80\\xa6ts from Kernel command line\u001b[0m... <NL> [   33.458509] systemd[1]: Starting Remount Root and Kernel File Systems... <NL> Starting \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m... <NL> [   33.490565] systemd[1]: Starting Coldplug All udev Devices... <NL> Starting \u001b[0;1;39mColdplug All udev Devices\u001b[0m... <NL> [   33.550354] systemd[1]: Started RPC Bind. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRPC Bind\u001b[0m. <NL> [   33.588769] systemd[1]: Mounted POSIX Message Queue File System. <NL> [   33.590543] fuse: init (API version 7.32) <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mPOSIX Message Queue File System\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:32.118Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p04.NE2-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p04", "keyword_name": "NE2-trib1-debug-ssh", "step_id": "NE2-trib1-debug-ssh", "message_content": "# 03:13:32 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:32 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\": process 3335 terminated with exitcode 0 <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #3 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 6 children running (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p04.NE2-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:32.374Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p06.NE3-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p06", "keyword_name": "NE3-trib1-debug-ssh", "step_id": "NE3-trib1-debug-ssh", "message_content": "# 03:13:32 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:32 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\": process 3337 terminated with exitcode 0 <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #5 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 5 children running (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p06.NE3-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:32.935Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p02.NE1-trib1-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p02", "keyword_name": "NE1-trib1-debug-ssh", "step_id": "NE1-trib1-debug-ssh", "message_content": "# 03:13:32 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:32 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:32 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\": process 3333 terminated with exitcode 0 <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"command\": finished (n01.p09.s01.p02.NE1-trib1-debug-ssh) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #1 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 4 children running (n01.p09.s01.startup (p)) <NL> # 03:13:32 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p02.NE1-trib1-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:33.192Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   22.635521] systemd-journald[360]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   26.008008] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   26.468059] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   26.471699] Console: switching to colour dummy device 80x25 <NL> [   26.552405] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   26.633684] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   26.772572] Console: switching to colour frame buffer device 128x48 <NL> [   26.927565] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [   27.295643] Floppy drive(s): fd0 is 1.44M <NL> [   27.358526] FDC 0 is a S82078B <NL> [   27.764691] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   27.791585] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [   34.937976] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:42726)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   37.650924] pktHandler[590]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.692932] pktHandler[590]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.732604] pktHandler[590]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.762145] pktHandler[590]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.771961] pktHandler[590]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.822758] pktHandler[590]: Init PktClient init complete <NL> [   37.825452] pktHandler[590]: EsalConfig::EsalConfig main 0 <NL> [   37.829949] pktHandler[590]: EsalConfig::EsalConfig trib 1 <NL> [   37.839300] pktHandler[590]: EsalConfig::EsalConfig ciRole 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   37.891417] pktHandler[590]: EsalConfig is not running inside container. <NL> [   38.027042] pktHandler[590]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:13:33.193Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   38.059020] pktHandler[590]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.071737] pktHandler[590]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.108346] pktHandler[590]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   38.118545] pktHandler[590]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   38.135459] pktHandler[590]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:13:34.135Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:46306)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   36.035193] pktHandler[580]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   36.052860] pktHandler[580]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   36.131081] pktHandler[580]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   36.207464] pktHandler[580]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   36.241961] pktHandler[580]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   36.249452] pktHandler[580]: Init PktClient init complete <NL> [   36.250253] pktHandler[580]: EsalConfig::EsalConfig main 0 <NL> [   36.250987] pktHandler[580]: EsalConfig::EsalConfig trib 1 <NL> [   36.273489] pktHandler[580]: EsalConfig::EsalConfig ciRole 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   36.281209] pktHandler[580]: EsalConfig is not running inside container. <NL> [   36.295428] pktHandler[580]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   36.308910] pktHandler[580]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   36.337248] pktHandler[580]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   36.339284] pktHandler[580]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   36.340346] pktHandler[580]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   36.372695] pktHandler[580]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   36.384260] pktHandler[580]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   36.410450] pktHandler[580]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   36.416583] pktHandler[580]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   36.417572] pktHandler[580]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   36.418596] pktHandler[580]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   36.432248] pktHandler[580]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   36.436672] pktHandler[580]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   36.443207] pktHandler[580]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   36.444314] pktHandler[580]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   36.445267] pktHandler[580]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   36.446350] pktHandler[580]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   36.447447] pktHandler[580]: pkt-handler: sd_notify ready <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   36.736330] commsdriver[595]: DllUtil::symbolInit() <NL> [   36.739332] commsdriver[595]: int DllInit() <NL> [   36.741334] commsdriver[595]: DllUtil::DllInit DllInit() return is null <NL> [   36.749338] commsdriver[595]: Could not resolve symbol name get_late_config_file_path <NL> [   36.752316] commsdriver[595]: Could not resolve symbol name create_l3_interface <NL> [   36.755192] commsdriver[595]: Could not resolve symbol name create_l2_interface <NL> [   36.762320] commsdriver[595]: Could not resolve symbol name delete_interface <NL> [   36.782356] commsdriver[595]: Could not resolve symbol name pre_setup_interfaces <NL> [   36.790912] commsdriver[595]: Could not resolve symbol name setup_interfaces <NL> [   36.809220] commsdriver[595]: Could not resolve symbol name post_setup_interfaces <NL> [   36.824869] commsdriver[595]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   36.833746] commsdriver[595]: Could not resolve symbol name setup_late_interfaces <NL> [   36.841867] commsdriver[595]: Could not resolve symbol name post_setup_late_interfaces <NL> [   36.851640] commsdriver[595]: Could not resolve symbol name pre_init <NL> [   36.858994] commsdriver[595]: Could not resolve symbol name post_init <NL> [   36.866493] commsdriver[595]: Could not resolve symbol name pre_handle_link_state_change <NL> [   36.873456] commsdriver[595]: Could not resolve symbol name handle_link_state_change <NL> [   36.879535] commsdriver[595]: Could not resolve symbol name post_handle_link_state_change <NL> [   36.881902] commsdriver[595]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   36.889429] commsdriver[595]: Could not resolve symbol name handle_link_state_notify <NL> [   36.894416] commsdriver[595]: Could not resolve symbol name post_handle_link_state_notify <NL> [   36.900695] commsdriver[595]: Could not resolve symbol name handle_rate_duplex_change <NL> [   36.906918] commsdriver[595]: Could not resolve symbol name delete_mac_address <NL> [   36.912858] commsdriver[595]: Could not resolve symbol name set_vlan_prio <NL> [   36.915247] commsdriver[595]: Could not resolve symbol name replay_mac <NL> [   36.916145] commsdriver[595]: Could not resolve symbol name set_red_state <NL> [   36.917083] commsdriver[595]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   36.918039] commsdriver[595]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   36.919068] commsdriver[595]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   36.926725] commsdriver[595]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   36.931501] commsdriver[595]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   36.937690] commsdriver[595]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   36.944467] commsdriver[595]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   36.950557] commsdriver[595]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   36.956431] commsdriver[595]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   36.965812] commsdriver[595]: unitcode=02_00_00_00, uc=02_00_00_00"}
{"timestamp_utc": "2024-07-31T08:13:34.136Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   36.967820] commsdriver[595]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   36.984364] commsdriver[595]: SharedMemory::getShmSegment creating new segment <NL> [   36.996749] commsdriver[595]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:34.393Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   32.525386] pktHandler[586]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   32.529486] pktHandler[586]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   32.532972] pktHandler[586]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   32.537819] pktHandler[586]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   32.547604] pktHandler[586]: Init PktClient init complete <NL> [   32.549184] pktHandler[586]: EsalConfig::EsalConfig main 0 <NL> [   32.550382] pktHandler[586]: EsalConfig::EsalConfig trib 1 <NL> [   32.551464] pktHandler[586]: EsalConfig::EsalConfig ciRole 0 <NL> [   32.594662] pktHandler[586]: EsalConfig is not running inside container. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   32.595659] pktHandler[586]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.600438] pktHandler[586]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.618343] pktHandler[586]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.633439] pktHandler[586]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   32.644388] pktHandler[586]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   32.650597] pktHandler[586]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   32.669925] pktHandler[586]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   32.670047] pktHandler[586]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   32.670124] pktHandler[586]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   32.670197] pktHandler[586]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   32.670270] pktHandler[586]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   32.670348] pktHandler[586]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   32.670425] pktHandler[586]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   32.670528] pktHandler[586]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   32.670619] pktHandler[586]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   32.670693] pktHandler[586]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   32.670781] pktHandler[586]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   32.670854] pktHandler[586]: pkt-handler: sd_notify ready <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   33.146217] commsdriver[603]: DllUtil::symbolInit() <NL> [   33.152513] commsdriver[603]: int DllInit() <NL> [   33.160278] commsdriver[603]: DllUtil::DllInit DllInit() return is null"}
{"timestamp_utc": "2024-07-31T08:13:34.394Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   33.178540] commsdriver[603]: Could not resolve symbol name get_late_config_file_path <NL> [   33.190865] commsdriver[603]: Could not resolve symbol name create_l3_interface <NL> [   33.198486] commsdriver[603]: Could not resolve symbol name create_l2_interface <NL> [   33.202109] commsdriver[603]: Could not resolve symbol name delete_interface <NL> [   33.209766] commsdriver[603]: Could not resolve symbol name pre_setup_interfaces <NL> [   33.213674] commsdriver[603]: Could not resolve symbol name setup_interfaces <NL> [   33.222950] commsdriver[603]: Could not resolve symbol name post_setup_interfaces <NL> [   33.227319] commsdriver[603]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   33.228600] commsdriver[603]: Could not resolve symbol name setup_late_interfaces <NL> [   33.229629] commsdriver[603]: Could not resolve symbol name post_setup_late_interfaces <NL> [   33.230613] commsdriver[603]: Could not resolve symbol name pre_init <NL> [   33.231417] commsdriver[603]: Could not resolve symbol name post_init <NL> [   33.240520] commsdriver[603]: Could not resolve symbol name pre_handle_link_state_change <NL> [   33.245859] commsdriver[603]: Could not resolve symbol name handle_link_state_change <NL> [   33.246937] commsdriver[603]: Could not resolve symbol name post_handle_link_state_change <NL> [   33.247938] commsdriver[603]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   33.251256] commsdriver[603]: Could not resolve symbol name handle_link_state_notify <NL> [   33.264858] commsdriver[603]: Could not resolve symbol name post_handle_link_state_notify <NL> [   33.267299] commsdriver[603]: Could not resolve symbol name handle_rate_duplex_change <NL> [   33.272234] commsdriver[603]: Could not resolve symbol name delete_mac_address <NL> [   33.275649] commsdriver[603]: Could not resolve symbol name set_vlan_prio <NL> [   33.284268] commsdriver[603]: Could not resolve symbol name replay_mac <NL> [   33.285794] commsdriver[603]: Could not resolve symbol name set_red_state <NL> [   33.286979] commsdriver[603]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   33.288118] commsdriver[603]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   33.292645] commsdriver[603]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   33.294357] commsdriver[603]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   33.307673] commsdriver[603]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.313113] commsdriver[603]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   33.321178] commsdriver[603]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.322629] commsdriver[603]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.323649] commsdriver[603]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   33.325180] commsdriver[603]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   33.340170] commsdriver[603]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   33.348774] commsdriver[603]: SharedMemory::getShmSegment creating new segment <NL> [   33.351267] commsdriver[603]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Database Manager\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser Slice of UID 3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Manager for UID 3000\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Manager for UID 3000\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSession c1 of User fujitsu\u001b[0m. <NL> [   36.861320] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> fujitsu login: [   36.378166] commsdriver[649]: SUCCESS <NL> [   37.945314] commsdriver[603]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   38.564099] device eth1 entered promiscuous mode <NL> [   38.001921] commsdriver[603]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   38.252973] commsdriver[603]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   38.921471] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   38.939493] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1000: link becomes ready <NL> [   38.952537] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   38.400471] commsdriver[687]: Actual changes: <NL> [   38.400698] commsdriver[687]: tx-checksum-ip-generic: off <NL> [   38.400796] commsdriver[687]: tx-tcp-segmentation: off [not requested] <NL> [   38.400867] commsdriver[687]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   38.400941] commsdriver[687]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   38.401039] commsdriver[687]: tx-tcp6-segmentation: off [not requested] <NL> [   39.184164] e1000 0000:00:04.0 eth1: Reset adapter <NL> [   39.044605] commsdriver[603]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   39.132495] commsdriver[699]: Actual changes: <NL> [   39.132696] commsdriver[699]: tx-checksum-ip-generic: off"}
{"timestamp_utc": "2024-07-31T08:13:34.652Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:34 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',) <NL> # 03:13:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37293, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:34 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37293\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:34.908Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:34 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:35.163Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:35 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:39.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   33.625456] systemd[1]: Mounted Kernel Debug File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Debug File System\u001b[0m. <NL> [   33.652382] systemd[1]: Mounted Kernel Trace File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Trace File System\u001b[0m. <NL> [   33.665197] systemd[1]: Finished Create List of Static Device Nodes. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate List of Static Device Nodes\u001b[0m. <NL> [   33.679351] systemd[1]: modprobe@configfs.service: Deactivated successfully. <NL> [   33.695186] systemd[1]: Finished Load Kernel Module configfs. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module configfs\u001b[0m. <NL> [   33.843212] systemd[1]: modprobe@drm.service: Deactivated successfully. <NL> [   33.860069] systemd[1]: Finished Load Kernel Module drm. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module drm\u001b[0m. <NL> [   33.885724] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   33.890663] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   33.912660] systemd[1]: Finished Generate network units from Kernel command line. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mGenerate network units from Kernel command line\u001b[0m. <NL> [   33.938194] systemd[1]: Finished Remount Root and Kernel File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRemount Root and Kernel File Systems\u001b[0m. <NL> [   34.013650] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   34.048128] systemd[1]: Mounting Kernel Configuration File System... <NL> Mounting \u001b[0;1;39mKernel Configuration File System\u001b[0m... <NL> [   34.154109] systemd[1]: Rebuild Hardware Database was skipped because all trigger condition checks failed. <NL> [   34.155568] systemd[1]: Platform Persistent Storage Archival was skipped because of a failed condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore). <NL> [   34.177615] systemd[1]: Starting Create Static Device Nodes in /dev... <NL> Starting \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m... <NL> [   34.196320] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   34.225422] systemd[1]: Mounted Kernel Configuration File System."}
{"timestamp_utc": "2024-07-31T08:13:39.331Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mKernel Configuration File System\u001b[0m. <NL> [   34.319501] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   34.345978] systemd[1]: Finished Create Static Device Nodes in /dev. <NL> [   34.350189] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Static Device Nodes in /dev\u001b[0m. <NL> [   34.425610] systemd[1]: Reached target Preparation for Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Local File Systems\u001b[0m. <NL> [   34.465546] systemd[1]: Mounting /var/ftp... <NL> Mounting \u001b[0;1;39m/var/ftp\u001b[0m... <NL> [   34.497013] systemd[1]: var-log.mount: Directory /var/log to mount over is not empty, mounting anyway. <NL> [   34.503692] systemd[1]: Mounting /var/log... <NL> Mounting \u001b[0;1;39m/var/log\u001b[0m... <NL> [   34.554323] dcn_phantom_drv: VIF Support v1.0 <NL> [   34.570071] systemd[1]: var-telemetry.mount: Directory /var/telemetry to mount over is not empty, mounting anyway. <NL> [   34.667934] systemd[1]: Mounting /var/telemetry... <NL> Mounting \u001b[0;1;39m/var/telemetry\u001b[0m... <NL> [   34.709850] systemd[1]: Mounting /var/volatile... <NL> Mounting \u001b[0;1;39m/var/volatile\u001b[0m... <NL> [   34.717873] packet_injector_class: driver registered correctly with major number 246 <NL> [   34.725483] Packet_injector 257949696: minor device creation 246:0 <NL> [   34.732261] Packet_injector 257949697: minor device creation 246:1 <NL> [   34.742774] Packet_injector 257949698: minor device creation 246:2 <NL> [   34.745196] Packet_injector 257949699: minor device creation 246:3 <NL> [   34.880448] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   34.933298] systemd[1]: Finished Load Kernel Modules. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> [   34.980333] systemd[1]: Finished Coldplug All udev Devices. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   35.020181] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   35.044770] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   35.056144] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m. <NL> [   35.062107] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   35.127198] systemd[1]: Mounting NFSD configuration filesystem... <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> [   35.152056] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   35.181016] systemd[1]: Starting Apply Kernel Variables... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [   35.230700] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   35.232991] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   35.250853] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   35.257045] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   35.271688] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   35.297675] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   35.561660] systemd-journald[360]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   37.026485] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [   37.684355] Floppy drive(s): fd0 is 1.44M <NL> [   37.726025] FDC 0 is a S82078B <NL> [   38.199539] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   38.353820] Console: switching to colour dummy device 80x25 <NL> [   38.385691] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> [   38.418070] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   38.467144] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   38.467272] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   38.494371] Console: switching to colour frame buffer device 128x48 <NL> [   38.520569] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [   37.022074] pktHandler[572]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.100032] pktHandler[572]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.134623] pktHandler[572]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   37.169948] pktHandler[572]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg"}
{"timestamp_utc": "2024-07-31T08:13:39.332Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   37.240917] pktHandler[572]: Init PktClient init complete <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [   37.254361] pktHandler[572]: EsalConfig::EsalConfig main 0 <NL> [   37.257678] pktHandler[572]: EsalConfig::EsalConfig trib 1 <NL> [   37.259794] pktHandler[572]: EsalConfig::EsalConfig ciRole 0 <NL> [   37.317623] pktHandler[572]: EsalConfig is not running inside container. <NL> [   37.324907] pktHandler[572]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   37.346250] pktHandler[572]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   37.350923] pktHandler[572]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   37.361180] pktHandler[572]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   37.397432] pktHandler[572]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   37.421527] pktHandler[572]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   37.462276] pktHandler[572]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   37.468492] pktHandler[572]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   37.477228] pktHandler[572]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   37.489937] pktHandler[572]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   37.507079] pktHandler[572]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   37.522603] pktHandler[572]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   37.528337] pktHandler[572]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   37.531315] pktHandler[572]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   37.598856] pktHandler[572]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   37.636561] pktHandler[572]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   37.667390] pktHandler[572]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   37.673726] pktHandler[572]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:58248)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   38.296610] commsdriver[588]: DllUtil::symbolInit() <NL> [   38.297726] commsdriver[588]: int DllInit() <NL> [   38.299735] commsdriver[588]: DllUtil::DllInit DllInit() return is null <NL> [   38.309585] commsdriver[588]: Could not resolve symbol name get_late_config_file_path <NL> [   38.349888] commsdriver[588]: Could not resolve symbol name create_l3_interface <NL> [   38.387634] commsdriver[588]: Could not resolve symbol name create_l2_interface <NL> [   38.398634] commsdriver[588]: Could not resolve symbol name delete_interface <NL> [   38.415981] commsdriver[588]: Could not resolve symbol name pre_setup_interfaces <NL> [   38.426753] commsdriver[588]: Could not resolve symbol name setup_interfaces <NL> [   38.482538] commsdriver[588]: Could not resolve symbol name post_setup_interfaces <NL> [   38.489831] commsdriver[588]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   38.492830] commsdriver[588]: Could not resolve symbol name setup_late_interfaces <NL> [   38.502810] commsdriver[588]: Could not resolve symbol name post_setup_late_interfaces <NL> [   38.504133] commsdriver[588]: Could not resolve symbol name pre_init <NL> [   38.515364] commsdriver[588]: Could not resolve symbol name post_init <NL> [   38.558929] commsdriver[588]: Could not resolve symbol name pre_handle_link_state_change <NL> [   38.577200] commsdriver[588]: Could not resolve symbol name handle_link_state_change <NL> [   38.578529] commsdriver[588]: Could not resolve symbol name post_handle_link_state_change <NL> [   38.579691] commsdriver[588]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   38.583098] commsdriver[588]: Could not resolve symbol name handle_link_state_notify <NL> [   38.617350] commsdriver[588]: Could not resolve symbol name post_handle_link_state_notify <NL> [   38.620343] commsdriver[588]: Could not resolve symbol name handle_rate_duplex_change <NL> [   38.645935] commsdriver[588]: Could not resolve symbol name delete_mac_address <NL> [   38.651042] commsdriver[588]: Could not resolve symbol name set_vlan_prio <NL> [   38.655854] commsdriver[588]: Could not resolve symbol name replay_mac <NL> [   38.663990] commsdriver[588]: Could not resolve symbol name set_red_state <NL> [   38.690351] commsdriver[588]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   38.710683] commsdriver[588]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   38.725151] commsdriver[588]: /usr/local/fnc/comms/config/simQemu/comms.cfg"}
{"timestamp_utc": "2024-07-31T08:13:39.333Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   38.743295] commsdriver[588]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   38.776822] commsdriver[588]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.811495] commsdriver[588]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   38.812651] commsdriver[588]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.833565] commsdriver[588]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.836694] commsdriver[588]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   38.848938] commsdriver[588]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   38.860255] commsdriver[588]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.883455] commsdriver[588]: SharedMemory::getShmSegment creating new segment <NL> [   38.904398] commsdriver[588]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   42.174787] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   41.904921] commsdriver[632]: SUCCESS <NL> [   44.147023] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   44.229970] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   44.352633] commsdriver[588]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   44.786432] device eth1 entered promiscuous mode <NL> [   44.423197] commsdriver[588]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   44.913569] commsdriver[588]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   45.024134] commsdriver[683]: Actual changes: <NL> [   45.024331] commsdriver[683]: tx-checksum-ip-generic: off <NL> [   45.024413] commsdriver[683]: tx-tcp-segmentation: off [not requested] <NL> [   45.024487] commsdriver[683]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   45.024556] commsdriver[683]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   45.024627] commsdriver[683]: tx-tcp6-segmentation: off [not requested] <NL> [   45.436633] commsdriver[588]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   45.492876] commsdriver[695]: Actual changes: <NL> [   45.493096] commsdriver[695]: tx-checksum-ip-generic: off <NL> [   45.493178] commsdriver[695]: tx-tcp-segmentation: off [not requested] <NL> [   45.493247] commsdriver[695]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   45.493315] commsdriver[695]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   45.493383] commsdriver[695]: tx-tcp6-segmentation: off [not requested] <NL> [   46.107247] br-odcc1: port 1(eth2) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:13:39.589Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:39 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:39.845Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "# 03:13:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37293, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:40.101Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:13:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:39 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:40.357Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:40.613Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   28.962018] systemd[1]: Starting Rule-based Manager for Device Events and Files... <NL> Starting \u001b[0;1;39mRule-based Manage\\xe2\\x80\\xa6for Device Events and Files\u001b[0m... <NL> [   28.993324] systemd[1]: modprobe@fuse.service: Deactivated successfully. <NL> [   29.012669] systemd[1]: Finished Load Kernel Module fuse. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Module fuse\u001b[0m. <NL> [   29.039488] systemd[1]: Mounted /var/ftp. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/ftp\u001b[0m. <NL> [   29.063171] systemd[1]: Mounted /var/log. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log\u001b[0m. <NL> [   29.080636] systemd[1]: Mounted /var/telemetry. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/telemetry\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:40.614Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   29.102406] systemd[1]: Mounted /var/volatile. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/volatile\u001b[0m. <NL> [   29.116353] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [   29.138783] systemd[1]: Mounting FUSE Control File System... <NL> Mounting \u001b[0;1;39mFUSE Control File System\u001b[0m... <NL> [   29.200188] systemd[1]: Mounting /var/log/sharedlogs... <NL> Mounting \u001b[0;1;39m/var/log/sharedlogs\u001b[0m... <NL> [   29.219855] systemd[1]: Bind mount volatile /var/cache was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/cache). <NL> [   29.242787] systemd[1]: Bind mount volatile /var/lib was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/lib). <NL> [   29.256192] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   29.287250] systemd[1]: Starting Load/Save Random Seed... <NL> Starting \u001b[0;1;39mLoad/Save Random Seed\u001b[0m... <NL> [   29.325504] systemd[1]: Bind mount volatile /var/spool was skipped because of a failed condition check (ConditionPathIsReadWrite=!/var/spool). <NL> [   29.344653] systemd[1]: Bind mount volatile /srv was skipped because of a failed condition check (ConditionPathIsReadWrite=!/srv). <NL> [   29.398070] dcn_phantom_drv: VIF Support v1.0 <NL> [   29.411498] systemd[1]: Mounted FUSE Control File System. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mFUSE Control File System\u001b[0m. <NL> [   29.495652] systemd[1]: Mounted /var/log/sharedlogs. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39m/var/log/sharedlogs\u001b[0m. <NL> [   29.579442] systemd[1]: Reached target Local File Systems. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> [   29.710447] systemd[1]: Starting Rebuild Dynamic Linker Cache... <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> [   29.784324] systemd[1]: Starting Initial phase of the Platform System Information startup... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> [   29.870376] systemd[1]: Finished Load/Save Random Seed. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m. <NL> [   29.917947] systemd[1]: First Boot Complete was skipped because of a failed condition check (ConditionFirstBoot=yes). <NL> [   29.923101] systemd[1]: Commit a transient machine-id on disk was skipped because of a failed condition check (ConditionPathIsMountPoint=/etc/machine-id). <NL> [   30.005187] systemd[1]: Started Journal Service. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJournal Service\u001b[0m. <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   30.114676] packet_injector_class: driver registered correctly with major number 246 <NL> [   30.138544] Packet_injector 257949696: minor device creation 246:0 <NL> [   30.332449] Packet_injector 257949697: minor device creation 246:1 <NL> [   30.423600] systemd-journald[324]: Received client request to flush runtime journal. <NL> [   30.466941] Packet_injector 257949698: minor device creation 246:2 <NL> [   30.630918] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   32.758030] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> [   36.582162] Floppy drive(s): fd0 is 1.44M <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> [   37.441505] FDC 0 is a S82078B <NL> [   37.475598] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> [   37.534086] parport_pc 00:04: reported by Plug and Play ACPI <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (11s / 5min 3s) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (12s / 5min 3s) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (12s / 5min 3s) <NL> [   38.972094] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   39.349670] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (13s / no limit)[   40.379695] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [   41.662233] fbcon: cirrusdrmfb (fb0) is primary device"}
{"timestamp_utc": "2024-07-31T08:13:40.615Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   41.868735] Console: switching to colour frame buffer device 128x48 <NL> [   42.521593] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically restarts sync-log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:40.871Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s01.NE2-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s01.NE2-main-debug-ssh", "step_id": "s01.NE2-main-debug-ssh", "message_content": "# 03:13:40 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:40 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:13:41.126Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:40 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:40 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:40 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\": process 3334 terminated with exitcode 0 <NL> # 03:13:40 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p03.s01.NE2-main-debug-ssh) <NL> # 03:13:40 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:13:40 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37291', '--delay', '5'] (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:13:40 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p03.s02.NE2-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37291', '--delay', '5'] <NL> # 03:13:40 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:13:40 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"command\" <NL> # 03:13:40 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.s01.NE2-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:13:41.383Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   38.143766] pktHandler[590]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   38.161975] pktHandler[590]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   38.165781] pktHandler[590]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   38.170809] pktHandler[590]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   38.187927] pktHandler[590]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   38.239098] pktHandler[590]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   38.256260] pktHandler[590]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   38.269025] pktHandler[590]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   38.269123] pktHandler[590]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   38.269197] pktHandler[590]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   38.269271] pktHandler[590]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   38.269342] pktHandler[590]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [   38.427549] commsdriver[612]: DllUtil::symbolInit() <NL> [   38.430084] commsdriver[612]: int DllInit() <NL> [   38.445197] commsdriver[612]: DllUtil::DllInit DllInit() return is null <NL> [   38.446168] commsdriver[612]: Could not resolve symbol name get_late_config_file_path <NL> [   38.447132] commsdriver[612]: Could not resolve symbol name create_l3_interface <NL> [   38.459097] commsdriver[612]: Could not resolve symbol name create_l2_interface <NL> [   38.465919] commsdriver[612]: Could not resolve symbol name delete_interface <NL> [   38.471839] commsdriver[612]: Could not resolve symbol name pre_setup_interfaces <NL> [   38.482573] commsdriver[612]: Could not resolve symbol name setup_interfaces <NL> [   38.484058] commsdriver[612]: Could not resolve symbol name post_setup_interfaces <NL> [   38.496426] commsdriver[612]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   38.497390] commsdriver[612]: Could not resolve symbol name setup_late_interfaces <NL> [   38.498282] commsdriver[612]: Could not resolve symbol name post_setup_late_interfaces <NL> [   38.527876] commsdriver[612]: Could not resolve symbol name pre_init <NL> [   38.539623] commsdriver[612]: Could not resolve symbol name post_init <NL> [   38.564371] commsdriver[612]: Could not resolve symbol name pre_handle_link_state_change <NL> [   38.565449] commsdriver[612]: Could not resolve symbol name handle_link_state_change <NL> [   38.589609] commsdriver[612]: Could not resolve symbol name post_handle_link_state_change <NL> [   38.605851] commsdriver[612]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   38.616130] commsdriver[612]: Could not resolve symbol name handle_link_state_notify <NL> [   38.626430] commsdriver[612]: Could not resolve symbol name post_handle_link_state_notify <NL> [   38.647364] commsdriver[612]: Could not resolve symbol name handle_rate_duplex_change <NL> [   38.657267] commsdriver[612]: Could not resolve symbol name delete_mac_address <NL> [   38.667624] commsdriver[612]: Could not resolve symbol name set_vlan_prio <NL> [   38.678531] commsdriver[612]: Could not resolve symbol name replay_mac <NL> [   38.690724] commsdriver[612]: Could not resolve symbol name set_red_state <NL> [   38.698856] commsdriver[612]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   38.705677] commsdriver[612]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   38.720071] commsdriver[612]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   38.753427] commsdriver[612]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   38.784273] commsdriver[612]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.807582] commsdriver[612]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   38.813966] commsdriver[612]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.831900] commsdriver[612]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.832021] commsdriver[612]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   38.832095] commsdriver[612]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   38.832167] commsdriver[612]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   38.832232] commsdriver[612]: SharedMemory::getShmSegment creating new segment <NL> [   38.832331] commsdriver[612]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   41.186595] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   40.940194] commsdriver[649]: SUCCESS <NL> [   43.226055] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX"}
{"timestamp_utc": "2024-07-31T08:13:41.384Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   43.270958] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   43.147375] commsdriver[612]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   43.592738] device eth1 entered promiscuous mode <NL> [   43.214830] commsdriver[612]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   43.814947] commsdriver[612]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   44.054411] commsdriver[687]: Actual changes: <NL> [   44.054642] commsdriver[687]: tx-checksum-ip-generic: off <NL> [   44.054735] commsdriver[687]: tx-tcp-segmentation: off [not requested] <NL> [   44.054806] commsdriver[687]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   44.054875] commsdriver[687]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   44.054943] commsdriver[687]: tx-tcp6-segmentation: off [not requested] <NL> [   44.567149] e1000 0000:00:04.0 eth1: Reset adapter <NL> [   44.678821] e1000 0000:00:04.0 eth1: Reset adapter <NL> [   44.646559] commsdriver[612]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   44.737528] commsdriver[699]: Actual changes: <NL> [   44.737752] commsdriver[699]: tx-checksum-ip-generic: off <NL> [   44.737845] commsdriver[699]: tx-tcp-segmentation: off [not requested] <NL> [   44.737918] commsdriver[699]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   44.737984] commsdriver[699]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   44.738066] commsdriver[699]: tx-tcp6-segmentation: off [not requested] <NL> [   45.513251] br-odcc1: port 1(eth2) entered blocking state <NL> [   45.524367] br-odcc1: port 1(eth2) entered disabled state <NL> [   45.530780] device eth2 entered promiscuous mode <NL> [   45.557292] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   45.573613] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   45.586186] device odcc1-peer entered promiscuous mode <NL> [   45.719273] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   45.737518] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   45.753559] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   45.795073] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   45.439270] commsdriver[612]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   45.472993] commsdriver[612]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   46.303409] br-odcc2: port 1(eth3) entered blocking state <NL> [   46.331100] br-odcc2: port 1(eth3) entered disabled state <NL> [   46.369968] device eth3 entered promiscuous mode <NL> [   46.449442] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   46.484083] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   46.540208] device odcc2-peer entered promiscuous mode <NL> [   46.598898] e1000 0000:00:04.0 eth1: Detected Tx Unit Hang <NL> [   46.598898]   Tx Queue             <0> <NL> [   46.598898]   TDH                  <0> <NL> [   46.598898]   TDT                  <1> <NL> [   46.598898]   next_to_use          <1> <NL> [   46.598898]   next_to_clean        <0> <NL> [   46.598898] buffer_info[next_to_clean] <NL> [   46.598898]   time_stamp           <fffc1a6a> <NL> [   46.598898]   next_to_watch        <0> <NL> [   46.598898]   jiffies              <fffc1fee> <NL> [   46.598898]   next_to_watch.status <0> <NL> [   46.615241] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   46.359548] commsdriver[612]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:13:41 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37291, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:41 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:41.948Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (16s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (16s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (17s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (17s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (18s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:41.949Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [   45.340456] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:46844)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [   47.287783] pktHandler[609]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.371700] pktHandler[609]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.406045] pktHandler[609]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   47.452376] pktHandler[609]: GetRxFilters:83 rawdata= <NL> [   47.460776] pktHandler[609]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.468641] pktHandler[609]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.483226] pktHandler[609]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   47.494532] pktHandler[609]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   47.505819] pktHandler[609]: GetRxFilters:83 rawdata= <NL> [   47.525933] pktHandler[609]: Init PktClient init complete <NL> [   47.529066] pktHandler[609]: EsalConfig::EsalConfig main 1 <NL> [   47.531983] pktHandler[609]: EsalConfig::EsalConfig trib 0"}
{"timestamp_utc": "2024-07-31T08:13:43.837Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad/Save Random Seed\u001b[0m.[   26.750342] dcn_phantom_drv: loading out-of-tree module taints kernel. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mLocal File Systems\u001b[0m. <NL> Starting \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m... <NL> Starting \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6 System Information startup\u001b[0m... <NL> Starting \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m... <NL> [   27.243377] dcn_phantom_drv: module verification failed: signature and/or required key missing - tainting kernel <NL> [   27.334490] systemd-journald[325]: Received client request to flush runtime journal. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mFlush Journal to Persistent Storage\u001b[0m. <NL> Starting \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m... <NL> [   27.556850] dcn_phantom_drv: VIF Support v1.0 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mColdplug All udev Devices\u001b[0m. <NL> [   28.249258] packet_injector_class: driver registered correctly with major number 246 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCreate Volatile Files and Directories\u001b[0m.[   28.450515] Packet_injector 257949696: minor device creation 246:0 <NL> Starting \u001b[0;1;39mRebuild Journal Catalog\u001b[0m... <NL> Starting \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m... <NL> [   28.742222] Packet_injector 257949697: minor device creation 246:1 <NL> [   28.846749] Packet_injector 257949698: minor device creation 246:2 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRecord System Boot/Shutdown in UTMP\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRule-based Manager for Device Events and Files\u001b[0m. <NL> [   29.259387] Packet_injector 257949699: minor device creation 246:3 <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mLoad Kernel Modules\u001b[0m. <NL> Mounting \u001b[0;1;39mNFSD configuration filesystem\u001b[0m... <NL> Starting \u001b[0;1;39mApply Kernel Variables\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Journal Catalog\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mApply Kernel Variables\u001b[0m. <NL> [   32.559759] Installing knfsd (copyright (C) 1996 okir@monad.swb.de). <NL> [\u001b[0;32m  OK  \u001b[0m] Mounted \u001b[0;1;39mNFSD configuration filesystem\u001b[0m. <NL> [\u001b[0m\u001b[0;31m*     \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> [   36.156710] Floppy drive(s): fd0 is 1.44M <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> [   36.449816] cirrus 0000:00:02.0: vgaarb: deactivate vga console <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (16s / 5min 6s) <NL> [   37.282084] FDC 0 is a S82078B <NL> [   37.323411] Console: switching to colour dummy device 80x25 <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (17s / 5min 6s) <NL> [   38.751628] [drm] Initialized cirrus 2.0.0 2019 for 0000:00:02.0 on minor 0 <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] (2 of 2) A start job is running for\\xe2\\x80\\xa6nformation startup (18s / 5min 6s) <NL> [   38.821170] fbcon: cirrusdrmfb (fb0) is primary device <NL> [   40.221162] parport_pc 00:04: reported by Plug and Play ACPI <NL> [   40.221249] parport0: PC-style at 0x378, irq 7 [PCSPP(,...)] <NL> [   40.422895] Console: switching to colour frame buffer device 128x48 <NL> [   42.273394] cirrus 0000:00:02.0: [drm] fb0: cirrusdrmfb frame buffer device <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] (1 of 2) A start job is running for\\xe2\\x80\\xa6amic Linker Cache (18s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mInitial phase of \\xe2\\x80\\xa6rm System Information startup\u001b[0m. <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mAuto correct the shell prompt of default users\u001b[0m. <NL> Starting \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically restarts sync-log\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:43.838Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy comms config files to /var/shared\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m...[   46.401101] sched: RT throttling activated <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:44.765Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:44 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:45.022Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:13:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:46.386Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:46.641Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:46 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:49.909Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   47.534372] pktHandler[609]: EsalConfig::EsalConfig ciRole 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [   47.550977] pktHandler[609]: EsalConfig is not running inside container. <NL> [   47.598459] pktHandler[609]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.632027] pktHandler[609]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.680256] pktHandler[609]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.732017] pktHandler[609]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   47.748565] pktHandler[609]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   47.762105] pktHandler[609]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   47.765068] pktHandler[609]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   47.775913] pktHandler[609]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   47.817663] pktHandler[609]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   47.845968] pktHandler[609]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   47.872983] pktHandler[609]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   47.888728] pktHandler[609]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   47.901503] pktHandler[609]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   47.938112] pktHandler[609]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   47.943586] pktHandler[609]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   47.966898] pktHandler[609]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   47.981828] pktHandler[609]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   47.985728] pktHandler[609]: pkt-handler: sd_notify ready <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mUser Database Manager\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   48.184212] commsdriver[629]: DllUtil::symbolInit() <NL> [   48.186274] commsdriver[629]: int DllInit() <NL> [   48.205200] commsdriver[629]: DllUtil::DllInit DllInit() return is null <NL> [   48.245187] commsdriver[629]: Could not resolve symbol name get_late_config_file_path <NL> [   48.262768] commsdriver[629]: Could not resolve symbol name create_l3_interface <NL> [   48.284365] commsdriver[629]: Could not resolve symbol name create_l2_interface <NL> [   48.285867] commsdriver[629]: Could not resolve symbol name delete_interface <NL> [   48.291227] commsdriver[629]: Could not resolve symbol name pre_setup_interfaces <NL> [   48.309470] commsdriver[629]: Could not resolve symbol name setup_interfaces <NL> [   48.311095] commsdriver[629]: Could not resolve symbol name post_setup_interfaces <NL> [   48.316340] commsdriver[629]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   48.336935] commsdriver[629]: Could not resolve symbol name setup_late_interfaces <NL> [   48.344336] commsdriver[629]: Could not resolve symbol name post_setup_late_interfaces <NL> [   48.350647] commsdriver[629]: Could not resolve symbol name pre_init <NL> [   48.360203] commsdriver[629]: Could not resolve symbol name post_init <NL> [   48.389280] commsdriver[629]: Could not resolve symbol name pre_handle_link_state_change <NL> [   48.395605] commsdriver[629]: Could not resolve symbol name handle_link_state_change <NL> [   48.417258] commsdriver[629]: Could not resolve symbol name post_handle_link_state_change <NL> [   48.418869] commsdriver[629]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   48.433971] commsdriver[629]: Could not resolve symbol name handle_link_state_notify <NL> [   48.463522] commsdriver[629]: Could not resolve symbol name post_handle_link_state_notify <NL> [   48.495239] commsdriver[629]: Could not resolve symbol name handle_rate_duplex_change <NL> [   48.502347] commsdriver[629]: Could not resolve symbol name delete_mac_address <NL> [   48.511165] commsdriver[629]: Could not resolve symbol name set_vlan_prio <NL> [   48.524656] commsdriver[629]: Could not resolve symbol name replay_mac <NL> [   48.547423] commsdriver[629]: Could not resolve symbol name set_red_state <NL> [   48.555082] commsdriver[629]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   48.566792] commsdriver[629]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   48.584866] commsdriver[629]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   48.585886] commsdriver[629]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   48.588583] commsdriver[629]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   48.607473] commsdriver[629]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   48.621242] commsdriver[629]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   48.632746] commsdriver[629]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg"}
{"timestamp_utc": "2024-07-31T08:13:49.910Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   48.633727] commsdriver[629]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   48.643803] commsdriver[629]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   48.653211] commsdriver[629]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   48.667618] commsdriver[629]: SharedMemory::getShmSegment creating new segment <NL> [   48.668606] commsdriver[629]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Database Manager\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mUser Slice of UID 3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUser Runtime Directory /run/user/3000\u001b[0m. <NL> Starting \u001b[0;1;39mUser Manager for UID 3000\u001b[0m... <NL> fujitsu login: [   51.617923] br-lcn00: port 1(eth3) entered blocking state <NL> [   51.618890] br-lcn00: port 1(eth3) entered disabled state <NL> [   51.630764] device eth3 entered promiscuous mode <NL> [   51.698756] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   51.726309] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   51.744620] device lcn00-peer entered promiscuous mode <NL> [   51.895643] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   51.590971] commsdriver[629]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   52.528517] br-lcn01: port 1(eth4) entered blocking state <NL> [   52.550402] br-lcn01: port 1(eth4) entered disabled state <NL> [   52.568583] device eth4 entered promiscuous mode <NL> [   52.601799] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   52.624255] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   52.625475] device lcn01-peer entered promiscuous mode <NL> [   52.760554] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   52.685848] commsdriver[629]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   53.607396] br-lmp00: port 1(eth2) entered blocking state <NL> [   53.629711] br-lmp00: port 1(eth2) entered disabled state <NL> [   53.643168] device eth2 entered promiscuous mode <NL> [   53.865420] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   53.878228] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   53.895672] device lmp00-peer entered promiscuous mode <NL> [   54.089501] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   53.795546] commsdriver[629]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   54.233251] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   54.349593] br-lcn00: port 1(eth3) entered blocking state <NL> [   54.362191] br-lcn00: port 1(eth3) entered forwarding state <NL> [   54.006067] commsdriver[629]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   54.456815] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   54.475775] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   54.481123] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   55.385927] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> # 03:13:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:49 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37320\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:51.798Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:51 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:54.329Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [   49.905856] pktHandler[526]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   50.337742] pktHandler[526]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   50.627378] pktHandler[526]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   51.452284] pktHandler[526]: GetRxFilters:83 rawdata= <NL> [   51.632100] pktHandler[526]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   51.882341] pktHandler[526]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   52.271251] pktHandler[526]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   52.825882] pktHandler[526]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   52.951179] pktHandler[526]: GetRxFilters:83 rawdata= <NL> [   53.017253] pktHandler[526]: Init PktClient init complete <NL> [   53.029174] pktHandler[526]: EsalConfig::EsalConfig main 1 <NL> [   53.285334] pktHandler[526]: EsalConfig::EsalConfig trib 0 <NL> [   53.658259] pktHandler[526]: EsalConfig::EsalConfig ciRole 0 <NL> [   53.867798] pktHandler[526]: EsalConfig is not running inside container. <NL> [   53.869410] pktHandler[526]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   54.199447] pktHandler[526]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   54.221312] pktHandler[526]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   54.456714] pktHandler[526]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   54.684348] pktHandler[526]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   54.996539] pktHandler[526]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> fujitsu[   55.331801] pktHandler[526]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> login: [   55.547609] pktHandler[526]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   55.618347] pktHandler[526]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   55.619316] pktHandler[526]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   55.722462] pktHandler[526]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   55.823323] pktHandler[526]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   55.896233] pktHandler[526]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   56.023970] pktHandler[526]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   56.144064] pktHandler[526]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   56.278653] pktHandler[526]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   56.466782] pktHandler[526]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   56.578551] pktHandler[526]: pkt-handler: sd_notify ready <NL> [   56.858682] commsdriver[542]: DllUtil::symbolInit() <NL> [   56.859467] commsdriver[542]: int DllInit() <NL> [   56.865471] commsdriver[542]: DllUtil::DllInit DllInit() return is null <NL> [   56.879601] commsdriver[542]: Could not resolve symbol name get_late_config_file_path <NL> [   56.881796] commsdriver[542]: Could not resolve symbol name create_l3_interface <NL> [   56.921330] commsdriver[542]: Could not resolve symbol name create_l2_interface <NL> [   56.923966] commsdriver[542]: Could not resolve symbol name delete_interface <NL> [   56.946055] commsdriver[542]: Could not resolve symbol name pre_setup_interfaces <NL> [   56.947296] commsdriver[542]: Could not resolve symbol name setup_interfaces <NL> [   56.958523] commsdriver[542]: Could not resolve symbol name post_setup_interfaces <NL> [   56.959773] commsdriver[542]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   56.975842] commsdriver[542]: Could not resolve symbol name setup_late_interfaces <NL> [   57.000494] commsdriver[542]: Could not resolve symbol name post_setup_late_interfaces <NL> [   57.019598] commsdriver[542]: Could not resolve symbol name pre_init"}
{"timestamp_utc": "2024-07-31T08:13:54.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   57.033546] commsdriver[542]: Could not resolve symbol name post_init <NL> [   57.044669] commsdriver[542]: Could not resolve symbol name pre_handle_link_state_change <NL> [   57.051913] commsdriver[542]: Could not resolve symbol name handle_link_state_change <NL> [   57.052969] commsdriver[542]: Could not resolve symbol name post_handle_link_state_change <NL> [   57.095729] commsdriver[542]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   57.126204] commsdriver[542]: Could not resolve symbol name handle_link_state_notify <NL> [   57.187504] commsdriver[542]: Could not resolve symbol name post_handle_link_state_notify <NL> [   57.188592] commsdriver[542]: Could not resolve symbol name handle_rate_duplex_change <NL> [   57.208833] commsdriver[542]: Could not resolve symbol name delete_mac_address <NL> [   57.231805] commsdriver[542]: Could not resolve symbol name set_vlan_prio <NL> [   57.238550] commsdriver[542]: Could not resolve symbol name replay_mac <NL> [   57.240402] commsdriver[542]: Could not resolve symbol name set_red_state <NL> [   57.245455] commsdriver[542]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   57.259303] commsdriver[542]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   57.260474] commsdriver[542]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   57.261419] commsdriver[542]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   57.262199] commsdriver[542]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.298726] commsdriver[542]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   57.322600] commsdriver[542]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.352604] commsdriver[542]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.355232] commsdriver[542]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   57.420077] commsdriver[542]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   57.423262] commsdriver[542]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.466390] commsdriver[542]: SharedMemory::getShmSegment creating new segment <NL> [   57.525700] commsdriver[542]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   58.207991] br-lcn00: port 1(eth3) entered blocking state <NL> [   58.231536] br-lcn00: port 1(eth3) entered disabled state <NL> [   58.265753] device eth3 entered promiscuous mode <NL> [   58.332381] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   58.395069] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   58.458973] device lcn00-peer entered promiscuous mode <NL> [   58.646537] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   58.384755] commsdriver[542]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   59.466780] br-lcn01: port 1(eth4) entered blocking state <NL> [   59.467524] br-lcn01: port 1(eth4) entered disabled state <NL> [   59.475661] device eth4 entered promiscuous mode <NL> [   59.494297] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   59.539310] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   59.554666] device lcn01-peer entered promiscuous mode <NL> [   59.754070] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   59.815662] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   59.851958] br-lcn01: port 2(lcn01-peer) entered forwarding state <NL> [   59.875326] br-lcn01: port 2(lcn01-peer) entered disabled state"}
{"timestamp_utc": "2024-07-31T08:13:54.587Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37320, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:13:54.843Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> [   45.249934] sched: RT throttling activated <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   49.475457] pktHandler[522]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   49.480285] pktHandler[522]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   49.491587] pktHandler[522]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   50.030837] pktHandler[522]: GetRxFilters:83 rawdata= <NL> [   50.043834] pktHandler[522]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   50.089353] pktHandler[522]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   51.223749] pktHandler[522]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   51.876400] pktHandler[522]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [   52.533694] pktHandler[522]: GetRxFilters:83 rawdata= <NL> [   52.590042] pktHandler[522]: Init PktClient init complete <NL> [   52.594639] pktHandler[522]: EsalConfig::EsalConfig main 1 <NL> [   52.595606] pktHandler[522]: EsalConfig::EsalConfig trib 0 <NL> [   52.677088] pktHandler[522]: EsalConfig::EsalConfig ciRole 0 <NL> [   52.747997] pktHandler[522]: EsalConfig is not running inside container. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [   53.017923] pktHandler[522]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   53.135344] pktHandler[522]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   53.473119] pktHandler[522]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   53.953324] pktHandler[522]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   54.334249] pktHandler[522]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   54.449787] pktHandler[522]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   54.459982] pktHandler[522]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   54.593248] pktHandler[522]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [   54.652301] pktHandler[522]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   54.880707] pktHandler[522]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> fujitsu login: [   54.984878] pktHandler[522]: Libconfig::openAndRead /var/shared/commsStp.conf"}
{"timestamp_utc": "2024-07-31T08:13:54.844Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   55.112134] pktHandler[522]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   55.145320] pktHandler[522]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   55.178952] pktHandler[522]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   55.306582] pktHandler[522]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   55.389441] pktHandler[522]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   55.629569] pktHandler[522]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   55.782241] pktHandler[522]: pkt-handler: sd_notify ready <NL> [   56.101089] commsdriver[539]: DllUtil::symbolInit() <NL> [   56.187365] commsdriver[539]: int DllInit() <NL> [   56.238890] commsdriver[539]: DllUtil::DllInit DllInit() return is null <NL> [   56.421620] commsdriver[539]: Could not resolve symbol name get_late_config_file_path <NL> [   56.422931] commsdriver[539]: Could not resolve symbol name create_l3_interface <NL> [   56.427835] commsdriver[539]: Could not resolve symbol name create_l2_interface <NL> [   56.467900] commsdriver[539]: Could not resolve symbol name delete_interface <NL> [   56.468842] commsdriver[539]: Could not resolve symbol name pre_setup_interfaces <NL> [   56.518909] commsdriver[539]: Could not resolve symbol name setup_interfaces <NL> [   56.536405] commsdriver[539]: Could not resolve symbol name post_setup_interfaces <NL> [   56.571137] commsdriver[539]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   56.592939] commsdriver[539]: Could not resolve symbol name setup_late_interfaces <NL> [   56.658755] commsdriver[539]: Could not resolve symbol name post_setup_late_interfaces <NL> [   56.826547] commsdriver[539]: Could not resolve symbol name pre_init <NL> [   56.932741] commsdriver[539]: Could not resolve symbol name post_init <NL> [   56.988897] commsdriver[539]: Could not resolve symbol name pre_handle_link_state_change <NL> [   57.063374] commsdriver[539]: Could not resolve symbol name handle_link_state_change <NL> [   57.132109] commsdriver[539]: Could not resolve symbol name post_handle_link_state_change <NL> [   57.188051] commsdriver[539]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   57.284645] commsdriver[539]: Could not resolve symbol name handle_link_state_notify <NL> [   57.463646] commsdriver[539]: Could not resolve symbol name post_handle_link_state_notify <NL> [   57.466410] commsdriver[539]: Could not resolve symbol name handle_rate_duplex_change"}
{"timestamp_utc": "2024-07-31T08:13:55.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:13:55 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:56.768Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:13:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:13:56 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:13:58.658Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6namic Linker Cache (9s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (10s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (11s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (12s / no limit) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (13s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (14s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (15s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (16s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (16s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (17s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (17s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (18s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (18s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (19s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (19s / no limit) <NL> \u001bM <NL> \u001b[K[     \u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (20s / no limit) <NL> \u001bM <NL> \u001b[K[    \u001b[0;31m*\u001b[0;1;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (20s / no limit) <NL> \u001bM <NL> \u001b[K[   \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*\u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (21s / no limit) <NL> \u001bM <NL> \u001b[K[  \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m* \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (21s / no limit) <NL> \u001bM <NL> \u001b[K[ \u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*  \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (22s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;31m*\u001b[0;1;31m*\u001b[0m\u001b[0;31m*   \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (22s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;1;31m*\u001b[0m\u001b[0;31m*    \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (23s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0m\u001b[0;31m*     \u001b[0m] A start job is running for Rebuild \\xe2\\x80\\xa6amic Linker Cache (23s / no limit) <NL> \u001bM <NL> \u001b[K[\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mRebuild Dynamic Linker Cache\u001b[0m. <NL> \u001b[K         Starting \u001b[0;1;39mUpdate is Completed\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mUpdate is Completed\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSystem Initialization\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSet Conditions for NETCONF socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mNTP init state check timer\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily rotation of log files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary of current process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mRun system activit\\xe2\\x80\\xa6ounting tool every 10 minutes\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGenerate summary o\\xe2\\x80\\xa6esterday's process accounting\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDaily Cleanup of Temporary Directories\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodically deletes remote accounts\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPath Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mTimer Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39mD-Bus System Message Bus Socket\u001b[0m. <NL> Starting \u001b[0;1;39msshd.socket\u001b[0m... <NL> Starting \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m... <NL> Starting \u001b[0;1;39mSetup Platform component file permissions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Listening on \u001b[0;1;39msshd.socket\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mReboot and dump vmcore via kexec\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mSocket Units\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mSetup Platform component file permissions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mBasic System\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPython api-mode sy\\xe2\\x80\\xa6ce between ACTIVE and STANDBY\u001b[0m. <NL> Starting \u001b[0;1;39mCopy API mode specific files\u001b[0m... <NL> Starting \u001b[0;1;39mJob spooling tools\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mCommsManager App startup service file\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPeriodic Command Scheduler\u001b[0m. <NL> Starting \u001b[0;1;39mD-Bus System Message Bus\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mdcn-network-pm application startup service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mDIP proxy service file\u001b[0m. <NL> Starting \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m... <NL> Starting \u001b[0;1;39mESAL Base startup service file\u001b[0m... <NL> Starting \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m... <NL> Starting \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOOM Kill process\u001b[0m. <NL> Starting \u001b[0;1;39mpidstat-summary.service\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSync user password service\u001b[0m. <NL> Starting \u001b[0;1;39mResets System Activity Logs\u001b[0m... <NL> Starting \u001b[0;1;39mUser Login Management\u001b[0m... <NL> Starting \u001b[0;1;39mPermit User Sessions\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mD-Bus System Message Bus\u001b[0m."}
{"timestamp_utc": "2024-07-31T08:13:58.659Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mJob spooling tools\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mEthernet Bridge Filtering Tables\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv6 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mIPv4 Packet Filtering Framework\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mNetwork Time Service (one-shot ntpdate mode)\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mResets System Activity Logs\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mPermit User Sessions\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Created slice \u001b[0;1;39mSlice /system/sshd\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Reached target \u001b[0;1;39mPreparation for Network\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mGetty on tty1\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS0\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mSerial Getty on ttyS1\u001b[0m. <NL> Starting \u001b[0;1;39mOpenSSH Key Generation\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mOpenSSH Key Generation\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mCopy API mode specific files\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mOpenSSH Per-Connection Daemon (172.17.0.1:46366)\u001b[0m. <NL> [   60.132915] sched: RT throttling activated <NL> [\u001b[0;32m  OK  \u001b[0m] Finished \u001b[0;1;39mpidstat-summary.service\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mUser Login Management\u001b[0m. <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mESAL Base startup service file\u001b[0m. <NL> Starting \u001b[0;1;39mPkt Handler App startup service file\u001b[0m..."}
{"timestamp_utc": "2024-07-31T08:13:59.585Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s01.NE1-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s01.NE1-main-debug-ssh", "step_id": "s01.NE1-main-debug-ssh", "message_content": "# 03:13:59 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:13:59 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\""}
{"timestamp_utc": "2024-07-31T08:13:59.842Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:13:59 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:13:59 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:13:59 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\": process 3332 terminated with exitcode 0 <NL> # 03:13:59 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p01.s01.NE1-main-debug-ssh) <NL> # 03:13:59 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:13:59 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37319', '--delay', '5'] (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:13:59 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p01.s02.NE1-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37319', '--delay', '5'] <NL> # 03:13:59 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:13:59 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"command\" <NL> # 03:13:59 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.s01.NE1-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:14:00.099Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:13:59 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend"}
{"timestamp_utc": "2024-07-31T08:14:00.100Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:13:59 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37319, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:00 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:00.356Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:01.722Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:01 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:04.238Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   61.069790] pktHandler[603]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   61.117612] pktHandler[603]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   61.170852] pktHandler[603]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   61.182899] pktHandler[603]: GetRxFilters:83 rawdata= <NL> [   61.206656] pktHandler[603]: cfg path=/usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   61.214718] pktHandler[603]: Libconfig::openAndRead status open path /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   61.223625] pktHandler[603]: Libconfig::openAndRead /usr/local/fnc/pkthandler/02_00_00_00/pktHandler.cfg <NL> [   61.246871] pktHandler[603]: GetRxFilters:116 mac=FF:FF:FF:FF:FF:FF macMask=FF:FF:FF:FF:FF:FF vlan=2003 vlanMask=4095 <NL> [   61.307705] pktHandler[603]: GetRxFilters:83 rawdata="}
{"timestamp_utc": "2024-07-31T08:14:04.239Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPkt Handler App startup service file\u001b[0m. <NL> [   61.325916] pktHandler[603]: Init PktClient init complete <NL> [   61.353168] pktHandler[603]: EsalConfig::EsalConfig main 1 <NL> [   61.384679] pktHandler[603]: EsalConfig::EsalConfig trib 0 <NL> Starting \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m... <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform Restore Default startup service file\u001b[0m. <NL> [   61.437220] pktHandler[603]: EsalConfig::EsalConfig ciRole 0 <NL> [   61.451474] pktHandler[603]: EsalConfig is not running inside container. <NL> [   61.465547] pktHandler[603]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   61.469630] pktHandler[603]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   61.541955] pktHandler[603]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> Starting \u001b[0;1;39mCommsdriver App startup service file\u001b[0m... <NL> [   61.649501] pktHandler[603]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [   61.693360] pktHandler[603]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   61.724301] pktHandler[603]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [   61.776718] pktHandler[603]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [   61.809285] pktHandler[603]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [\u001b[0;32m  OK  \u001b[0m] Started \u001b[0;1;39mPlatform MSLM Chassis startup service file\u001b[0m. <NL> [   61.837256] pktHandler[603]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [   61.877695] pktHandler[603]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [   61.903779] pktHandler[603]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [   61.913982] pktHandler[603]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [   61.927352] pktHandler[603]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [   61.939617] pktHandler[603]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [   61.949126] pktHandler[603]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [   61.962915] pktHandler[603]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [   61.979533] pktHandler[603]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [   61.992614] pktHandler[603]: pkt-handler: sd_notify ready <NL> [   62.015176] commsdriver[619]: DllUtil::symbolInit() <NL> [   62.040418] commsdriver[619]: int DllInit() <NL> [   62.046334] commsdriver[619]: DllUtil::DllInit DllInit() return is null <NL> [   62.055312] commsdriver[619]: Could not resolve symbol name get_late_config_file_path <NL> [   62.084034] commsdriver[619]: Could not resolve symbol name create_l3_interface <NL> [   62.089727] commsdriver[619]: Could not resolve symbol name create_l2_interface <NL> [   62.110780] commsdriver[619]: Could not resolve symbol name delete_interface <NL> [   62.147682] commsdriver[619]: Could not resolve symbol name pre_setup_interfaces <NL> [   62.151526] commsdriver[619]: Could not resolve symbol name setup_interfaces <NL> [   62.173373] commsdriver[619]: Could not resolve symbol name post_setup_interfaces <NL> [   62.175359] commsdriver[619]: Could not resolve symbol name pre_setup_late_interfaces <NL> [   62.184668] commsdriver[619]: Could not resolve symbol name setup_late_interfaces <NL> [   62.219334] commsdriver[619]: Could not resolve symbol name post_setup_late_interfaces <NL> [   62.248471] commsdriver[619]: Could not resolve symbol name pre_init <NL> [   62.257993] commsdriver[619]: Could not resolve symbol name post_init <NL> [   62.288647] commsdriver[619]: Could not resolve symbol name pre_handle_link_state_change <NL> [   62.299457] commsdriver[619]: Could not resolve symbol name handle_link_state_change <NL> [   62.304990] commsdriver[619]: Could not resolve symbol name post_handle_link_state_change <NL> [   62.334612] commsdriver[619]: Could not resolve symbol name pre_handle_link_state_notify <NL> [   62.345599] commsdriver[619]: Could not resolve symbol name handle_link_state_notify <NL> [   62.350020] commsdriver[619]: Could not resolve symbol name post_handle_link_state_notify <NL> [   62.400566] commsdriver[619]: Could not resolve symbol name handle_rate_duplex_change <NL> [   62.410210] commsdriver[619]: Could not resolve symbol name delete_mac_address <NL> [   62.414578] commsdriver[619]: Could not resolve symbol name set_vlan_prio <NL> [   62.432389] commsdriver[619]: Could not resolve symbol name replay_mac <NL> [   62.450816] commsdriver[619]: Could not resolve symbol name set_red_state <NL> [   62.453418] commsdriver[619]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   62.461628] commsdriver[619]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   62.468713] commsdriver[619]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   62.502640] commsdriver[619]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   62.518986] commsdriver[619]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   62.531561] commsdriver[619]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   62.544350] commsdriver[619]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   62.557421] commsdriver[619]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   62.561408] commsdriver[619]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   62.565303] commsdriver[619]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   62.569273] commsdriver[619]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   62.592340] commsdriver[619]: SharedMemory::getShmSegment creating new segment <NL> [   62.596294] commsdriver[619]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> fujitsu login: [   65.096965] br-lcn00: port 1(eth3) entered blocking state <NL> [   65.102726] br-lcn00: port 1(eth3) entered disabled state <NL> [   65.113269] device eth3 entered promiscuous mode <NL> [   65.131468] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   65.146055] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   65.148628] device lcn00-peer entered promiscuous mode <NL> [   65.302425] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   65.125430] commsdriver[619]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   65.989433] br-lcn01: port 1(eth4) entered blocking state <NL> [   66.009525] br-lcn01: port 1(eth4) entered disabled state <NL> [   66.011521] device eth4 entered promiscuous mode <NL> [   66.038554] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   66.052142] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   66.054785] device lcn01-peer entered promiscuous mode <NL> [   66.111991] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   65.916411] commsdriver[619]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   66.678309] br-lmp00: port 1(eth2) entered blocking state <NL> [   66.683282] br-lmp00: port 1(eth2) entered disabled state <NL> [   66.686194] device eth2 entered promiscuous mode <NL> [   66.695734] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   66.697833] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   66.699454] device lmp00-peer entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:05.166Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   55.387369] br-lcn01: port 1(eth4) entered blocking state <NL> [   55.388072] br-lcn01: port 1(eth4) entered forwarding state <NL> [   56.062773] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   56.102957] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   56.161688] br-lmp00: port 1(eth2) entered blocking state <NL> [   56.174681] br-lmp00: port 1(eth2) entered forwarding state <NL> [   55.817159] commsdriver[755]: SUCCESS <NL> [   58.077984] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   58.079854] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   59.032567] commsdriver[629]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   59.599189] device eth5 entered promiscuous mode <NL> [   59.241284] commsdriver[629]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   59.705640] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   59.585971] commsdriver[629]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   60.027983] device erstp-peer entered promiscuous mode <NL> [   60.365602] br-odcc1: port 1(eth1) entered blocking state <NL> [   60.376729] br-odcc1: port 1(eth1) entered disabled state <NL> [   60.388296] device eth1 entered promiscuous mode <NL> [   60.409815] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   60.423162] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   60.435189] device odcc1-peer entered promiscuous mode <NL> [   60.483397] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   60.523194] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   60.537933] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   60.546394] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   60.193297] commsdriver[629]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   60.198599] commsdriver[629]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   60.909641] br-odcc2: port 1(eth6) entered blocking state <NL> [   60.937986] br-odcc2: port 1(eth6) entered disabled state <NL> [   60.954112] device eth6 entered promiscuous mode <NL> [   61.019865] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   61.020668] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   61.021575] device odcc2-peer entered promiscuous mode <NL> [   61.112749] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   61.406862] br-odcc2: port 2(odcc2-peer) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:14:05.167Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[   61.457231] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   61.467292] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   61.127599] commsdriver[629]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   61.144632] commsdriver[629]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   62.206222] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   62.231844] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   62.249570] device eth1.3800 entered promiscuous mode <NL> [   62.288340] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   62.289148] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   62.290233] device gcc0-peer entered promiscuous mode <NL> [   62.355169] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   62.370359] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   62.397560] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   62.035731] commsdriver[629]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   62.053370] commsdriver[629]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   62.747467] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   62.810378] br-odcc1: port 1(eth1) entered blocking state <NL> [   62.821046] br-odcc1: port 1(eth1) entered forwarding state <NL> [   62.823342] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   62.839900] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   62.866253] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.3801: link becomes ready <NL> [   63.018787] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   63.031418] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   63.051935] device eth1.3801 entered promiscuous mode <NL> [   63.071902] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   63.074398] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   63.085163] device gcc1-peer entered promiscuous mode <NL> [   63.149124] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   63.149910] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   63.165711] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   63.181699] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   62.818155] commsdriver[629]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   62.836892] commsdriver[629]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   63.766507] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   63.769307] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   63.783240] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   63.785635] device eth6.3802 entered promiscuous mode <NL> [   63.807490] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   63.813873] br-odcc2: port 1(eth6) entered blocking state <NL> [   63.830858] br-odcc2: port 1(eth6) entered forwarding state <NL> [   63.843337] IPv6: ADDRCONF(NETDEV_CHANGE): eth6.3802: link becomes ready <NL> [   63.862034] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   63.869407] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   63.880996] device lwap-peer entered promiscuous mode <NL> [   64.026776] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   64.047561] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   63.707645] commsdriver[629]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   63.707779] commsdriver[629]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   64.110187] commsdriver[629]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   64.203991] commsdriver[946]: Actual changes: <NL> [   64.204187] commsdriver[946]: tx-checksum-ip-generic: off <NL> [   64.204280] commsdriver[946]: tx-tcp-segmentation: off [not requested] <NL> [   64.204362] commsdriver[946]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   64.204433] commsdriver[946]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   64.204506] commsdriver[946]: tx-tcp6-segmentation: off [not requested] <NL> [   64.768306] e1000 0000:00:08.0 eth5: Reset adapter <NL> [   64.761912] commsdriver[629]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   64.836408] commsdriver[958]: Actual changes: <NL> [   64.836594] commsdriver[958]: tx-checksum-ip-generic: off <NL> [   64.836694] commsdriver[958]: tx-tcp-segmentation: off [not requested] <NL> [   64.836818] commsdriver[958]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   64.836937] commsdriver[958]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   64.837040] commsdriver[958]: tx-tcp6-segmentation: off [not requested] <NL> [   65.033761] commsready[961]: callback: Entry PID=0x3C1 signo(15) <NL> [   65.054635] change_esal_priority.sh[965]: Comms check for and selectively change esal priorities <NL> [   65.637095] change_esal_priority.sh[965]: Comms did not change any esal thread priorities <NL> [   66.067121] python[1010]: running intRstpEnable file creation SCRIPT <NL> [   66.067346] python[1010]: Already set to  TRUE <NL> [   66.067449] python[1010]:  , NO CHANGE! <NL> [   66.211863] sh[1045]: In startMstpInt <NL> [   66.928850] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   66.934412] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   66.572502] serialportMon[1024]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   67.592483] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   67.643214] NFSD: Using legacy client tracking operations. <NL> [   67.687161] NFSD: starting 90-second grace period (net f0000098) <NL> [   67.709222] sh[1045]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   69.822323] br.rstp_int: port 1(istp1) entered blocking state <NL> [   69.834879] br.rstp_int: port 1(istp1) entered disabled state <NL> [   69.835848] device istp1 entered promiscuous mode <NL> 2024-07-31 08:14:04,651 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> # 03:14:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:05 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:06.533Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:06 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:07.897Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   59.624584] commsdriver[542]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   60.426471] br-lmp00: port 1(eth2) entered blocking state <NL> [   60.550427] br-lmp00: port 1(eth2) entered disabled state <NL> [   60.562163] device eth2 entered promiscuous mode <NL> [   60.598477] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   60.626070] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   60.641679] device lmp00-peer entered promiscuous mode <NL> [   60.702274] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   60.751731] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   60.752575] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   60.763208] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   60.455344] commsdriver[542]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   60.526185] commsdriver[542]: DEBUG: set_ip Marking lmp00 down for 2[   60.919500] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   60.941659] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   60.987929] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   60.989520] br-lcn00: port 1(eth3) entered blocking state <NL> [   60.990206] br-lcn00: port 1(eth3) entered forwarding state <NL> [   62.242855] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   62.390748] br-lcn01: port 1(eth4) entered blocking state <NL> [   62.412647] br-lcn01: port 1(eth4) entered forwarding state <NL> [   62.668201] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   62.729728] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   62.422101] commsdriver[678]: SUCCESS[   62.800499] br-lmp00: port 1(eth2) entered blocking state <NL> [   62.820336] br-lmp00: port 1(eth2) entered forwarding state <NL> [   64.711624] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   64.739014] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   64.905045] commsdriver[542]: DEBUG: change_linkstate Marking eth5.2003 down for 44[   65.281926] device eth5 entered promiscuous mode <NL> [   64.951747] commsdriver[542]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   65.301360] commsdriver[542]: DEBUG: change_linkstate Marking erstp down for 46[   65.689548] device erstp-peer entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:07.898Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   66.038527] br-odcc1: port 1(eth1) entered blocking state <NL> [   66.082156] br-odcc1: port 1(eth1) entered disabled state <NL> [   66.105549] device eth1 entered promiscuous mode <NL> [   66.166806] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   66.225788] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   66.250612] device odcc1-peer entered promiscuous mode <NL> [   66.330930] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   66.372609] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   66.404507] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   66.432357] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   66.171428] commsdriver[542]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   66.240125] commsdriver[542]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   66.862552] br-odcc2: port 1(eth6) entered blocking state <NL> [   66.874128] br-odcc2: port 1(eth6) entered disabled state <NL> [   66.896246] device eth6 entered promiscuous mode <NL> [   66.927053] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   66.937702] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   66.948042] device odcc2-peer entered promiscuous mode <NL> [   66.974953] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   66.992465] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   67.004894] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   67.017226] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   66.710164] commsdriver[542]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   66.776296] commsdriver[542]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   67.872657] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   67.896293] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   67.958617] device eth1.3800 entered promiscuous mode <NL> [   68.133667] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   68.146557] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   68.174748] device gcc0-peer entered promiscuous mode <NL> [   68.268199] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   68.316142] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   68.335333] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   68.057722] commsdriver[542]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   68.076969] commsdriver[542]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   68.817487] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   68.858443] br-odcc1: port 1(eth1) entered blocking state <NL> [   68.859155] br-odcc1: port 1(eth1) entered forwarding state <NL> [   68.860002] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   68.865755] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   68.988668] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   69.002155] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   69.058997] device eth1.3801 entered promiscuous mode <NL> [   69.109969] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   69.131415] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   69.148598] device gcc1-peer entered promiscuous mode <NL> [   69.232058] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   69.237983] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   69.239546] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   69.277111] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   69.316547] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   69.330514] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   69.345172] br-odcc2: port 1(eth6) entered blocking state <NL> [   69.373748] br-odcc2: port 1(eth6) entered forwarding state <NL> [   69.042810] commsdriver[542]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   69.088495] commsdriver[542]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   70.139220] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   70.200298] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   70.267753] device eth6.3802 entered promiscuous mode <NL> [   70.329474] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   70.398431] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   70.442961] device lwap-peer entered promiscuous mode <NL> [   70.596042] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   70.626259] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   70.678055] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   70.697707] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   70.418250] commsdriver[542]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   70.478916] commsdriver[542]: DEBUG: change_linkstate_peer Marking lwap down for 15[   70.860242] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   71.129040] commsdriver[542]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   71.303683] commsdriver[863]: Actual changes: <NL> [   71.352837] commsdriver[863]: tx-checksum-ip-generic: off <NL> [   71.380452] commsdriver[863]: tx-tcp-segmentation: off [not requested] <NL> [   71.390054] commsdriver[863]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   71.407956] commsdriver[863]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   71.441102] commsdriver[863]: tx-tcp6-segmentation: off [not requested] <NL> [   71.912312] e1000 0000:00:08.0 eth5: Reset adapter <NL> [   72.345219] commsdriver[542]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   72.442677] commsdriver[875]: Actual changes: <NL> [   72.489930] commsdriver[875]: tx-checksum-ip-generic: off <NL> [   72.565288] commsdriver[875]: tx-tcp-segmentation: off [not requested] <NL> [   72.791674] commsdriver[875]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   72.982244] commsdriver[875]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   73.074916] commsdriver[875]: tx-tcp6-segmentation: off [not requested] <NL> [   73.077393] commsready[878]: callback: Entry PID=0x36E signo(15) <NL> [   73.080524] change_esal_priority.sh[882]: Comms check for and selectively change esal priorities"}
{"timestamp_utc": "2024-07-31T08:14:10.414Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:10 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:11.340Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   57.467925] commsdriver[539]: Could not resolve symbol name delete_mac_address"}
{"timestamp_utc": "2024-07-31T08:14:11.341Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   57.474047] commsdriver[539]: Could not resolve symbol name set_vlan_prio <NL> [   57.540105] commsdriver[539]: Could not resolve symbol name replay_mac <NL> [   57.561340] commsdriver[539]: Could not resolve symbol name set_red_state <NL> [   57.562182] commsdriver[539]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   57.585132] commsdriver[539]: config file=int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   57.587344] commsdriver[539]: /usr/local/fnc/comms/config/simQemu/comms.cfg <NL> [   57.604045] commsdriver[539]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   57.612623] commsdriver[539]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.621420] commsdriver[539]: late config file=unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   57.624358] commsdriver[539]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.647554] commsdriver[539]: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.667772] commsdriver[539]: int get_config_file_path(char*, uint16_t) in commsQemu <NL> [   57.745931] commsdriver[539]: unitcode=02_00_00_00, uc=02_00_00_00 <NL> [   57.748450] commsdriver[539]: get_config_file_path_common Config path: /usr/local/fnc/comms/config/02_00_00_00/comms_late.cfg <NL> [   57.804977] commsdriver[539]: SharedMemory::getShmSegment creating new segment <NL> [   57.955108] commsdriver[539]: SharedMemory::getShmSegment SUCCESS shmid_ = 0 <NL> [   58.342891] br-lcn00: port 1(eth3) entered blocking state <NL> [   58.400389] br-lcn00: port 1(eth3) entered disabled state <NL> [   58.425252] device eth3 entered promiscuous mode <NL> [   58.505792] br-lcn00: port 2(lcn00-peer) entered blocking state <NL> [   58.595414] br-lcn00: port 2(lcn00-peer) entered disabled state <NL> [   58.699084] device lcn00-peer entered promiscuous mode <NL> [   58.921312] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   58.999977] commsdriver[539]: DEBUG: change_linkstate Marking lcn00 down for 1 <NL> [   60.033114] br-lcn01: port 1(eth4) entered blocking state <NL> [   60.033888] br-lcn01: port 1(eth4) entered disabled state <NL> [   60.053539] device eth4 entered promiscuous mode <NL> [   60.110132] br-lcn01: port 2(lcn01-peer) entered blocking state <NL> [   60.127334] br-lcn01: port 2(lcn01-peer) entered disabled state <NL> [   60.190965] device lcn01-peer entered promiscuous mode <NL> [   60.439259] 8021q: adding VLAN 0 to HW filter on device eth4 <NL> [   60.411958] commsdriver[539]: DEBUG: change_linkstate Marking lcn01 down for 3 <NL> [   61.310886] br-lmp00: port 1(eth2) entered blocking state <NL> [   61.351116] br-lmp00: port 1(eth2) entered disabled state <NL> [   61.389879] device eth2 entered promiscuous mode <NL> [   61.434352] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   61.497964] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   61.578639] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   61.758732] device lmp00-peer entered promiscuous mode <NL> [   61.811307] br-lcn00: port 1(eth3) entered blocking state <NL> [   61.849613] br-lcn00: port 1(eth3) entered forwarding state <NL> [   62.298799] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   62.280935] commsdriver[539]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   62.395664] commsdriver[539]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   62.658086] IPv6: ADDRCONF(NETDEV_CHANGE): lmp00: link becomes ready <NL> [   62.680732] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   62.697733] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   62.768446] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   62.778313] br-lcn01: port 1(eth4) entered blocking state <NL> [   62.779092] br-lcn01: port 1(eth4) entered forwarding state <NL> [   64.217188] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   64.115384] commsdriver[685]: SUCCESS <NL> [   64.304525] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   64.357700] br-lmp00: port 1(eth2) entered blocking state <NL> [   64.364321] br-lmp00: port 1(eth2) entered forwarding state <NL> [   66.224401] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   66.374108] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   66.896153] commsdriver[539]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   67.149019] device eth5 entered promiscuous mode <NL> [   67.009268] commsdriver[539]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   67.592958] commsdriver[539]: DEBUG: change_linkstate Marking erstp down for 46[   67.796065] device erstp-peer entered promiscuous mode <NL> [   68.516207] br-odcc1: port 1(eth1) entered blocking state <NL> [   68.592978] br-odcc1: port 1(eth1) entered disabled state <NL> [   68.634462] device eth1 entered promiscuous mode <NL> [   68.706386] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   68.733313] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   68.776752] device odcc1-peer entered promiscuous mode <NL> [   69.040223] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   69.061487] commsdriver[539]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   69.107227] commsdriver[539]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   69.530414] br-odcc2: port 1(eth6) entered blocking state <NL> [   69.539781] br-odcc2: port 1(eth6) entered disabled state <NL> [   69.561961] device eth6 entered promiscuous mode <NL> [   69.622357] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   69.656106] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   69.694051] device odcc2-peer entered promiscuous mode <NL> [   69.795716] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   69.778408] commsdriver[539]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   69.819816] commsdriver[539]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   71.114627] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   71.118782] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   71.136797] device eth1.3800 entered promiscuous mode <NL> [   71.158970] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   71.248545] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   71.296991] device gcc0-peer entered promiscuous mode <NL> [   71.465580] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   71.525009] br-odcc1: port 1(eth1) entered blocking state <NL> [   71.544223] br-odcc1: port 1(eth1) entered forwarding state <NL> [   71.615567] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   71.636018] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   71.710016] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   71.727445] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   71.784536] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   71.737795] commsdriver[539]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   71.800927] commsdriver[539]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   72.196600] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   72.275614] br-odcc2: port 1(eth6) entered blocking state <NL> [   72.277469] br-odcc2: port 1(eth6) entered forwarding state <NL> [   72.943676] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   73.019741] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   73.078634] device eth1.3801 entered promiscuous mode <NL> [   73.147052] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   73.215279] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   73.266204] device gcc1-peer entered promiscuous mode <NL> [   73.425589] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   73.461757] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   73.509207] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   73.531554] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   73.480848] commsdriver[539]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   73.554752] commsdriver[539]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   73.849426] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   74.189342] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   74.241444] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   74.271675] device eth6.3802 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:11.598Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:11 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:15.760Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:15 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:15 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:16.687Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   66.772004] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   66.800510] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   66.810916] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   66.826586] br-lmp00: port 2(lmp00-peer) entered disabled state <NL> [   66.590963] commsdriver[619]: DEBUG: change_linkstate Marking lmp00 down for 2 <NL> [   66.635824] commsdriver[619]: DEBUG: set_ip Marking lmp00 down for 2 <NL> [   66.947467] br-lmp00: port 2(lmp00-peer) entered blocking state <NL> [   66.959440] br-lmp00: port 2(lmp00-peer) entered forwarding state <NL> [   67.660488] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   67.661945] br-lcn00: port 1(eth3) entered blocking state <NL> [   67.662623] br-lcn00: port 1(eth3) entered forwarding state <NL> [   68.370306] 8021q: adding VLAN 0 to HW filter on device eth5 <NL> [   68.429521] e1000: eth4 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   68.456055] br-lcn01: port 1(eth4) entered blocking state <NL> [   68.483136] br-lcn01: port 1(eth4) entered forwarding state <NL> [   68.220913] commsdriver[753]: SUCCESS <NL> [   68.816399] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   68.817957] br-lmp00: port 1(eth2) entered blocking state <NL> [   68.818664] br-lmp00: port 1(eth2) entered forwarding state <NL> [   70.412482] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   70.414569] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.2003: link becomes ready <NL> [   70.483798] commsdriver[619]: DEBUG: change_linkstate Marking eth5.2003 down for 44 <NL> [   70.814741] device eth5 entered promiscuous mode <NL> [   70.561156] commsdriver[619]: DEBUG: set_ip Marking eth5.2003 down for 44 <NL> [   70.879909] commsdriver[619]: DEBUG: change_linkstate Marking erstp down for 46 <NL> [   71.194798] device erstp-peer entered promiscuous mode <NL> [   71.587688] br-odcc1: port 1(eth1) entered blocking state <NL> [   71.606397] br-odcc1: port 1(eth1) entered disabled state <NL> [   71.639449] device eth1 entered promiscuous mode <NL> [   71.709176] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   71.714094] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   71.723861] device odcc1-peer entered promiscuous mode <NL> [   71.811161] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   71.858962] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   71.882083] br-odcc1: port 2(odcc1-peer) entered forwarding state"}
{"timestamp_utc": "2024-07-31T08:14:16.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   71.909996] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   71.724617] commsdriver[619]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   71.756121] commsdriver[619]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   72.577885] br-odcc2: port 1(eth6) entered blocking state <NL> [   72.599731] br-odcc2: port 1(eth6) entered disabled state <NL> [   72.617559] device eth6 entered promiscuous mode <NL> [   72.642131] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   72.649288] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   72.671275] device odcc2-peer entered promiscuous mode <NL> [   72.775324] 8021q: adding VLAN 0 to HW filter on device eth6 <NL> [   72.816550] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   72.837019] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   72.867794] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   72.645539] commsdriver[619]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   72.673149] commsdriver[619]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   73.862814] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   73.884174] br-gcc0: port 1(eth1.3800) entered disabled state <NL> [   73.935783] device eth1.3800 entered promiscuous mode <NL> [   73.972582] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   73.990367] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   74.007265] device gcc0-peer entered promiscuous mode <NL> [   74.099123] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   74.116094] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   74.140321] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   73.895151] commsdriver[619]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   73.935440] commsdriver[619]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   74.252473] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   74.255796] br-odcc1: port 1(eth1) entered blocking state <NL> [   74.257855] br-odcc1: port 1(eth1) entered forwarding state <NL> [   74.260647] br-gcc0: port 1(eth1.3800) entered blocking state <NL> [   74.266132] br-gcc0: port 1(eth1.3800) entered forwarding state <NL> [   74.817359] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   74.855759] br-gcc1: port 1(eth1.3801) entered disabled state <NL> [   74.906061] device eth1.3801 entered promiscuous mode <NL> [   74.996017] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   74.996775] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   75.014290] device gcc1-peer entered promiscuous mode <NL> [   75.124216] br-gcc1: port 1(eth1.3801) entered blocking state <NL> [   75.132560] br-gcc1: port 1(eth1.3801) entered forwarding state <NL> [   75.148599] e1000: eth6 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   75.153213] br-odcc2: port 1(eth6) entered blocking state <NL> [   75.161111] br-odcc2: port 1(eth6) entered forwarding state <NL> [   75.176472] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   75.181349] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   74.947140] commsdriver[619]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   74.971815] commsdriver[619]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   75.573538] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   75.728345] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   75.733900] br-lwap: port 1(eth6.3802) entered disabled state <NL> [   75.767550] device eth6.3802 entered promiscuous mode <NL> [   75.800009] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   75.816156] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   75.838608] device lwap-peer entered promiscuous mode <NL> [   75.995689] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   76.020095] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   76.072521] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   76.084805] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   75.864491] commsdriver[619]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   75.864654] commsdriver[619]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   76.604214] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   76.336306] commsdriver[619]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   76.429467] commsdriver[939]: Actual changes: <NL> [   76.429680] commsdriver[939]: tx-checksum-ip-generic: off <NL> [   76.429769] commsdriver[939]: tx-tcp-segmentation: off [not requested] <NL> [   76.429838] commsdriver[939]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   76.429906] commsdriver[939]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   76.429974] commsdriver[939]: tx-tcp6-segmentation: off [not requested] <NL> [   76.860935] commsdriver[619]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   76.899117] commsdriver[951]: Actual changes: <NL> [   76.899298] commsdriver[951]: tx-checksum-ip-generic: off <NL> [   76.899374] commsdriver[951]: tx-tcp-segmentation: off [not requested] <NL> [   76.899443] commsdriver[951]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   76.899516] commsdriver[951]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   76.905267] commsdriver[951]: tx-tcp6-segmentation: off [not requested] <NL> [   77.071526] commsready[954]: callback: Entry PID=0x3BA signo(15) <NL> [   77.105954] change_esal_priority.sh[958]: Comms check for and selectively change esal priorities <NL> [   77.973368] change_esal_priority.sh[958]: Comms did not change any esal thread priorities <NL> [   78.934315] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   78.964061] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   78.770695] python[1006]: running intRstpEnable file creation SCRIPT <NL> [   78.923975] python[1006]: Already set to  TRUE <NL> [   79.103652] python[1006]:  , NO CHANGE! <NL> # 03:14:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:16 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:20.871Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:14:19 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:20 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:21.798Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:21 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:25.068Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:14:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:25.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:25 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:26.689Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:26 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:30.857Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:30 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:31.785Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:31 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:35.952Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:35 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:35 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:36.880Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:36 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:40.148Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:14:40 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:14:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:40 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:40.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:14:41.770Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:41 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:45.936Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:14:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:45 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:46.864Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:46 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:47.791Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   39.132790] commsdriver[699]: tx-tcp-segmentation: off [not requested] <NL> [   39.132873] commsdriver[699]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   39.132952] commsdriver[699]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   39.133050] commsdriver[699]: tx-tcp6-segmentation: off [not requested] <NL> [   40.314727] br-odcc1: port 1(eth2) entered blocking state <NL> [   40.347169] br-odcc1: port 1(eth2) entered disabled state <NL> [   40.371543] device eth2 entered promiscuous mode <NL> [   40.414270] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   40.425587] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   40.454149] device odcc1-peer entered promiscuous mode <NL> [   40.514123] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   40.539821] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   40.540645] br-odcc1: port 2(odcc1-peer) entered forwarding state <NL> [   40.541780] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   40.005454] commsdriver[603]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   40.012268] commsdriver[603]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   41.082835] br-odcc2: port 1(eth3) entered blocking state <NL> [   41.100265] br-odcc2: port 1(eth3) entered disabled state <NL> [   41.124462] device eth3 entered promiscuous mode <NL> [   41.166452] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   41.178828] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   41.193808] device odcc2-peer entered promiscuous mode <NL> [   41.257401] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   41.288885] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   41.325760] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   41.338377] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   41.359473] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   41.375360] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   40.810274] commsdriver[603]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   40.813990] commsdriver[603]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   42.136888] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   42.163769] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   42.186641] device eth2.3800 entered promiscuous mode <NL> [   42.235319] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   42.239469] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   42.287818] device gcc0-peer entered promiscuous mode <NL> [   42.386180] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   42.399538] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   42.401144] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   41.823839] commsdriver[603]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   41.831671] commsdriver[603]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   42.829596] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   42.860812] br-odcc1: port 1(eth2) entered blocking state <NL> [   42.862569] br-odcc1: port 1(eth2) entered forwarding state <NL> [   42.884825] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   42.886818] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   42.909233] IPv6: ADDRCONF(NETDEV_CHANGE): eth2.3801: link becomes ready <NL> [   42.995552] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   42.997721] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   43.016001] device eth2.3801 entered promiscuous mode <NL> [   43.032527] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   43.053676] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   43.055797] device gcc1-peer entered promiscuous mode <NL> [   43.128802] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   43.143705] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   43.165199] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   43.179584] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   42.661328] commsdriver[603]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   42.668238] commsdriver[603]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   43.601328] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   43.666325] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   43.689300] br-odcc2: port 1(eth3) entered blocking state <NL> [   43.712086] br-odcc2: port 1(eth3) entered forwarding state <NL> [   43.720687] IPv6: ADDRCONF(NETDEV_CHANGE): eth3.3802: link becomes ready <NL> [   43.778531] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   43.798535] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   43.815850] device eth3.3802 entered promiscuous mode <NL> [   43.834906] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   43.837571] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   43.889673] device lwap-peer entered promiscuous mode <NL> [   43.958769] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   43.981452] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   43.503390] commsdriver[603]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   43.512367] commsdriver[603]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   44.777513] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   44.806007] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   44.844255] device eth3.3803 entered promiscuous mode <NL> [   44.894262] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   44.895074] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   44.910449] device illdp-peer entered promiscuous mode <NL> [   45.033060] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   45.050231] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   44.573890] commsdriver[603]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   45.789364] commsready[873]: callback: Entry PID=0x369 signo(15)"}
{"timestamp_utc": "2024-07-31T08:14:47.792Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[   45.790267] commsready[873]: DipLog_pimpl destructor called <NL> [   45.803588] commsready[873]: DipVerbosity Listener ZMQ error <NL> [   45.808748] commsready[873]:     ret='Context was terminated <NL> [   45.815341] commsready[873]: deleting subscriber_ socket <NL> [   45.816774] commsready[873]: Exiting verb listener <NL> [   45.822666] change_esal_priority.sh[879]: Comms check for and selectively change esal priorities <NL> [   46.558320] change_esal_priority.sh[879]: Comms did not change any esal thread priorities <NL> [   46.714367] python[923]: running intRstpEnable file creation SCRIPT <NL> [   46.714575] python[923]: Already set to  TRUE <NL> [   46.714687] python[923]:  , NO CHANGE! <NL> [   47.369501] serialportMon[937]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   47.468249] sh[969]: In startMstpInt <NL> [   49.003118] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   49.138702] NFSD: Using legacy client tracking operations. <NL> [   49.141151] NFSD: starting 90-second grace period (net f0000098) <NL> [   48.745098] sh[969]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> 2024-07-31 08:13:43,629 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> [   51.125832] br.rstp_int: port 1(istp1) entered blocking state <NL> [   51.147559] br.rstp_int: port 1(istp1) entered disabled state <NL> [   51.166111] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:47,968 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:48,004 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:48,004 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   62.197396] vsftpd_listen_address[941]: listen_address=127.1.1.1 <NL> [   63.397909] br.rstp_int: port 2(istp2) entered blocking state <NL> [   63.398760] br.rstp_int: port 2(istp2) entered disabled state <NL> [   63.400286] device istp2 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:50.309Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:50 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:51.674Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:51 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:52.238Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   46.107995] br-odcc1: port 1(eth2) entered disabled state <NL> [   46.118645] device eth2 entered promiscuous mode <NL> [   46.129238] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   46.130121] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   46.140904] device odcc1-peer entered promiscuous mode <NL> [   46.245031] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   45.921355] commsdriver[588]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   45.926993] commsdriver[588]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   46.902204] br-odcc2: port 1(eth3) entered blocking state <NL> [   46.913144] br-odcc2: port 1(eth3) entered disabled state <NL> [   46.923281] device eth3 entered promiscuous mode <NL> [   46.957801] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   46.964387] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   46.965271] device odcc2-peer entered promiscuous mode <NL> [   47.080699] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   47.116156] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   47.132006] br-odcc2: port 2(odcc2-peer) entered forwarding state <NL> [   47.158648] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   46.850783] commsdriver[588]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   46.879379] commsdriver[588]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   47.538995] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   47.616158] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   47.963128] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   47.972554] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   48.008483] device eth2.3800 entered promiscuous mode <NL> [   48.060847] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   48.110289] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   48.147011] device gcc0-peer entered promiscuous mode <NL> [   48.274918] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   48.299316] br-gcc0: port 2(gcc0-peer) entered forwarding state <NL> [   48.373038] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   48.439133] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   48.451113] br-odcc1: port 1(eth2) entered blocking state <NL> [   48.451871] br-odcc1: port 1(eth2) entered forwarding state <NL> [   48.480260] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   48.481224] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   48.032204] commsdriver[588]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   48.125054] commsdriver[588]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   48.957886] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   48.963272] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   48.981211] device eth2.3801 entered promiscuous mode <NL> [   49.025484] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   49.040347] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   49.056082] device gcc1-peer entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:52.239Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[   49.175208] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   49.206762] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   49.252695] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   49.283137] br-gcc1: port 2(gcc1-peer) entered forwarding state <NL> [   49.331537] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   48.987425] commsdriver[588]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   49.003783] commsdriver[588]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   49.421139] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   49.424677] br-odcc2: port 1(eth3) entered blocking state <NL> [   49.426828] br-odcc2: port 1(eth3) entered forwarding state <NL> [   49.866512] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   49.885558] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   49.900061] device eth3.3802 entered promiscuous mode <NL> [   49.949846] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   49.950663] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   49.971601] device lwap-peer entered promiscuous mode <NL> [   50.154860] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   50.159015] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   50.173147] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   50.180111] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   49.923833] commsdriver[588]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   49.947513] commsdriver[588]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   50.398625] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   51.110221] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   51.130627] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   51.168476] device eth3.3803 entered promiscuous mode <NL> [   51.223860] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   51.226197] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   51.234771] device illdp-peer entered promiscuous mode <NL> [   51.438314] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   51.444028] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   51.119233] commsdriver[588]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   51.329801] commsready[871]: callback: Entry PID=0x367 signo(15) <NL> [   51.329969] commsready[871]: DipLog_pimpl destructor called <NL> [   51.330096] commsready[871]: DipVerbosity Listener ZMQ error <NL> [   51.330167] commsready[871]:     ret='Context was terminated <NL> [   51.330286] commsready[871]: deleting subscriber_ socket <NL> [   51.330367] commsready[871]: Exiting verb listener <NL> [   51.411953] change_esal_priority.sh[877]: Comms check for and selectively change esal priorities <NL> [   52.108923] change_esal_priority.sh[877]: Comms did not change any esal thread priorities <NL> [   52.475438] python[921]: running intRstpEnable file creation SCRIPT <NL> [   52.475659] python[921]: Already set to  TRUE <NL> [   52.475774] python[921]:  , NO CHANGE! <NL> [   52.869111] sh[967]: In startMstpInt <NL> [   52.922217] serialportMon[951]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   53.951939] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   54.060506] NFSD: Using legacy client tracking operations. <NL> [   54.108702] NFSD: starting 90-second grace period (net f0000098) <NL> [   54.745812] sh[967]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   56.894652] br.rstp_int: port 1(istp1) entered blocking state <NL> [   56.904695] br.rstp_int: port 1(istp1) entered disabled state <NL> [   56.905732] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:50,443 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:52,244 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:13:52,271 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:52,272 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   67.865938] vsftpd_listen_address[955]: listen_address=127.1.1.2 <NL> [   69.112254] br.rstp_int: port 2(istp2) entered blocking state <NL> [   69.119662] br.rstp_int: port 2(istp2) entered disabled state <NL> [   69.140963] device istp2 entered promiscuous mode <NL> [  119.017228] ntputils[1703]: int ntputils_main(int, char**)Starting ntputils <NL> [  119.148951] ntputils[1703]: Running as a daemon <NL> [  119.178812] ntputils[1703]: shelf role is: TRIB <NL> [  119.178960] ntputils[1703]: slot number is: 0 <NL> [  119.179073] ntputils[1703]: slot role is: UNKNOWN <NL> [  119.179159] ntputils[1703]: redundancy_mode: UNKNOWN <NL> [  119.179284] ntputils[1703]: Executing on a work blade <NL> [  119.179372] ntputils[1703]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN"}
{"timestamp_utc": "2024-07-31T08:14:54.126Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[   39.636021] 8021q: adding VLAN 0 to HW filter on device eth1 <NL> [   38.983216] commsdriver[636]: SUCCESS <NL> fujitsu login: [   41.751390] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   41.786957] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.2003: link becomes ready <NL> [   41.416220] commsdriver[595]: DEBUG: change_linkstate Marking eth1.2003 down for 44 <NL> [   42.198633] device eth1 entered promiscuous mode <NL> [   41.501479] commsdriver[595]: DEBUG: set_ip Marking eth1.2003 down for 44 <NL> [   41.863845] commsdriver[595]: DEBUG: change_linkstate Marking eth1.1000 down for 220 <NL> [   41.957654] commsdriver[684]: Actual changes: <NL> [   41.957838] commsdriver[684]: tx-checksum-ip-generic: off <NL> [   41.957923] commsdriver[684]: tx-tcp-segmentation: off [not requested] <NL> [   41.957994] commsdriver[684]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   41.958103] commsdriver[684]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   41.958189] commsdriver[684]: tx-tcp6-segmentation: off [not requested] <NL> [   42.454443] commsdriver[595]: DEBUG: change_linkstate Marking eth1.1001 down for 221 <NL> [   42.530944] commsdriver[696]: Actual changes: <NL> [   42.531138] commsdriver[696]: tx-checksum-ip-generic: off <NL> [   42.552769] commsdriver[696]: tx-tcp-segmentation: off [not requested] <NL> [   42.552865] commsdriver[696]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   42.552938] commsdriver[696]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   42.553023] commsdriver[696]: tx-tcp6-segmentation: off [not requested] <NL> [   43.737849] br-odcc1: port 1(eth2) entered blocking state <NL> [   43.758502] br-odcc1: port 1(eth2) entered disabled state <NL> [   43.759963] device eth2 entered promiscuous mode <NL> [   43.775953] br-odcc1: port 2(odcc1-peer) entered blocking state <NL> [   43.796448] br-odcc1: port 2(odcc1-peer) entered disabled state <NL> [   43.802944] device odcc1-peer entered promiscuous mode <NL> [   43.937712] 8021q: adding VLAN 0 to HW filter on device eth2 <NL> [   43.418414] commsdriver[595]: DEBUG: change_linkstate Marking odcc1 down for 11 <NL> [   43.418926] commsdriver[595]: DEBUG: change_linkstate_peer Marking odcc1 down for 11 <NL> [   44.809872] br-odcc2: port 1(eth3) entered blocking state <NL> [   44.810569] br-odcc2: port 1(eth3) entered disabled state <NL> [   44.811616] device eth3 entered promiscuous mode <NL> [   44.859532] br-odcc2: port 2(odcc2-peer) entered blocking state <NL> [   44.898994] br-odcc2: port 2(odcc2-peer) entered disabled state <NL> [   44.927300] device odcc2-peer entered promiscuous mode <NL> [   44.934341] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   44.955408] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   45.011166] 8021q: adding VLAN 0 to HW filter on device eth3 <NL> [   44.375833] commsdriver[595]: DEBUG: change_linkstate Marking odcc2 down for 12 <NL> [   44.397483] commsdriver[595]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   45.835760] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   45.871372] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   45.908475] device eth2.3800 entered promiscuous mode <NL> [   45.941419] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   45.952166] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   45.979652] device gcc0-peer entered promiscuous mode <NL> [   45.466919] commsdriver[595]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   45.488622] commsdriver[595]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   46.403417] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.404950] br-odcc1: port 1(eth2) entered blocking state <NL> [   46.405644] br-odcc1: port 1(eth2) entered forwarding state <NL> [   46.411228] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   46.411989] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   46.732064] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   46.749375] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   46.787727] device eth2.3801 entered promiscuous mode <NL> [   46.831176] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   46.849384] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   46.878188] device gcc1-peer entered promiscuous mode <NL> [   47.012003] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   47.035681] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   46.459486] commsdriver[595]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   46.488788] commsdriver[595]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   47.299426] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   47.357255] br-odcc2: port 1(eth3) entered blocking state <NL> [   47.370222] br-odcc2: port 1(eth3) entered forwarding state <NL> [   47.824924] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   47.825712] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   47.833863] device eth3.3802 entered promiscuous mode <NL> [   47.913960] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   47.976123] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   47.997582] device lwap-peer entered promiscuous mode <NL> [   48.135359] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   48.154069] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   47.529610] commsdriver[595]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   47.558593] commsdriver[595]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   48.835044] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   48.856694] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   48.879128] device eth3.3803 entered promiscuous mode <NL> [   48.958386] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   48.969417] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   48.996285] device illdp-peer entered promiscuous mode <NL> [   49.105723] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   49.117165] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   48.479464] commsdriver[595]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   48.750256] commsready[868]: callback: Entry PID=0x364 signo(15) <NL> [   48.806016] change_esal_priority.sh[872]: Comms check for and selectively change esal priorities <NL> [   49.866021] change_esal_priority.sh[872]: Comms did not change any esal thread priorities <NL> [   50.457667] python[932]: running intRstpEnable file creation SCRIPT <NL> [   50.457861] python[932]: Already set to  TRUE <NL> [   50.457958] python[932]:  , NO CHANGE! <NL> [   50.747042] sh[958]: In startMstpInt <NL> [   51.073579] serialportMon[945]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   52.307034] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   52.339232] NFSD: Using legacy client tracking operations. <NL> [   52.391049] NFSD: starting 90-second grace period (net f0000098) <NL> [   52.760734] sh[958]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   55.613270] br.rstp_int: port 1(istp1) entered blocking state <NL> [   55.623125] br.rstp_int: port 1(istp1) entered disabled state <NL> [   55.628608] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:50,566 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:52,887 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:13:52,887 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:52,903 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   65.608079] vsftpd_listen_address[949]: listen_address=127.1.1.2 <NL> [   67.725260] br.rstp_int: port 2(istp2) entered blocking state <NL> [   67.726112] br.rstp_int: port 2(istp2) entered disabled state <NL> [   67.739726] device istp2 entered promiscuous mode"}
{"timestamp_utc": "2024-07-31T08:14:54.688Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  112.613028] ntputils[1716]: int ntputils_main(int, char**)Starting ntputils <NL> [  112.613397] ntputils[1716]: Running as a daemon <NL> [  112.613532] ntputils[1716]: shelf role is: TRIB <NL> [  112.613607] ntputils[1716]: slot number is: 0 <NL> [  112.613675] ntputils[1716]: slot role is: UNKNOWN <NL> [  112.613765] ntputils[1716]: redundancy_mode: UNKNOWN <NL> [  112.613900] ntputils[1716]: Executing on a work blade <NL> [  112.613974] ntputils[1716]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  112.614065] ntputils[1716]: ================================ <NL> [  112.614137] ntputils[1716]: shelf_role is: TRIB <NL> [  112.614206] ntputils[1716]: redundancy_mode: UNKNOWN <NL> [  112.614275] ntputils[1716]: active_status: active <NL> [  112.614357] ntputils[1716]: ntp_role: trib <NL> [  112.614427] ntputils[1716]: ================================ <NL> [  112.614597] ntputils[1716]: NTPUtilsConfig::do_default_config <NL> [  112.614670] ntputils[1716]: shelf_num/is_client: 1 <NL> [  112.614751] ntputils[1716]: server_ip: 0x55654c104fc0 <NL> [  112.614827] ntputils[1716]: ip_addr(ilan): 0x55654c104f80 <NL> [  112.614899] ntputils[1716]: ntp_role trib <NL> [  112.614983] ntputils[1716]: shelf_num aka is_client > 0 <NL> [  112.615071] ntputils[1716]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.615161] ntputils[1716]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.615235] ntputils[1716]: NTPServer::execute_cmd spawning: <NL> [  112.615311] ntputils[1716]: systemctl --no-block stop ntpd <NL> [  112.615382] ntputils[1716]: child pid is 1737 <NL> [  112.931420] ntputils[1716]: exited, status is 0 <NL> [  112.931724] ntputils[1716]: NTPServer::execute_cmd spawning: <NL> [  112.931844] ntputils[1716]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  112.931918] ntputils[1716]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  112.932014] ntputils[1716]: child pid is 1748 <NL> [  112.984296] ntputils[1751]: Changing Stratum and adding restrictions <NL> [  113.239257] ntputils[1770]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:47,310 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 59 seconds <NL> 2024-07-31 08:14:47,452 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:47,453 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  113.498328] ntputils[1716]: exited, status is 0 <NL> [  113.507298] ntputils[1716]: NTPServer::execute_cmd spawning: <NL> [  113.532228] ntputils[1716]: /bin/systemctl reset-failed ntpd <NL> [  113.590354] ntputils[1716]: child pid is 1794 <NL> [  113.680498] ntputils[1716]: exited, status is 0 <NL> [  113.731398] ntputils[1716]: NTPServer::execute_cmd spawning: <NL> [  113.775813] ntputils[1716]: systemctl --no-block start ntpd <NL> 2024-07-31 08:14:47,789 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:47,876 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  113.819686] ntputils[1716]: child pid is 1797 <NL> [  113.923183] ntputils[1716]: exited, status is 0 <NL> [  113.923295] ntputils[1716]: client role with Python client, systemD starts it <NL> 2024-07-31 08:14:48,107 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:48,108 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:48,108 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:48,108 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:48,108 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:48,109 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:48,111 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:48,111 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:48,111 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:48,151 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:14:51,510 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:51,595 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:51,630 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority):"}
{"timestamp_utc": "2024-07-31T08:14:54.689Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "(priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:51,697 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:51,698 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:51,775 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:51,812 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> [  117.865308] fujitsu-check-ssh-host-key.pl[1893]: Checking system account status... <NL> [  117.865567] fujitsu-check-ssh-host-key.pl[1893]: System account found... <NL> [  117.935620] fujitsu-check-ssh-host-key.pl[1893]: 3004 <NL> 2024-07-31 08:14:51,984 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:51,984 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:51,984 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  117.974076] fujitsu-check-ssh-host-key.pl[1893]: /bin/bash <NL> [  117.981806] fujitsu-check-ssh-host-key.pl[1893]: /home/system exists <NL> [  117.981906] fujitsu-check-ssh-host-key.pl[1893]: Checking for trib... <NL> [  118.042602] fujitsu-check-ssh-host-key.pl[1893]: Creating factory user for trib.. <NL> [  118.773915] fujitsu-check-ssh-host-key.pl[1919]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  118.774156] fujitsu-check-ssh-host-key.pl[1919]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  118.852270] fujitsu-check-ssh-host-key.pl[1927]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  118.852455] fujitsu-check-ssh-host-key.pl[1927]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  118.904551] fujitsu-check-ssh-host-key.pl[1930]: Filesystem      Size  Used Avail Use% Mounted on <NL> 2024-07-31 08:14:53,022 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:53,045 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:14:53,045 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:53,046 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:53,046 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:53,047 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:14:53,047 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY"}
{"timestamp_utc": "2024-07-31T08:14:55.252Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:14:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:55 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> [   46.388810] commsdriver[612]: DEBUG: change_linkstate_peer Marking odcc2 down for 12 <NL> [   46.821330] e1000: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   46.854640] IPv6: ADDRCONF(NETDEV_CHANGE): eth1.1001: link becomes ready <NL> [   47.507234] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   47.544148] br-gcc0: port 1(eth2.3800) entered disabled state <NL> [   47.569312] device eth2.3800 entered promiscuous mode <NL> [   47.602252] br-gcc0: port 2(gcc0-peer) entered blocking state <NL> [   47.605574] br-gcc0: port 2(gcc0-peer) entered disabled state <NL> [   47.610300] device gcc0-peer entered promiscuous mode <NL> [   47.408677] commsdriver[612]: DEBUG: change_linkstate Marking gcc0 down for 13 <NL> [   47.415867] commsdriver[612]: DEBUG: change_linkstate_peer Marking gcc0 down for 13 <NL> [   48.089165] e1000: eth2 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   48.102344] br-odcc1: port 1(eth2) entered blocking state <NL> [   48.103076] br-odcc1: port 1(eth2) entered forwarding state <NL> [   48.103943] br-gcc0: port 1(eth2.3800) entered blocking state <NL> [   48.106618] br-gcc0: port 1(eth2.3800) entered forwarding state <NL> [   48.400645] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   48.413462] br-gcc1: port 1(eth2.3801) entered disabled state <NL> [   48.428804] device eth2.3801 entered promiscuous mode <NL> [   48.454650] IPv6: ADDRCONF(NETDEV_CHANGE): eth2.3801: link becomes ready <NL> [   48.480335] br-gcc1: port 2(gcc1-peer) entered blocking state <NL> [   48.498388] br-gcc1: port 2(gcc1-peer) entered disabled state <NL> [   48.515548] device gcc1-peer entered promiscuous mode <NL> [   48.601043] br-gcc1: port 1(eth2.3801) entered blocking state <NL> [   48.619692] br-gcc1: port 1(eth2.3801) entered forwarding state <NL> [   48.297643] commsdriver[612]: DEBUG: change_linkstate Marking gcc1 down for 14 <NL> [   48.318887] commsdriver[612]: DEBUG: change_linkstate_peer Marking gcc1 down for 14 <NL> [   49.047641] e1000: eth3 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   49.076432] br-odcc2: port 1(eth3) entered blocking state <NL> [   49.085156] br-odcc2: port 1(eth3) entered forwarding state <NL> [   49.093417] IPv6: ADDRCONF(NETDEV_CHANGE): eth3.3802: link becomes ready <NL> [   49.164798] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   49.193138] br-lwap: port 1(eth3.3802) entered disabled state <NL> [   49.218872] device eth3.3802 entered promiscuous mode <NL> [   49.292868] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   49.303442] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   49.342050] device lwap-peer entered promiscuous mode <NL> [   49.460746] br-lwap: port 1(eth3.3802) entered blocking state <NL> [   49.479301] br-lwap: port 1(eth3.3802) entered forwarding state <NL> [   49.161246] commsdriver[612]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   49.215418] commsdriver[612]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   50.405068] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   50.438370] br-illdp: port 1(eth3.3803) entered disabled state <NL> [   50.471545] device eth3.3803 entered promiscuous mode <NL> [   50.537318] br-illdp: port 2(illdp-peer) entered blocking state <NL> [   50.593835] br-illdp: port 2(illdp-peer) entered disabled state <NL> [   50.650145] device illdp-peer entered promiscuous mode <NL> [   50.727913] br-illdp: port 1(eth3.3803) entered blocking state <NL> [   50.753911] br-illdp: port 1(eth3.3803) entered forwarding state <NL> [   50.428326] commsdriver[612]: DEBUG: change_linkstate Marking illdp down for 29 <NL> [   51.710510] commsready[874]: callback: Entry PID=0x36A signo(15) <NL> [   51.829558] change_esal_priority.sh[878]: Comms check for and selectively change esal priorities <NL> [   53.178817] change_esal_priority.sh[878]: Comms did not change any esal thread priorities <NL> [   54.041427] python[939]: running intRstpEnable file creation SCRIPT <NL> [   54.041654] python[939]: Already set to  TRUE <NL> [   54.088601] python[939]:  , NO CHANGE! <NL> [   54.089087] serialportMon[952]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   54.323337] sh[977]: In startMstpInt <NL> [   55.347862] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   55.467387] NFSD: Using legacy client tracking operations. <NL> [   55.608978] NFSD: starting 90-second grace period (net f0000098) <NL> [   55.732134] sh[977]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   58.279350] br.rstp_int: port 1(istp1) entered blocking state <NL> [   58.314407] br.rstp_int: port 1(istp1) entered disabled state <NL> [   58.331015] device istp1 entered promiscuous mode <NL> 2024-07-31 08:13:52,727 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:13:53,693 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=daughter, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:13:53,785 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:13:53,820 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.daughter.yaml <NL> [   68.944229] vsftpd_listen_address[957]: listen_address=127.1.1.1 <NL> [   70.563356] br.rstp_int: port 2(istp2) entered blocking state"}
{"timestamp_utc": "2024-07-31T08:14:55.253Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[   70.565788] br.rstp_int: port 2(istp2) entered disabled state <NL> [   70.582097] device istp2 entered promiscuous mode <NL> 2024-07-31 08:14:53,357 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 59 seconds <NL> [  119.197585] ntputils[1700]: int ntputils_main(int, char**)Starting ntputils <NL> [  119.449512] ntputils[1700]: Running as a daemon <NL> [  119.491286] ntputils[1700]: shelf role is: TRIB <NL> [  119.491993] ntputils[1700]: slot number is: 0 <NL> [  119.492565] ntputils[1700]: slot role is: UNKNOWN <NL> [  119.661297] ntputils[1700]: redundancy_mode: UNKNOWN <NL> [  119.661437] ntputils[1700]: Executing on a work blade <NL> [  119.661508] ntputils[1700]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  119.661579] ntputils[1700]: ================================ <NL> [  119.661687] ntputils[1700]: shelf_role is: TRIB <NL> [  119.661762] ntputils[1700]: redundancy_mode: UNKNOWN <NL> [  119.661831] ntputils[1700]: active_status: active <NL> [  119.661901] ntputils[1700]: ntp_role: trib <NL> [  119.661982] ntputils[1700]: ================================ <NL> [  119.662132] ntputils[1700]: NTPUtilsConfig::do_default_config <NL> [  119.662205] ntputils[1700]: shelf_num/is_client: 1 <NL> [  119.662274] ntputils[1700]: server_ip: 0x559ac0216fc0 <NL> [  119.662345] ntputils[1700]: ip_addr(ilan): 0x559ac0216f80 <NL> [  119.662414] ntputils[1700]: ntp_role trib <NL> [  119.662485] ntputils[1700]: shelf_num aka is_client > 0 <NL> [  119.662555] ntputils[1700]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  119.662636] ntputils[1700]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  119.662719] ntputils[1700]: NTPServer::execute_cmd spawning: <NL> [  119.662791] ntputils[1700]: systemctl --no-block stop ntpd <NL> [  119.666820] ntputils[1700]: child pid is 1713 <NL> [  119.668849] ntputils[1700]: exited, status is 0 <NL> [  119.668948] ntputils[1700]: NTPServer::execute_cmd spawning: <NL> [  119.669036] ntputils[1700]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  119.669114] ntputils[1700]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  119.669184] ntputils[1700]: child pid is 1718 <NL> [  119.835093] ntputils[1720]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:54,074 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:14:54,075 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default"}
{"timestamp_utc": "2024-07-31T08:14:55.509Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:14:55 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:14:56.873Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:14:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:14:56 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:00.143Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:00 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:00.399Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:00 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:00.960Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  119.179446] ntputils[1703]: ================================ <NL> [  119.179516] ntputils[1703]: shelf_role is: TRIB <NL> [  119.179584] ntputils[1703]: redundancy_mode: UNKNOWN <NL> [  119.179651] ntputils[1703]: active_status: active <NL> [  119.179729] ntputils[1703]: ntp_role: trib <NL> [  119.179800] ntputils[1703]: ================================ <NL> [  119.179914] ntputils[1703]: NTPUtilsConfig::do_default_config <NL> [  119.179996] ntputils[1703]: shelf_num/is_client: 1 <NL> [  119.180097] ntputils[1703]: server_ip: 0x563265c23fc0 <NL> [  119.180169] ntputils[1703]: ip_addr(ilan): 0x563265c23f80 <NL> [  119.180239] ntputils[1703]: ntp_role trib <NL> [  119.180317] ntputils[1703]: shelf_num aka is_client > 0 <NL> [  119.180395] ntputils[1703]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  119.180470] ntputils[1703]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  119.180540] ntputils[1703]: NTPServer::execute_cmd spawning: <NL> [  119.180611] ntputils[1703]: systemctl --no-block stop ntpd <NL> [  119.180682] ntputils[1703]: child pid is 1740 <NL> 2024-07-31 08:14:51,700 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 59 seconds <NL> [  119.472441] ntputils[1703]: exited, status is 0 <NL> [  119.472669] ntputils[1703]: NTPServer::execute_cmd spawning: <NL> [  119.472752] ntputils[1703]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  119.472835] ntputils[1703]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> 2024-07-31 08:14:51,895 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  119.543800] ntputils[1703]: child pid is 1746 <NL> 2024-07-31 08:14:51,942 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  119.650806] ntputils[1755]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:52,342 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:52,422 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  120.145496] ntputils[1791]: Changing Stratum and adding restrictions <NL> [  120.499720] ntputils[1703]: exited, status is 0 <NL> [  120.499925] ntputils[1703]: NTPServer::execute_cmd spawning: <NL> [  120.500035] ntputils[1703]: /bin/systemctl reset-failed ntpd <NL> [  120.500124] ntputils[1703]: child pid is 1812 <NL> 2024-07-31 08:14:53,056 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:53,057 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:53,057 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:53,057 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:53,057 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:53,057 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:53,157 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:53,388 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:53,388 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  120.937510] ntputils[1703]: exited, status is 0 <NL> [  121.027304] ntputils[1703]: NTPServer::execute_cmd spawning: <NL> [  121.027402] ntputils[1703]: systemctl --no-block start ntpd <NL> [  121.027479] ntputils[1703]: child pid is 1822 <NL> 2024-07-31 08:14:53,472 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  121.234836] ntputils[1703]: exited, status is 0 <NL> [  121.253652] ntputils[1703]: client role with Python client, systemD starts it <NL> [  122.037290] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  122.156402] ntputils_client.py[1708]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  122.204611] ntputils_client.py[1708]: b'31 Jul 08:14:54 ntpdate[1853]: the NTP socket is in use, exiting\\n' <NL> [  124.653804] fujitsu-check-ssh-host-key.pl[1921]: Checking system account status... <NL> [  124.808702] fujitsu-check-ssh-host-key.pl[1921]: System account found... <NL> [  124.912314] fujitsu-check-ssh-host-key.pl[1921]: 3004"}
{"timestamp_utc": "2024-07-31T08:15:00.961Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  124.965468] fujitsu-check-ssh-host-key.pl[1921]: /bin/bash <NL> [  124.965717] fujitsu-check-ssh-host-key.pl[1921]: /home/system exists <NL> [  124.965812] fujitsu-check-ssh-host-key.pl[1921]: Checking for trib... <NL> [  125.068840] fujitsu-check-ssh-host-key.pl[1921]: Creating factory user for trib.. <NL> 2024-07-31 08:14:58,465 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:14:58,510 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:58,510 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:58,511 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:58,511 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:58,512 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:58,685 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:58,741 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:58,742 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:58,742 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  127.327503] fujitsu-check-ssh-host-key.pl[1995]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.327741] fujitsu-check-ssh-host-key.pl[1995]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  127.383641] fujitsu-check-ssh-host-key.pl[1996]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.383871] fujitsu-check-ssh-host-key.pl[1996]: /dev/root       2.2G  1.8G  311M  86% / <NL> 2024-07-31 08:14:59,762 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:14:59,764 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  127.386755] fujitsu-check-ssh-host-key.pl[1997]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.547237] fujitsu-check-ssh-host-key.pl[1997]: /dev/root       2.2G  1.8G  311M  86% / <NL> 2024-07-31 08:14:59,914 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:14:59,915 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:14:59,915 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:14:59,970 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:15:00,130 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:15:00,130 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE"}
{"timestamp_utc": "2024-07-31T08:15:01.889Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:01 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:03.265Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  118.625663] ntputils[1688]: int ntputils_main(int, char**)Starting ntputils <NL> 2024-07-31 08:14:53,390 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 60 seconds <NL> [  118.626104] ntputils[1688]: Running as a daemon <NL> [  118.930921] ntputils[1688]: shelf role is: TRIB <NL> [  118.931061] ntputils[1688]: slot number is: 0 <NL> [  118.931142] ntputils[1688]: slot role is: UNKNOWN <NL> [  118.931220] ntputils[1688]: redundancy_mode: UNKNOWN <NL> [  119.046330] ntputils[1688]: Executing on a work blade <NL> [  119.066695] ntputils[1688]: trib_str shelf role is TRIB or piu_str slot role is UNKNOWN <NL> [  119.066903] ntputils[1688]: ================================ <NL> [  119.066994] ntputils[1688]: shelf_role is: TRIB <NL> [  119.067105] ntputils[1688]: redundancy_mode: UNKNOWN <NL> [  119.067183] ntputils[1688]: active_status: active <NL> [  119.067262] ntputils[1688]: ntp_role: trib <NL> [  119.067340] ntputils[1688]: ================================ <NL> [  119.122099] ntputils[1688]: NTPUtilsConfig::do_default_config <NL> [  119.205929] ntputils[1688]: shelf_num/is_client: 1 <NL> [  119.206041] ntputils[1688]: server_ip: 0x5586770cafc0 <NL> [  119.206127] ntputils[1688]: ip_addr(ilan): 0x5586770caf80 <NL> [  119.206198] ntputils[1688]: ntp_role trib <NL> [  119.206271] ntputils[1688]: shelf_num aka is_client > 0 <NL> [  119.206345] ntputils[1688]: restart daemon with: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> [  119.206446] ntputils[1688]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  119.206520] ntputils[1688]: NTPServer::execute_cmd spawning: <NL> [  119.206590] ntputils[1688]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:14:53,852 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  119.314013] ntputils[1688]: child pid is 1703 <NL> [  119.382398] ntputils[1688]: exited, status is 0 <NL> [  119.382509] ntputils[1688]: NTPServer::execute_cmd spawning: <NL> [  119.382584] ntputils[1688]: /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.254 /etc/ntp.conf; \\ <NL> 2024-07-31 08:14:54,075 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  119.632372] ntputils[1688]:                     /usr/local/fnc/ntputils/setClientConf.sh 127.1.254.253 /etc/ntp.conf <NL> [  119.668759] ntputils[1688]: child pid is 1717 <NL> [  119.691231] ntputils[1726]: Changing Stratum and adding restrictions <NL> [  120.048998] ntputils[1754]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:54,690 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:54,742 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  120.484951] ntputils[1688]: exited, status is 0 <NL> [  120.485185] ntputils[1688]: NTPServer::execute_cmd spawning: <NL> [  120.485278] ntputils[1688]: /bin/systemctl reset-failed ntpd <NL> [  120.756939] ntputils[1688]: child pid is 1789 <NL> [  120.851694] ntputils[1688]: exited, status is 0 <NL> [  120.851902] ntputils[1688]: NTPServer::execute_cmd spawning: <NL> [  120.851978] ntputils[1688]: systemctl --no-block start ntpd <NL> 2024-07-31 08:14:55,447 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:55,447 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:55,447 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:55,448 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:55,448 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:55,589 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:14:55,599 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  121.003110] ntputils[1688]: child pid is 1798 <NL> 2024-07-31 08:14:55,806 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:55,837 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:55,969 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  121.410458] ntputils[1688]: exited, status is 0 <NL> [  121.410644] ntputils[1688]: client role with Python client, systemD starts it <NL> 2024-07-31 08:14:59,284 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=2, slot_id=0 <NL> 2024-07-31 08:14:59,285 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:59,285 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:14:59,286 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:14:59,502 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:14:59,529 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:14:59,530 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:14:59,536 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:14:59,626 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:14:59,663 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> [  125.589861] fujitsu-check-ssh-host-key.pl[1918]: Checking system account status... <NL> [  125.603326] fujitsu-check-ssh-host-key.pl[1918]: System account found... <NL> [  125.764324] fujitsu-check-ssh-host-key.pl[1918]: 3004 <NL> [  125.925242] fujitsu-check-ssh-host-key.pl[1918]: /bin/bash <NL> [  125.925498] fujitsu-check-ssh-host-key.pl[1918]: /home/system exists <NL> [  125.925591] fujitsu-check-ssh-host-key.pl[1918]: Checking for trib... <NL> [  125.939980] fujitsu-check-ssh-host-key.pl[1918]: Creating factory user for trib.. <NL> 2024-07-31 08:15:00,705 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:00,803 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:00,804 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:00,804 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:15:00,805 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:00,806 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:15:01,002 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:15:01,002 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  127.793566] fujitsu-check-ssh-host-key.pl[1988]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.796081] fujitsu-check-ssh-host-key.pl[1988]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  127.796561] fujitsu-check-ssh-host-key.pl[1990]: Filesystem      Size  Used Avail Use% Mounted on"}
{"timestamp_utc": "2024-07-31T08:15:05.153Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:05.409Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:05 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:06.781Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:06 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:10.957Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:10 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:11.884Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:11 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:12.140Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "2024-07-31 08:14:54,507 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:14:54,508 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  120.795358] ntputils[1763]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:14:55,063 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:14:55,064 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:55,065 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:14:55,065 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:14:55,065 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:14:55,071 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE"}
{"timestamp_utc": "2024-07-31T08:15:12.141Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "2024-07-31 08:14:55,224 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:14:55,370 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:14:55,377 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:14:55,532 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> [  121.717813] ntputils[1700]: exited, status is 0 <NL> [  121.718115] ntputils[1700]: NTPServer::execute_cmd spawning: <NL> [  121.718191] ntputils[1700]: /bin/systemctl reset-failed ntpd <NL> [  121.718261] ntputils[1700]: child pid is 1806 <NL> [  121.925177] ntputils[1700]: exited, status is 0 <NL> [  121.925375] ntputils[1700]: NTPServer::execute_cmd spawning: <NL> [  121.925471] ntputils[1700]: systemctl --no-block start ntpd <NL> [  121.945220] ntputils[1700]: child pid is 1814 <NL> [  122.171129] ntputils[1700]: exited, status is 0 <NL> [  122.272289] ntputils[1700]: client role with Python client, systemD starts it <NL> 2024-07-31 08:15:01,493 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:01,531 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:01,561 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:15:01,673 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:15:01,807 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  127.626483] fujitsu-check-ssh-host-key.pl[1951]: Checking system account status... <NL> [  127.820679] fujitsu-check-ssh-host-key.pl[1951]: System account found... <NL> 2024-07-31 08:15:01,816 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:01,992 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:02,025 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  127.963363] fujitsu-check-ssh-host-key.pl[1951]: 3004 <NL> [  128.056946] fujitsu-check-ssh-host-key.pl[1951]: /bin/bash <NL> [  128.057061] fujitsu-check-ssh-host-key.pl[1951]: /home/system exists <NL> [  128.057140] fujitsu-check-ssh-host-key.pl[1951]: Checking for trib... <NL> [  128.057264] fujitsu-check-ssh-host-key.pl[1951]: Creating factory user for trib.. <NL> 2024-07-31 08:15:02,173 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:02,249 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=RESET <NL> 2024-07-31 08:15:03,252 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:03,323 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:03,592 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:03,722 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, VALIDATE <NL> 2024-07-31 08:15:03,734 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:03,791 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> 2024-07-31 08:15:03,793 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=daughter, action=REPLAY <NL> 2024-07-31 08:15:03,799 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  130.197139] fujitsu-check-ssh-host-key.pl[2001]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.197344] fujitsu-check-ssh-host-key.pl[2001]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.197587] fujitsu-check-ssh-host-key.pl[2002]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.197722] fujitsu-check-ssh-host-key.pl[2002]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.197936] fujitsu-check-ssh-host-key.pl[2003]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  130.198028] fujitsu-check-ssh-host-key.pl[2003]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  130.279970] fujitsu-check-ssh-host-key.pl[2005]: useradd: user 'fujitsu' already exists <NL> [  131.564071] fujitsu-check-ssh-host-key.pl[1975]: DDS Peristency is enabled <NL> [  131.565254] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  131.565657] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  131.565973] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  131.566499] fujitsu-check-ssh-host-key.pl[1975]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  131.625403] fujitsu-check-ssh-host-key.pl[1975]: Factory user shell set to /bin/bash <NL> [  131.678412] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  131.678654] ntputils_client.py[1702]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  131.678770] ntputils_client.py[1702]: b'31 Jul 08:15:05 ntpdate[1856]: no server suitable for synchronization found\\n' <NL> [  131.770784] fujitsu-check-ssh-host-key.pl[1951]: Converting fujitsu user to bash shell... <NL> [  131.800137] fujitsu-check-ssh-host-key.pl[2014]: usermod: no changes <NL> [  131.801688] fujitsu-check-ssh-host-key.pl[1951]: Lock Root account in TRIB... <NL> [  131.835381] fujitsu-check-ssh-host-key.pl[2015]: Running lock on root account... <NL> [  132.159843] fujitsu-check-ssh-host-key.pl[2017]: passwd: password changed. <NL> [  132.160105] fujitsu-check-ssh-host-key.pl[1951]: Trib check done. <NL> [  132.674488] startup[2035]: Startup, World! <NL> [  132.677963] startup[2035]: Cmd arg set to loop 1 <NL> [  132.909688] startup_finished.py[2031]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  133.215573] ains_manager[2032]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  134.624245] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  134.776604] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  134.628348] confd_mgr_action_server[2052]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  134.628778] sh[2090]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  134.628895] sh[2090]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument"}
{"timestamp_utc": "2024-07-31T08:15:15.407Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "(priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:06,544 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:06,546 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:06,547 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> 2024-07-31 08:14:06,954 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:06,983 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:06,993 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> [   81.129768] vsftpd_listen_address[1030]: listen_address=127.1.254.254 <NL> [   82.017805] br.rstp_int: port 2(istp2) entered blocking state <NL> [   82.030263] br.rstp_int: port 2(istp2) entered disabled state <NL> [   82.031841] device istp2 entered promiscuous mode <NL> [  131.914037] dcn_ka[1606]:  WaitForActive <NL> [  133.885545] dcn_dns_controller[1604]:  WaitForActive <NL> 2024-07-31 08:15:11,119 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 64 seconds <NL> [  137.209780] ntputils[1971]: int ntputils_main(int, char**)Starting ntputils <NL> [  137.348672] ntputils[1971]: Running as a daemon <NL> [  137.348809] ntputils[1971]: shelf role is: MAIN <NL> [  137.348895] ntputils[1971]: slot number is: 0 <NL> [  137.348972] ntputils[1971]: slot role is: UNKNOWN <NL> [  137.349063] ntputils[1971]: redundancy_mode: UNKNOWN <NL> [  137.349191] ntputils[1971]: Executing on a work blade <NL> [  137.349267] ntputils[1971]: ================================ <NL> [  137.349339] ntputils[1971]: shelf_role is: MAIN <NL> [  137.349408] ntputils[1971]: redundancy_mode: UNKNOWN <NL> [  137.349477] ntputils[1971]: active_status: active <NL> [  137.349545] ntputils[1971]: ntp_role: act"}
{"timestamp_utc": "2024-07-31T08:15:15.408Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  137.349621] ntputils[1971]: ================================ <NL> [  137.349701] ntputils[1971]: NTPUtilsConfig::do_default_config <NL> [  137.349822] ntputils[1971]: shelf_num/is_client: 0 <NL> [  137.349913] ntputils[1971]: server_ip: 0x55d402c10fc0 <NL> [  137.349998] ntputils[1971]: ip_addr(ilan): 0x55d402c10f80 <NL> [  137.350105] ntputils[1971]: ntp_role act <NL> [  137.350181] ntputils[1971]: shelf_num aka is_client == 0 <NL> [  137.350263] ntputils[1971]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  137.350344] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  137.350416] ntputils[1971]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:11,495 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 64 seconds <NL> 2024-07-31 08:15:11,553 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:11,555 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  137.409746] ntputils[1971]: child pid is 2012 <NL> [  137.885268] ntputils[1971]: exited, status is 0 <NL> [  137.885449] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  137.885557] ntputils[1971]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  137.885665] ntputils[1971]: child pid is 2038 <NL> 2024-07-31 08:15:12,046 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:12,137 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  138.289368] ntputils[2043]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:15:12,472 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:15:12,767 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  138.940608] ntputils[1971]: exited, status is 0 <NL> [  139.160108] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  139.202856] ntputils[1971]: /bin/systemctl reset-failed ntpd <NL> [  139.253513] ntputils[1971]: child pid is 2065 <NL> [  139.255123] rdm[1984]: RdmConfig: file_exist 0 <NL> [  139.255772] rdm[1984]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  139.256523] rdm[1984]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  139.378364] rdm[1984]: start rdm msg hdlr thd <NL> [  139.378788] ntputils[1971]: exited, status is 0 <NL> [  139.378881] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  139.378950] ntputils[1971]: systemctl --no-block start ntpd <NL> [  139.379044] ntputils[1971]: child pid is 2113 <NL> [  139.379116] ntputils[1971]: exited, status is 0 <NL> [  139.379181] ntputils[1971]: server role, server_ip is set to: 127.0.0.1 <NL> [  139.379251] ntputils[1971]: Running in production mode <NL> [  139.379322] ntputils[1971]: InitDaemon redundancy_mode: UNKNOWN <NL> [  139.544902] ntputils[1971]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  139.545137] ntputils[1971]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  139.545223] ntputils[1971]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  139.545306] ntputils[1971]: registration socket.send OK <NL> 2024-07-31 08:15:13,522 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:13,694 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:13,695 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:13,747 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:13,747 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:13,747 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:13,748 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> 2024-07-31 08:15:13,762 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:13,763 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:13,992 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:13,899 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:14,000 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:14,000 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:14,021 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:15:13,993 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:14,214 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> 2024-07-31 08:15:14,244 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> # 03:15:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:15 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:15 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:16.807Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:16 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:20.974Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:20 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> 2024-07-31 08:15:14,439 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> [  140.437044] ntputils[1971]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  140.464932] ntputils[1971]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  140.465037] ntputils[1971]:  topic reg for:"}
{"timestamp_utc": "2024-07-31T08:15:20.975Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  140.465123] ntputils[1971]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  140.465210] ntputils[1971]: registration socket.send OK <NL> 2024-07-31 08:15:14,538 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:14,621 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:14,621 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:14,622 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:14,622 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:14,622 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> 2024-07-31 08:15:14,594 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:15:14,624 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:15:14,702 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  140.590877] ntputils[1971]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  140.783604] ntputils[1971]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  140.784619] ntputils[1971]:  topic reg for: <NL> [  140.785096] ntputils[1971]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  140.785886] ntputils[1971]: registration socket.send OK <NL> [  140.803574] ntputils[1971]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  140.897102] ntputils[1971]: void NTPServer::check_ntp_enabled() <NL> [  140.897919] ntputils[1971]: check_ntp_enabled not empty <NL> [  140.898644] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  140.899418] ntputils[1971]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  140.992970] ntputils[1971]: child pid is 2171 <NL> [  141.114184] ntputils[1971]: exited, status is 0 <NL> [  141.121255] ntputils[1971]: check_ntp_enabled skip system script_start <NL> [  141.144953] ntputils[1971]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  141.170525] ntputils[1971]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  141.236222] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  141.436360] ntputils[1971]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  141.532235] ntputils[1971]: child pid is 2173 <NL> [  141.532335] ntputils[1971]: exited, status is 0 <NL> [  141.532425] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  141.532494] ntputils[1971]: systemctl --no-block stop ntpd <NL> [  141.532566] ntputils[1971]: child pid is 2183 <NL> [  141.577899] ntputils[1971]: exited, status is 0 <NL> [  141.747446] ntputils[1971]: call delete_all_external_servers <NL> [  141.747555] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  141.747627] ntputils[1971]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> 2024-07-31 08:15:15,722 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  141.747700] ntputils[1971]: child pid is 2184 <NL> 2024-07-31 08:15:15,723 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:15,722 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:15,723 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  141.748598] ntputils[2184]: remove_all_ext_src <NL> [  141.748681] ntputils[2184]: delete: <NL> [  141.870583] ntputils[1971]: exited, status is 0 <NL> [  142.052274] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  142.052382] ntputils[1971]: /bin/systemctl reset-failed ntpd <NL> [  142.052492] ntputils[1971]: child pid is 2188 <NL> [  142.052578] ntputils[1971]: exited, status is 0 <NL> [  142.053204] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  142.053293] ntputils[1971]: systemctl --no-block start ntpd <NL> [  142.053376] ntputils[1971]: child pid is 2189 <NL> [  142.231660] ntputils[1971]: exited, status is 0 <NL> [  142.231862] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  142.507437] ntputils[1971]: /bin/systemctl reset-failed init_state_check.timer <NL> [  142.598713] ntputils[1971]: child pid is 2196 <NL> [  142.601750] ntputils[1971]: exited, status is 0 <NL> [  142.623407] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  142.669373] ntputils[1971]: /bin/systemctl --no-block start init_state_check.timer <NL> [  142.669468] ntputils[1971]: child pid is 2200 <NL> [  142.669542] ntputils[1971]: exited, status is 0 <NL> [  142.669612] ntputils[1971]: server.InitDaemon <NL> [  142.669708] ntputils[1971]: int NTPServer::platformdds_listen() <NL> [  142.669784] ntputils[1971]: void NTPServer::poller() <NL> [  142.669869] ntputils[1971]: void NTPServer::late_joiner() <NL> [  143.519434] ntputils[1971]: bool NTPServer::handle_command(const string&) <NL> [  143.520360] ntputils[1971]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  143.521249] ntputils[1971]: got Platform::RedundancyMode: UNKNOWN <NL> [  143.575269] ntputils[1971]: got Platform::RedundancyStatus: STANDALONE <NL> [  143.575364] ntputils[1971]: my current red mode is: UNKNOWN <NL> [  143.575438] ntputils[1971]: new red mode is: UNKNOWN <NL> [  143.575510] ntputils[1971]: my current red status is: active <NL> [  143.575582] ntputils[1971]: new red status is: STANDALONE <NL> [  143.575654] ntputils[1971]: received unknown! <NL> [  143.575727] ntputils[1971]: new red mode is: UNKNOWN <NL> [  143.575816] ntputils[1971]: new red status is: STANDALONE <NL> [  143.575905] ntputils[1971]: red status change, update active => STANDALONE <NL> [  143.575976] ntputils[1971]: no active/not-active status change: 0 <NL> 2024-07-31 08:15:19,479 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:19,479 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:19,479 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:15:19,480 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:15:19,480 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:19,481 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:19,482 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE"}
{"timestamp_utc": "2024-07-31T08:15:20.976Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "2024-07-31 08:15:19,490 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:19,607 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:19,607 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:19,504 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:19,617 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:19,570 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> # 03:15:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:20 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:21.903Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:21 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:22.829Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "2024-07-31 08:15:19,649 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:19,649 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  146.023166] ntp_oper_data.py[1973]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  146.023444] ntp_oper_data.py[1973]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  146.049245] ntp_oper_data.py[1973]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096')"}
{"timestamp_utc": "2024-07-31T08:15:22.830Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  146.049336] ntp_oper_data.py[1973]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  146.105583] usb_script_handler.py[2001]: usb: INFO - usb_base.disable_if_not_ha_mode[323] Disabling USB SSW: ha_mode != USB. <NL> [  146.105775] usb_script_handler.py[2001]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  146.105880] usb_script_handler.py[2001]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> [  146.347594] ntputils[1971]: bool NTPServer::handle_command(const string&) <NL> [  146.347775] ntputils[1971]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  146.347865] ntputils[1971]: got Platform::RedundancyMode: UNKNOWN <NL> [  146.347967] ntputils[1971]: got Platform::RedundancyStatus: STANDALONE <NL> [  146.348091] ntputils[1971]: my current red mode is: UNKNOWN <NL> [  146.348171] ntputils[1971]: new red mode is: UNKNOWN <NL> [  146.348280] ntputils[1971]: my current red status is: STANDALONE <NL> [  146.348370] ntputils[1971]: new red status is: STANDALONE <NL> [  146.348438] ntputils[1971]: received unknown! <NL> [  146.348558] ntputils[1971]: new red mode is: UNKNOWN <NL> [  146.348634] ntputils[1971]: new red status is: STANDALONE <NL> [  146.348711] ntputils[1971]: no active/not-active status change: 0 <NL> 2024-07-31 08:15:20,650 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:20,671 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:20,672 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:20,672 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:20,673 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:15:20,673 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:20,674 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:20,674 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:20,771 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:15:20,716 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:20,784 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:20,785 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:20,785 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:20,785 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:20,786 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:20,809 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> [  146.844649] fujitsu-check-ssh-host-key.pl[2283]: Checking system account status... <NL> [  147.048635] fujitsu-check-ssh-host-key.pl[2283]: System account found... <NL> [  147.049376] ntp_oper_data.py[1973]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  147.049476] ntp_oper_data.py[1973]: INFO:root:redundancy status now set to standalone <NL> [  147.049600] ntp_oper_data.py[1973]: INFO:root:Received redundancy topic <NL> [  147.049689] ntp_oper_data.py[1973]: INFO:root:Redundancy status is standalone <NL> [  147.114101] fujitsu-check-ssh-host-key.pl[2283]: 3004 <NL> 2024-07-31 08:15:21,149 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:21,150 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  147.241195] fujitsu-check-ssh-host-key.pl[2283]: /bin/bash <NL> [  147.241398] fujitsu-check-ssh-host-key.pl[2283]: /home/system exists <NL> [  147.241476] fujitsu-check-ssh-host-key.pl[2283]: Checking for trib... <NL> [  147.241885] fujitsu-check-ssh-host-key.pl[2283]: Checking for PIU ... <NL> 2024-07-31 08:15:21,234 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:21,235 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:21,235 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:21,239 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:21,242 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:15:21,242 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:15:21,242 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:21,243 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:21,244 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:21,279 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:21,289 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:21,310 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:21,385 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:15:21,402 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:15:21,402 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:21,403 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:21,403 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  147.451989] fujitsu-check-ssh-host-key.pl[2283]: slot number (0) is not a PIU. <NL> [  147.452160] fujitsu-check-ssh-host-key.pl[2283]: Trib check done. <NL> 2024-07-31 08:15:21,441 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:15:21,635 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present"}
{"timestamp_utc": "2024-07-31T08:15:25.350Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:25 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:26.741Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:26.742Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:26 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:27.672Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "2024-07-31 08:15:21,628 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:15:21,659 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:15:21,660 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:21,661 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:21,816 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:21,817 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:21,817 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:21,833 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:21,834 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:21,834 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:21,834 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:21,834 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:21,855 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:21,931 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:21,931 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:21,932 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:15:21,932 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:21,932 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": {"}
{"timestamp_utc": "2024-07-31T08:15:27.673Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "\"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> 2024-07-31 08:15:21,933 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:21,933 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:21,933 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:21,933 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: RESET -> READY_STATE -> reset_fn -> WAIT_STATE <NL> 2024-07-31 08:15:21,971 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:22,152 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount  --script  --base /mnt/secondary/var/shared --algorithm longest-match L1-OTSG2.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  148.442300] startup[2322]: Startup, World! <NL> [  148.442512] startup[2322]: Cmd arg set to loop 1 <NL> 2024-07-31 08:15:22,772 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:22,772 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:22,946 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:22,946 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:22,971 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:23,010 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:23,193 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:23,194 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:23,194 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:23,196 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:23,196 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:23,196 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:23,197 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:23,197 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:23,303 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:23,437 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:23,458 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:23,534 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:23,574 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:23,482 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:23,591 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:23,764 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:23,772 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  150.191644] ains_manager[2318]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  151.433401] startup_finished.py[2316]: *****Startup Finished Monitor:Starting the event loop***** <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> ERROR:root:empty repository"}
{"timestamp_utc": "2024-07-31T08:15:30.945Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:30 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:31.874Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:31 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:32.438Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  127.796663] fujitsu-check-ssh-host-key.pl[1990]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  127.877904] fujitsu-check-ssh-host-key.pl[1991]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  127.878168] fujitsu-check-ssh-host-key.pl[1991]: /dev/root       2.2G  1.8G  311M  86% / <NL> [  128.098131] fujitsu-check-ssh-host-key.pl[1994]: useradd: user 'fujitsu' already exists <NL> [  128.691961] fujitsu-check-ssh-host-key.pl[1941]: DDS Peristency is enabled <NL> [  128.703593] fujitsu-check-ssh-host-key.pl[1941]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  128.717354] fujitsu-check-ssh-host-key.pl[1941]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  128.722908] fujitsu-check-ssh-host-key.pl[1941]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  128.724113] fujitsu-check-ssh-host-key.pl[1941]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  128.725151] fujitsu-check-ssh-host-key.pl[1941]: Factory user shell set to /bin/bash <NL> [  129.021559] fujitsu-check-ssh-host-key.pl[1918]: Converting fujitsu user to bash shell... <NL> [  129.023094] fujitsu-check-ssh-host-key.pl[2006]: usermod: no changes <NL> [  129.057411] fujitsu-check-ssh-host-key.pl[1918]: Lock Root account in TRIB... <NL> [  129.089089] fujitsu-check-ssh-host-key.pl[2007]: Running lock on root account... <NL> [  129.170098] fujitsu-check-ssh-host-key.pl[2008]: passwd: password changed. <NL> [  129.171195] fujitsu-check-ssh-host-key.pl[1918]: Trib check done. <NL> [  129.684195] startup[2020]: Startup, World! <NL> [  129.723405] startup[2020]: Cmd arg set to loop 1 <NL> [  130.862734] ains_manager[2017]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  130.963768] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  130.964925] ntputils_client.py[1689]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  130.999570] ntputils_client.py[1689]: b'31 Jul 08:15:05 ntpdate[1844]: no server suitable for synchronization found\\n' <NL> [  131.171586] startup_finished.py[2016]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  132.693194] dhal_sim_startup.sh[2073]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  133.797399] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  133.246139] confd_mgr_action_server[2062]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 2 <NL> [  134.145907] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  133.461852] sh[2091]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  133.489134] sh[2091]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  135.901382] zebra[2089]: 2024/07/31 08:15:10 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  136.290504] startup_finished.py[2016]: Startup Finished: systemd state is non-Production mode and running <NL> [  136.441151] startup_finished.py[2016]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  138.047390] startup_finished.py[2016]: *****Startup Finished: stopping EOW timer***** <NL> [  138.492647] startup_finished.py[2016]: systemctl stop startup_finished_limit.timer <NL> 2024-07-31 08:15:14,683 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  144.444696] ains_manager[2257]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  146.574541] layer1_control_layer[2075]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  153.596597] layer1_control_layer[2075]: DIP entity prov dump <NL> [  154.187326] python3[2191]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  154.256101] python3[2191]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  154.286385] python3[2191]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  154.287159] python3[2191]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  154.288024] python3[2191]: max_slotNumber=5 <NL> [  154.328107] layer1_control_layer[2075]: EsalConfig::EsalConfig main 0 <NL> [  154.392992] layer1_control_layer[2075]: EsalConfig::EsalConfig trib 1 <NL> [  154.393830] layer1_control_layer[2075]: EsalConfig::EsalConfig ciRole 0 <NL> [  154.394845] layer1_control_layer[2075]: EsalConfig is not running inside container. <NL> [  154.499101] layer1_control_layer[2075]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.535144] layer1_control_layer[2075]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.557778] layer1_control_layer[2075]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.783549] layer1_control_layer[2075]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.805779] layer1_control_layer[2075]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  154.826784] layer1_control_layer[2075]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  154.846704] layer1_control_layer[2075]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  154.862978] layer1_control_layer[2075]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  154.880094] layer1_control_layer[2075]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  154.984464] layer1_control_layer[2075]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  155.039409] layer1_control_layer[2075]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  155.044451] layer1_control_layer[2075]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  155.045692] layer1_control_layer[2075]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  155.059435] layer1_control_layer[2075]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  155.115257] layer1_control_layer[2075]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  155.116289] layer1_control_layer[2075]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  155.117485] layer1_control_layer[2075]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> 2024-07-31 08:15:31,183 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:31,204 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:31,314 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:31,344 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True"}
{"timestamp_utc": "2024-07-31T08:15:32.439Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:15:31,449 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":2} <NL> 2024-07-31 08:15:31,491 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:31,632 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:31,678 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:15:31,648 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> [  157.201530] ntputils_client.py[1689]: INFO:root:command failed. <NL> 2024-07-31 08:15:31,830 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:15:31,832 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:31,832 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:31,834 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> [  157.240506] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:15:34.334Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[   79.137957] serialportMon[1023]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   79.249987] sh[1055]: In startMstpInt <NL> [   80.491867] sh[1055]: startMstpInt: IntRstpEnableCheck.py returns true, starting mstpd-int <NL> [   80.825106] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   80.846908] NFSD: Using legacy client tracking operations. <NL> [   80.847853] NFSD: starting 90-second grace period (net f0000098) <NL> [   82.837529] br.rstp_int: port 1(istp1) entered blocking state <NL> [   82.838621] br.rstp_int: port 1(istp1) entered disabled state <NL> [   82.844500] device istp1 entered promiscuous mode <NL> 2024-07-31 08:14:20,191 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:22,200 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:22,277 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:22,315 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> 2024-07-31 08:14:22,328 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:14:22,358 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:22,359 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> [   93.617773] vsftpd_listen_address[1026]: listen_address=127.1.254.254 <NL> [   95.007518] br.rstp_int: port 2(istp2) entered blocking state <NL> [   95.008378] br.rstp_int: port 2(istp2) entered disabled state <NL> [   95.009607] device istp2 entered promiscuous mode <NL> [  147.901940] dcn_dns_controller[1601]:  WaitForActive <NL> [  148.268667] dcn_ka[1603]:  WaitForActive <NL> [  153.076172] ntputils[1975]: int ntputils_main(int, char**)Starting ntputils <NL> [  153.076404] ntputils[1975]: Running as a daemon <NL> [  153.076528] ntputils[1975]: shelf role is: MAIN <NL> [  153.076610] ntputils[1975]: slot number is: 0 <NL> [  153.076694] ntputils[1975]: slot role is: UNKNOWN <NL> [  153.076765] ntputils[1975]: redundancy_mode: UNKNOWN <NL> [  153.076874] ntputils[1975]: Executing on a work blade <NL> [  153.076945] ntputils[1975]: ================================ <NL> [  153.143636] ntputils[1975]: shelf_role is: MAIN <NL> [  153.298957] ntputils[1975]: redundancy_mode: UNKNOWN <NL> [  153.299081] ntputils[1975]: active_status: active <NL> 2024-07-31 08:15:29,766 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 67 seconds <NL> [  153.444104] ntputils[1975]: ntp_role: act <NL> [  153.711667] ntputils[1975]: ================================ <NL> 2024-07-31 08:15:29,875 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 67 seconds <NL> 2024-07-31 08:15:30,529 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:30,530 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  154.397552] ntputils[1975]: NTPUtilsConfig::do_default_config <NL> [  154.397791] ntputils[1975]: shelf_num/is_client: 0 <NL> [  154.397880] ntputils[1975]: server_ip: 0x5633ff636fc0 <NL> [  154.397955] ntputils[1975]: ip_addr(ilan): 0x5633ff636f80 <NL> [  154.398131] ntputils[1975]: ntp_role act <NL> [  154.398208] ntputils[1975]: shelf_num aka is_client == 0 <NL> [  154.398284] ntputils[1975]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  154.398360] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  154.398442] ntputils[1975]: systemctl --no-block stop ntpd <NL> [  154.398521] ntputils[1975]: child pid is 1991 <NL> [  154.398609] ntputils[1975]: exited, status is 0 <NL> [  154.398702] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  154.398780] ntputils[1975]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  154.398871] ntputils[1975]: child pid is 2011 <NL> 2024-07-31 08:15:30,895 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:31,040 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  154.647534] ntputils[2013]: Changing Stratum and adding restrictions <NL> [  154.919241] ntputils[1975]: exited, status is 0 <NL> [  155.022485] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  155.227803] ntputils[1975]: /bin/systemctl reset-failed ntpd <NL> [  155.227906] ntputils[1975]: child pid is 2025 <NL> [  155.227980] ntputils[1975]: exited, status is 0 <NL> [  155.228115] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  155.228186] ntputils[1975]: systemctl --no-block start ntpd <NL> [  155.228258] ntputils[1975]: child pid is 2028 <NL> [  155.228329] ntputils[1975]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:15:34.335Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  155.228395] ntputils[1975]: server role, server_ip is set to: 127.0.0.1 <NL> [  155.228466] ntputils[1975]: Running in production mode <NL> [  155.228537] ntputils[1975]: InitDaemon redundancy_mode: UNKNOWN <NL> [  155.228643] ntputils[1975]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  155.228756] ntputils[1975]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  155.228833] ntputils[1975]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  155.228909] ntputils[1975]: registration socket.send OK <NL> [  155.362921] rdm[1982]: RdmConfig: file_exist 0 <NL> [  155.363181] rdm[1982]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  155.363311] rdm[1982]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  155.363393] rdm[1982]: start rdm msg hdlr thd <NL> 2024-07-31 08:15:31,448 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:31,831 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:31,832 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:31,832 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:31,832 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:31,832 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> 2024-07-31 08:15:32,224 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:32,224 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:32,251 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> 2024-07-31 08:15:32,704 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:32,820 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:32,976 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:32,977 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:33,157 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated"}
{"timestamp_utc": "2024-07-31T08:15:35.701Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:35 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:35 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:37.069Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:36 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:40.337Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:40 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:40.594Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:40 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:40.851Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:15:33,157 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:15:33,158 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:33,158 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:33,193 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> [  157.421384] ntputils[1975]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  157.421592] ntputils[1975]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  157.421673] ntputils[1975]:  topic reg for: <NL> [  157.421748] ntputils[1975]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  157.421839] ntputils[1975]: registration socket.send OK <NL> 2024-07-31 08:15:33,839 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:33,839 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:33,941 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn -> STANDALONE_EVT <NL> 2024-07-31 08:15:33,941 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> 2024-07-31 08:15:33,941 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:33,998 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  157.607341] ntputils[1975]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  157.607500] ntputils[1975]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  157.607582] ntputils[1975]:  topic reg for: <NL> [  157.607655] ntputils[1975]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  157.607762] ntputils[1975]: registration socket.send OK <NL> 2024-07-31 08:15:34,001 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:34,001 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:34,001 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:34,003 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:15:34,096 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  157.852970] ntputils[1975]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  157.921380] ntputils[1975]: void NTPServer::check_ntp_enabled() <NL> [  157.947100] ntputils[1975]: check_ntp_enabled not empty <NL> [  158.153289] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  158.153405] ntputils[1975]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  158.153612] ntputils[1975]: child pid is 2168 <NL> [  158.153692] ntputils[1975]: exited, status is 0 <NL> [  158.153760] ntputils[1975]: check_ntp_enabled skip system script_start <NL> [  158.153832] ntputils[1975]: int NTPServer::InitDaemon() (1 OK) rc = 1"}
{"timestamp_utc": "2024-07-31T08:15:40.852Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  158.153905] ntputils[1975]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  158.153979] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  158.154085] ntputils[1975]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  158.154159] ntputils[1975]: child pid is 2170 <NL> 2024-07-31 08:15:34,775 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:34,775 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  158.459163] ntputils[1975]: exited, status is 0 <NL> [  158.459373] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  158.459451] ntputils[1975]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:34,852 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:34,852 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  158.528275] ntputils[1975]: child pid is 2184 <NL> [  158.631036] ntputils[1975]: exited, status is 0 <NL> [  158.631242] ntputils[1975]: call delete_all_external_servers <NL> [  158.631340] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  158.631412] ntputils[1975]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  158.631488] ntputils[1975]: child pid is 2190 <NL> [  158.762616] ntputils[2190]: remove_all_ext_src <NL> [  158.899805] ntputils[2190]: delete: <NL> [  158.900096] ntputils[1975]: exited, status is 0 <NL> [  158.900186] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  158.900284] ntputils[1975]: /bin/systemctl reset-failed ntpd <NL> [  159.076431] ntputils[1975]: child pid is 2192 <NL> [  159.329385] ntputils[1975]: exited, status is 0 <NL> [  159.389732] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  159.507924] ntputils[1975]: systemctl --no-block start ntpd <NL> [  159.508122] ntputils[1975]: child pid is 2195 <NL> [  159.508208] ntputils[1975]: exited, status is 0 <NL> [  159.508277] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  159.508347] ntputils[1975]: /bin/systemctl reset-failed init_state_check.timer <NL> [  159.508421] ntputils[1975]: child pid is 2198 <NL> [  159.657208] ntputils[1975]: exited, status is 0 <NL> [  159.657396] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  159.657472] ntputils[1975]: /bin/systemctl --no-block start init_state_check.timer <NL> [  159.680910] ntputils[1975]: child pid is 2199 <NL> [  159.936297] ntputils[1975]: exited, status is 0 <NL> [  159.936534] ntputils[1975]: server.InitDaemon <NL> [  159.936618] ntputils[1975]: int NTPServer::platformdds_listen() <NL> [  159.936694] ntputils[1975]: void NTPServer::late_joiner() <NL> [  160.022238] ntputils[1975]: void NTPServer::poller() <NL> [  161.145851] ntputils[1975]: bool NTPServer::handle_command(const string&) <NL> [  161.166445] ntputils[1975]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  161.166634] ntputils[1975]: got Platform::RedundancyMode: UNKNOWN <NL> [  161.166758] ntputils[1975]: got Platform::RedundancyStatus: STANDALONE <NL> [  161.166841] ntputils[1975]: my current red mode is: UNKNOWN <NL> [  161.166920] ntputils[1975]: new red mode is: UNKNOWN <NL> [  161.167034] ntputils[1975]: my current red status is: active <NL> [  161.167120] ntputils[1975]: new red status is: STANDALONE <NL> [  161.167203] ntputils[1975]: received unknown! <NL> [  161.167270] ntputils[1975]: new red mode is: UNKNOWN <NL> [  161.167347] ntputils[1975]: new red status is: STANDALONE <NL> [  161.167425] ntputils[1975]: red status change, update active => STANDALONE <NL> [  161.167520] ntputils[1975]: no active/not-active status change: 0 <NL> [  162.278732] usb_script_handler.py[1987]: usb: INFO - usb_base.disable_if_not_ha_mode[323] Disabling USB SSW: ha_mode != USB. <NL> 2024-07-31 08:15:38,750 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:38,751 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  162.278934] usb_script_handler.py[1987]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  162.544873] usb_script_handler.py[1987]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> 2024-07-31 08:15:38,753 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:39,070 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  163.335065] ntputils[1975]: bool NTPServer::handle_command(const string&) <NL> [  163.335314] ntputils[1975]: bool NTPServer::handle_redundancy_topic(const string&)"}
{"timestamp_utc": "2024-07-31T08:15:42.220Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:41 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:44.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  163.391351] ntputils[1975]: got Platform::RedundancyMode: UNKNOWN <NL> [  163.430862] ntputils[1975]: got Platform::RedundancyStatus: STANDALONE <NL> [  163.430970] ntputils[1975]: my current red mode is: UNKNOWN <NL> [  163.431081] ntputils[1975]: new red mode is: UNKNOWN <NL> [  163.432623] ntputils[1975]: my current red status is: STANDALONE <NL> [  163.432768] ntputils[1975]: new red status is: STANDALONE <NL> [  163.432854] ntputils[1975]: received unknown! <NL> [  163.432972] ntputils[1975]: new red mode is: UNKNOWN <NL> [  163.433085] ntputils[1975]: new red status is: STANDALONE <NL> [  163.433161] ntputils[1975]: no active/not-active status change: 0 <NL> 2024-07-31 08:15:40,784 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=f9fc, unitName=L1-OTSG2, shelf_id=1, slot_id=0 <NL> 2024-07-31 08:15:40,786 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:15:40,845 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> 2024-07-31 08:15:40,878 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:15:40,880 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:40,974 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:41,012 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:15:41,057 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:15:41,069 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:15:41,074 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:41,097 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:41,125 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:41,166 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:41,138 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:41,235 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  165.096129] fujitsu-check-ssh-host-key.pl[2276]: Checking system account status... <NL> [  165.221302] ntp_oper_data.py[1976]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  165.222701] ntp_oper_data.py[1976]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  165.251525] fujitsu-check-ssh-host-key.pl[2276]: System account found..."}
{"timestamp_utc": "2024-07-31T08:15:44.738Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  165.296189] ntp_oper_data.py[1976]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  165.296403] ntp_oper_data.py[1976]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  165.392611] fujitsu-check-ssh-host-key.pl[2276]: 3004 <NL> [  165.469608] ntp_oper_data.py[1976]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  165.469819] ntp_oper_data.py[1976]: INFO:root:redundancy status now set to standalone <NL> [  165.469952] ntp_oper_data.py[1976]: INFO:root:Received redundancy topic <NL> [  165.470073] ntp_oper_data.py[1976]: INFO:root:Redundancy status is standalone <NL> [  165.575755] fujitsu-check-ssh-host-key.pl[2276]: /bin/bash <NL> [  165.575958] fujitsu-check-ssh-host-key.pl[2276]: /home/system exists <NL> [  165.576070] fujitsu-check-ssh-host-key.pl[2276]: Checking for trib... <NL> [  165.576191] fujitsu-check-ssh-host-key.pl[2276]: Checking for PIU ... <NL> [  165.647490] fujitsu-check-ssh-host-key.pl[2276]: slot number (0) is not a PIU. <NL> [  165.647794] fujitsu-check-ssh-host-key.pl[2276]: Trib check done. <NL> 2024-07-31 08:15:42,252 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:42,273 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:42,375 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:42,489 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:42,579 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:42,515 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:42,633 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:42,636 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:42,645 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:42,645 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:15:42,644 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> 2024-07-31 08:15:42,683 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> 2024-07-31 08:15:42,733 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:42,900 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:42,943 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:15:42,971 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> 2024-07-31 08:15:43,206 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> [  166.866733] startup[2311]: Startup, World! <NL> 2024-07-31 08:15:43,303 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  166.912415] startup[2311]: Cmd arg set to loop 1 <NL> 2024-07-31 08:15:43,336 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:43,400 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:43,575 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:43,576 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:43,576 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:15:43,576 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:15:43,576 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:27,144 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:27,144 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:27,145 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:27,145 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:27,146 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:27,146 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:15:27,147 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:27,267 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  154.542524] dhal_sim_startup.sh[2404]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  155.743581] confd_mgr_action_server[2397]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  155.880628] confd_phase_sentry[2430]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  155.880966] confd_phase_sentry[2430]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  156.779404] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  157.501597] temp_acct_cleanup_app[2450]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  157.501778] temp_acct_cleanup_app[2450]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  159.096936] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  159.369384] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  159.797755] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 1 <NL> [  161.142057] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  161.142242] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  161.142785] ypg_app[2392]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  163.035487] sncp_app[2391]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set."}
{"timestamp_utc": "2024-07-31T08:15:44.739Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  163.152813] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 2 <NL> 2024-07-31 08:15:38,685 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:15:39,377 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:15:39,694 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:39,694 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:39,694 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  165.763659] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 3 <NL> 2024-07-31 08:15:39,811 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:15:39,923 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:15:40,001 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:15:39,822 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> [  165.971524] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  166.270675] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:15:40,372 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:40,372 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:40,372 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:40,372 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:40,373 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:40,467 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:40,467 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:41,364 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:41,498 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:15:41,499 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:41,499 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:41,499 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:41,499 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:41,944 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:41,945 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:41,945 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:42,190 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  168.868489] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 4 <NL> [  170.287205] common_alarm_handler[2385]: gen_util: DDS_P2MP not available <NL> [  170.305367] common_alarm_handler[2385]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  170.330030] common_alarm_handler[2385]: topic = SystemProv; id = 1 <NL> [  170.426248] common_alarm_handler[2385]: topic = WdmcfgProv; id = 2 <NL> [  170.439153] common_alarm_handler[2385]: topic = LicenseStatusTopic; id = 3 <NL> [  170.439248] common_alarm_handler[2385]: topic = ShelfProv; id = 5"}
{"timestamp_utc": "2024-07-31T08:15:45.299Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:15:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:15:45.556Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:45 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:46.923Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:15:43,644 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:43,657 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:43,658 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:15:43,772 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:15:43,772 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:15:43,772 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:43,773 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:43,700 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:43,859 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:43,860 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:43,861 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:43,862 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:15:43,981 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:15:43,982 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:43,982 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:43,982 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:43,983 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:15:43,983 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:15:43,984 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:43,986 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:43,986 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:44,100 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:15:44,116 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:15:44,117 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:44,117 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:44,118 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:44,119 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:44,119 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:15:44,120 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:44,120 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> 2024-07-31 08:15:44,189 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:15:44,197 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:15:44,253 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:15:44,253 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: RESET -> READY_STATE -> reset_fn -> WAIT_STATE <NL> 2024-07-31 08:15:44,230 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:15:44,394 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount  --script  --base /mnt/secondary/var/shared --algorithm longest-match L1-OTSG2.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  168.251467] ains_manager[2306]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:15:45,259 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:15:45,260 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:45,260 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:45,261 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:15:45,261 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:45,262 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:15:45,379 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:45,422 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:45,424 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:45,508 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:15:45,509 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:15:45,509 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,602 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:45,704 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:45,704 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:15:45,862 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:45,898 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:46,003 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> # 03:15:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:46 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:47.180Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  170.439378] common_alarm_handler[2385]: topic = SlotProv; id = 6 <NL> [  170.439451] common_alarm_handler[2385]: topic = PortProv; id = 7 <NL> [  170.487167] common_alarm_handler[2385]: topic = SubportProv; id = 8 <NL> [  170.487256] common_alarm_handler[2385]: topic = FconProv; id = 9 <NL> [  170.487328] common_alarm_handler[2385]: topic = XconProv; id = 10 <NL> [  170.487416] common_alarm_handler[2385]: topic = OchProv; id = 11 <NL> [  170.487487] common_alarm_handler[2385]: topic = OmsProv; id = 12 <NL> [  170.487577] common_alarm_handler[2385]: topic = OtsProv; id = 13 <NL> [  170.487691] common_alarm_handler[2385]: topic = EthernetProv; id = 14 <NL> [  170.487769] common_alarm_handler[2385]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  170.487867] common_alarm_handler[2385]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  170.487955] common_alarm_handler[2385]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  170.488060] common_alarm_handler[2385]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  170.488140] common_alarm_handler[2385]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  170.488222] common_alarm_handler[2385]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  170.488295] common_alarm_handler[2385]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  170.488373] common_alarm_handler[2385]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  170.488446] common_alarm_handler[2385]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  170.488519] common_alarm_handler[2385]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  170.488593] common_alarm_handler[2385]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  170.488690] common_alarm_handler[2385]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  170.488770] common_alarm_handler[2385]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  170.488851] common_alarm_handler[2385]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  170.488960] common_alarm_handler[2385]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  170.916121] common_alarm_handler[2385]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  170.916267] common_alarm_handler[2385]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  170.916346] common_alarm_handler[2385]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  170.916473] common_alarm_handler[2385]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  170.916547] common_alarm_handler[2385]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  170.916625] common_alarm_handler[2385]: topic = AlarmNotification; id = 40"}
{"timestamp_utc": "2024-07-31T08:15:47.181Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  170.916697] common_alarm_handler[2385]: topic = GenericOperInfoReq; id = 41 <NL> [  170.916768] common_alarm_handler[2385]: topic = PmRtrvReq; id = 42 <NL> [  170.916854] common_alarm_handler[2385]: topic = PmRtrvResp; id = 43 <NL> [  170.916927] common_alarm_handler[2385]: topic = PmInitReq; id = 44 <NL> [  170.917079] common_alarm_handler[2385]: topic = PmOperData; id = 45 <NL> [  170.917165] common_alarm_handler[2385]: topic = StateChange; id = 46 <NL> [  170.917246] common_alarm_handler[2385]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  170.917321] common_alarm_handler[2385]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  170.917400] common_alarm_handler[2385]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> [  170.917482] common_alarm_handler[2385]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  170.917570] common_alarm_handler[2385]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  170.917644] common_alarm_handler[2385]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  170.973847] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  171.191281] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  171.191520] common_alarm_handler[2385]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  171.191619] common_alarm_handler[2385]: topic = EthIfProv; id = 56 <NL> [  171.327790] common_alarm_handler[2385]: topic = DcnNat64Attributes; id = 57 <NL> [  171.328138] common_alarm_handler[2385]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  171.328291] common_alarm_handler[2385]: topic = LldpGlobalCfgProv; id = 59 <NL> [  171.328400] common_alarm_handler[2385]: topic = LldpPortCfgProv; id = 60 <NL> [  171.328506] common_alarm_handler[2385]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  171.328610] common_alarm_handler[2385]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  171.328744] common_alarm_handler[2385]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  171.328859] common_alarm_handler[2385]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  171.328962] common_alarm_handler[2385]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  171.329115] common_alarm_handler[2385]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  171.329222] common_alarm_handler[2385]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  171.329324] common_alarm_handler[2385]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  171.329424] common_alarm_handler[2385]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  171.329506] common_alarm_handler[2385]: topic = DcnPppAttributesProv; id = 70 <NL> [  171.329584] common_alarm_handler[2385]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  171.329658] common_alarm_handler[2385]: topic = LldpBladeCfgProv; id = 72 <NL> [  171.329735] common_alarm_handler[2385]: topic = LldpPortInstCfgProv; id = 73 <NL> [  171.329848] common_alarm_handler[2385]: topic = DcnGreTunnelProv; id = 74 <NL> [  171.330146] common_alarm_handler[2385]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  171.330225] common_alarm_handler[2385]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  171.330298] common_alarm_handler[2385]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  171.330373] common_alarm_handler[2385]: topic = SysGnmiCertProv; id = 78 <NL> [  171.330456] common_alarm_handler[2385]: topic = IetfInterfaceProv; id = 79 <NL> [  171.330535] common_alarm_handler[2385]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  171.330610] common_alarm_handler[2385]: topic = SystemAutoLogoffProv; id = 81 <NL> [  171.330696] common_alarm_handler[2385]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  171.330785] common_alarm_handler[2385]: topic = SystemPortsProv; id = 83 <NL> [  171.330871] common_alarm_handler[2385]: topic = OspfProvisioningModeProv; id = 84 <NL> [  171.330948] common_alarm_handler[2385]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  171.390135] common_alarm_handler[2385]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  171.803293] common_alarm_handler[2385]: topic = BasicGroupProv; id = 87 <NL> [  171.803413] common_alarm_handler[2385]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  171.803516] common_alarm_handler[2385]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  171.803628] common_alarm_handler[2385]: topic = SystemFipsProv; id = 90 <NL> [  171.803717] common_alarm_handler[2385]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  171.803802] common_alarm_handler[2385]: topic = SecuritySystemwideProv; id = 92 <NL> [  172.244661] common_alarm_handler[2385]: topic = DataEncryptionProv; id = 93 <NL> [  172.245636] common_alarm_handler[2385]: topic = SystemServicesProv; id = 94 <NL> [  172.246519] common_alarm_handler[2385]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  172.247495] common_alarm_handler[2385]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  172.387547] common_alarm_handler[2385]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  172.388422] common_alarm_handler[2385]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  172.389414] common_alarm_handler[2385]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  172.469713] common_alarm_handler[2385]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  172.477884] common_alarm_handler[2385]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  172.604540] common_alarm_handler[2385]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  172.609513] common_alarm_handler[2385]: topic = FscProv; id = 111"}
{"timestamp_utc": "2024-07-31T08:15:49.069Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   73.604214] change_esal_priority.sh[882]: Comms did not change any esal thread priorities[   75.096613] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   76.231597] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   77.980883] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   77.982159] NFSD: Using legacy client tracking operations."}
{"timestamp_utc": "2024-07-31T08:15:49.070Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[   78.092120] NFSD: starting 90-second grace period (net f0000098) <NL> [   78.827345] serialportMon[1166]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   91.911544] vsftpd_listen_address[1169]: listen_address=127.1.254.254 <NL> 2024-07-31 08:14:27,193 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:29,529 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:29,597 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:29,621 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:29,643 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:29,657 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> 2024-07-31 08:14:29,677 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  102.752210] hrtimer: interrupt took 174609 ns <NL> [  123.741927] dcn_ka[1368]:  WaitForActive <NL> [  130.434117] dcn_dns_controller[1366]:  WaitForActive <NL> 2024-07-31 08:15:14,242 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 44 seconds <NL> 2024-07-31 08:15:14,822 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 44 seconds <NL> 2024-07-31 08:15:15,122 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  142.069781] ntputils[1725]: int ntputils_main(int, char**)Starting ntputils <NL> 2024-07-31 08:15:18,306 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:19,057 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  146.107402] ntputils[1725]: Running as a daemon <NL> 2024-07-31 08:15:21,013 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  147.568705] ntputils[1725]: shelf role is: MAIN <NL> [  148.286078] ntputils[1725]: slot number is: 0 <NL> [  148.602338] ntputils[1725]: slot role is: UNKNOWN <NL> [  149.611830] ntputils[1725]: redundancy_mode: UNKNOWN <NL> 2024-07-31 08:15:24,377 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:25,118 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> [  151.752439] ntputils[1725]: Executing on a work blade <NL> 2024-07-31 08:15:26,441 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:15:26,767 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  154.000784] ntputils[1725]: ================================ <NL> 2024-07-31 08:15:28,527 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:29,782 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn <NL> [  156.135950] ntputils[1725]: shelf_role is: MAIN <NL> [  157.159097] ntputils[1725]: redundancy_mode: UNKNOWN <NL> [  157.287370] ntputils[1725]: active_status: active <NL> [  157.306824] ntputils[1725]: ntp_role: act <NL> [  159.685248] ntputils[1725]: ================================ <NL> 2024-07-31 08:15:33,659 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> [  160.451208] standby_filesync[1384]: DipLog_pimpl destructor called <NL> [  161.098516] standby_filesync[1384]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:34,777 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn <NL> [  161.237718] standby_filesync[1384]:     ret='Context was terminated <NL> [  162.383662] standby_filesync[1384]: deleting subscriber_ socket <NL> [  162.391322] standby_filesync[1384]: Exiting verb listener <NL> [  162.812020] ntputils[1725]: NTPUtilsConfig::do_default_config <NL> [  163.221548] ntputils[1725]: shelf_num/is_client: 0 <NL> [  163.235183] ntputils[1725]: server_ip: 0x55ee17c6efc0 <NL> [  163.242098] ntputils[1725]: ip_addr(ilan): 0x55ee17c6ef80 <NL> [  163.611658] ntputils[1725]: ntp_role act <NL> [  163.815803] ntputils[1725]: shelf_num aka is_client == 0 <NL> [  164.283259] ntputils[1725]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:37,568 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:37,595 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  164.892226] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:15:39,095 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> [  165.564258] ntputils[1725]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:39,198 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> 2024-07-31 08:15:39,752 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  166.156229] ntputils[1725]: child pid is 1746 <NL> [  168.126136] ntputils[1725]: exited, status is 0 <NL> [  168.150072] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  168.151782] ntputils[1725]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:41,251 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:41,359 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  168.514744] ntputils[1725]: child pid is 1772 <NL> 2024-07-31 08:15:43,352 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> 2024-07-31 08:15:45,394 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  171.785158] ops-redundancy-mgr[1379]: DipLog_pimpl destructor called <NL> 2024-07-31 08:15:43,857 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:46,183 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> [  172.747100] ops-redundancy-mgr[1379]: DipVerbosity Listener ZMQ error <NL> [  173.883468] ops-redundancy-mgr[1379]:     ret='Context was terminated"}
{"timestamp_utc": "2024-07-31T08:15:49.997Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  127.797952] fujitsu-check-ssh-host-key.pl[2000]: useradd: user 'fujitsu' already exists <NL> [  128.395264] fujitsu-check-ssh-host-key.pl[1935]: DDS Peristency is enabled <NL> [  128.478497] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  128.478631] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  128.478728] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  128.478803] fujitsu-check-ssh-host-key.pl[1935]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  128.478874] fujitsu-check-ssh-host-key.pl[1935]: Factory user shell set to /bin/bash <NL> [  128.523704] fujitsu-check-ssh-host-key.pl[1921]: Converting fujitsu user to bash shell... <NL> [  128.566588] fujitsu-check-ssh-host-key.pl[2017]: usermod: no changes <NL> [  128.613238] fujitsu-check-ssh-host-key.pl[1921]: Lock Root account in TRIB... <NL> [  128.621751] fujitsu-check-ssh-host-key.pl[2018]: Running lock on root account... <NL> [  128.703425] fujitsu-check-ssh-host-key.pl[2019]: passwd: password changed. <NL> [  128.715346] fujitsu-check-ssh-host-key.pl[1921]: Trib check done. <NL> [  129.088676] startup[2031]: Startup, World! <NL> [  129.088955] startup[2031]: Cmd arg set to loop 1 <NL> [  129.934456] ains_manager[2028]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  130.398634] startup_finished.py[2027]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  131.018246] dhal_sim_startup.sh[2068]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  132.175251] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  132.024876] confd_mgr_action_server[2061]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 2[  132.412244] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured"}
{"timestamp_utc": "2024-07-31T08:15:49.998Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  132.397891] sh[2096]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  132.683635] sh[2096]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  133.809690] zebra[2095]: 2024/07/31 08:15:06 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  135.149469] startup_finished.py[2027]: Startup Finished: systemd state is non-Production mode and running <NL> [  135.149657] startup_finished.py[2027]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  135.574033] startup_finished.py[2027]: *****Startup Finished: stopping EOW timer***** <NL> [  136.303877] startup_finished.py[2027]: systemctl stop startup_finished_limit.timer <NL> [  145.659501] layer1_control_layer[2080]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  146.161648] ains_manager[2298]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  151.511518] layer1_control_layer[2080]: DIP entity prov dump <NL> [  151.796401] layer1_control_layer[2080]: EsalConfig::EsalConfig main 0 <NL> [  151.815340] layer1_control_layer[2080]: EsalConfig::EsalConfig trib 1 <NL> [  151.815521] layer1_control_layer[2080]: EsalConfig::EsalConfig ciRole 0 <NL> [  151.815608] layer1_control_layer[2080]: EsalConfig is not running inside container. <NL> [  151.815774] layer1_control_layer[2080]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  151.815979] layer1_control_layer[2080]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  151.816127] layer1_control_layer[2080]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  151.816885] layer1_control_layer[2080]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  151.816989] layer1_control_layer[2080]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  151.817157] layer1_control_layer[2080]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  151.817239] layer1_control_layer[2080]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  151.817311] layer1_control_layer[2080]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  151.817392] layer1_control_layer[2080]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  151.818735] layer1_control_layer[2080]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  151.818817] layer1_control_layer[2080]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  151.818889] layer1_control_layer[2080]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  151.818960] layer1_control_layer[2080]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  151.819063] layer1_control_layer[2080]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  151.819134] layer1_control_layer[2080]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  151.846726] layer1_control_layer[2080]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  151.846853] layer1_control_layer[2080]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  153.552918] python3[2209]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  153.553375] python3[2209]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  153.553487] python3[2209]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  153.553567] python3[2209]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  153.553650] python3[2209]: max_slotNumber=5 <NL> 2024-07-31 08:15:33,688 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=2 <NL> [  164.354924] python3[2429]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  164.355205] python3[2429]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  164.355314] python3[2429]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  164.355393] python3[2429]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  164.355477] python3[2429]: max_slotNumber=5 <NL> [  164.355552] python3[2429]:  prov channel is 127.0.0.1:10000 <NL> [  164.355632] python3[2429]: success: command executed <NL> [  164.741585] layer1_hal[2103]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  164.813315] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2371 <NL> 2024-07-31 08:15:48,848 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:15:48,850 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:48,902 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:15:48,927 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:15:48,928 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":2} <NL> 2024-07-31 08:15:48,964 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:15:48,970 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:15:48,972 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:48,994 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:49,030 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:15:48,946 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:15:49,199 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:15:49,200 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":2}"}
{"timestamp_utc": "2024-07-31T08:15:50.560Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:15:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:50 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:51.121Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[   74.324150] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   74.345434] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   74.375296] device lwap-peer entered promiscuous mode <NL> [   74.733252] br-lwap: port 1(eth6.3802) entered blocking state <NL> [   74.751287] br-lwap: port 1(eth6.3802) entered forwarding state <NL> [   74.850033] br-lwap: port 2(lwap-peer) entered blocking state <NL> [   74.869035] br-lwap: port 2(lwap-peer) entered forwarding state <NL> [   74.901771] br-lwap: port 2(lwap-peer) entered disabled state <NL> [   74.854052] commsdriver[539]: DEBUG: change_linkstate Marking lwap down for 15 <NL> [   74.935803] commsdriver[539]: DEBUG: change_linkstate_peer Marking lwap down for 15 <NL> [   75.816860] commsdriver[539]: DEBUG: change_linkstate Marking eth5.1000 down for 220 <NL> [   75.897694] commsdriver[874]: Actual changes: <NL> [   75.918565] commsdriver[874]: tx-checksum-ip-generic: off <NL> [   75.944197] commsdriver[874]: tx-tcp-segmentation: off [not requested] <NL> [   75.955387] commsdriver[874]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   75.992722] commsdriver[874]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   76.012262] commsdriver[874]: tx-tcp6-segmentation: off [not requested] <NL> [   76.346379] commsdriver[539]: DEBUG: change_linkstate Marking eth5.1001 down for 221 <NL> [   76.407289] commsdriver[886]: Actual changes: <NL> [   76.451462] commsdriver[886]: tx-checksum-ip-generic: off <NL> [   76.461095] commsdriver[886]: tx-tcp-segmentation: off [not requested] <NL> [   76.619578] commsdriver[886]: tx-tcp-ecn-segmentation: off [not requested] <NL> [   76.719193] commsdriver[886]: tx-tcp-mangleid-segmentation: off [not requested] <NL> [   76.926335] commsdriver[886]: tx-tcp6-segmentation: off [not requested] <NL> [   77.030082] commsready[889]: callback: Entry PID=0x379 signo(15) <NL> [   77.287336] change_esal_priority.sh[893]: Comms check for and selectively change esal priorities <NL> [   78.283077] e1000: eth5 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX <NL> [   78.366045] IPv6: ADDRCONF(NETDEV_CHANGE): eth5.1001: link becomes ready <NL> [   79.065790] change_esal_priority.sh[893]: Comms did not change any esal thread priorities <NL> [   86.197268] serialportMon[1164]: IO Exception while reading file: /etc/fos2/platform/default/serialportmonitor.cfg <NL> [   87.149412] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory <NL> [   87.870858] NFSD: Using legacy client tracking operations. <NL> [   87.871603] NFSD: starting 90-second grace period (net f0000098) <NL> 2024-07-31 08:14:33,194 remote-file-info: INFO - remote_file_info_server.run[266] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/remote-file-info/config/common.yaml <NL> (priority[1]): /usr/share/remote-file-info/config/qemu.yaml <NL> 2024-07-31 08:14:35,127 swdllite(agt): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=local_agent, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:35,183 swdllite(agt): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:35,219 swdllite(agt): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.local_agent.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> 2024-07-31 08:14:35,249 swdllite(mgr): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=main, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:14:35,305 swdllite(mgr): INFO - swdllited_base.run[457] redundancy_mode=working <NL> 2024-07-31 08:14:35,315 swdllite(mgr): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.main.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [   99.839822] vsftpd_listen_address[1197]: listen_address=127.1.254.254 <NL> [  134.415819] dcn_dns_controller[1387]:  WaitForActive <NL> [  138.804363] dcn_ka[1389]:  WaitForActive <NL> 2024-07-31 08:15:27,203 swdllite(agt): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 51 seconds <NL> 2024-07-31 08:15:27,740 swdllite(mgr): INFO - swdllited_base_utils.wait_for_unblock[447] startup unblocked after 50 seconds <NL> [  152.643963] ops-redundancy-mgr[1397]: DipLog_pimpl destructor called <NL> [  153.112371] ops-redundancy-mgr[1397]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:29,303 swdllite(mgr): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> [  153.902872] ops-redundancy-mgr[1397]:     ret='Context was terminated <NL> 2024-07-31 08:15:30,204 swdllite(agt): ERROR - swdllited_base_utils.get_hostname[243] error reading hostname from /var/potes-persist-restart/etc/hostname <NL> 2024-07-31 08:15:31,436 swdllite(mgr): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default <NL> [  155.851806] ops-redundancy-mgr[1397]: deleting subscriber_ socket <NL> 2024-07-31 08:15:32,914 swdllite(agt): INFO - swdllited_base_utils.evaluate_hostname[309] hostname: fujitsu, default_state changing unknown -> default[  161.337250] hrtimer: interrupt took 10378 ns"}
{"timestamp_utc": "2024-07-31T08:15:51.122Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  160.189173] ops-redundancy-mgr[1397]: Exiting verb listener <NL> 2024-07-31 08:15:36,619 swdllite(mgr): INFO - swdl_mgr_fn.start_event_fn[429] starting the swdllite manager <NL> 2024-07-31 08:15:37,629 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  161.935857] ntputils[1724]: int ntputils_main(int, char**)Starting ntputils <NL> 2024-07-31 08:15:38,399 swdllite(mgr): INFO - fsm.log[312] LOGFSM: START_EVT -> INITIAL_STATE -> start_event_fn -> WAIT_REDUNDANCY_STATE <NL> [  162.467757] ntputils[1724]: Running as a daemon <NL> [  162.617615] ntputils[1724]: shelf role is: MAIN <NL> [  162.618469] ntputils[1724]: slot number is: 0 <NL> 2024-07-31 08:15:38,853 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> wait_redundancy_entry_fn <NL> [  163.077383] ntputils[1724]: slot role is: UNKNOWN <NL> [  164.306464] ntputils[1724]: redundancy_mode: UNKNOWN <NL> 2024-07-31 08:15:40,178 swdllite(agt): INFO - swdl_agent_fn.start_event_fn[275] starting the swdllite agent <NL> [  164.427516] ntputils[1724]: Executing on a work blade <NL> [  164.695593] ntputils[1724]: ================================ <NL> [  164.884934] ntputils[1724]: shelf_role is: MAIN <NL> 2024-07-31 08:15:41,427 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  165.860257] ntputils[1724]: redundancy_mode: UNKNOWN <NL> [  168.105767] ntputils[1724]: active_status: active <NL> [  168.106475] ntputils[1724]: ntp_role: act <NL> [  168.423704] ntputils[1724]: ================================ <NL> [  169.671706] ntputils[1724]: NTPUtilsConfig::do_default_config <NL> [  169.931492] ntputils[1724]: shelf_num/is_client: 0 <NL> [  169.952051] ntputils[1724]: server_ip: 0x558b7c7affc0 <NL> 2024-07-31 08:15:46,349 swdllite(agt): INFO - fsm.log[312] LOGFSM: MOUNT_GOOD_EVT -> INITIAL_STATE -> WAIT_REDUNDANCY_STATE <NL> 2024-07-31 08:15:46,755 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> WAIT_REDUNDANCY_STATE -> agent_wait_redundancy_entry_fn <NL> [  171.000774] ntputils[1724]: ip_addr(ilan): 0x558b7c7aff80 <NL> 2024-07-31 08:15:48,091 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:48,137 swdllite(mgr): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=_restart_autofs <NL> [  172.292582] ntputils[1724]: ntp_role act <NL> [  172.392515] ntputils[1724]: shelf_num aka is_client == 0 <NL> [  172.393253] ntputils[1724]: restart daemon with: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> [  173.255907] ntputils[1724]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:15:52.048Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:51 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:52.305Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  172.791560] ains_manager[2644]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  172.994943] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 5 <NL> [  173.003573] common_alarm_handler[2385]: topic = XconProv_v2Prov; id = 112 <NL> [  173.003704] common_alarm_handler[2385]: topic = OchIfProv; id = 113 <NL> [  173.003798] common_alarm_handler[2385]: topic = AclProfileProv; id = 114 <NL> [  173.003898] common_alarm_handler[2385]: topic = OtuProv; id = 115 <NL> [  173.004035] common_alarm_handler[2385]: topic = GeProv; id = 116 <NL> [  173.004099] common_alarm_handler[2385]: topic = OduProv; id = 117 <NL> [  173.004161] common_alarm_handler[2385]: topic = TcmProv; id = 118 <NL> [  173.004223] common_alarm_handler[2385]: topic = OCnProv; id = 119 <NL> [  173.004284] common_alarm_handler[2385]: topic = OnDemandDM; id = 120 <NL> [  173.004345] common_alarm_handler[2385]: topic = OducnProv; id = 121 <NL> [  173.004432] common_alarm_handler[2385]: topic = OtsiProv; id = 122 <NL> [  173.004495] common_alarm_handler[2385]: topic = OtsigProv; id = 123 <NL> [  173.004559] common_alarm_handler[2385]: topic = OtucnProv; id = 124 <NL> [  173.004620] common_alarm_handler[2385]: topic = YpgProv; id = 125 <NL> [  173.004682] common_alarm_handler[2385]: topic = EpgProv; id = 126 <NL> [  173.004744] common_alarm_handler[2385]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  173.004812] common_alarm_handler[2385]: topic = DataEncryptionOperReq; id = 128 <NL> [  173.004888] common_alarm_handler[2385]: topic = RoutePolicyTableProv; id = 129 <NL> [  173.004963] common_alarm_handler[2385]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  173.005035] common_alarm_handler[2385]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  173.005097] common_alarm_handler[2385]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  173.005236] common_alarm_handler[2385]: topic = ShapingProfileProv; id = 133 <NL> [  173.005300] common_alarm_handler[2385]: topic = TaildropProfileProv; id = 134 <NL> [  173.005366] common_alarm_handler[2385]: topic = PolicingProfileProv; id = 135 <NL> [  173.005429] common_alarm_handler[2385]: topic = CapabilityProfileProv; id = 136 <NL> [  173.005500] common_alarm_handler[2385]: topic = TransportInterfaceRateProv; id = 137 <NL> [  173.005563] common_alarm_handler[2385]: topic = PmRtrvReqSess; id = 138 <NL> [  173.005632] common_alarm_handler[2385]: topic = PmRtrvRespSess; id = 139 <NL> [  173.005694] common_alarm_handler[2385]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  173.005757] common_alarm_handler[2385]: topic = DataEncryptionPskReq; id = 141"}
{"timestamp_utc": "2024-07-31T08:15:52.306Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  173.005818] common_alarm_handler[2385]: topic = SystemWebserverProv; id = 142 <NL> [  173.005907] common_alarm_handler[2385]: NO match: <NL> [  173.005981] common_alarm_handler[2385]: NO match: <NL> [  173.006086] common_alarm_handler[2385]: NO match: <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> Exception: Connect failed <NL> [  174.840942] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 6 <NL> [  175.916660] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  176.350402] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  176.647925] python3[2423]: [.608] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  176.648182] python3[2423]: [.609] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  176.690086] python3[2423]: [.647] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  176.963641] python3[2423]: [.648] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  176.963732] python3[2423]: [.648] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  176.963808] python3[2423]: [.648] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  177.264905] python3[2423]: [.648] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  177.265040] python3[2423]: [.648] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  177.291947] python3[2423]: [.683] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  177.292128] python3[2423]: [.683] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  177.292215] python3[2423]: [.684] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  177.292295] python3[2423]: [.684] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  177.292384] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  177.292459] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  177.292562] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  177.292635] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  177.292741] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  177.292832] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  177.292909] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  177.292984] python3[2423]: [.686] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  177.293080] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  177.293203] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  177.293295] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  177.293463] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  177.293577] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  177.293665] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  177.293760] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  177.294080] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  177.294176] python3[2423]: [.687] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  177.294306] python3[2423]: [.799] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  177.294426] python3[2423]: [.829] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  177.294514] python3[2423]: [.829] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  177.294608] python3[2423]: [.830] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:15:55.571Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:15:55 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:15:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:55 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:15:57.458Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:15:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:15:56 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:00.788Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:00 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:00 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:02.153Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:01 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:02.409Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:15:48,595 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:48,643 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  173.647897] ntputils[1724]: systemctl --no-block stop ntpd <NL> 2024-07-31 08:15:51,365 swdllite(mgr): INFO - fsm.log[312] LOGFSM: GO_STARTUP_EVT -> WAIT_REDUNDANCY_STATE -> STARTUP_STATE <NL> 2024-07-31 08:15:52,065 swdllite(agt): INFO - swdl_redundancy.go_standalone_agent_fn[215] emitting GO_STANDALONE_EVT <NL> [  176.093766] ntputils[1724]: child pid is 1777 <NL> 2024-07-31 08:15:51,366 swdllite(mgr): INFO - swdl_subprocess.subprocesscmd[93] systemctl restart autofs simulated <NL> [  177.269496] ntputils[1724]: exited, status is 0 <NL> [  177.271790] ntputils[1724]: NTPServer::execute_cmd spawning:"}
{"timestamp_utc": "2024-07-31T08:16:02.410Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:15:52,674 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> 2024-07-31 08:15:53,372 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  177.279370] ntputils[1724]: /usr/local/fnc/ntputils/setServerConf.sh 127.1.0.0 255.255.0.0 /etc/ntp.conf act <NL> 2024-07-31 08:15:53,368 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:15:53,393 swdllite(agt): INFO - fsm.log[312] LOGFSM: STANDALONE_EVT -> WAIT_REDUNDANCY_STATE -> go_standalone_agent_fn -> GO_STANDALONE_EVT(drop) -> STARTUP_STATE <NL> [  177.299087] ntputils[1724]: child pid is 1791 <NL> 2024-07-31 08:15:53,413 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:53,496 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  177.443289] standby_filesync[1402]: DipLog_pimpl destructor called <NL> [  177.804315] standby_filesync[1402]: DipVerbosity Listener ZMQ error <NL> 2024-07-31 08:15:53,831 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  177.831387] standby_filesync[1402]:     ret='Context was terminated <NL> [  177.832353] standby_filesync[1402]: deleting subscriber_ socket <NL> 2024-07-31 08:15:53,931 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> [  177.832990] standby_filesync[1402]: Exiting verb listener <NL> 2024-07-31 08:15:54,122 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:54,172 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:15:54,179 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:15:54,408 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  178.345051] ntputils[1797]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:15:54,480 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:15:54,452 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:54,520 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> 2024-07-31 08:15:54,553 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:54,597 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  178.517540] ntputils[1724]: exited, status is 0 <NL> [  178.528421] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  178.555770] ntputils[1724]: /bin/systemctl reset-failed ntpd <NL> [  178.566236] ntputils[1724]: child pid is 1806 <NL> [  178.653808] ntputils[1724]: exited, status is 0 <NL> 2024-07-31 08:15:54,974 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  179.019145] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  179.390527] ntputils[1724]: systemctl --no-block start ntpd <NL> [  179.445920] ntputils[1724]: child pid is 1811 <NL> [  179.471396] ntputils[1724]: exited, status is 0 <NL> [  179.471981] ntputils[1724]: server role, server_ip is set to: 127.0.0.1 <NL> [  179.605772] ntputils[1724]: Running in production mode <NL> [  180.154187] ntputils[1724]: InitDaemon redundancy_mode: UNKNOWN <NL> [  180.162738] ntputils[1724]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  180.164658] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  180.211492] ntputils[1724]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  180.213298] ntputils[1724]: registration socket.send OK <NL> [  180.213951] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  180.264392] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  180.603401] ntputils[1724]:  topic reg for: <NL> [  180.603988] ntputils[1724]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  180.854213] ntputils[1724]: registration socket.send OK <NL> [  181.114178] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  181.215930] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  181.358777] ntputils[1724]:  topic reg for: <NL> [  181.367349] ntputils[1724]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  181.368356] ntputils[1724]: registration socket.send OK <NL> [  181.677751] ntputils[1724]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  181.678933] ntputils[1724]: void NTPServer::check_ntp_enabled() <NL> [  181.789625] ntputils[1724]: check_ntp_enabled not empty <NL> [  181.809520] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  182.021939] ntputils[1724]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  182.166653] ntputils[1724]: child pid is 1906 <NL> [  182.181491] ntputils[1724]: exited, status is 0 <NL> [  182.533275] ntputils[1724]: check_ntp_enabled skip system script_start <NL> [  182.546501] ntputils[1724]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  182.548476] ntputils[1724]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  182.711949] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  182.754556] ntputils[1724]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  182.793170] ntputils[1724]: child pid is 1917 <NL> [  182.794317] ntputils[1724]: exited, status is 0 <NL> [  182.845419] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  182.846176] ntputils[1724]: systemctl --no-block stop ntpd <NL> [  182.846825] ntputils[1724]: child pid is 1925 <NL> [  182.847425] ntputils[1724]: exited, status is 0 <NL> [  182.888625] ntputils[1724]: call delete_all_external_servers <NL> [  182.891567] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  182.917196] ntputils[1724]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  182.989162] ntputils[1724]: child pid is 1940 <NL> [  183.649028] ntputils[1940]: remove_all_ext_src <NL> [  183.777768] ntputils[1940]: delete: <NL> [  183.948971] ntputils[1724]: exited, status is 0 <NL> [  184.319293] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  184.503362] ntputils[1724]: /bin/systemctl reset-failed ntpd <NL> [  184.504187] ntputils[1724]: child pid is 1947 <NL> [  184.504759] ntputils[1724]: exited, status is 0 <NL> [  184.505394] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  184.521660] ntputils[1724]: systemctl --no-block start ntpd <NL> [  184.600943] ntputils[1724]: child pid is 1948 <NL> [  184.612770] ntputils[1724]: exited, status is 0 <NL> [  184.619426] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  184.626304] ntputils[1724]: /bin/systemctl reset-failed init_state_check.timer <NL> [  184.637743] ntputils[1724]: child pid is 1951 <NL> [  184.680749] ntputils[1724]: exited, status is 0 <NL> [  184.711398] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  184.713320] ntputils[1724]: /bin/systemctl --no-block start init_state_check.timer <NL> [  184.968772] ntputils[1724]: child pid is 1953"}
{"timestamp_utc": "2024-07-31T08:16:05.681Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:15:46,004 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  169.859136] startup_finished.py[2305]: *****Startup Finished Monitor:Starting the event loop***** <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> ERROR:root:empty repository <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:15:49,364 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:15:49,365 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:15:49,365 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:15:49,366 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:15:49,366 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> 2024-07-31 08:15:49,367 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> 2024-07-31 08:15:49,367 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:15:49,367 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0,"}
{"timestamp_utc": "2024-07-31T08:16:05.682Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "\"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  174.681387] dhal_sim_startup.sh[2412]: mkdir: cannot create directory '/tmp/dip/hal/': File exists <NL> [  174.765522] confd_mgr_action_server[2403]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  176.485746] temp_acct_cleanup_app[2457]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  176.574152] temp_acct_cleanup_app[2457]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  176.862218] confd_phase_sentry[2450]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  177.556458] confd_phase_sentry[2450]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  177.556685] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  177.868485] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 1 <NL> [  178.949382] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  178.950739] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  180.591928] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 2 <NL> [  181.557580] sncp_app[2391]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  181.687996] ypg_app[2400]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  181.985088] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  182.119221] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  182.475036] ains_manager[2577]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> 2024-07-31 08:15:59,780 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> [  183.657194] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 3 <NL> 2024-07-31 08:16:00,487 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:16:00,714 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:16:00,882 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:16:00,882 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:16:00,883 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:16:00,883 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:16:01,103 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:16:01,179 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:16:01,797 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:01,798 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:16:02,094 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:16:02,095 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:16:02,303 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:16:02,304 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:16:02,304 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:16:02,433 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> [  186.704396] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  186.788259] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  186.841653] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 4 <NL> 2024-07-31 08:16:03,115 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726223700 <NL> 2024-07-31 08:16:03,965 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:16:03,966 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:16:03,995 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:16:03,995 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:16:03,996 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> 2024-07-31 08:16:04,056 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> # 03:16:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:05 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:07.048Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:06 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:07.610Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "2024-07-31 08:16:04,057 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:04,058 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726223700\" <NL> } <NL> [  188.160986] common_alarm_handler[2388]: gen_util: DDS_P2MP not available <NL> [  188.835422] common_alarm_handler[2388]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  188.835677] common_alarm_handler[2388]: topic = SystemProv; id = 1 <NL> [  188.836552] common_alarm_handler[2388]: topic = WdmcfgProv; id = 2 <NL> [  188.836642] common_alarm_handler[2388]: topic = LicenseStatusTopic; id = 3 <NL> [  188.836738] common_alarm_handler[2388]: topic = ShelfProv; id = 5 <NL> [  188.836892] common_alarm_handler[2388]: topic = SlotProv; id = 6 <NL> [  188.836994] common_alarm_handler[2388]: topic = PortProv; id = 7 <NL> [  188.837092] common_alarm_handler[2388]: topic = SubportProv; id = 8 <NL> [  188.837172] common_alarm_handler[2388]: topic = FconProv; id = 9 <NL> [  188.837250] common_alarm_handler[2388]: topic = XconProv; id = 10 <NL> [  188.837330] common_alarm_handler[2388]: topic = OchProv; id = 11 <NL> [  188.837426] common_alarm_handler[2388]: topic = OmsProv; id = 12 <NL> [  188.837498] common_alarm_handler[2388]: topic = OtsProv; id = 13 <NL> [  188.837610] common_alarm_handler[2388]: topic = EthernetProv; id = 14 <NL> [  188.837709] common_alarm_handler[2388]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  188.837800] common_alarm_handler[2388]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  188.837874] common_alarm_handler[2388]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  188.837945] common_alarm_handler[2388]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  188.853103] common_alarm_handler[2388]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  189.425128] common_alarm_handler[2388]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  189.425246] common_alarm_handler[2388]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  189.425331] common_alarm_handler[2388]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  189.425424] common_alarm_handler[2388]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  189.425525] common_alarm_handler[2388]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  189.425607] common_alarm_handler[2388]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  189.425690] common_alarm_handler[2388]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  189.425772] common_alarm_handler[2388]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> [  189.425861] common_alarm_handler[2388]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  189.425944] common_alarm_handler[2388]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  189.426061] common_alarm_handler[2388]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  189.426146] common_alarm_handler[2388]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> [  189.426243] common_alarm_handler[2388]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  189.426326] common_alarm_handler[2388]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> [  189.426423] common_alarm_handler[2388]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  189.426525] common_alarm_handler[2388]: topic = AlarmNotification; id = 40 <NL> [  189.426635] common_alarm_handler[2388]: topic = GenericOperInfoReq; id = 41 <NL> [  189.426719] common_alarm_handler[2388]: topic = PmRtrvReq; id = 42 <NL> [  189.426801] common_alarm_handler[2388]: topic = PmRtrvResp; id = 43 <NL> [  189.426884] common_alarm_handler[2388]: topic = PmInitReq; id = 44 <NL> [  189.427073] common_alarm_handler[2388]: topic = PmOperData; id = 45 <NL> [  189.427158] common_alarm_handler[2388]: topic = StateChange; id = 46 <NL> [  189.427238] common_alarm_handler[2388]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  189.427328] common_alarm_handler[2388]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> [  189.427413] common_alarm_handler[2388]: topic = DcnIpv6Ipv6Attributes; id = 50"}
{"timestamp_utc": "2024-07-31T08:16:07.611Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  189.427514] common_alarm_handler[2388]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  189.427599] common_alarm_handler[2388]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  189.427684] common_alarm_handler[2388]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  189.427766] common_alarm_handler[2388]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  189.450924] common_alarm_handler[2388]: topic = EthIfProv; id = 56 <NL> [  189.504137] common_alarm_handler[2388]: topic = DcnNat64Attributes; id = 57 <NL> [  189.504255] common_alarm_handler[2388]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  189.504342] common_alarm_handler[2388]: topic = LldpGlobalCfgProv; id = 59 <NL> [  189.504447] common_alarm_handler[2388]: topic = LldpPortCfgProv; id = 60 <NL> [  189.504545] common_alarm_handler[2388]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  189.504638] common_alarm_handler[2388]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  189.504720] common_alarm_handler[2388]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  189.504802] common_alarm_handler[2388]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  189.504884] common_alarm_handler[2388]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  189.504964] common_alarm_handler[2388]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  189.505086] common_alarm_handler[2388]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  189.505174] common_alarm_handler[2388]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  189.505273] common_alarm_handler[2388]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  189.505356] common_alarm_handler[2388]: topic = DcnPppAttributesProv; id = 70 <NL> [  189.505441] common_alarm_handler[2388]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  189.505524] common_alarm_handler[2388]: topic = LldpBladeCfgProv; id = 72 <NL> [  189.505605] common_alarm_handler[2388]: topic = LldpPortInstCfgProv; id = 73 <NL> [  189.505700] common_alarm_handler[2388]: topic = DcnGreTunnelProv; id = 74 <NL> [  189.505784] common_alarm_handler[2388]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  189.505872] common_alarm_handler[2388]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  189.505974] common_alarm_handler[2388]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  189.506085] common_alarm_handler[2388]: topic = SysGnmiCertProv; id = 78 <NL> [  189.506166] common_alarm_handler[2388]: topic = IetfInterfaceProv; id = 79 <NL> [  189.506252] common_alarm_handler[2388]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  189.506344] common_alarm_handler[2388]: topic = SystemAutoLogoffProv; id = 81 <NL> [  189.506441] common_alarm_handler[2388]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  189.548145] common_alarm_handler[2388]: topic = SystemPortsProv; id = 83 <NL> [  189.600340] common_alarm_handler[2388]: topic = OspfProvisioningModeProv; id = 84 <NL> [  189.600653] common_alarm_handler[2388]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  189.600875] common_alarm_handler[2388]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  189.601249] common_alarm_handler[2388]: topic = BasicGroupProv; id = 87 <NL> [  189.601480] common_alarm_handler[2388]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  189.601733] common_alarm_handler[2388]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  189.601967] common_alarm_handler[2388]: topic = SystemFipsProv; id = 90 <NL> [  189.602213] common_alarm_handler[2388]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  189.602427] common_alarm_handler[2388]: topic = SecuritySystemwideProv; id = 92 <NL> [  189.602664] common_alarm_handler[2388]: topic = DataEncryptionProv; id = 93 <NL> [  189.602892] common_alarm_handler[2388]: topic = SystemServicesProv; id = 94 <NL> [  189.653556] common_alarm_handler[2388]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  189.653676] common_alarm_handler[2388]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  189.653778] common_alarm_handler[2388]: topic = SecurityRadiusAuthProv; id = 97"}
{"timestamp_utc": "2024-07-31T08:16:10.906Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:10 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:11.467Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  177.294708] python3[2423]: [.830] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  177.294803] python3[2423]: [.830] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  177.644613] python3[2423]: [.830] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  177.644729] python3[2423]: [.830] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  177.644831] python3[2423]: [.831] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  177.644908] python3[2423]: [.831] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  177.644983] python3[2423]: [.831] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  177.645127] python3[2423]: [.831] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  177.645205] python3[2423]: [.899] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  177.645282] python3[2423]: [.899] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  177.645356] python3[2423]: [.899] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> [  177.659104] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  178.306616] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  178.537520] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> [  178.682774] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 7 <NL> [  179.049180] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  179.049348] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  179.049445] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  179.049523] python3[2423]: [.075] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  179.049594] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  179.049674] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  179.049747] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  179.049837] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  179.049955] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  179.050137] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  179.050219] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  179.050295] python3[2423]: [.109] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  179.050374] python3[2423]: [.110] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  179.050453] python3[2423]: [.110] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  179.050525] python3[2423]: [.110] hookhdlr 140490876737344 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  179.050600] python3[2423]: [.110] hookhdlr 140490876737344 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  179.050687] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  179.050765] python3[2423]: [.721] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  180.933281] txid_tracker[2454]: ::::create_confd_subscription_connection() try number 8 <NL> [  180.934574] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  180.934681] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  182.267840] layer1_control_layer[2425]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  182.726583] python3[2564]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  182.833946] python3[2564]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  182.834089] python3[2564]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  182.834165] python3[2564]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  182.834238] python3[2564]: max_slotNumber=5 <NL> [  185.361254] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 1 <NL> [  185.935784] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  185.936208] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  187.922282] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  187.956110] python3[2423]: [.738] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  188.644680] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 2 <NL> [  191.068840] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  191.069025] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  191.419256] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 3 <NL> [  194.390723] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 4 <NL> [  195.971170] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  195.971363] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  196.038599] dcn_dns_controller[1604]: dnsClientStartup() <NL> [  196.159972] dcn_dns_controller[1604]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  196.160145] dcn_dns_controller[1604]: fin_dnsmasq_conf is open <NL> [  196.357652] dcn_ka[1606]: KaSessMgr Process Startup <NL> [  196.878971] python3[2972]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  196.879169] python3[2972]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  196.879428] python3[2972]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  196.898958] python3[2972]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  196.963886] python3[2972]: max_slotNumber=5 <NL> [  196.964103] python3[2972]:  prov channel is 127.0.0.1:10000"}
{"timestamp_utc": "2024-07-31T08:16:12.030Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:12 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:13.919Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:15:45,864 swdllite(mgr): INFO - swdl_disk_mount.restart_autofs[431] restart autofs, rc=0 <NL> 2024-07-31 08:15:47,439 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  174.369018] ops-redundancy-mgr[1379]: deleting subscriber_ socket <NL> 2024-07-31 08:15:48,025 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  174.867429] ops-redundancy-mgr[1379]: Exiting verb listener <NL> 2024-07-31 08:15:48,632 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> initial_version_request_fn -> CHECK_SHELFPROV_EVT <NL> 2024-07-31 08:15:48,964 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:15:49,026 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:15:49,064 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:15:49,435 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  175.730438] rdm[1730]: RdmConfig: file_exist 0 <NL> [  175.950017] rdm[1730]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  175.950793] rdm[1730]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> 2024-07-31 08:15:49,470 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  176.265919] rdm[1730]: start rdm msg hdlr thd <NL> 2024-07-31 08:15:50,239 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:15:50,844 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> STARTUP_STATE -> startup_entry_fn <NL> 2024-07-31 08:15:51,694 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  178.237495] ntputils[1806]: Changing Stratum and adding restrictions <NL> 2024-07-31 08:15:52,433 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  179.950908] ntputils[1725]: exited, status is 0 <NL> 2024-07-31 08:15:53,674 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=0 <NL> [  180.362710] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  180.616751] ntputils[1725]: /bin/systemctl reset-failed ntpd <NL> [  180.895679] ntputils[1725]: child pid is 1823 <NL> [  181.178090] ntputils[1725]: exited, status is 0 <NL> [  181.356760] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  181.780615] ntputils[1725]: systemctl --no-block start ntpd <NL> [  181.980569] ntputils[1725]: child pid is 1829 <NL> [  181.981772] ntputils[1725]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:16:13.920Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  182.107996] ntputils[1725]: server role, server_ip is set to: 127.0.0.1 <NL> [  182.568871] ntputils[1725]: Running in production mode <NL> [  182.614246] ntputils[1725]: InitDaemon redundancy_mode: UNKNOWN <NL> [  182.875033] ntputils[1725]: bool NTPUtilsConfig::platform_dds_registration() <NL> [  183.222024] ntputils[1725]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  183.513949] ntputils[1725]:  topic reg for: Time;tcp://127.0.0.1:5576 <NL> [  183.811655] ntputils[1725]: registration socket.send OK <NL> [  184.026277] ntputils[1725]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  184.621936] ntputils[1725]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  184.800325] ntputils[1725]:  topic reg for: <NL> [  185.070987] ntputils[1725]: \u001fPlatform_dds_TimePersistentProv\u0012\u0014tcp://127.0.0.1:5576 <NL> [  185.313413] ntputils[1725]: registration socket.send OK <NL> [  185.469339] ntputils[1725]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  185.694781] ntputils[1725]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) <NL> [  185.801140] ntputils[1725]:  topic reg for: <NL> [  186.033298] ntputils[1725]: \u0017Platform_dds_Redundancy\u0012\u0014tcp://127.0.0.1:5576 <NL> [  186.343240] ntputils[1725]: registration socket.send OK <NL> [  186.479867] ntputils[1725]: bool NTPUtilsConfig::dds_topic_registration(const string&, const string&) rc = 1 <NL> [  186.617469] ntputils[1725]: void NTPServer::check_ntp_enabled() <NL> [  186.667086] ntputils[1725]: check_ntp_enabled not empty <NL> [  186.708771] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  186.753451] ntputils[1725]: /usr/local/fnc/ntputils/ext_config.sh -c /etc/ntp.conf <NL> [  186.936273] ntputils[1725]: child pid is 1909 <NL> [  187.177743] ntputils[1725]: exited, status is 0 <NL> [  187.563916] ntputils[1725]: check_ntp_enabled skip system script_start <NL> [  187.578140] ntputils[1725]: int NTPServer::InitDaemon() (1 OK) rc = 1 <NL> [  187.579154] ntputils[1725]: bool NTPServer::delete_all_external_servers(std::string, std::string) <NL> [  187.713269] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  187.713973] ntputils[1725]: /bin/systemctl --no-block stop init_state_check.timer <NL> [  188.070294] ntputils[1725]: child pid is 1911 <NL> [  188.295783] ntputils[1725]: exited, status is 0 <NL> [  188.692862] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  188.751758] ntputils[1725]: systemctl --no-block stop ntpd <NL> [  189.178777] ntputils[1725]: child pid is 1917 <NL> [  189.378518] ntputils[1725]: exited, status is 0 <NL> [  189.531945] ntputils[1725]: call delete_all_external_servers <NL> [  189.849443] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  190.074403] ntputils[1725]: /usr/local/fnc/ntputils/ext_config.sh -das /etc/ntp.conf <NL> [  190.294874] ntputils[1725]: child pid is 1926 <NL> [  190.734905] ntp_oper_data.py[1726]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  191.657575] ntp_oper_data.py[1726]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  191.945305] ntp_oper_data.py[1726]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  191.985030] ntp_oper_data.py[1726]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  192.029982] ntputils[1926]: remove_all_ext_src <NL> [  192.287872] ntputils[1926]: delete: <NL> [  193.015234] ntp_oper_data.py[1726]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  193.295837] ntp_oper_data.py[1726]: INFO:root:redundancy status now set to standalone <NL> [  193.300314] ntp_oper_data.py[1726]: INFO:root:Received redundancy topic <NL> [  193.354097] ntp_oper_data.py[1726]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:16:07,057 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> 2024-07-31 08:16:07,379 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> [  193.977892] ntputils[1725]: exited, status is 0 <NL> 2024-07-31 08:16:07,691 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  194.242540] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:09,738 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> [  196.218384] ntputils[1725]: /bin/systemctl reset-failed ntpd <NL> 2024-07-31 08:16:10,424 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> [  196.858437] ntputils[1725]: child pid is 1928 <NL> 2024-07-31 08:16:10,762 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:16:11,082 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  197.809056] ntputils[1725]: exited, status is 0 <NL> 2024-07-31 08:16:12,310 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE"}
{"timestamp_utc": "2024-07-31T08:16:14.483Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  189.653877] common_alarm_handler[2388]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  189.653960] common_alarm_handler[2388]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  189.654091] common_alarm_handler[2388]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  189.654210] common_alarm_handler[2388]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  189.654316] common_alarm_handler[2388]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  189.654405] common_alarm_handler[2388]: topic = FscProv; id = 111 <NL> [  189.654498] common_alarm_handler[2388]: topic = XconProv_v2Prov; id = 112 <NL> [  189.654582] common_alarm_handler[2388]: topic = OchIfProv; id = 113 <NL> [  189.656319] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 5 <NL> [  189.656536] common_alarm_handler[2388]: topic = AclProfileProv; id = 114 <NL> [  189.656652] common_alarm_handler[2388]: topic = OtuProv; id = 115 <NL> [  189.656738] common_alarm_handler[2388]: topic = GeProv; id = 116 <NL> [  189.656821] common_alarm_handler[2388]: topic = OduProv; id = 117 <NL> [  189.656903] common_alarm_handler[2388]: topic = TcmProv; id = 118 <NL> [  189.663076] common_alarm_handler[2388]: topic = OCnProv; id = 119 <NL> [  189.687417] common_alarm_handler[2388]: topic = OnDemandDM; id = 120 <NL> [  190.380344] common_alarm_handler[2388]: topic = OducnProv; id = 121 <NL> [  190.410515] common_alarm_handler[2388]: topic = OtsiProv; id = 122 <NL> [  190.722504] common_alarm_handler[2388]: topic = OtsigProv; id = 123 <NL> [  190.722626] common_alarm_handler[2388]: topic = OtucnProv; id = 124 <NL> [  190.722723] common_alarm_handler[2388]: topic = YpgProv; id = 125 <NL> [  190.722813] common_alarm_handler[2388]: topic = EpgProv; id = 126 <NL> [  190.722902] common_alarm_handler[2388]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  190.722995] common_alarm_handler[2388]: topic = DataEncryptionOperReq; id = 128 <NL> [  190.723102] common_alarm_handler[2388]: topic = RoutePolicyTableProv; id = 129 <NL> [  190.723213] common_alarm_handler[2388]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  190.723306] common_alarm_handler[2388]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  190.723395] common_alarm_handler[2388]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  190.723587] common_alarm_handler[2388]: topic = ShapingProfileProv; id = 133 <NL> [  190.723674] common_alarm_handler[2388]: topic = TaildropProfileProv; id = 134 <NL> [  190.723781] common_alarm_handler[2388]: topic = PolicingProfileProv; id = 135 <NL> [  190.723876] common_alarm_handler[2388]: topic = CapabilityProfileProv; id = 136 <NL> [  190.723988] common_alarm_handler[2388]: topic = TransportInterfaceRateProv; id = 137 <NL> [  191.107332] common_alarm_handler[2388]: topic = PmRtrvReqSess; id = 138 <NL> [  191.108203] common_alarm_handler[2388]: topic = PmRtrvRespSess; id = 139 <NL> [  191.298361] common_alarm_handler[2388]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  191.298694] common_alarm_handler[2388]: topic = DataEncryptionPskReq; id = 141 <NL> [  191.298784] common_alarm_handler[2388]: topic = SystemWebserverProv; id = 142 <NL> [  191.298869] common_alarm_handler[2388]: NO match: <NL> [  191.298952] common_alarm_handler[2388]: NO match: <NL> [  191.299076] common_alarm_handler[2388]: NO match: <NL> [  192.113540] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  192.115269] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  192.681971] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 6 <NL> Exception: Connect failed <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  195.705470] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 7 <NL> [  196.100740] python3[2425]: [.492] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.173803] python3[2425]: [.492] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.495804] python3[2425]: [.496] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  196.495936] python3[2425]: [.556] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.496070] python3[2425]: [.556] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  196.496249] python3[2425]: [.556] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  196.496348] python3[2425]: [.571] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  196.496416] python3[2425]: [.571] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.496482] python3[2425]: [.653] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.496549] python3[2425]: [.653] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.496614] python3[2425]: [.654] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  196.496696] python3[2425]: [.654] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  196.496768] python3[2425]: [.663] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  196.496842] python3[2425]: [.697] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.496958] python3[2425]: [.697] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  196.497080] python3[2425]: [.697] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  196.497187] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  196.497262] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  196.497331] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  196.497398] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  196.497464] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.497531] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  196.497614] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  196.497682] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  196.909392] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  196.909630] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'}"}
{"timestamp_utc": "2024-07-31T08:16:14.484Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  196.909764] python3[2425]: [.698] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  196.909851] python3[2425]: [.699] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'}"}
{"timestamp_utc": "2024-07-31T08:16:15.852Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:16:15 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:15 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:17.220Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:17 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:19.736Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  185.061472] ntputils[1724]: exited, status is 0 <NL> [  185.101240] ntputils[1724]: server.InitDaemon <NL> [  185.251791] ntputils[1724]: int NTPServer::platformdds_listen() <NL> [  185.430476] ntputils[1724]: void NTPServer::late_joiner() <NL> [  185.432579] ntputils[1724]: void NTPServer::poller() <NL> [  185.662736] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  186.007271] ntputils[1724]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  186.260272] ntputils[1724]: got Platform::RedundancyMode: UNKNOWN <NL> [  186.468188] ntputils[1724]: got Platform::RedundancyStatus: STANDALONE <NL> [  186.899243] ntputils[1724]: my current red mode is: UNKNOWN <NL> [  186.983857] ntputils[1724]: new red mode is: UNKNOWN <NL> [  187.157693] ntputils[1724]: my current red status is: active <NL> [  187.280305] ntputils[1724]: new red status is: STANDALONE <NL> [  187.528350] ntputils[1724]: received unknown! <NL> [  187.682904] ntputils[1724]: new red mode is: UNKNOWN <NL> [  187.947014] ntputils[1724]: new red status is: STANDALONE <NL> [  187.947796] ntputils[1724]: red status change, update active => STANDALONE <NL> [  188.314788] ntputils[1724]: no active/not-active status change: 0 <NL> [  188.542790] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  188.735627] ntputils[1724]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  188.905555] ntputils[1724]: got Platform::RedundancyMode: UNKNOWN <NL> [  188.943859] ntputils[1724]: got Platform::RedundancyStatus: STANDALONE <NL> [  189.022229] ntputils[1724]: my current red mode is: UNKNOWN <NL> [  189.135666] ntputils[1724]: new red mode is: UNKNOWN <NL> [  189.244856] ntputils[1724]: my current red status is: STANDALONE <NL> [  189.469314] ntputils[1724]: new red status is: STANDALONE <NL> [  189.470125] ntputils[1724]: received unknown! <NL> [  189.470820] ntputils[1724]: new red mode is: UNKNOWN <NL> [  189.472503] ntputils[1724]: new red status is: STANDALONE <NL> [  189.473869] ntputils[1724]: no active/not-active status change: 0 <NL> [  189.519801] rdm[1734]: RdmConfig: file_exist 0 <NL> [  189.780043] rdm[1734]: RdmConfig: RDM_WTN_DIS, file_exist = 0 <NL> [  190.204143] rdm[1734]: RdmConfig: RDM_RM_VAL_DIS, file_exist = 0 <NL> [  190.351567] rdm[1734]: start rdm msg hdlr thd <NL> [  190.887337] ntp_oper_data.py[1725]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  191.125684] ntp_oper_data.py[1725]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  191.431774] ntp_oper_data.py[1725]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://127.0.0.1:1096') <NL> [  191.461679] ntp_oper_data.py[1725]: INFO:root:dds_registration_socket: reg_msg = bytearray(b'\\n\\x18Platform_dds_NtpAssocReq\\x12\\x14tcp://127.0.0.1:1096') <NL> [  192.145753] usb_script_handler.py[1738]: usb: INFO - usb_base.check_manual_bind_unbind[251] kernel mimic check to manually verify usb presence <NL> [  192.402883] ntp_oper_data.py[1725]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  192.459923] ntp_oper_data.py[1725]: INFO:root:redundancy status now set to standalone <NL> [  192.513976] ntp_oper_data.py[1725]: INFO:root:Received redundancy topic <NL> [  192.628071] ntp_oper_data.py[1725]: INFO:root:Redundancy status is standalone <NL> [  193.197817] usb_script_handler.py[1738]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  194.731974] usb_script_handler.py[1738]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  195.005317] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[106] trying to mount usb as secondary storage <NL> [  195.411491] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[108] checking for /dev/mapper/usb-secondary device <NL> 2024-07-31 08:16:11,865 swdllite(int): INFO - swdllited_base.run[449] using runtime config platform=qemu, role=interface, unitCode=c200, unitName=BDC2-C200, shelf_id=200, slot_id=0 <NL> [  195.906701] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[111] found /dev/mapper/usb-secondary device <NL> 2024-07-31 08:16:12,252 swdllite(int): INFO - swdllited_base.run[457] redundancy_mode=working <NL> [  196.673821] usb_script_handler.py[1738]: usb: INFO - usb_ssw_main.mount_usb_secondary[118] USB ssw mount successful <NL> 2024-07-31 08:16:12,866 swdllite(int): INFO - swdl_runtime_config.log_config_list[190] config file list (from lowest to highest priority): <NL> (priority[0]): /usr/share/swdllite/config/common_config.yaml <NL> (priority[1]): /usr/share/swdllite/config/qemu.yaml <NL> (priority[2]): /usr/share/swdllite/config/qemu.interface.yaml <NL> (priority[3]): /usr/share/swdllite/config/unit/c200/qemu.yaml <NL> [  196.931935] usb_script_handler.py[1738]: usb: INFO - usb_base.update_usb_psi_info[550] Publishing Mocked USB PSI Info on Qemu <NL> 2024-07-31 08:16:15,054 swdllite(int): INFO - swdllited_int.start_event_fn[43] starting the swdllite interface agent <NL> 2024-07-31 08:16:15,203 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:16:15,290 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:16:15,394 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:15,421 swdllite(int): INFO - fsm.log[312] LOGFSM: RUNNING_EVT -> INITIAL_STATE -> RUNNING_STATE <NL> 2024-07-31 08:16:15,729 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:16:15,605 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  199.613868] usb_script_handler.py[1738]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> 2024-07-31 08:16:15,755 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:15,943 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:15,944 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> [  200.026275] usb_script_handler.py[1738]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> 2024-07-31 08:16:16,238 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:16:16,239 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  200.168266] fujitsu-check-ssh-host-key.pl[2056]: Checking system account status... <NL> [  200.208494] fujitsu-check-ssh-host-key.pl[2056]: System account found... <NL> [  200.236731] fujitsu-check-ssh-host-key.pl[2056]: 3004 <NL> [  200.272296] fujitsu-check-ssh-host-key.pl[2056]: /bin/bash <NL> [  200.483116] fujitsu-check-ssh-host-key.pl[2056]: /home/system exists <NL> [  200.610245] fujitsu-check-ssh-host-key.pl[2056]: Checking for trib... <NL> [  200.719031] fujitsu-check-ssh-host-key.pl[2056]: Checking for PIU ... <NL> [  200.895862] fujitsu-check-ssh-host-key.pl[2056]: slot number (0) is not a PIU."}
{"timestamp_utc": "2024-07-31T08:16:19.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  201.001622] fujitsu-check-ssh-host-key.pl[2056]: Trib check done. <NL> 2024-07-31 08:16:17,282 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:17,427 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  201.564987] usb_script_handler.py[2046]: 2024-Jul-31 08:16:11CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:17,677 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:16:17,875 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  201.892836] usb_script_handler.py[2046]: 2024-Jul-31 08:16:14CommClient::CommClient Connection refused <NL> [  201.899104] usb_script_handler.py[2046]: 2024-Jul-31 08:16:16CommClient::CommClient Connection refused"}
{"timestamp_utc": "2024-07-31T08:16:20.298Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:20 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:20.555Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:16:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:20.811Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:20 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:22.198Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:22 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:24.713Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  196.964215] python3[2972]: success: command executed <NL> 2024-07-31 08:16:11,364 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:11,364 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> 2024-07-31 08:16:11,486 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> [  197.623749] confd_mgr[3010]: ConfdMgrConf: DB signature is NOT supported <NL> [  197.745712] confd_mgr[3010]: Read reset type failed basic_ios::clear: iostream error <NL> [  197.927678] confd_mgr[3010]: Use reset_type = NONE    rollback_timer = 000000 <NL> 2024-07-31 08:16:11,566 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  198.142319] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 5 <NL> [  198.230277] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  198.321858] python3[2423]: [.754] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  198.364316] layer1_hal[2469]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  198.365656] ntp_oper_data.py[1973]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  198.365791] ntp_oper_data.py[1973]: INFO:root:redundancy status now set to standalone <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  198.856618] ntp_oper_data.py[1973]: INFO:root:Received redundancy topic <NL> [  198.856755] ntp_oper_data.py[1973]: INFO:root:Redundancy status is standalone <NL> [  198.910692] startup_finished.py[2316]: Startup Finished: systemd state is non-Production mode and running <NL> [  198.910857] startup_finished.py[2316]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  198.910934] startup_finished.py[2316]: *****Startup Finished: stopping EOW timer***** <NL> [  198.911787] startup_finished.py[2316]: systemctl stop startup_finished_limit.timer"}
{"timestamp_utc": "2024-07-31T08:16:24.714Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  198.973663] ntputils[1971]: bool NTPServer::handle_command(const string&) <NL> [  198.973964] ntputils[1971]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  198.974106] ntputils[1971]: got Platform::RedundancyMode: WORK <NL> [  199.032436] ntputils[1971]: got Platform::RedundancyStatus: STANDALONE <NL> [  199.032661] ntputils[1971]: my current red mode is: UNKNOWN <NL> [  199.032770] ntputils[1971]: new red mode is: WORK <NL> [  199.032870] ntputils[1971]: my current red status is: STANDALONE <NL> [  199.032947] ntputils[1971]: new red status is: STANDALONE <NL> [  199.033051] ntputils[1971]: red mode change, update: UNKNOWN => WORK <NL> [  199.033129] ntputils[1971]: no active/not-active status change: 0 <NL> [  200.176640] dcn_dns_controller[1604]: subscribe_data Enter main loop <NL> [  200.443694] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 6 <NL> [  201.066483] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  201.073576] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:16:15,210 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  203.670381] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 7 <NL> [  203.815223] confd_mgr[3010]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  203.867185] confd_mgr[3010]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> 2024-07-31 08:16:18,196 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  204.566298] confd_mgr[3152]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:16:18 UTC 2024 <NL> [  205.019702] confd_mgr[3186]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  205.229821] confd_mgr[3152]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  205.280466] confd_mgr[3196]: /usr/bin/ui_sys_reset.py NONE <NL> [  205.998251] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  205.998519] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  206.414940] layer1_control_layer[2425]: DIP entity prov dump <NL> [  206.484865] txid_tracker[2883]: ::::create_confd_subscription_connection() try number 8 <NL> [  207.542793] layer1_control_layer[2425]: EsalConfig::EsalConfig main 1 <NL> [  207.555520] layer1_control_layer[2425]: EsalConfig::EsalConfig trib 0 <NL> [  207.555669] layer1_control_layer[2425]: EsalConfig::EsalConfig ciRole 0 <NL> [  207.698732] layer1_control_layer[2425]: EsalConfig is not running inside container. <NL> [  208.257476] hrtimer: interrupt took 32740 ns <NL> [  207.917649] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  208.128458] python3[2423]: [.851] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  208.396651] layer1_control_layer[2425]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  208.429226] layer1_control_layer[2425]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  208.459196] layer1_control_layer[2425]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  208.521622] layer1_control_layer[2425]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  208.538756] layer1_control_layer[2425]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  208.568262] layer1_control_layer[2425]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  208.625608] layer1_control_layer[2425]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  208.756368] layer1_control_layer[2425]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  208.807634] layer1_control_layer[2425]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  208.816215] layer1_control_layer[2425]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  208.844182] layer1_control_layer[2425]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  208.845284] layer1_control_layer[2425]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  209.056484] layer1_control_layer[2425]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  209.192331] layer1_control_layer[2425]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  209.401370] layer1_control_layer[2425]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  209.600238] layer1_control_layer[2425]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  209.659438] layer1_control_layer[2425]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  209.662113] confd_mgr[3216]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  209.837420] confd_mgr[3216]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  209.838272] confd_mgr[3217]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  209.838354] confd_mgr[3217]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  209.838638] confd_mgr[3218]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  209.838732] confd_mgr[3218]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  209.839233] confd_mgr[3198]: DDS Peristency is enabled <NL> [  209.839312] confd_mgr[3198]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  209.839390] confd_mgr[3198]: (ui-sys-reset) Running /bin/df -h /home/..."}
{"timestamp_utc": "2024-07-31T08:16:25.275Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:25.837Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:25 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> 2024-07-31 08:16:12,438 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:12,573 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  198.965513] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  199.900838] ntputils[1725]: systemctl --no-block start ntpd <NL> 2024-07-31 08:16:13,169 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6664 <NL> 2024-07-31 08:16:13,296 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:13,616 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  200.069783] ntputils[1725]: child pid is 1929 <NL> 2024-07-31 08:16:13,964 swdllite(int): INFO - swdllited_int.send_restart_notification_fn[31] sending INTERFACE_RESTART to tcp://localhost:6662 <NL> 2024-07-31 08:16:14,082 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  200.724641] ntputils[1725]: exited, status is 0 <NL> [  201.315466] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  201.493640] ntputils[1725]: /bin/systemctl reset-failed init_state_check.timer <NL> 2024-07-31 08:16:15,316 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  201.748416] ntputils[1725]: child pid is 1932 <NL> [  201.923148] ntputils[1725]: exited, status is 0 <NL> 2024-07-31 08:16:15,842 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:15,912 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  202.372055] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:16:16,300 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:16:16,433 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> [  202.828462] ntputils[1725]: /bin/systemctl --no-block start init_state_check.timer <NL> 2024-07-31 08:16:16,950 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:16:17,237 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  203.877182] ntputils[1725]: child pid is 1935 <NL> 2024-07-31 08:16:17,919 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> 2024-07-31 08:16:17,947 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> [  204.381565] ntputils[1725]: exited, status is 0 <NL> [  204.744229] ntputils[1725]: server.InitDaemon <NL> 2024-07-31 08:16:18,244 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> 2024-07-31 08:16:18,474 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> [  204.814309] ntputils[1725]: int NTPServer::platformdds_listen()"}
{"timestamp_utc": "2024-07-31T08:16:25.838Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:16:18,678 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> [  205.858361] ntputils[1725]: void NTPServer::poller() <NL> 2024-07-31 08:16:19,702 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  206.245630] ntputils[1725]: void NTPServer::late_joiner() <NL> 2024-07-31 08:16:20,299 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  206.644810] ntputils[1725]: bool NTPServer::handle_command(const string&) <NL> 2024-07-31 08:16:20,352 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> [  206.700032] ntputils[1725]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  206.700776] ntputils[1725]: got Platform::RedundancyMode: UNKNOWN <NL> [  206.711248] ntputils[1725]: got Platform::RedundancyStatus: STANDALONE <NL> [  206.722577] ntputils[1725]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:16:20,367 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> [  206.796227] ntputils[1725]: new red mode is: UNKNOWN <NL> [  206.893173] ntputils[1725]: my current red status is: active <NL> 2024-07-31 08:16:20,607 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  206.944178] ntputils[1725]: new red status is: STANDALONE <NL> [  206.950065] ntputils[1725]: received unknown! <NL> 2024-07-31 08:16:20,699 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> [  207.130099] ntputils[1725]: new red mode is: UNKNOWN <NL> 2024-07-31 08:16:20,835 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> 2024-07-31 08:16:21,139 swdllite(mgr): INFO - swdl_state_confdmgr.confdmgr_notify_wait_fn[81] mgr_confdmgr_state: confdmgr notification suppressed, OrderedDict([('mode', 'NORMAL'), ('status', 'SUCCESS'), ('rdm-status', 'STANDALONE')]) <NL> [  207.760880] ntputils[1725]: new red status is: STANDALONE <NL> 2024-07-31 08:16:21,779 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> [  208.369961] ntputils[1725]: red status change, update active => STANDALONE <NL> 2024-07-31 08:16:22,066 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  208.715008] ntputils[1725]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:22,400 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> [  208.834424] ntputils[1725]: bool NTPServer::handle_command(const string&) <NL> 2024-07-31 08:16:22,422 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> 2024-07-31 08:16:22,634 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:22,798 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> [  209.118197] ntputils[1725]: bool NTPServer::handle_redundancy_topic(const string&) <NL> 2024-07-31 08:16:22,978 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  209.446930] ntputils[1725]: got Platform::RedundancyMode: UNKNOWN <NL> 2024-07-31 08:16:23,128 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:16:23,240 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  209.700665] ntputils[1725]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:16:23,523 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:23,747 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  210.270448] ntputils[1725]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:16:24,236 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  211.069864] ntputils[1725]: new red mode is: UNKNOWN <NL> [  211.357866] ntputils[1725]: my current red status is: STANDALONE <NL> [  211.358703] ntputils[1725]: new red status is: STANDALONE <NL> [  211.359381] ntputils[1725]: received unknown! <NL> [  211.360050] ntputils[1725]: new red mode is: UNKNOWN <NL> [  211.360661] ntputils[1725]: new red status is: STANDALONE <NL> 2024-07-31 08:16:25,072 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY"}
{"timestamp_utc": "2024-07-31T08:16:27.203Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:27 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:29.134Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  196.909945] python3[2425]: [.699] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  196.910075] python3[2425]: [.699] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  196.910156] python3[2425]: [.747] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.910220] python3[2425]: [.747] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  196.910300] python3[2425]: [.747] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.910363] python3[2425]: [.762] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.910436] python3[2425]: [.764] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  196.910499] python3[2425]: [.764] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  196.910561] python3[2425]: [.768] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  196.910624] python3[2425]: [.769] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  196.910688] python3[2425]: [.769] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.910755] python3[2425]: [.769] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  196.910856] python3[2425]: [.769] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  196.910926] python3[2425]: [.059] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.911015] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  196.911611] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  196.911681] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  196.918864] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'}"}
{"timestamp_utc": "2024-07-31T08:16:29.135Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  196.919031] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  196.919118] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  196.919198] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  196.919276] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  196.919352] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  196.919430] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  196.919528] python3[2425]: [.060] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  196.919607] python3[2425]: [.082] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  196.919696] python3[2425]: [.082] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  196.919775] python3[2425]: [.082] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  197.282498] python3[2425]: [.082] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  197.401401] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  197.483784] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  197.496318] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  197.536531] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  197.538252] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  197.590288] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  197.590395] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  197.590483] python3[2425]: [.336] hookhdlr 140460325144384 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  197.590580] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  197.590663] python3[2425]: [.337] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  198.137789] python3[2589]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  198.138038] python3[2589]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  198.138189] python3[2589]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  198.138282] python3[2589]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  198.138359] python3[2589]: max_slotNumber=5 <NL> [  198.680656] txid_tracker[2458]: ::::create_confd_subscription_connection() try number 8 <NL> [  201.723672] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  201.723860] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  202.829600] layer1_control_layer[2444]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  203.391618] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 1 <NL> [  206.637134] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 2 <NL> [  206.754240] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  206.754533] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  207.040145] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  207.173417] python3[2425]: [.364] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  209.419327] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 3 <NL> [  210.219079] python3[2939]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  210.240773] python3[2939]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  210.248834] python3[2939]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  210.301506] python3[2939]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  210.318547] python3[2939]: max_slotNumber=5 <NL> [  210.347447] python3[2939]:  prov channel is 127.0.0.1:10000 <NL> [  210.405173] python3[2939]: success: command executed <NL> [  210.727316] layer1_hal[2471]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  211.775032] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:16:31.023Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:30 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:32.390Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:32 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:35.666Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:16:35 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:35.921Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:35 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:37.286Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:37 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:37.848Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:16:17,947 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:18,230 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:16:18,876 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:16:18,966 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, VALIDATE <NL> [  202.992312] usb_script_handler.py[2046]: 2024-Jul-31 08:16:18CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:19,196 swdllite(agt): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  203.220361] startup[2084]: Startup, World! <NL> 2024-07-31 08:16:19,469 swdllite(agt): INFO - swdl_state_manager.disconnect[46] state manager disconnect"}
{"timestamp_utc": "2024-07-31T08:16:37.849Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:16:19,222 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=VALIDATE <NL> [  203.525947] startup[2084]: Cmd arg set to loop 1 <NL> 2024-07-31 08:16:20,010 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:20,012 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=RESET <NL> 2024-07-31 08:16:20,035 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> 2024-07-31 08:16:20,052 swdllite(mgr): INFO - swdl_mgr_discovery.discovery_check_trigger_fn[121] discovery_check_trigger_fn <NL> 2024-07-31 08:16:20,063 swdllite(mgr): INFO - swdl_mgr_fn.normal_ready_transition_fn[527] software signature match <NL> 2024-07-31 08:16:20,326 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:16:20,508 swdllite(mgr): INFO - swdl_state_confdmgr.confdmgr_notify_wait_fn[81] mgr_confdmgr_state: confdmgr notification suppressed, OrderedDict([('mode', 'NORMAL'), ('status', 'SUCCESS'), ('rdm-status', 'STANDALONE')]) <NL> 2024-07-31 08:16:21,040 swdllite(agt): INFO - swdl_state_manager.connect[35] state manager connect <NL> [  205.228018] usb_script_handler.py[2046]: 2024-Jul-31 08:16:20CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:21,900 swdllite(agt): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6665') <NL> [  205.885607] startup_finished.py[2080]: *****Startup Finished Monitor:Starting the event loop***** <NL> 2024-07-31 08:16:22,260 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  206.480294] ains_manager[2081]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:16:22,625 swdllite(agt): INFO - swdl_state_confdmgr.replay[190] agent_confdmgr_state: role=local_agent, action=REPLAY <NL> 2024-07-31 08:16:23,023 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  206.977064] usb_script_handler.py[2046]: 2024-Jul-31 08:16:23CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:23,651 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE <NL> 2024-07-31 08:16:23,862 swdllite(mgr): INFO - fsm.log[312] LOGFSM: SSW_OK_EVT -> STARTUP_STATE -> normal_ready_transition_fn -> READY_STATE <NL> 2024-07-31 08:16:23,993 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:24,535 swdllite(mgr): INFO - swdl_main_fsm_fn.ready_entry_fn[489] ready_entry_fn called <NL> 2024-07-31 08:16:25,453 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  209.446380] usb_script_handler.py[2046]: 2024-Jul-31 08:16:25CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:25,592 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> 2024-07-31 08:16:25,760 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"VALIDATE\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:26,574 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> [  211.063802] usb_script_handler.py[2046]: 2024-Jul-31 08:16:27CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:27,565 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:16:28,310 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:16:28,729 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  213.612607] usb_script_handler.py[2046]: 2024-Jul-31 08:16:29CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:29,897 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:16:30,896 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> 2024-07-31 08:16:31,222 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> 2024-07-31 08:16:31,420 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:16:31,488 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  215.456095] usb_script_handler.py[2046]: 2024-Jul-31 08:16:31CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:31,658 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:16:31,778 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> 2024-07-31 08:16:31,786 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:16:31,802 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> 2024-07-31 08:16:31,869 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:16:32,060 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> 2024-07-31 08:16:32,117 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:16:33,194 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> 2024-07-31 08:16:33,736 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  217.756464] dcn_dns_controller[1387]: dnsClientStartup() <NL> [  218.843233] dcn_dns_controller[1387]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  219.046433] dcn_dns_controller[1387]: fin_dnsmasq_conf is open <NL> [  219.164983] usb_script_handler.py[2046]: 2024-Jul-31 08:16:34CommClient::CommClient Connection refused <NL> 2024-07-31 08:16:34,935 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  219.210211] usb_script_handler.py[2046]: Exception: Connect failed <NL> 2024-07-31 08:16:35,365 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0"}
{"timestamp_utc": "2024-07-31T08:16:40.366Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:40 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:40.622Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:16:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:40.877Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:40 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:42.241Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:42 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:43.605Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  209.839450] confd_mgr[3198]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  209.839510] confd_mgr[3198]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  209.873690] confd_mgr[3196]: /usr/bin/dbrestore_no.py <NL> [  209.992767] confd_mgr[3226]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  210.122849] confd_mgr[3010]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  210.131234] confd_mgr[3010]: entering: wait_for_alarm_event <NL> [  210.131333] confd_mgr[3010]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  210.139619] confd_mgr[3010]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  210.139841] confd_mgr[3010]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  210.139933] confd_mgr[3010]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  210.139997] confd_mgr[3010]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  210.146566] confd_mgr[3010]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  210.147160] confd_mgr[3010]: entering: at_sm::wait_for_SWDL <NL> [  210.147296] confd_mgr[3010]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  210.147389] confd_mgr[3010]: ha_sm : wait_for_SWDL_s timer is set <NL> [  210.487960] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  210.501378] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  210.501567] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  210.664626] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  210.664751] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  210.664845] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  210.664935] confd_mgr[3010]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  210.665070] confd_mgr[3010]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  211.046642] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  211.086758] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  211.087650] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 1 <NL> [  213.916729] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 2 <NL> [  214.272258] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3264 <NL> [  215.522775] confd_mgr[3241]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'NONE', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  215.881547] confd_mgr[3010]: ConfdMgrConf::reload: DB signature set to false <NL> [  215.881735] confd_mgr[3010]: is_swdl_alarm_0 <NL> [  215.888183] confd_mgr[3010]: sdb_restore_= 0 <NL> [  215.888278] confd_mgr[3010]: swdl_alarm_ = NONE <NL> [  215.888367] confd_mgr[3010]: swdl_alarm_tag_ = <NL> [  215.888454] confd_mgr[3010]: swdl status = SUCCESS <NL> [  215.888603] confd_mgr[3010]: is_swdl_in_swupgrade = 0 <NL> [  215.888684] confd_mgr[3010]: is_swdl_alarm_0 <NL> [  215.888757] confd_mgr[3010]: sdb_restore_= 0 <NL> [  215.888858] confd_mgr[3010]: swdl_alarm_ = NONE <NL> [  215.888939] confd_mgr[3010]: swdl_alarm_tag_ = <NL> [  215.889028] confd_mgr[3010]: swdl status = SUCCESS <NL> [  215.889102] confd_mgr[3010]: is_swdl_in_swupgrade = 0 <NL> [  215.889177] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  215.941218] confd_mgr[3239]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  215.941423] confd_mgr[3010]: main::/run/rdm_status.sh found. Invoking it. <NL> [  216.014664] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  216.069381] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  216.073724] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  216.105904] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  216.618355] confd_mgr[3010]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  216.797750] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  216.864635] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  217.090384] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  217.122842] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd"}
{"timestamp_utc": "2024-07-31T08:16:43.606Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  217.162549] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  217.201501] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  217.201617] confd_mgr[3010]: ConfdMgrConf::reload: DB signature set to false <NL> [  217.201699] confd_mgr[3010]: confd_db_init::sConfd_db_init_executed_=false <NL> [  217.201789] confd_mgr[3010]: ConfdMgrConf::reload: DB signature set to false <NL> [  217.210617] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 3 <NL> [  217.653471] systemd-journald[359]: Data hash table of /run/log/journal/12df99ced2034c9fba488a3b06dd9477/system.journal has a fill level at 75.0 (13654 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  217.790315] systemd-journald[359]: /run/log/journal/12df99ced2034c9fba488a3b06dd9477/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  217.905882] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  217.906122] python3[2423]: [.870] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  219.884230] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 4 <NL> [  221.016969] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  221.017314] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  221.835054] confd_mgr[3387]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  221.904412] confd_mgr[3290]: build /etc/confd/confd.conf.bank0 NONE <NL> [  222.862008] systemd-sysv-generator[3405]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  222.882665] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 5 <NL> [  223.120780] confd_mgr[3290]: /etc/confd/default_backup.dbs <NL> [  223.121730] confd_mgr[3290]: Create default DB in bank0 <NL> [  225.900530] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 6 <NL> [  226.065395] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  226.065694] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  227.927277] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  227.928108] python3[2423]: [.902] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  229.057468] tun: Universal TUN/TAP device driver, 1.6 <NL> [  228.917234] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 7 <NL> [  229.179448] confd_mgr[3010]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  229.179646] confd_mgr[3010]: confd_db_init::RESET REASON IS NONE <NL> [  229.179762] confd_mgr[3010]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  229.188402] confd_mgr[3010]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  229.188540] confd_mgr[3010]: ha_sm leaving: wait_for_SWDL_s <NL> [  229.188640] confd_mgr[3010]: ha_sm entering: no_ha_s"}
{"timestamp_utc": "2024-07-31T08:16:44.970Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  211.776810] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:16:29,177 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:29,183 swdllite(agt): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  212.936841] dcn_ka[1603]: KaSessMgr Process Startup <NL> 2024-07-31 08:16:29,388 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:16:29,805 swdllite(mgr): INFO - swdllited_base_utils.handle_redundancy_topic[70] unknown status: standalone, don't process any event <NL> [  213.540942] dcn_dns_controller[1601]: dnsClientStartup() <NL> [  213.611994] dcn_dns_controller[1601]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  213.612194] dcn_dns_controller[1601]: fin_dnsmasq_conf is open <NL> [  213.615048] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 4 <NL> [  213.718352] confd_mgr[3001]: ConfdMgrConf: DB signature is NOT supported <NL> [  213.718658] confd_mgr[3001]: Read reset type failed basic_ios::clear: iostream error <NL> [  213.718797] confd_mgr[3001]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  213.719646] ntp_oper_data.py[1976]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  213.719787] ntp_oper_data.py[1976]: INFO:root:redundancy status now set to standalone"}
{"timestamp_utc": "2024-07-31T08:16:44.971Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  213.719893] ntp_oper_data.py[1976]: INFO:root:Received redundancy topic <NL> [  213.719989] ntp_oper_data.py[1976]: INFO:root:Redundancy status is standalone <NL> [  213.822388] ntputils[1975]: bool NTPServer::handle_command(const string&) <NL> [  213.921290] ntputils[1975]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  213.921393] ntputils[1975]: got Platform::RedundancyMode: WORK <NL> [  213.921471] ntputils[1975]: got Platform::RedundancyStatus: STANDALONE <NL> [  213.921542] ntputils[1975]: my current red mode is: UNKNOWN <NL> [  213.921612] ntputils[1975]: new red mode is: WORK <NL> [  213.921687] ntputils[1975]: my current red status is: STANDALONE <NL> [  213.921848] ntputils[1975]: new red status is: STANDALONE <NL> [  213.921950] ntputils[1975]: red mode change, update: UNKNOWN => WORK <NL> [  213.922054] ntputils[1975]: no active/not-active status change: 0 <NL> [  215.411764] startup_finished.py[2305]: Startup Finished: systemd state is non-Production mode and running <NL> [  215.465819] startup_finished.py[2305]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  215.503311] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 5 <NL> [  215.990736] startup_finished.py[2305]: *****Startup Finished: stopping EOW timer***** <NL> [  216.853487] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  216.853829] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  217.211194] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  217.211393] python3[2425]: [.424] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  217.225962] startup_finished.py[2305]: systemctl stop startup_finished_limit.timer <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  218.075700] dcn_dns_controller[1601]: subscribe_data Enter main loop <NL> Exception: Connect failed <NL> [  218.470723] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 6 <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  219.696272] confd_mgr[3001]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  219.700712] confd_mgr[3001]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  219.820853] confd_mgr[3120]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:16:36 UTC 2024 <NL> 2024-07-31 08:16:36,831 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> 2024-07-31 08:16:37,433 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  221.473116] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 7 <NL> [  221.790276] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  221.790554] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  221.855817] confd_mgr[3161]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  222.720289] confd_mgr[3120]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  222.835284] confd_mgr[3185]: /usr/bin/ui_sys_reset.py NONE <NL> [  224.492111] txid_tracker[2897]: ::::create_confd_subscription_connection() try number 8 <NL> [  225.877952] layer1_control_layer[2444]: DIP entity prov dump <NL> [  226.584638] layer1_control_layer[2444]: EsalConfig::EsalConfig main 1 <NL> [  226.861295] layer1_control_layer[2444]: EsalConfig::EsalConfig trib 0 <NL> [  226.861419] layer1_control_layer[2444]: EsalConfig::EsalConfig ciRole 0 <NL> [  226.910201] confd_mgr[3206]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  226.910454] confd_mgr[3206]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  226.911306] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  226.962635] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  226.963043] confd_mgr[3207]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  226.963141] confd_mgr[3207]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  226.964488] confd_mgr[3211]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  226.964634] confd_mgr[3211]: /dev/root       2.2G  1.8G  309M  86% / <NL> [  226.965131] confd_mgr[3186]: DDS Peristency is enabled <NL> [  227.021879] confd_mgr[3186]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  227.121097] confd_mgr[3186]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  227.121201] confd_mgr[3186]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  227.121282] confd_mgr[3186]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  227.128341] layer1_control_layer[2444]: EsalConfig is not running inside container. <NL> [  227.131428] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  227.135350] python3[2425]: [.509] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  227.201344] confd_mgr[3185]: /usr/bin/dbrestore_no.py <NL> [  227.220707] layer1_control_layer[2444]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  227.220925] layer1_control_layer[2444]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  227.221030] layer1_control_layer[2444]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  227.221104] layer1_control_layer[2444]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  227.221235] layer1_control_layer[2444]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  227.221317] layer1_control_layer[2444]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  227.221397] layer1_control_layer[2444]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  227.221476] layer1_control_layer[2444]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  227.221554] layer1_control_layer[2444]: isFileValid /var/shared/commsOscMode.conf  returning 1"}
{"timestamp_utc": "2024-07-31T08:16:45.533Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:16:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:45.789Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:45 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:47.179Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:16:47.435Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:47 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:51.631Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:16:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:50 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:52.558Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:52 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:55.841Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:16:55 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',) <NL> # 03:16:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:55 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:56.768Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  157.240606] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.213223, delay 0.06342\\n31 Jul 08:15:31 ntpdate[2357]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:15:32,054 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:15:32,144 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":2} <NL> 2024-07-31 08:15:32,312 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:15:32,705 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:15:32,771 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:15:32,771 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:32,772 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> openDdsPorts interfaces  eth1.2003 <NL> 2024-07-31 08:15:32,827 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:15:32,900 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:15:32,901 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:15:32,901 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:32,902 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:32,902 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:15:32,906 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> REPO_REPL_EVT <NL> 2024-07-31 08:15:33,098 swdllite(agt): ERROR - swdl_agent_repo_repl.replicate[400] error(1): error: missing config <NL> 2024-07-31 08:15:33,099 swdllite(agt): ERROR - swdl_agent_staging.repo_repl_fn[400] non-recoverable error encountered <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161"}
{"timestamp_utc": "2024-07-31T08:16:56.769Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "2024-07-31 08:15:35,259 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:15:35,260 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:15:35,266 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  165.831663] python3[2465]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  165.831970] python3[2465]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  165.832083] python3[2465]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  165.832174] python3[2465]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  165.832252] python3[2465]: max_slotNumber=5 <NL> [  165.832322] python3[2465]:  prov channel is 127.0.0.1:10000 <NL> [  165.832402] python3[2465]: success: command executed <NL> [  165.852824] layer1_hal[2094]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  165.996491] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2451 <NL> 2024-07-31 08:15:41,355 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:15:41,355 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  169.279565] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  169.279897] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  169.279979] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.212424, delay 0.03757\\n31 Jul 08:15:43 ntpdate[2507]: no server suitable for synchronization found\\n' <NL> [  181.257515] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  181.264170] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  181.265215] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.224088, delay 0.04001\\n31 Jul 08:15:55 ntpdate[2546]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  193.495301] hrtimer: interrupt took 3208798 ns <NL> [  193.287711] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  193.288732] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  193.301127] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.226967, delay 0.06476\\n31 Jul 08:16:07 ntpdate[2605]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:16:18,878 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  205.326903] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  205.340116] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  205.365376] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.228382, delay 0.04820\\n31 Jul 08:16:19 ntpdate[2634]: no server suitable for synchronization found\\n' <NL> [  217.410838] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  217.430889] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  217.431940] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.218977, delay 0.04134\\n31 Jul 08:16:31 ntpdate[2668]: no server suitable for synchronization found\\n' <NL> [  229.263521] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  229.264576] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  229.273266] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.216044, delay 0.04506\\n31 Jul 08:16:43 ntpdate[2695]: no server suitable for synchronization found\\n' <NL> [  241.369338] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  241.392161] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:16:57.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:16:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:16:57 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:16:58.749Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  119.027242] fujitsu-check-ssh-host-key.pl[1930]: /dev/root       2.2G  1.8G  311M  86% / <NL> 2024-07-31 08:14:53,068 swdllite(agt): INFO - swdl_base_fsm_fn.unknown_evt_fn[191] FSM rcvd UNKNOWN event INTERFACE_CONNECTED_EVT in state STARTUP_STATE"}
{"timestamp_utc": "2024-07-31T08:16:58.750Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  119.362572] fujitsu-check-ssh-host-key.pl[1933]: useradd: user 'fujitsu' already exists <NL> [  120.786573] fujitsu-check-ssh-host-key.pl[1909]: DDS Peristency is enabled <NL> [  120.817573] fujitsu-check-ssh-host-key.pl[1909]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  120.879018] fujitsu-check-ssh-host-key.pl[1909]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  120.890859] fujitsu-check-ssh-host-key.pl[1909]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  120.902235] fujitsu-check-ssh-host-key.pl[1909]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  120.928266] fujitsu-check-ssh-host-key.pl[1909]: Factory user shell set to /bin/bash <NL> [  121.038387] fujitsu-check-ssh-host-key.pl[1893]: Converting fujitsu user to bash shell... <NL> [  121.103172] fujitsu-check-ssh-host-key.pl[1997]: usermod: no changes <NL> [  121.104948] fujitsu-check-ssh-host-key.pl[1893]: Lock Root account in TRIB... <NL> [  121.220232] fujitsu-check-ssh-host-key.pl[1998]: Running lock on root account... <NL> [  121.898411] fujitsu-check-ssh-host-key.pl[2000]: passwd: password changed. <NL> [  121.966756] fujitsu-check-ssh-host-key.pl[1893]: Trib check done. <NL> [  122.837870] startup[2022]: Startup, World! <NL> [  122.838144] startup[2022]: Cmd arg set to loop 1 <NL> [  123.311835] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  123.312176] ntputils_client.py[1717]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  123.312346] ntputils_client.py[1717]: b'31 Jul 08:14:57 ntpdate[1849]: no server suitable for synchronization found\\n' <NL> [  123.542818] confd_mgr_action_server[2024]: confd_mgr_action_server::main: Shelf Role = TRIB, Red Mode = UNKNOWN, Shelf number = 1 <NL> [  124.603422] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  124.805602] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  124.225126] sh[2051]: /usr/bin/IpdccAgentPreExec: line 34: echo: write error: Operation not permitted <NL> [  124.317054] sh[2051]: /usr/bin/IpdccAgentPreExec: line 35: echo: write error: Invalid argument <NL> [  126.223629] ains_manager[2019]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  126.387260] zebra[2050]: 2024/07/31 08:15:00 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  127.273019] startup_finished.py[2018]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  129.119666] startup_finished.py[2018]: Startup Finished: systemd state is non-Production mode and running <NL> [  129.139979] startup_finished.py[2018]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  130.319288] startup_finished.py[2018]: *****Startup Finished: stopping EOW timer***** <NL> [  130.852274] startup_finished.py[2018]: systemctl stop startup_finished_limit.timer <NL> [  134.299280] layer1_control_layer[2044]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  136.851373] ains_manager[2307]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  139.973880] layer1_control_layer[2044]: DIP entity prov dump <NL> [  140.138363] layer1_control_layer[2044]: EsalConfig::EsalConfig main 0 <NL> [  140.138632] layer1_control_layer[2044]: EsalConfig::EsalConfig trib 1 <NL> [  140.138709] layer1_control_layer[2044]: EsalConfig::EsalConfig ciRole 0 <NL> [  140.226080] layer1_control_layer[2044]: EsalConfig is not running inside container. <NL> [  140.261657] layer1_control_layer[2044]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  140.315689] layer1_control_layer[2044]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  140.315882] layer1_control_layer[2044]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  140.315968] layer1_control_layer[2044]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  140.316073] layer1_control_layer[2044]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  140.316192] layer1_control_layer[2044]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  140.316266] layer1_control_layer[2044]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  140.316361] layer1_control_layer[2044]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  140.316443] layer1_control_layer[2044]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  140.316514] layer1_control_layer[2044]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  140.316609] layer1_control_layer[2044]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  140.317215] layer1_control_layer[2044]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  140.317295] layer1_control_layer[2044]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  140.317378] layer1_control_layer[2044]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  140.317457] layer1_control_layer[2044]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  140.317525] layer1_control_layer[2044]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  140.317617] layer1_control_layer[2044]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  143.812522] python3[2191]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  143.812808] python3[2191]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  143.812930] python3[2191]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  143.813024] python3[2191]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  143.813103] python3[2191]: max_slotNumber=5 <NL> [  153.728867] python3[2429]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  153.729601] python3[2429]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  153.777118] python3[2429]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  153.777636] python3[2429]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  153.845621] python3[2429]: max_slotNumber=5 <NL> [  153.868083] python3[2429]:  prov channel is 127.0.0.1:10000 <NL> [  153.868267] python3[2429]: success: command executed <NL> [  153.869784] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2353 <NL> [  153.869977] layer1_hal[2055]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> 2024-07-31 08:15:55,238 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=4 <NL> [  195.164566] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  195.165134] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  195.165254] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.038017, delay 0.04958\\n31 Jul 08:16:09 ntpdate[2539]: no server suitable for synchronization found\\n' <NL> [  207.476406] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  207.477023] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  207.477151] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.044004, delay 0.06491\\n31 Jul 08:16:21 ntpdate[2558]: no server suitable for synchronization found\\n' <NL> [  219.315407] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  219.365851] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  219.366266] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.035088, delay 0.03958\\n31 Jul 08:16:33 ntpdate[2586]: no server suitable for synchronization found\\n' <NL> [  231.201487] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  231.202430] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  231.204399] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.036333, delay 0.03226\\n31 Jul 08:16:45 ntpdate[2607]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:17:00.640Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:00 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:00.895Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:00.896Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:00 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:02.265Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:02 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:02.869Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  227.221705] layer1_control_layer[2444]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  227.221840] layer1_control_layer[2444]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  227.221920] layer1_control_layer[2444]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  227.222033] layer1_control_layer[2444]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  227.222114] layer1_control_layer[2444]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  227.222196] layer1_control_layer[2444]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  227.222276] layer1_control_layer[2444]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  227.222360] layer1_control_layer[2444]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  227.222611] confd_mgr[3215]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  227.328840] confd_mgr[3001]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  227.405765] confd_mgr[3001]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  227.424838] confd_mgr[3001]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  227.424993] confd_mgr[3001]: entering: wait_for_alarm_event <NL> [  227.425421] confd_mgr[3001]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  227.425507] confd_mgr[3001]: ha_sm : wait_for_SWDL_s timer is set <NL> [  227.454407] confd_mgr[3001]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  227.454931] confd_mgr[3001]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  227.455067] confd_mgr[3001]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  227.455163] confd_mgr[3001]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  227.574111] confd_mgr[3001]: entering: at_sm::wait_for_SWDL <NL> [  227.648510] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  227.648716] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  227.648821] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  227.648896] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  227.648980] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  227.649081] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  227.649151] confd_mgr[3001]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  227.649259] confd_mgr[3001]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  228.901913] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 1 <NL> [  230.136512] confd_mgr[3232]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'NONE', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  230.763479] confd_mgr[3001]: ConfdMgrConf::reload: DB signature set to false <NL> [  230.763694] confd_mgr[3001]: is_swdl_alarm_0 <NL> [  230.763789] confd_mgr[3001]: sdb_restore_= 0 <NL> [  230.763875] confd_mgr[3001]: swdl_alarm_ = NONE <NL> [  230.763963] confd_mgr[3001]: swdl_alarm_tag_ = <NL> [  230.764089] confd_mgr[3001]: swdl status = SUCCESS <NL> [  230.764249] confd_mgr[3001]: is_swdl_in_swupgrade = 0 <NL> [  230.764362] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  230.764465] confd_mgr[3001]: is_swdl_alarm_0 <NL> [  230.764552] confd_mgr[3001]: sdb_restore_= 0 <NL> [  230.764636] confd_mgr[3001]: swdl_alarm_ = NONE <NL> [  230.764722] confd_mgr[3001]: swdl_alarm_tag_ = <NL> [  230.764806] confd_mgr[3001]: swdl status = SUCCESS <NL> [  230.764896] confd_mgr[3001]: is_swdl_in_swupgrade = 0 <NL> [  230.891487] confd_mgr[3230]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  230.891722] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  230.891859] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  230.892217] confd_mgr[3001]: main::/run/rdm_status.sh found. Invoking it. <NL> [  231.217064] confd_mgr[3001]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  231.512392] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  231.512626] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  231.512721] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  231.512806] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  231.512888] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  231.512980] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  231.513083] confd_mgr[3001]: ConfdMgrConf::reload: DB signature set to false <NL> [  231.513901] confd_mgr[3001]: confd_db_init::sConfd_db_init_executed_=false <NL> [  231.535665] confd_mgr[3001]: ConfdMgrConf::reload: DB signature set to false <NL> [  231.894776] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  231.895044] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  231.906081] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 2 <NL> [  231.936351] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3285 <NL> [  232.752201] systemd-journald[360]: Data hash table of /run/log/journal/f38823065b5945208cb896204d6562ff/system.journal has a fill level at 75.0 (13654 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  232.817382] systemd-journald[360]: /run/log/journal/f38823065b5945208cb896204d6562ff/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  234.892976] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 3 <NL> [  236.417206] confd_mgr[3368]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  236.447364] confd_mgr[3277]: build /etc/confd/confd.conf.bank0 NONE <NL> [  236.900132] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  236.900326] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  237.123834] confd_mgr[3277]: /etc/confd/default_backup.dbs <NL> [  237.124065] confd_mgr[3277]: Create default DB in bank0 <NL> [  237.159993] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  237.160493] python3[2425]: [.547] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  237.930448] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 4 <NL> [  238.334998] systemd-sysv-generator[3409]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  240.954858] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 5 <NL> [  241.846946] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  241.914803] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  244.004500] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 6"}
{"timestamp_utc": "2024-07-31T08:17:02.870Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  244.667250] tun: Universal TUN/TAP device driver, 1.6 <NL> [  244.793797] confd_mgr[3001]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  245.111787] confd_mgr[3001]: confd_db_init::RESET REASON IS NONE <NL> [  245.268383] confd_mgr[3001]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  245.268600] confd_mgr[3001]: ha_sm leaving: wait_for_SWDL_s <NL> [  245.268811] confd_mgr[3001]: ha_sm entering: no_ha_s <NL> [  245.268887] confd_mgr[3001]: Start_type: GO_NONE (STANDALONE/WORK)"}
{"timestamp_utc": "2024-07-31T08:17:05.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:05.961Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:05 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:07.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:07 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:11.525Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:10 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:12.451Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:12 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:15.721Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:15 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:15.977Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:15 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:17.341Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:17 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:20.648Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:20 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:20.904Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:20 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:22.791Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:22 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:26.057Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:25 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:27.422Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:27 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:31.586Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:30 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> [  229.188765] confd_mgr[3010]: leaving: at_sm::wait_for_SWDL <NL> [  229.188848] confd_mgr[3010]: entering: at_sm::wait_for_start_bank <NL> [  229.188957] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  229.189045] confd_mgr[3010]: leaving: at_sm::wait_for_start_bank <NL> [  229.189139] confd_mgr[3010]: entering: at_sm_dbready::wait_for_db_status <NL> [  229.189228] confd_mgr[3010]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  229.189302] confd_mgr[3010]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  229.189372] confd_mgr[3010]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  229.286102] confd_mgr[3622]: Executing check_db.sh <NL> [  229.286337] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  229.286453] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  229.304798] confd_mgr[3286]: TRUE <NL> [  229.312044] confd_mgr[3622]: check_db.sh: found xml files <NL> [  229.312221] confd_mgr[3622]: 0 <NL> [  229.312341] confd_mgr[3010]: Found no error <NL> [  229.312417] confd_mgr[3010]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  229.312489] confd_mgr[3010]: cur_gdbissue 24-1-1 gdbissue 24-1-1 rc = 1 <NL> [  229.312591] confd_mgr[3010]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  229.340237] confd_mgr[3010]: L1-BLADE is in the list: L1-BLADE <NL> [  229.340328] confd_mgr[3010]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  229.340402] confd_mgr[3010]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  229.340479] confd_mgr[3010]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  229.340546] confd_mgr[3010]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  229.340617] confd_mgr[3010]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  229.340687] confd_mgr[3010]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  229.340788] confd_mgr[3010]: guard is_db_okay_g: The HA mode is NONE <NL> [  229.340873] confd_mgr[3010]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  229.360430] confd_mgr[3010]: entering: sm_startconfd::start_confd_p0 <NL> [  229.390933] confd_mgr[3010]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  229.561585] confd_mgr[3628]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:16:43 UTC 2024 <NL> [  229.664094] confd_mgr[3010]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  231.098186] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  231.098589] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  231.893750] txid_tracker[3242]: ::::create_confd_subscription_connection() try number 8 <NL> [  235.808636] healthcheck_agt.py[3671]: /bin/sh: line 1: podman: command not found <NL> [  236.073209] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  236.073388] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  236.285442] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 1 <NL> [  237.949204] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  237.949443] python3[2423]: [.923] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  239.319827] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 2 <NL> [  241.076835] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  241.077056] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  242.320726] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 3 <NL> [  245.342643] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 4 <NL> [  246.078685] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  246.079041] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  247.965465] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  247.965697] python3[2423]: [.938] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  248.324665] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 5 <NL> [  251.085256] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  251.085475] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  251.324998] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 6 <NL> [  254.328801] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 7 <NL> [  256.091605] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  256.091834] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  257.342565] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 8 <NL> [  258.027733] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  258.040131] python3[2423]: [.968] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  261.114636] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  261.159410] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  261.655881] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 1 <NL> [  264.723567] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 2 <NL> [  266.106894] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  266.107956] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  267.702660] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 3 <NL> [  268.022143] python3[2423]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  268.081153] python3[2423]: [.997] hookhdlr 140490876737344 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1!"}
{"timestamp_utc": "2024-07-31T08:17:31.587Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  270.737296] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 4 <NL> [  271.109339] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  271.109553] confd_phase_sentry[2430]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f6a420855c7; Failed to connect to ConfD: Connection refused <NL> [  273.817163] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 5 <NL> [  276.133945] confd_phase_sentry[2430]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  276.454512] confd_phase_sentry[2430]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  276.829026] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 6 <NL> [  276.876187] healthcheck_result_display.py[2414]: Traceback (most recent call last): <NL> [  276.876445] healthcheck_result_display.py[2414]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module>"}
{"timestamp_utc": "2024-07-31T08:17:32.512Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:32 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:35.799Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:35 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:36.055Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:35 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:37.417Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:37 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:40.760Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:40 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:17:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:41.015Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:40 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:41.271Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "2024-07-31 08:15:49,270 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:15:49,303 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> 2024-07-31 08:15:49,394 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> 2024-07-31 08:15:49,449 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:15:49,456 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:15:49,459 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> openDdsPorts Input udpPorts-  7650 <NL> 2024-07-31 08:15:49,477 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> openDdsPorts Output udpPorts-  7650 <NL> 2024-07-31 08:15:49,504 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> 2024-07-31 08:15:49,542 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:15:49,551 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:15:49,563 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> 2024-07-31 08:15:49,618 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> REPO_REPL_EVT <NL> 2024-07-31 08:15:49,640 swdllite(agt): ERROR - swdl_agent_repo_repl.replicate[400] error(1): error: missing config <NL> 2024-07-31 08:15:49,659 swdllite(agt): ERROR - swdl_agent_staging.repo_repl_fn[400] non-recoverable error encountered <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:15:50,027 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:15:50,069 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:15:50,145 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> 2024-07-31 08:15:50,172 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:15:50,213 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  179.915047] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  179.915414] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  179.915774] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.379726, delay 0.09183\\n31 Jul 08:15:52 ntpdate[2507]: no server suitable for synchronization found\\n' <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:15:56,315 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:15:56,376 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  192.375047] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  192.375301] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:17:41.272Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  192.375404] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.343087, delay 0.05342\\n31 Jul 08:16:04 ntpdate[2572]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  204.265491] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  204.265807] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  204.265914] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.344713, delay 0.03685\\n31 Jul 08:16:16 ntpdate[2603]: no server suitable for synchronization found\\n' <NL> [  216.469775] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  216.505881] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  216.506073] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.352526, delay 0.06149\\n31 Jul 08:16:28 ntpdate[2639]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:16:35,667 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  228.447467] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  228.447829] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  228.447932] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.347254, delay 0.06833\\n31 Jul 08:16:40 ntpdate[2677]: no server suitable for synchronization found\\n' <NL> [  240.382047] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  240.382613] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  240.382706] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.366170, delay 0.06981\\n31 Jul 08:16:52 ntpdate[2707]: no server suitable for synchronization found\\n' <NL> [  252.467691] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  252.468397] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  252.468485] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.350273, delay 0.05759\\n31 Jul 08:17:04 ntpdate[2760]: no server suitable for synchronization found\\n' <NL> [  264.385222] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  264.385778] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  264.385876] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.348303, delay 0.05040\\n31 Jul 08:17:16 ntpdate[2788]: no server suitable for synchronization found\\n' <NL> [  276.316215] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  276.329794] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  276.330141] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.336213, delay 0.05458\\n31 Jul 08:17:28 ntpdate[2814]: no server suitable for synchronization found\\n' <NL> [  288.138928] ntputils_client.py[1708]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:17:42.636Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:42 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:43.197Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  211.509718] ntputils[1725]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:25,276 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:25,970 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> 2024-07-31 08:16:26,151 swdllite(agt): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0"}
{"timestamp_utc": "2024-07-31T08:17:43.198Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:16:26,358 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:26,310 swdllite(mgr): ERROR - swdl_check_integrity.is_repository_empty[499] empty repository <NL> [  212.875568] fujitsu-check-ssh-host-key.pl[2010]: Checking system account status... <NL> 2024-07-31 08:16:26,737 swdllite(mgr): INFO - swdl_check_integrity.validate_repository[555] swdl_check_integrity.validate_repository: /var/swdl/repository/active, result=MISSING <NL> [  213.168439] fujitsu-check-ssh-host-key.pl[2010]: System account found... <NL> 2024-07-31 08:16:27,109 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  213.545226] fujitsu-check-ssh-host-key.pl[2010]: 3004 <NL> [  213.722865] fujitsu-check-ssh-host-key.pl[2010]: /bin/bash <NL> [  213.723612] fujitsu-check-ssh-host-key.pl[2010]: /home/system exists <NL> 2024-07-31 08:16:27,452 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:16:27,514 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  213.902936] fujitsu-check-ssh-host-key.pl[2010]: Checking for trib... <NL> 2024-07-31 08:16:27,872 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> [  214.336292] fujitsu-check-ssh-host-key.pl[2010]: Checking for PIU ... <NL> 2024-07-31 08:16:27,872 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  214.483534] fujitsu-check-ssh-host-key.pl[2010]: slot number (0) is not a PIU. <NL> 2024-07-31 08:16:28,107 swdllite(mgr): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn -> SSW_PUBLISH_EVT <NL> [  215.341738] fujitsu-check-ssh-host-key.pl[2010]: Trib check done. <NL> 2024-07-31 08:16:28,235 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> 2024-07-31 08:16:29,828 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  222.042287] ntp_oper_data.py[1726]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  222.989803] ntp_oper_data.py[1726]: INFO:root:redundancy status now set to standalone <NL> [  223.606747] ntp_oper_data.py[1726]: INFO:root:Received redundancy topic <NL> 2024-07-31 08:16:37,583 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  225.093821] ntp_oper_data.py[1726]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:16:39,279 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:16:40,397 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  228.259634] ntputils[1725]: bool NTPServer::handle_command(const string&)[  232.741950] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  233.357677] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> 2024-07-31 08:16:46,203 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  233.928856] ntputils[1725]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  234.838844] ntputils[1725]: got Platform::RedundancyMode: WORK <NL> 2024-07-31 08:16:48,506 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  235.628062] ntputils[1725]: got Platform::RedundancyStatus: STANDALONE <NL> 2024-07-31 08:16:52,211 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:16:52,893 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  239.563956] ntputils[1725]: my current red mode is: UNKNOWN <NL> 2024-07-31 08:17:00,467 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  248.488246] ntputils[1725]: new red mode is: WORK <NL> [  253.451773] ntputils[1725]: my current red status is: STANDALONE <NL> 2024-07-31 08:17:07,385 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  254.589117] ntputils[1725]: new red status is: STANDALONE <NL> [  255.432404] ntputils[1725]: red mode change, update: UNKNOWN => WORK <NL> 2024-07-31 08:17:08,863 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> [  256.439104] ntputils[1725]: no active/not-active status change: 0 <NL> 2024-07-31 08:17:11,128 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:17:13,332 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:17:18,426 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  265.417980] ains_manager[2041]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:17:22,647 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  269.287817] ains_manager[2161]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> 2024-07-31 08:17:25,271 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  274.985798] startup_finished.py[2040]: *****Startup Finished Monitor:Starting the event loop***** <NL> [  277.711976] startup[2046]: Startup, World! <NL> 2024-07-31 08:17:31,539 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  279.100675] startup[2046]: Cmd arg set to loop 1 <NL> 2024-07-31 08:17:35,254 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:17:38,060 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  284.529154] trb-cdsf-app[2115]: DDD cdsf-app running <NL> 2024-07-31 08:17:38,934 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:17:39,193 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> 2024-07-31 08:17:40,309 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  287.053638] cia_control_layer[2116]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:17:41,880 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  288.421886] sncp_app[2118]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:17:42,050 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0"}
{"timestamp_utc": "2024-07-31T08:17:45.713Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:17:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:17:45.968Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:45 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:47.867Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:47 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:49.765Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  245.268984] confd_mgr[3001]: leaving: at_sm::wait_for_SWDL <NL> [  245.269070] confd_mgr[3001]: entering: at_sm::wait_for_start_bank <NL> [  245.269141] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  245.275453] confd_mgr[3272]: TRUE <NL> [  245.491035] confd_mgr[3001]: leaving: at_sm::wait_for_start_bank <NL> [  245.505823] confd_mgr[3001]: entering: at_sm_dbready::wait_for_db_status <NL> [  245.506034] confd_mgr[3001]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  245.506225] confd_mgr[3001]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  245.506362] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  245.507447] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  245.630831] confd_mgr[3605]: Executing check_db.sh <NL> [  245.711311] confd_mgr[3001]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  245.772176] confd_mgr[3605]: check_db.sh: found xml files <NL> [  245.772396] confd_mgr[3605]: 0 <NL> [  245.829580] confd_mgr[3001]: Found no error <NL> [  245.829746] confd_mgr[3001]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  245.829822] confd_mgr[3001]: cur_gdbissue 24-1-1 gdbissue 24-1-1 rc = 1 <NL> [  245.829894] confd_mgr[3001]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  245.829966] confd_mgr[3001]: L1-BLADE is in the list: L1-BLADE <NL> [  245.935278] confd_mgr[3001]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  245.935427] confd_mgr[3001]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  245.935502] confd_mgr[3001]: Start_type: GO_NONE (STANDALONE/WORK) <NL> [  245.935570] confd_mgr[3001]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  245.935669] confd_mgr[3001]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  245.935742] confd_mgr[3001]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  245.935820] confd_mgr[3001]: guard is_db_okay_g: The HA mode is NONE <NL> [  245.935893] confd_mgr[3001]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  245.935965] confd_mgr[3001]: entering: sm_startconfd::start_confd_p0 <NL> [  245.936111] confd_mgr[3001]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  245.936783] confd_mgr[3613]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:17:02 UTC 2024 <NL> [  246.100358] confd_mgr[3001]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  246.829252] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  246.829566] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  246.975880] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 7 <NL> [  247.175356] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  247.186492] python3[2425]: [.565] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  248.715871] hrtimer: interrupt took 41022441 ns <NL> [  249.989259] txid_tracker[3239]: ::::create_confd_subscription_connection() try number 8 <NL> [  251.841251] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  251.841593] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:17:49.766Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  254.511578] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 1 <NL> [  256.853567] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  256.884522] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  257.245666] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  257.246824] python3[2425]: [.638] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  257.529459] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 2 <NL> [  260.537941] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 3 <NL> [  262.033183] healthcheck_agt.py[3688]: /bin/sh: line 1: podman: command not found <NL> [  262.042415] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  262.042609] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  263.538929] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 4 <NL> [  266.539081] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 5 <NL> [  267.027880] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  267.036635] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  267.331670] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  267.333457] python3[2425]: [.713] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  269.537301] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 6 <NL> [  272.021355] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  272.021572] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  272.550495] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 7 <NL> [  275.549958] txid_tracker[3668]: ::::create_confd_subscription_connection() try number 8 <NL> [  277.030978] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  277.031328] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  277.357939] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  277.358167] python3[2425]: [.746] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  279.924643] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 1 <NL> [  282.023760] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  282.079547] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  282.929776] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 2 <NL> [  285.929670] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 3 <NL> [  287.059739] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  287.061087] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  287.371165] python3[2425]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  287.388835] python3[2425]: [.762] hookhdlr 140460325144384 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  288.944851] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 4 <NL> [  291.960750] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 5 <NL> [  292.133658] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:17:51.131Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:50 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:52.496Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:52 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:55.783Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:17:55 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:56.039Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:17:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:56 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:17:57.944Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:17:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:17:57 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:00.458Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:00 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:00.715Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:01.277Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:01 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:02.206Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  276.976677] healthcheck_result_display.py[2414]:     main(hc_utils.setup_logging(__name__)) <NL> [  276.976882] healthcheck_result_display.py[2414]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  276.978219] healthcheck_result_display.py[2414]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  276.978335] healthcheck_result_display.py[2414]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  276.978774] healthcheck_result_display.py[2414]:     self._init_connection() <NL> [  276.980210] healthcheck_result_display.py[2414]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  276.980323] healthcheck_result_display.py[2414]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  276.980412] healthcheck_result_display.py[2414]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  277.180482] healthcheck_result_display.py[2414]:     _tm.dp.connect( <NL> [  277.180764] healthcheck_result_display.py[2414]: _confd.error.EOF: ConfD closed connection <NL> [  278.418109] python3[2423]: DEBUG EOF on socket to ConfD <NL> [  278.464467] python3[2423]: [.389] hookhdlr 140490876737344 callbackhdlr:457 Exception to create daemon <NL> [  278.471972] python3[2423]: Traceback (most recent call last): <NL> [  278.492389] python3[2423]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  278.504068] python3[2423]:     daemon = self.create_daemon() <NL> [  278.514802] python3[2423]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  278.527546] python3[2423]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  278.534613] python3[2423]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  278.535872] python3[2423]:     self._init_connection() <NL> [  278.536600] python3[2423]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection"}
{"timestamp_utc": "2024-07-31T08:18:02.207Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  278.547569] python3[2423]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  278.550667] python3[2423]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  278.554334] python3[2423]:     _tm.dp.connect( <NL> [  278.557959] python3[2423]: _confd.error.EOF: ConfD closed connection <NL> [  278.569248] python3[2423]: [.441] hookhdlr 140490876737344 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  279.343183] db_info.py[2399]: Traceback (most recent call last): <NL> [  279.344117] db_info.py[2399]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  279.374606] db_info.py[2399]:     main() <NL> [  279.374789] db_info.py[2399]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  279.374907] db_info.py[2399]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  279.375015] db_info.py[2399]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  279.375301] db_info.py[2399]:     self._init_connection() <NL> [  279.375489] db_info.py[2399]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  279.375604] db_info.py[2399]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  279.381996] db_info.py[2399]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  279.520324] db_info.py[2399]:     _tm.dp.connect( <NL> [  279.520534] db_info.py[2399]: _confd.error.EOF: ConfD closed connection <NL> [  279.844533] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 7 <NL> [  280.328397] rasis_system_stats.py[2433]: Traceback (most recent call last): <NL> [  280.328634] rasis_system_stats.py[2433]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  280.356670] rasis_system_stats.py[2433]:     main() <NL> [  280.394890] rasis_system_stats.py[2433]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  280.395036] rasis_system_stats.py[2433]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  280.395135] rasis_system_stats.py[2433]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  280.395211] rasis_system_stats.py[2433]:     self._init_connection() <NL> [  280.395277] rasis_system_stats.py[2433]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  280.395368] rasis_system_stats.py[2433]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  280.395436] rasis_system_stats.py[2433]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  280.395502] rasis_system_stats.py[2433]:     _tm.dp.connect( <NL> [  280.395572] rasis_system_stats.py[2433]: _confd.error.EOF: ConfD closed connection <NL> [  282.869458] txid_tracker[3738]: ::::create_confd_subscription_connection() try number 8 <NL> [  287.330732] txid_tracker[3791]: ::::create_confd_subscription_connection() connected <NL> [  288.523039] python3[2423]: [.467] hookhdlr 140490876737344 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  288.681257] python3[2423]: [.641] hookhdlr 140490876737344 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  288.681705] python3[2423]: [.641] hookhdlr 140490876737344 callbackhdlr:293 Loading schemas <NL> [  288.804774] python3[2423]: DEBUG item does not exist - shared memory schema not enabled <NL> [  292.507571] python3[2423]: [.440] hookhdlr 140490876737344 callbackhdlr:382 Done load schemas <NL> [  292.547606] python3[2423]: [.440] hookhdlr 140490876737344 callbackhdlr:389 Done register transaction callback <NL> [  293.607775] python3[2423]: [.574] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  293.643224] python3[2423]: [.609] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  293.652977] python3[2423]: [.628] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  293.808984] python3[2423]: [.782] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  294.118898] python3[2423]: [.093] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  294.213332] python3[2423]: [.187] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  294.227838] python3[2423]: [.202] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  294.349335] python3[2423]: [.322] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  294.458153] python3[2423]: [.422] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  294.495071] python3[2423]: [.445] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  294.558560] python3[2423]: [.532] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  294.665655] python3[2423]: [.635] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  297.500508] python3[2423]: [.473] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  299.945372] python3[2423]: [.908] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  302.977864] python3[2423]: [.907] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  305.340086] python3[2423]: [.307] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  307.575689] python3[2423]: [.548] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  307.691302] python3[2423]: [.644] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  307.710720] python3[2423]: [.685] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  307.780914] python3[2423]: [.754] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  307.785226] python3[2423]: [.758] hookhdlr 140490876737344 callbackhdlr:252 Done register callpoint cb tcmListHook"}
{"timestamp_utc": "2024-07-31T08:18:02.768Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:02 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:06.037Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:06 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:07.924Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:07 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:11.188Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:11 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> [  137.254718] zebra[2087]: 2024/07/31 08:15:11 warnings: ZEBRA: [EC 4043309105] Disabling MPLS support (no kernel support) <NL> [  137.834095] startup_finished.py[2031]: Startup Finished: systemd state is non-Production mode and running <NL> [  137.834272] startup_finished.py[2031]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  138.462172] startup_finished.py[2031]: *****Startup Finished: stopping EOW timer***** <NL> [  139.218100] startup_finished.py[2031]: systemctl stop startup_finished_limit.timer <NL> [  147.512374] ains_manager[2284]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  148.408675] layer1_control_layer[2064]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  153.897137] layer1_control_layer[2064]: DIP entity prov dump <NL> [  154.260512] layer1_control_layer[2064]: EsalConfig::EsalConfig main 0 <NL> [  154.260832] layer1_control_layer[2064]: EsalConfig::EsalConfig trib 1 <NL> [  154.260923] layer1_control_layer[2064]: EsalConfig::EsalConfig ciRole 0 <NL> [  154.263479] layer1_control_layer[2064]: EsalConfig is not running inside container. <NL> [  154.295512] layer1_control_layer[2064]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.295702] layer1_control_layer[2064]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.295801] layer1_control_layer[2064]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.295893] layer1_control_layer[2064]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  154.295970] layer1_control_layer[2064]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  154.296108] layer1_control_layer[2064]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  154.337988] layer1_control_layer[2064]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  154.338213] layer1_control_layer[2064]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  154.338378] layer1_control_layer[2064]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  154.338461] layer1_control_layer[2064]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  154.338539] layer1_control_layer[2064]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  154.338630] layer1_control_layer[2064]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  154.338705] layer1_control_layer[2064]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  154.338789] layer1_control_layer[2064]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  154.338865] layer1_control_layer[2064]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  154.338933] layer1_control_layer[2064]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  154.339026] layer1_control_layer[2064]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  155.769699] python3[2202]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  155.769968] python3[2202]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  155.770123] python3[2202]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  155.770208] python3[2202]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  155.770319] python3[2202]: max_slotNumber=5 <NL> [  162.535687] hrtimer: interrupt took 19744542 ns <NL> [  166.480381] python3[2438]: ==== Reading Dhalsim Config File: /etc/fss2/dhalsim/dhalsim_config.py <NL> [  166.501574] python3[2438]: /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  166.564907] python3[2438]: /var/confd/cdb/L1-OTSG2_cardData.xml <NL> [  166.565041] python3[2438]: Parsing the file /var/confd/cdb/L1-OTSG2_shelfData.xml <NL> [  166.565163] python3[2438]: max_slotNumber=5 <NL> [  166.565328] python3[2438]:  prov channel is 127.0.0.1:10000 <NL> [  166.565420] python3[2438]: success: command executed <NL> [  166.660858] layer1_hal[2091]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  166.770251] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2386 <NL> 2024-07-31 08:15:53,419 swdllite(agt): INFO - swdllited_agent.version_response_handler[411] initial_version_response stats: version_req_timeouts=3 <NL> [  183.212656] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  183.212926] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  183.213061] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.194328, delay 0.06874\\n31 Jul 08:15:57 ntpdate[2506]: no server suitable for synchronization found\\n' <NL> [  195.053133] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  195.077542] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  195.122372] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.198744, delay 0.05640\\n31 Jul 08:16:09 ntpdate[2530]: no server suitable for synchronization found\\n' <NL> [  207.065291] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  207.083049] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  207.084243] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.242211, delay 0.12274\\n31 Jul 08:16:21 ntpdate[2543]: no server suitable for synchronization found\\n' <NL> [  219.127568] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  219.173408] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  219.195028] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.179095, delay 0.08099\\n31 Jul 08:16:33 ntpdate[2571]: no server suitable for synchronization found\\n' <NL> [  231.260685] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  231.265360] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  231.314471] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.204941, delay 0.07750\\n31 Jul 08:16:45 ntpdate[2597]: no server suitable for synchronization found\\n' <NL> [  243.153162] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  243.168669] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  243.195627] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.203914, delay 0.03493\\n31 Jul 08:16:57 ntpdate[2621]: no server suitable for synchronization found\\n' <NL> [  255.920862] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  255.926483] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  255.927598] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.199531, delay 0.02968\\n31 Jul 08:17:10 ntpdate[2649]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:18:11.189Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  268.390532] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  268.402419] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  268.402531] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.201396, delay 0.02823\\n31 Jul 08:17:22 ntpdate[2669]: no server suitable for synchronization found\\n' <NL> [  280.410859] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  280.411486] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  280.411590] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.210311, delay 0.05786\\n31 Jul 08:17:34 ntpdate[2697]: no server suitable for synchronization found\\n' <NL> [  292.277783] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  292.278196] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  292.278292] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.230909, delay 0.08900\\n31 Jul 08:17:46 ntpdate[2717]: no server suitable for synchronization found\\n' <NL> [  304.304231] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  304.304818] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  304.304905] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.212768, delay 0.08159\\n31 Jul 08:17:58 ntpdate[2738]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:18:12.553Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:12 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:15.070Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:16:36,532 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=local_agent, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:16:36,282 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  221.507854] dcn_ka[1389]: KaSessMgr Process Startup <NL> 2024-07-31 08:16:38,785 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  224.109718] ntp_oper_data.py[1725]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: standalone <NL> [  225.319223] ntp_oper_data.py[1725]: INFO:root:redundancy status now set to standalone <NL> 2024-07-31 08:16:40,182 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  226.920143] ntp_oper_data.py[1725]: INFO:root:Received redundancy topic <NL> [  227.197940] ntp_oper_data.py[1725]: INFO:root:Redundancy status is standalone <NL> 2024-07-31 08:16:43,315 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> 2024-07-31 08:16:43,338 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  227.396894] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  227.906296] ntputils[1724]: bool NTPServer::handle_redundancy_topic(const string&) <NL> [  227.907408] ntputils[1724]: got Platform::RedundancyMode: WORK <NL> [  228.070268] ntputils[1724]: got Platform::RedundancyStatus: STANDALONE <NL> [  228.070981] ntputils[1724]: my current red mode is: UNKNOWN <NL> [  228.086807] ntputils[1724]: new red mode is: WORK <NL> [  228.087746] ntputils[1724]: my current red status is: STANDALONE <NL> 2024-07-31 08:16:44,019 swdllite(mgr): INFO - swdl_base_fsm_fn.interface_agent_restart_fn[645] received INTERFACE_RESTART_EVT <NL> [  228.512850] ntputils[1724]: new red status is: STANDALONE <NL> [  229.139249] ntputils[1724]: red mode change, update: UNKNOWN => WORK <NL> [  229.241511] ntputils[1724]: no active/not-active status change: 0 <NL> 2024-07-31 08:16:45,274 swdllite(mgr): INFO - swdl_state_manager.disconnect[46] state manager disconnect <NL> [  229.819386] dcn_dns_controller[1387]: subscribe_data Enter main loop <NL> 2024-07-31 08:16:47,883 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=RESET <NL> 2024-07-31 08:16:48,917 swdllite(mgr): INFO - swdl_state_manager.connect[35] state manager connect <NL> 2024-07-31 08:16:50,492 swdllite(mgr): INFO - swdllited_base.register_with_dds[411] dds_register: reg_msg = bytearray(b'\\n\\x17Platform_dds_Redundancy\\x12\\x14tcp://localhost:6667') <NL> 2024-07-31 08:16:53,341 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> 2024-07-31 08:16:53,943 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:16:55,188 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  248.191725] dcn_phantom_drv: vif_conf_flush_if_write:1195 ENDS INFO - Invalid Owner name[IPDCC] <NL> [  249.510908] confd_phase_sentry[2246]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  250.904232] dcn_phantom_drv: vif_conf_flush_local_ip_write:759 ENDS INFO - Role not configured <NL> [  251.012258] confd_phase_sentry[2246]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> [  254.439116] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:17:06,065 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  259.607958] temp_acct_cleanup_app[2253]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set."}
{"timestamp_utc": "2024-07-31T08:18:15.071Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:17:16,372 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  261.582468] temp_acct_cleanup_app[2253]: DEBUG Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:17:18,112 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  264.099445] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  268.886633] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  269.343645] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> 2024-07-31 08:17:20,952 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> [  269.723369] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:17:32,715 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":200} <NL> [  278.323121] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> 2024-07-31 08:17:36,683 swdllite(mgr): INFO - swdl_state_confdmgr.replay[190] mgr_confdmgr_state: role=main, action=REPLAY <NL> [  282.841770] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  289.709706] confd_mgr_action_server[2232]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 200 <NL> [  290.410661] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 1 <NL> 2024-07-31 08:17:46,561 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  291.578513] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 2 <NL> [  294.679833] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 3 <NL> [  295.423813] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 4 <NL> 2024-07-31 08:17:50,858 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  296.025332] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 5 <NL> [  302.922813] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 6 <NL> [  302.923873] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 7 <NL> 2024-07-31 08:17:59,042 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  304.374409] txid_tracker[2254]: ::::create_confd_subscription_connection() try number 8 <NL> [  309.582167] ypg_app[2230]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  313.144099] sncp_app[2229]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  314.934905] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  317.081351] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  317.138290] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:18:15.999Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:18:15 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37261\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:16.257Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:16 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:17.626Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:17 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:20.890Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:20 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',) <NL> # 03:18:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:21.146Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:21 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:23.033Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:22 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:24.954Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  292.169344] confd_phase_sentry[2450]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7f32ad25f5c7; Failed to connect to ConfD: Connection refused <NL> [  294.783056] rasis_system_stats.py[2453]: Traceback (most recent call last): <NL> [  294.795879] rasis_system_stats.py[2453]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  294.821224] rasis_system_stats.py[2453]:     main() <NL> [  294.844985] rasis_system_stats.py[2453]:   File \"/usr/bin/rasis_system_stats.py\", line 352, in main <NL> [  294.874903] rasis_system_stats.py[2453]:     maapi.Maapi(port=CONFD_PORT) <NL> [  294.892616] rasis_system_stats.py[2453]:   File \"/usr/lib/python3.10/site-packages/confd/maapi.py\", line 321, in __init__ <NL> [  294.914768] rasis_system_stats.py[2453]:     self.msock = connect(ip, port, path) <NL> [  294.916888] rasis_system_stats.py[2453]:   File \"/usr/lib/python3.10/site-packages/confd/maapi.py\", line 118, in connect <NL> [  294.918142] rasis_system_stats.py[2453]:     _tm.maapi.connect(msock, ip, port) <NL> [  294.919057] rasis_system_stats.py[2453]: _confd.error.EOF: ConfD closed connection <NL> [  295.114668] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 6 <NL> [  297.150579] confd_phase_sentry[2450]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  297.236600] confd_phase_sentry[2450]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  297.556478] python3[2425]: DEBUG EOF on socket to ConfD <NL> [  297.579424] python3[2425]: [.937] hookhdlr 140460325144384 callbackhdlr:457 Exception to create daemon <NL> [  297.583281] python3[2425]: Traceback (most recent call last): <NL> [  297.584161] python3[2425]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  297.584305] python3[2425]:     daemon = self.create_daemon()"}
{"timestamp_utc": "2024-07-31T08:18:24.955Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  297.585727] python3[2425]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  297.585916] python3[2425]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  297.586749] python3[2425]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  297.636989] python3[2425]:     self._init_connection() <NL> [  297.705162] python3[2425]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  297.706669] python3[2425]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  297.706801] python3[2425]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  297.706885] python3[2425]:     _tm.dp.connect( <NL> [  297.706978] python3[2425]: _confd.error.EOF: ConfD closed connection <NL> [  297.707111] python3[2425]: [.974] hookhdlr 140460325144384 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  298.151462] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 7 <NL> [  299.494936] db_info.py[2405]: Traceback (most recent call last): <NL> [  299.600289] db_info.py[2405]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  299.600480] db_info.py[2405]:     main() <NL> [  299.600572] db_info.py[2405]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  299.601925] db_info.py[2405]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  299.602182] db_info.py[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  299.602290] db_info.py[2405]:     self._init_connection() <NL> [  299.602373] db_info.py[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  299.602466] db_info.py[2405]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  299.602573] db_info.py[2405]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  299.602663] db_info.py[2405]:     _tm.dp.connect( <NL> [  299.602768] db_info.py[2405]: _confd.error.EOF: ConfD closed connection <NL> [  300.867205] healthcheck_result_display.py[2421]: Traceback (most recent call last): <NL> [  300.939869] healthcheck_result_display.py[2421]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  300.950644] healthcheck_result_display.py[2421]:     main(hc_utils.setup_logging(__name__)) <NL> [  300.950758] healthcheck_result_display.py[2421]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  300.950879] healthcheck_result_display.py[2421]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  300.951029] healthcheck_result_display.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  300.951119] healthcheck_result_display.py[2421]:     self._init_connection() <NL> [  300.951195] healthcheck_result_display.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  300.951270] healthcheck_result_display.py[2421]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  300.951399] healthcheck_result_display.py[2421]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  300.951477] healthcheck_result_display.py[2421]:     _tm.dp.connect( <NL> [  300.952522] healthcheck_result_display.py[2421]: _confd.error.EOF: ConfD closed connection <NL> [  301.136821] txid_tracker[3723]: ::::create_confd_subscription_connection() try number 8 <NL> [  305.843931] txid_tracker[3776]: ::::create_confd_subscription_connection() connected <NL> [  307.601933] python3[2425]: [.993] hookhdlr 140460325144384 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  307.701462] python3[2425]: [.090] hookhdlr 140460325144384 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  307.723629] python3[2425]: [.090] hookhdlr 140460325144384 callbackhdlr:293 Loading schemas <NL> [  307.800504] python3[2425]: DEBUG item does not exist - shared memory schema not enabled <NL> [  311.022175] python3[2425]: [.406] hookhdlr 140460325144384 callbackhdlr:382 Done load schemas <NL> [  311.077259] python3[2425]: [.407] hookhdlr 140460325144384 callbackhdlr:389 Done register transaction callback <NL> [  312.323169] python3[2425]: [.693] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  312.445938] python3[2425]: [.819] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  312.679919] python3[2425]: [.981] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  312.774394] python3[2425]: [.137] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  313.275175] python3[2425]: [.651] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  313.421744] python3[2425]: [.812] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  313.525936] python3[2425]: [.917] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  313.570226] python3[2425]: [.962] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  313.772413] python3[2425]: [.152] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  313.890481] python3[2425]: [.251] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  314.198768] python3[2425]: [.591] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  314.361176] python3[2425]: [.753] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  317.490726] python3[2425]: [.796] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  320.070074] python3[2425]: [.460] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  322.510651] python3[2425]: [.866] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  324.831339] python3[2425]: [.216] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  327.169154] python3[2425]: [.553] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook"}
{"timestamp_utc": "2024-07-31T08:18:25.516Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:26.443Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:26 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:27.806Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:27 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:31.968Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:31 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:32.894Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:32 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:37.065Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:36 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:37.626Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:37 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:40.889Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:40 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37229\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:41.450Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:41 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:42.815Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:42 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:46.107Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:18:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:18:46.362Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:46 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:46.923Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  307.785396] python3[2423]: [.758] hookhdlr 140490876737344 callbackhdlr:391 Done register data callbacks <NL> [  348.704231] confd_mgr[3010]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  348.758860] confd_mgr[3913]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:18:42 UTC 2024 <NL> [  348.885044] confd_mgr[3913]: Starting valhdlr.service <NL> [  349.268511] confd_mgr[3913]: Starting validation-handler.service <NL> [  349.357779] confd_mgr[3913]: Starting snmp-fss-fw.service <NL> [  349.732715] confd_mgr[3010]: leaving: sm_startconfd::start_confd_p0 <NL> [  349.732898] confd_mgr[3010]: entering: sm_startconfd::wait_for_p0 <NL> [  349.732986] confd_mgr[3010]: PROCESS1 has not registered yet. <NL> [  349.733090] confd_mgr[3010]: PROCESS_SNMP_CLID has not registered yet. <NL> [  349.733213] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  350.010600] python3[2423]: DEBUG No crypto keys configured <NL> [  350.042764] python3[2423]: [.924] hookhdlr 140490876737344 callbackhdlr:401 Unable to install crypto keys! <NL> [  350.146311] python3[2423]: [.120] hookhdlr 140490876737344 callbackhdlr:322 Started data handler daemon... <NL> [  350.277634] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  350.277861] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  350.277985] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  350.279237] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  350.279320] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  350.279411] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  350.279491] confd_mgr[3010]: ConfdHA Not supported command CONFIRM <NL> [  350.374281] confd_mgr[3010]: sm_startconfd::p0_ready_dbc <NL> [  350.374465] confd_mgr[3010]: Find message MESSAGE1 <NL> [  350.374573] confd_mgr[3010]: PROCESS_SNMP_CLID has not registered yet. <NL> [  350.374658] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  350.374731] confd_mgr[3010]: sm_startconfd::p0_not_ready <NL> [  350.374817] confd_mgr[3010]: Find message MESSAGE1 <NL> [  350.374889] confd_mgr[3010]: PROCESS_SNMP_CLID has not registered yet. <NL> [  350.374958] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  350.375041] confd_mgr[3010]: leaving: sm_startconfd::wait_for_p0"}
{"timestamp_utc": "2024-07-31T08:18:46.924Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  350.375120] confd_mgr[3010]: entering: sm_startconfd::wait_for_p0 <NL> [  350.375194] confd_mgr[3010]: PROCESS_SNMP_CLID has not registered yet. <NL> [  350.375273] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  350.375339] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  350.394650] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  350.394755] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  350.528644] confd_mgr[3010]: Timer /ConfdAT|wait_for_p0 already created <NL> [  351.526316] python3[3922]: [.497] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  351.531396] python3[3922]: [.499] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  351.569399] python3[3922]: [.499] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  351.569541] python3[3922]: [.499] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  351.569622] python3[3922]: [.499] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  351.569708] python3[3922]: [.500] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  351.569825] python3[3922]: [.500] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  351.569976] python3[3922]: [.529] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  351.598088] python3[3922]: [.529] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  351.656378] python3[3922]: [.529] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  351.656660] python3[3922]: [.529] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  351.657275] python3[3922]: [.529] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  351.657531] python3[3922]: [.539] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  351.704049] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  351.704303] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  351.750764] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  351.752441] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  351.762468] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  351.771831] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  351.771936] python3[3922]: [.678] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  351.772049] python3[3922]: [.679] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  351.772289] python3[3922]: [.679] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  351.772396] python3[3922]: [.679] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  351.772459] python3[3922]: [.695] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  351.772528] python3[3922]: [.703] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  351.772591] python3[3922]: [.704] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  351.772658] python3[3922]: [.706] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  351.772730] python3[3922]: [.708] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  351.772801] python3[3922]: [.708] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  351.772869] python3[3922]: [.708] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  351.772931] python3[3922]: [.711] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  351.772992] python3[3922]: [.711] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  351.773075] python3[3922]: [.713] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  351.773161] python3[3922]: [.722] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  351.869575] python3[3922]: [.840] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  351.869815] python3[3922]: [.840] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  351.869949] python3[3922]: [.840] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  351.870063] python3[3922]: [.840] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  351.870142] python3[3922]: [.841] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  351.940731] python3[3922]: [.841] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'}"}
{"timestamp_utc": "2024-07-31T08:18:47.851Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:47 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:48.415Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  288.847543] usb_script_handler.py[1734]: usb: INFO - usb_base.check_manual_bind_unbind[251] kernel mimic check to manually verify usb presence <NL> 2024-07-31 08:17:42,552 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> 2024-07-31 08:17:43,750 swdllite(mgr): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  290.138692] ypg_app[2119]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> 2024-07-31 08:17:45,664 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> 2024-07-31 08:17:48,882 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  297.007738] common_alarm_handler[2114]: gen_util: DDS_P2MP not available <NL> 2024-07-31 08:17:46,085 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:17:55,145 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  303.298570] usb_script_handler.py[1734]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> 2024-07-31 08:17:58,559 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> [  307.417243] common_alarm_handler[2114]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> 2024-07-31 08:18:06,105 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  313.111252] common_alarm_handler[2114]: topic = SystemProv; id = 1 <NL> [  313.150201] common_alarm_handler[2114]: topic = WdmcfgProv; id = 2 <NL> [  313.191662] common_alarm_handler[2114]: topic = LicenseStatusTopic; id = 3 <NL> [  313.239047] common_alarm_handler[2114]: topic = ShelfProv; id = 5 <NL> [  313.469613] common_alarm_handler[2114]: topic = SlotProv; id = 6 <NL> [  313.548665] common_alarm_handler[2114]: topic = PortProv; id = 7 <NL> [  313.549568] common_alarm_handler[2114]: topic = SubportProv; id = 8 <NL> [  313.556613] common_alarm_handler[2114]: topic = FconProv; id = 9 <NL> [  313.574724] common_alarm_handler[2114]: topic = XconProv; id = 10 <NL> [  313.575550] common_alarm_handler[2114]: topic = OchProv; id = 11 <NL> [  313.576333] common_alarm_handler[2114]: topic = OmsProv; id = 12 <NL> [  314.627030] common_alarm_handler[2114]: topic = OtsProv; id = 13 <NL> 2024-07-31 08:18:09,284 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  316.224378] common_alarm_handler[2114]: topic = EthernetProv; id = 14 <NL> 2024-07-31 08:18:14,144 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  321.219610] common_alarm_handler[2114]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15 <NL> [  321.860668] common_alarm_handler[2114]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  324.318428] common_alarm_handler[2114]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> [  325.934347] common_alarm_handler[2114]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> [  327.351680] common_alarm_handler[2114]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  329.184567] common_alarm_handler[2114]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> [  330.317422] common_alarm_handler[2114]: topic = router_bgp_dds_bgp_global_prov; id = 22"}
{"timestamp_utc": "2024-07-31T08:18:48.416Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  331.857959] common_alarm_handler[2114]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> 2024-07-31 08:18:25,789 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> [  332.909157] common_alarm_handler[2114]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  333.048903] common_alarm_handler[2114]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  333.413046] common_alarm_handler[2114]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  333.430914] common_alarm_handler[2114]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> [  333.491822] common_alarm_handler[2114]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28 <NL> 2024-07-31 08:18:27,144 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> [  333.552758] common_alarm_handler[2114]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> [  333.807326] common_alarm_handler[2114]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> [  333.810470] common_alarm_handler[2114]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> 2024-07-31 08:18:27,453 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  333.831136] common_alarm_handler[2114]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> 2024-07-31 08:18:27,936 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> [  334.616832] common_alarm_handler[2114]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  336.008186] common_alarm_handler[2114]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> 2024-07-31 08:18:28,341 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> 2024-07-31 08:18:28,461 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> [  336.157692] common_alarm_handler[2114]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> 2024-07-31 08:18:31,250 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:18:31,696 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  338.748983] common_alarm_handler[2114]: topic = AlarmNotification; id = 40 <NL> 2024-07-31 08:18:35,502 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> [  342.351845] common_alarm_handler[2114]: topic = GenericOperInfoReq; id = 41 <NL> [  342.352796] common_alarm_handler[2114]: topic = PmRtrvReq; id = 42 <NL> 2024-07-31 08:18:35,084 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:18:36,912 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> [  343.243937] common_alarm_handler[2114]: topic = PmRtrvResp; id = 43 <NL> 2024-07-31 08:18:37,485 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:18:37,672 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  344.850500] common_alarm_handler[2114]: topic = PmInitReq; id = 44 <NL> [  346.299216] common_alarm_handler[2114]: topic = PmOperData; id = 45 <NL> 2024-07-31 08:18:40,130 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  346.948434] common_alarm_handler[2114]: topic = StateChange; id = 46 <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> 2024-07-31 08:18:42,453 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> [  351.906859] common_alarm_handler[2114]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> [  353.939250] common_alarm_handler[2114]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> 2024-07-31 08:18:47,503 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  354.162841] common_alarm_handler[2114]: topic = DcnIpv6Ipv6Attributes; id = 50"}
{"timestamp_utc": "2024-07-31T08:18:51.689Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:51 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:53.053Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:52 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:56.316Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:18:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:56 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:18:57.681Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:18:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:18:57 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:01.858Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:01 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:02.431Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  316.336540] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  316.337186] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  316.337326] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.196190, delay 0.04430\\n31 Jul 08:18:10 ntpdate[2757]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:18:16,586 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:18:16,593 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:16,625 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:16,675 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:18:16,677 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:18:16,694 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:18:16,695 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:18:16,695 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:18:16,713 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:18:16,760 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:18:16,761 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:18:16,830 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:18:16,903 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:18:16,904 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":1} <NL> 2024-07-31 08:18:16,905 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:18:16,918 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:18:16,961 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> 2024-07-31 08:18:17,026 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:18:17,026 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:18:17,026 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> 2024-07-31 08:18:17,027 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:18:17,103 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> 2024-07-31 08:18:17,103 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:18:17,104 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:18:17,104 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:18:17,105 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> 2024-07-31 08:18:17,105 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> openDdsPorts interfaces  eth1.2003 <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661"}
{"timestamp_utc": "2024-07-31T08:19:02.432Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "openDdsPorts Output udpPorts-  7661 <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> openDdsPorts Output udpPorts-  7651 <NL> openDdsPorts Input udpPorts-  7900 <NL> openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:18:18,093 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:18:18,101 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:18:18,119 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer <NL> INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> [  328.292336] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  328.292751] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  328.292834] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.204287, delay 0.04356\\n31 Jul 08:18:22 ntpdate[2823]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:18:24,218 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:18:24,222 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  340.169111] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  340.169747] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  340.169845] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.169240, delay 0.08972\\n31 Jul 08:18:34 ntpdate[2868]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  354.219229] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  354.220481] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  354.246659] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.200756, delay 0.02626\\n31 Jul 08:18:48 ntpdate[2908]: no server suitable for synchronization found\\n' <NL> [  366.332573] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  366.332982] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  366.333078] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.208294, delay 0.05170\\n31 Jul 08:19:00 ntpdate[2954]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh"}
{"timestamp_utc": "2024-07-31T08:19:02.720Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:02 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:04.088Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  327.274735] python3[2425]: [.650] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  327.274964] python3[2425]: [.665] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  327.328999] python3[2425]: [.710] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  327.368785] python3[2425]: [.753] hookhdlr 140460325144384 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  327.369027] python3[2425]: [.753] hookhdlr 140460325144384 callbackhdlr:391 Done register data callbacks <NL> [  362.714871] confd_mgr[3001]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh <NL> [  362.783403] confd_mgr[3912]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:18:59 UTC 2024 <NL> [  362.897134] confd_mgr[3912]: Starting valhdlr.service <NL> [  363.294236] confd_mgr[3912]: Starting validation-handler.service <NL> [  363.444857] confd_mgr[3912]: Starting snmp-fss-fw.service <NL> [  363.558049] python3[2425]: DEBUG No crypto keys configured <NL> [  363.614066] python3[2425]: [.945] hookhdlr 140460325144384 callbackhdlr:401 Unable to install crypto keys! <NL> [  363.682805] confd_mgr[3001]: leaving: sm_startconfd::start_confd_p0 <NL> [  363.789436] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  363.936855] confd_mgr[3001]: entering: sm_startconfd::wait_for_p0 <NL> [  363.939039] confd_mgr[3001]: PROCESS1 has not registered yet. <NL> [  363.939928] confd_mgr[3001]: PROCESS_SNMP_CLID has not registered yet. <NL> [  363.940863] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  363.941827] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  363.943459] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1"}
{"timestamp_utc": "2024-07-31T08:19:04.089Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  363.960749] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  363.977544] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  363.989735] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  363.990628] confd_mgr[3001]: ConfdHA Not supported command CONFIRM <NL> [  363.991638] python3[2425]: [.174] hookhdlr 140460325144384 callbackhdlr:322 Started data handler daemon... <NL> [  364.006569] confd_mgr[3001]: sm_startconfd::p0_ready_dbc <NL> [  364.041139] confd_mgr[3001]: Find message MESSAGE1 <NL> [  364.047402] confd_mgr[3001]: PROCESS_SNMP_CLID has not registered yet. <NL> [  364.052851] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  364.053694] confd_mgr[3001]: sm_startconfd::p0_not_ready <NL> [  364.054384] confd_mgr[3001]: Find message MESSAGE1 <NL> [  364.074791] confd_mgr[3001]: PROCESS_SNMP_CLID has not registered yet. <NL> [  364.091084] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  364.109671] confd_mgr[3001]: leaving: sm_startconfd::wait_for_p0 <NL> [  364.131645] confd_mgr[3001]: entering: sm_startconfd::wait_for_p0 <NL> [  364.137613] confd_mgr[3001]: PROCESS_SNMP_CLID has not registered yet. <NL> [  364.143919] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  364.174813] confd_mgr[3001]: Timer /ConfdAT|wait_for_p0 already created <NL> [  364.187139] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  364.195802] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  364.207278] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  365.327923] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.355139] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.379480] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.415367] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.425339] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.427764] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.429165] python3[3920]: [.693] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.430700] python3[3920]: [.708] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.466624] python3[3920]: [.718] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.470625] python3[3920]: [.719] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.475731] python3[3920]: [.719] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.489718] python3[3920]: [.719] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.511078] python3[3920]: [.719] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.519535] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.534049] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.545954] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.572300] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.613571] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.644650] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  365.668308] python3[3920]: [.790] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  365.713032] python3[3920]: [.791] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.723142] python3[3920]: [.791] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  365.724437] python3[3920]: [.791] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.743458] python3[3920]: [.791] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  365.749482] python3[3920]: [.802] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  365.756343] python3[3920]: [.802] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  365.757548] python3[3920]: [.805] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  365.817644] python3[3920]: [.805] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  365.820253] python3[3920]: [.805] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  365.821558] python3[3920]: [.805] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  365.822897] python3[3920]: [.810] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  365.928902] python3[3920]: [.812] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  365.954042] python3[3920]: [.812] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  365.980690] python3[3920]: [.813] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.003528] python3[3920]: [.829] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  366.014977] python3[3920]: [.829] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  366.027654] python3[3920]: [.829] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'}"}
{"timestamp_utc": "2024-07-31T08:19:05.977Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:19:05 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37261\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:19:06.539Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:06 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:07.903Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:07 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:11.168Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:19:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:11.423Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:11 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:11.680Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  354.183426] common_alarm_handler[2114]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> [  354.192972] common_alarm_handler[2114]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> [  354.202344] common_alarm_handler[2114]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> [  354.271657] common_alarm_handler[2114]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> 2024-07-31 08:18:47,955 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  354.327139] confd_mgr_action_server[2121]: confd_mgr_action_server::main: Shelf Role = MAIN, Red Mode = UNKNOWN, Shelf number = 200 <NL> [  354.369766] usb_script_handler.py[1734]: usb: INFO - usb_base.is_fujitsu_encrypted[225] Fujitsu encrypted usb has been detected <NL> [  354.405455] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[106] trying to mount usb as secondary storage <NL> [  354.435378] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[108] checking for /dev/mapper/usb-secondary device <NL> [  354.460933] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[111] found /dev/mapper/usb-secondary device <NL> [  354.479725] usb_script_handler.py[1734]: usb: INFO - usb_ssw_main.mount_usb_secondary[118] USB ssw mount successful <NL> [  354.538364] usb_script_handler.py[1734]: usb: INFO - usb_base.update_usb_psi_info[550] Publishing Mocked USB PSI Info on Qemu <NL> [  354.579186] usb_script_handler.py[1734]: usb: INFO - usb_utils.clear_alarm[227] invalidUSB alarm cleared <NL> [  354.718928] usb_script_handler.py[1734]: usb: INFO - usb_utils.clear_alarm[227] noSecondaryStorage alarm cleared <NL> 2024-07-31 08:18:48,455 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  355.280586] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  357.265951] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  357.490457] ntputils[1725]: child pid is 2667 <NL> 2024-07-31 08:18:50,958 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  357.993120] ntputils[1725]: exited, status is 0 <NL> 2024-07-31 08:18:53,257 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  360.297996] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:19:00,796 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  367.500701] ntputils[1725]: poller time change delta is: 1 <NL> [  370.340180] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  370.424899] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  371.284780] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> 2024-07-31 08:19:04,471 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  371.648675] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> [  371.947030] ntputils[1725]: push_local_changes OK <NL> [  371.954336] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  371.977432] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  372.023513] ntputils[1725]: child pid is 2677 <NL> [  372.032399] ntputils[1725]: exited, status is 0 <NL> [  372.071205] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  372.118578] ntputils[1725]: poller time change delta is: 1 <NL> [  372.481738] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  372.492273] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  372.552140] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> STANDALONE <NL> [  373.196282] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> ======= Changing UNKNOWN redMode ========= <NL> [  373.941779] ntputils[1725]: push_local_changes OK <NL> 2024-07-31 08:19:07,049 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  374.223289] common_alarm_handler[2114]: topic = EthIfProv; id = 56 <NL> [  374.393513] common_alarm_handler[2114]: topic = DcnNat64Attributes; id = 57 <NL> [  374.394559] common_alarm_handler[2114]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  374.977575] common_alarm_handler[2114]: topic = LldpGlobalCfgProv; id = 59 <NL> [  375.147207] common_alarm_handler[2114]: topic = LldpPortCfgProv; id = 60 <NL> [  375.157506] common_alarm_handler[2114]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  375.159683] common_alarm_handler[2114]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  375.189892] common_alarm_handler[2114]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  375.359423] common_alarm_handler[2114]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  375.366247] common_alarm_handler[2114]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  375.368371] common_alarm_handler[2114]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  375.379544] common_alarm_handler[2114]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  375.427606] common_alarm_handler[2114]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> 2024-07-31 08:19:08,934 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY"}
{"timestamp_utc": "2024-07-31T08:19:11.681Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  375.704481] common_alarm_handler[2114]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  375.841638] common_alarm_handler[2114]: topic = DcnPppAttributesProv; id = 70 <NL> 2024-07-31 08:19:09,583 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  376.167801] common_alarm_handler[2114]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  376.461529] common_alarm_handler[2114]: topic = LldpBladeCfgProv; id = 72 <NL> [  376.467194] common_alarm_handler[2114]: topic = LldpPortInstCfgProv; id = 73 <NL> [  376.704828] common_alarm_handler[2114]: topic = DcnGreTunnelProv; id = 74 <NL> 2024-07-31 08:19:10,206 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> ERROR:root:empty repository <NL> [  376.713810] common_alarm_handler[2114]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  376.768407] common_alarm_handler[2114]: topic = DcnDnsClientSearchProv; id = 76 <NL> [  376.769603] common_alarm_handler[2114]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  376.777307] common_alarm_handler[2114]: topic = SysGnmiCertProv; id = 78 <NL> [  376.791824] common_alarm_handler[2114]: topic = IetfInterfaceProv; id = 79 <NL> [  376.796302] common_alarm_handler[2114]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  376.880295] common_alarm_handler[2114]: topic = SystemAutoLogoffProv; id = 81 <NL> [  377.008343] common_alarm_handler[2114]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  377.022639] common_alarm_handler[2114]: topic = SystemPortsProv; id = 83 <NL> [  377.027485] common_alarm_handler[2114]: topic = OspfProvisioningModeProv; id = 84 <NL> [  377.033557] common_alarm_handler[2114]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  377.040508] common_alarm_handler[2114]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  377.046316] common_alarm_handler[2114]: topic = BasicGroupProv; id = 87 <NL> [  377.053286] common_alarm_handler[2114]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  377.061381] common_alarm_handler[2114]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  377.073557] common_alarm_handler[2114]: topic = SystemFipsProv; id = 90 <NL> [  377.084370] common_alarm_handler[2114]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  377.094345] common_alarm_handler[2114]: topic = SecuritySystemwideProv; id = 92 <NL> [  377.105530] common_alarm_handler[2114]: topic = DataEncryptionProv; id = 93 <NL> [  377.115192] common_alarm_handler[2114]: topic = SystemServicesProv; id = 94 <NL> [  377.122970] common_alarm_handler[2114]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  377.135642] common_alarm_handler[2114]: topic = SystemSshAlgorithmProv; id = 96"}
{"timestamp_utc": "2024-07-31T08:19:12.243Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  243.159630] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  243.170593] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  243.170697] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.036372, delay 0.03685\\n31 Jul 08:16:57 ntpdate[2631]: no server suitable for synchronization found\\n' <NL> [  252.057939] hrtimer: interrupt took 80307903 ns <NL> [  255.041046] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  255.041578] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  255.041672] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.034247, delay 0.03049\\n31 Jul 08:17:09 ntpdate[2653]: no server suitable for synchronization found\\n' <NL> [  266.971683] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  266.980894] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  266.982141] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.037037, delay 0.04637\\n31 Jul 08:17:21 ntpdate[2678]: no server suitable for synchronization found\\n' <NL> [  278.875131] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  278.876473] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  278.892238] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.053123, delay 0.08984\\n31 Jul 08:17:32 ntpdate[2707]: no server suitable for synchronization found\\n' <NL> [  290.806414] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  290.884183] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  290.935316] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.045107, delay 0.04747\\n31 Jul 08:17:44 ntpdate[2727]: no server suitable for synchronization found\\n' <NL> [  302.711316] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  302.713209] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  302.746172] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.029160, delay 0.03748\\n31 Jul 08:17:56 ntpdate[2742]: no server suitable for synchronization found\\n' <NL> [  314.701922] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  314.728059] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  314.770046] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.037110, delay 0.03836\\n31 Jul 08:18:08 ntpdate[2765]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:19:12.244Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  327.016597] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  327.027576] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  327.083715] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.028686, delay 0.04588\\n31 Jul 08:18:21 ntpdate[2788]: no server suitable for synchronization found\\n' <NL> [  340.154417] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  340.173533] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  340.198513] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.035582, delay 0.02859\\n31 Jul 08:18:34 ntpdate[2824]: no server suitable for synchronization found\\n' <NL> [  352.175537] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  352.202361] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  352.243461] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.037127, delay 0.03622\\n31 Jul 08:18:46 ntpdate[2844]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:19:12.500Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[  364.058978] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  364.075644] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  364.078156] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.036433, delay 0.03882\\n31 Jul 08:18:58 ntpdate[2879]: no server suitable for synchronization found\\n' <NL> [  375.974885] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  376.011915] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  376.021047] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.023405, delay 0.06190\\n31 Jul 08:19:09 ntpdate[2915]: no server suitable for synchronization found\\n' <NL> 2024-07-31 08:19:10,163 swdllite(agt): INFO - swdl_state_confdmgr.update[181] agent_confdmgr_state: role=daughter, action=CONFDMGR_NOTIFY <NL> 2024-07-31 08:19:10,205 swdllite(agt): INFO - swdl_int_agent_fn.background_interface_agent[114] sending background message: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:19:10,341 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:19:10,374 swdllite(agt): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> 2024-07-31 08:19:10,389 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> 2024-07-31 08:19:10,411 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareVersionMismatch: entity=Shelf, clear=True <NL> 2024-07-31 08:19:10,413 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareVersionMismatch location {\\\"shelf\\\":1} <NL> 2024-07-31 08:19:10,415 swdllite(agt): INFO - swdl_int_agent_fn.agent_version_match[143] change in match_state None->True <NL> 2024-07-31 08:19:10,446 swdllite(int): INFO - swdllited_int.version_match_fn[103] updating version match: None->True <NL> 2024-07-31 08:19:10,507 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: state: \"VALIDATE\" <NL> 2024-07-31 08:19:10,538 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:19:10,554 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:19:10,592 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> openDdsPorts interfaces  eth1.2003 <NL> 2024-07-31 08:19:10,641 swdllite(agt): INFO - swdl_state_alarm.replay[117] publish softwareStageInProgress: entity=Shelf, clear=True <NL> 2024-07-31 08:19:10,696 swdllite(agt): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareStageInProgress location {\\\"shelf\\\":1} <NL> 2024-07-31 08:19:10,706 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> 2024-07-31 08:19:10,739 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> openDdsPorts Input udpPorts-  7660 <NL> openDdsPorts Output udpPorts-  7660 <NL> openDdsPorts Input udpPorts-  7661 <NL> openDdsPorts Output udpPorts-  7661 <NL> 2024-07-31 08:19:10,905 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:19:10,959 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> 2024-07-31 08:19:10,961 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> openDdsPorts Input udpPorts-  7650 <NL> openDdsPorts Output udpPorts-  7650 <NL> openDdsPorts Input udpPorts-  7651 <NL> 2024-07-31 08:19:10,996 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:19:11,008 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> openDdsPorts Output udpPorts-  7651 <NL> 2024-07-31 08:19:11,019 swdllite(agt): INFO - swdl_state_version.replay[51] agent_version: <NL> 2024-07-31 08:19:11,033 swdllite(agt): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl daughter.working.standalone, READY <NL> 2024-07-31 08:19:11,053 swdllite(agt): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> 2024-07-31 08:19:11,074 swdllite(agt): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\""}
{"timestamp_utc": "2024-07-31T08:19:12.501Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "openDdsPorts Input udpPorts-  7900"}
{"timestamp_utc": "2024-07-31T08:19:12.756Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:12 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:13.324Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  351.940991] python3[3922]: [.911] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  351.941092] python3[3922]: [.911] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  351.941181] python3[3922]: [.911] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  351.941258] python3[3922]: [.911] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  351.941334] python3[3922]: [.911] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  351.941441] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  351.941519] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  351.941601] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  351.941716] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  351.941812] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  351.941902] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  351.941979] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  351.986631] python3[3922]: [.960] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  351.986833] python3[3922]: [.960] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  351.986915] python3[3922]: [.960] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  351.986989] python3[3922]: [.961] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  351.987079] python3[3922]: [.961] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  351.987174] python3[3922]: [.961] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  351.987249] python3[3922]: [.961] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  352.007398] python3[3922]: [.979] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  352.007584] python3[3922]: [.979] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  352.007682] python3[3922]: [.980] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  352.007757] python3[3922]: [.980] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  352.007842] python3[3922]: [.980] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  352.007916] python3[3922]: [.980] valhdlr 139905129789248 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  352.007999] python3[3922]: [.980] valhdlr 139905129789248 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  352.043995] python3[3922]: [.017] valhdlr 139905129789248 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  352.050468] python3[3922]: [.018] valhdlr 139905129789248 callbackhdlr:293 Loading schemas <NL> [  352.092598] python3[3922]: DEBUG item does not exist - shared memory schema not enabled <NL> [  352.646973] snmp_clid[3928]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  353.590304] python3[3922]: [.554] valhdlr 139905129789248 callbackhdlr:382 Done load schemas <NL> [  353.590562] python3[3922]: [.554] valhdlr 139905129789248 callbackhdlr:389 Done register transaction callback <NL> [  354.051855] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted"}
{"timestamp_utc": "2024-07-31T08:19:13.325Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  354.119507] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  354.120411] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  354.120578] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  354.120700] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  354.120825] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  354.121942] confd_mgr[3010]: ConfdHA Not supported command CONFIRM <NL> [  354.204353] confd_mgr[3010]: sm_startconfd::p0_ready_dbc <NL> [  354.204820] confd_mgr[3010]: Find message SNMP_CLID_CONFIRM <NL> [  354.215249] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  354.215483] confd_mgr[3010]: sm_startconfd::p0_not_ready <NL> [  354.215644] confd_mgr[3010]: Find message SNMP_CLID_CONFIRM <NL> [  354.215721] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  354.215801] confd_mgr[3010]: leaving: sm_startconfd::wait_for_p0 <NL> [  354.215873] confd_mgr[3010]: entering: sm_startconfd::wait_for_p0 <NL> [  354.215940] confd_mgr[3010]: PROCESS_VALHDLR has not registered yet. <NL> [  354.216021] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  354.216096] confd_mgr[3010]: Timer /ConfdAT|wait_for_p0 already created <NL> [  354.226626] snmp_clid[3952]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  354.272163] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  354.272276] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  354.639707] python3[3922]: [.613] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  354.826204] python3[3922]: [.800] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  354.871894] python3[3922]: [.842] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  368.184552] python3[3922]: [.148] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  368.305211] python3[3922]: [.279] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  368.457392] python3[3922]: [.431] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  368.522171] python3[3922]: [.496] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  368.757403] python3[3922]: [.731] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  368.845642] python3[3922]: [.813] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  368.897475] python3[3922]: [.871] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  368.974762] python3[3922]: [.949] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  369.035397] python3[3922]: [.009] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  369.125995] python3[3922]: [.099] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  372.641592] python3[3922]: [.603] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  374.880653] python3[3922]: [.850] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  376.362579] python3[3922]: [.337] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  378.890858] python3[3922]: [.863] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  378.922457] python3[3922]: [.897] valhdlr 139905129789248 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  378.946597] python3[3922]: [.897] valhdlr 139905129789248 callbackhdlr:391 Done register data callbacks <NL> [  378.962187] python3[3922]: DEBUG No crypto keys configured"}
{"timestamp_utc": "2024-07-31T08:19:16.591Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:16 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:17.956Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:17 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:22.121Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:21 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:23.048Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:22 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:25.565Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  366.028966] python3[3920]: [.830] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  366.053727] python3[3920]: [.830] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  366.084378] python3[3920]: [.835] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  366.091457] python3[3920]: [.835] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  366.092859] python3[3920]: [.849] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  366.140889] python3[3920]: [.862] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  366.152901] python3[3920]: [.865] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  366.154117] python3[3920]: [.865] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  366.191825] python3[3920]: [.876] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  366.193448] python3[3920]: [.876] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  366.214668] python3[3920]: [.879] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  366.248527] python3[3920]: [.881] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.255199] python3[3920]: [.881] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  366.286659] python3[3920]: [.885] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  366.371824] python3[3920]: [.911] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  366.430930] python3[3920]: [.939] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  366.446527] python3[3920]: [.940] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  366.473237] python3[3920]: [.940] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  366.473363] python3[3920]: [.941] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  366.473592] python3[3920]: [.941] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  366.476525] python3[3920]: [.960] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  366.476665] python3[3920]: [.960] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.476766] python3[3920]: [.963] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  366.490819] python3[3920]: [.963] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  366.537774] python3[3920]: [.963] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  366.599979] python3[3920]: [.963] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  366.610903] python3[3920]: [.963] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  366.611049] python3[3920]: [.964] valhdlr 140012999513920 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  366.611130] python3[3920]: [.964] valhdlr 140012999513920 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  366.611768] python3[3920]: [.036] valhdlr 140012999513920 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  366.611869] python3[3920]: [.036] valhdlr 140012999513920 callbackhdlr:293 Loading schemas <NL> [  366.612088] python3[3920]: DEBUG item does not exist - shared memory schema not enabled <NL> [  367.180402] snmp_clid[3925]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  368.191705] python3[3920]: [.573] valhdlr 140012999513920 callbackhdlr:382 Done load schemas <NL> [  368.191963] python3[3920]: [.574] valhdlr 140012999513920 callbackhdlr:389 Done register transaction callback <NL> [  369.045270] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  369.046122] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  369.056508] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  369.056684] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  369.056769] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  369.056854] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  369.062488] confd_mgr[3001]: ConfdHA Not supported command CONFIRM <NL> [  369.062653] confd_mgr[3001]: sm_startconfd::p0_ready_dbc <NL> [  369.062747] confd_mgr[3001]: Find message SNMP_CLID_CONFIRM <NL> [  369.062842] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  369.062920] confd_mgr[3001]: sm_startconfd::p0_not_ready <NL> [  369.063111] confd_mgr[3001]: Find message SNMP_CLID_CONFIRM <NL> [  369.063219] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  369.063300] confd_mgr[3001]: leaving: sm_startconfd::wait_for_p0 <NL> [  369.063382] confd_mgr[3001]: entering: sm_startconfd::wait_for_p0 <NL> [  369.063449] confd_mgr[3001]: PROCESS_VALHDLR has not registered yet. <NL> [  369.063568] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  369.063652] confd_mgr[3001]: Timer /ConfdAT|wait_for_p0 already created <NL> [  369.064487] snmp_clid[3957]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  369.064655] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  369.064738] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  369.415193] python3[3920]: [.795] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  369.600016] python3[3920]: [.991] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  369.623158] python3[3920]: [.014] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  380.068723] python3[3920]: [.444] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  380.141844] python3[3920]: [.533] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  380.625969] python3[3920]: [.017] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  380.717108] python3[3920]: [.106] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  380.863659] python3[3920]: [.253] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  380.917893] python3[3920]: [.308] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  380.986797] python3[3920]: [.375] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  380.992994] python3[3920]: [.384] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  381.047870] python3[3920]: [.423] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  381.108512] python3[3920]: [.499] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  383.381131] python3[3920]: [.757] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  385.405395] python3[3920]: [.789] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb port_capability_validation"}
{"timestamp_utc": "2024-07-31T08:19:26.128Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  377.145751] common_alarm_handler[2114]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  377.161458] common_alarm_handler[2114]: topic = SecurityRadiusAcctProv; id = 98 <NL> [  377.181817] common_alarm_handler[2114]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  377.231059] common_alarm_handler[2114]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  377.300123] common_alarm_handler[2114]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  377.325226] common_alarm_handler[2114]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  377.563775] common_alarm_handler[2114]: topic = FscProv; id = 111 <NL> [  377.737246] common_alarm_handler[2114]: topic = XconProv_v2Prov; id = 112 <NL> [  377.862679] common_alarm_handler[2114]: topic = OchIfProv; id = 113 <NL> [  378.641318] usb_script_handler.py[2505]: 2024-Jul-31 08:18:07CommClient::CommClient Connection refused <NL> [  378.876986] usb_script_handler.py[2505]: 2024-Jul-31 08:18:09CommClient::CommClient Connection refused <NL> [  378.882860] usb_script_handler.py[2505]: 2024-Jul-31 08:18:12CommClient::CommClient Connection refused <NL> [  378.908222] usb_script_handler.py[2505]: 2024-Jul-31 08:18:14CommClient::CommClient Connection refused <NL> [  378.912668] usb_script_handler.py[2505]: 2024-Jul-31 08:18:16CommClient::CommClient Connection refused <NL> [  378.920160] usb_script_handler.py[2505]: 2024-Jul-31 08:18:19CommClient::CommClient Connection refused <NL> [  378.926828] usb_script_handler.py[2505]: 2024-Jul-31 08:18:21CommClient::CommClient Connection refused <NL> [  378.934459] usb_script_handler.py[2505]: 2024-Jul-31 08:18:27CommClient::CommClient Connection refused <NL> [  378.943238] usb_script_handler.py[2505]: 2024-Jul-31 08:18:29CommClient::CommClient Connection refused <NL> [  378.958410] usb_script_handler.py[2505]: 2024-Jul-31 08:18:31CommClient::CommClient Connection refused <NL> [  378.968701] usb_script_handler.py[2505]: 2024-Jul-31 08:18:33CommClient::CommClient Connection refused <NL> [  378.979550] usb_script_handler.py[2505]: Exception: Connect failed <NL> 2024-07-31 08:19:12,670 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  379.121174] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:19:13,151 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  380.644942] ntputils[1725]: /sbin/hwclock -u --systohc <NL> 2024-07-31 08:19:14,906 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  381.559803] ntputils[1725]: child pid is 2737 <NL> [  381.719651] ntputils[1725]: exited, status is 0 <NL> [  381.720891] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> 2024-07-31 08:19:15,224 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  383.732187] ntputils[1725]: poller time change delta is: 1 <NL> [  384.021274] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  384.022126] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> 2024-07-31 08:19:17,731 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  384.154088] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  384.155725] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> 2024-07-31 08:19:18,007 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  384.651954] ntputils[1725]: push_local_changes OK <NL> 2024-07-31 08:19:18,578 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  385.043384] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> 2024-07-31 08:19:19,367 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  386.569253] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  387.905592] ntputils[1725]: child pid is 2763 <NL> [  388.143811] ntputils[1725]: exited, status is 0 <NL> [  388.280376] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  388.425491] ntputils[1725]: poller time change delta is: 1 <NL> [  388.529353] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  388.680294] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  388.740592] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  388.783978] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  388.979569] ntputils[1725]: push_local_changes OK <NL> [  388.981443] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  388.991735] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  388.992441] ntputils[1725]: child pid is 2772 <NL> [  389.022728] ntputils[1725]: exited, status is 0 <NL> [  389.030684] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  389.036747] ntputils[1725]: poller time change delta is: 1 <NL> [  389.038442] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  389.044988] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  389.056726] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  389.099128] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  389.122670] ntputils[1725]: push_local_changes OK"}
{"timestamp_utc": "2024-07-31T08:19:26.129Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  389.166807] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  389.190433] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  389.210270] ntputils[1725]: child pid is 2788 <NL> [  389.216487] ntputils[1725]: exited, status is 0 <NL> [  389.220941] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  389.230351] ntputils[1725]: poller time change delta is: 1 <NL> [  389.236149] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  389.264070] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  389.273842] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  389.314750] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  389.329419] ntputils[1725]: push_local_changes OK <NL> [  389.373139] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  389.398507] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  389.437537] ntputils[1725]: child pid is 2810 <NL> [  389.490767] ntputils[1725]: exited, status is 0 <NL> [  389.717269] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  389.786872] ntputils[1725]: poller time change delta is: 2 <NL> [  389.927895] ntputils[1725]: push_local_changes user_changed: 0 delta: 2 <NL> [  389.934613] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  389.996329] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  390.343112] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  390.382988] ntputils[1725]: push_local_changes OK <NL> [  390.530921] cia_control_layer[2116]: EsalConfig::EsalConfig main 1 <NL> [  390.618065] cia_control_layer[2116]: EsalConfig::EsalConfig trib 0 <NL> [  390.737885] cia_control_layer[2116]: EsalConfig::EsalConfig ciRole 0 <NL> [  391.204853] cia_control_layer[2116]: EsalConfig is not running inside container. <NL> [  391.355314] cia_control_layer[2116]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  391.744620] cia_control_layer[2116]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  391.804720] cia_control_layer[2116]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  391.810698] cia_control_layer[2116]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  391.852851] cia_control_layer[2116]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:19:26.691Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:26 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:27.253Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:18:11,822 swdllite(mgr): INFO - fsm.log[312] STATE-CONFDMGR: GO_READY -> WAIT_STATE -> replay_fn -> READY_STATE <NL> [  317.501256] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:18:20,400 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: update, redundancyStatus: 0 <NL> 2024-07-31 08:18:20,846 swdllite(int): INFO - swdllited_int.executor_fn[59] executing: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  328.021913] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  332.977220] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  333.663034] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  333.695289] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:18:29,837 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[30] started: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE <NL> [  335.587823] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  336.267915] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  338.128862] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  338.176353] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:18:33,026 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  338.541577] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  342.007512] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:18:36,544 swdllite(mgr): INFO - swdl_base_fsm_fn.update_redundancy_info[48] msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: 0 <NL> [  346.507228] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> 2024-07-31 08:18:51,221 swdllite(mgr): INFO - swdl_state_confdmgr.update[181] mgr_confdmgr_state: role=main, action=REDUNDANCY_UPDATE <NL> [  356.425945] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  359.643740] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  361.619754] ains_manager[2388]: Failed to get unit file state for rdm-chassis.service: No such file or directory <NL> [  361.865507] trb-cdsf-app[2226]: DDD cdsf-app running <NL> [  363.149502] cia_control_layer[2227]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> ERROR:root:empty repository <NL> [  365.514179] common_alarm_handler[2225]: gen_util: DDS_P2MP not available <NL> [  368.580341] common_alarm_handler[2225]: static void sll::key_value::TopicKeyValueFile::ReadTopicIdFile(): reading file: /etc/topic_id_mapping.csv <NL> [  369.315985] common_alarm_handler[2225]: topic = SystemProv; id = 1 <NL> [  372.538077] common_alarm_handler[2225]: topic = WdmcfgProv; id = 2 <NL> [  373.212796] common_alarm_handler[2225]: topic = LicenseStatusTopic; id = 3 <NL> [  373.251963] common_alarm_handler[2225]: topic = ShelfProv; id = 5 <NL> [  373.353411] common_alarm_handler[2225]: topic = SlotProv; id = 6 <NL> [  373.398961] common_alarm_handler[2225]: topic = PortProv; id = 7 <NL> [  373.429039] common_alarm_handler[2225]: topic = SubportProv; id = 8 <NL> [  373.448555] common_alarm_handler[2225]: topic = FconProv; id = 9 <NL> 2024-07-31 08:19:11,250 swdllite(agt): INFO - swdllited_base_utils.start_background_thread[517] start_background_thread: func=background_backup <NL> [  375.251182] common_alarm_handler[2225]: topic = XconProv; id = 10 <NL> [  376.127158] common_alarm_handler[2225]: topic = OchProv; id = 11 <NL> 2024-07-31 08:19:12,042 swdllite(mgr): INFO - swdl_base_fsm_fn.cmd_line_processing[110] executing command: ssw-sync <NL> 2024-07-31 08:19:12,508 swdllite(agt): INFO - swdl_backup.run[208] running backup: notblocked=True, notpaused=True, skip_disk_check=True <NL> [  378.872810] common_alarm_handler[2225]: topic = OmsProv; id = 12 <NL> 2024-07-31 08:19:16,258 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  381.807314] common_alarm_handler[2225]: topic = OtsProv; id = 13 <NL> 2024-07-31 08:19:18,221 swdllite(agt): INFO - swdllited_agent.read_versions[229] agent: active version: <NL> 2024-07-31 08:19:19,414 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  383.878157] common_alarm_handler[2225]: topic = EthernetProv; id = 14 <NL> 2024-07-31 08:19:20,095 swdllite(agt): INFO - swdllited_agent.read_versions[231] agent: staging version: <NL> [  384.023892] common_alarm_handler[2225]: topic = DcnDhcpDhcpV4ClientAttributes; id = 15"}
{"timestamp_utc": "2024-07-31T08:19:27.254Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:19:20,124 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> 2024-07-31 08:19:20,578 swdllite(agt): INFO - swdllited_agent.read_versions[233] agent: backup version: <NL> [  384.498965] common_alarm_handler[2225]: topic = DcnDhcpv6Dhcpv6ClientAttributes; id = 16 <NL> [  384.661637] common_alarm_handler[2225]: topic = DcnIpInterface_IntfAttributes; id = 17 <NL> 2024-07-31 08:19:20,748 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> 2024-07-31 08:19:20,859 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> 2024-07-31 08:19:20,890 swdllite(agt): INFO - fsm.log[312] LOGFSM: BACKUP_COMPLETE_EVT -> STARTUP_STATE -> backup_complete_fn -> READY_STATE <NL> 2024-07-31 08:19:20,955 swdllite(agt): INFO - swdl_agent_fn.ready_entry_fn[309] ready_entry_fn called <NL> [  384.864967] common_alarm_handler[2225]: topic = DcnIpv4_Ipv4Attributes; id = 18 <NL> 2024-07-31 08:19:21,173 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> 2024-07-31 08:19:21,358 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  385.279532] common_alarm_handler[2225]: topic = DcnIpv6_Ipv6Attributes; id = 19 <NL> [  385.764571] common_alarm_handler[2225]: topic = DcnStaticRoute_DcnStaticRoute; id = 21 <NL> 2024-07-31 08:19:21,897 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> [  386.004649] common_alarm_handler[2225]: topic = router_bgp_dds_bgp_global_prov; id = 22 <NL> [  386.052121] common_alarm_handler[2225]: topic = router_bgp_dds_bgp_network_prov; id = 23 <NL> [  386.095747] common_alarm_handler[2225]: topic = router_bgp_dds_bgp_peer_group_prov; id = 24 <NL> [  386.120370] common_alarm_handler[2225]: topic = router_bgp_dds_bgp_peer_prov; id = 25 <NL> [  386.596045] common_alarm_handler[2225]: topic = router_ospf_dds_ospf_area_group_prov; id = 26 <NL> [  386.598318] common_alarm_handler[2225]: topic = router_ospf_dds_ospf_area_range_group_prov; id = 27 <NL> 2024-07-31 08:19:23,071 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  387.304205] common_alarm_handler[2225]: topic = router_ospf_dds_ospf_basic_group_prov; id = 28"}
{"timestamp_utc": "2024-07-31T08:19:27.815Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:28.070Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:27 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:32.245Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:31 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:33.173Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:33.174Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:32 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:36.477Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  391.858323] cia_control_layer[2116]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  391.862749] cia_control_layer[2116]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  391.903112] cia_control_layer[2116]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  392.015678] cia_control_layer[2116]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  392.016804] cia_control_layer[2116]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  392.017874] cia_control_layer[2116]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  392.180638] cia_control_layer[2116]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  392.210221] cia_control_layer[2116]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  392.317128] cia_control_layer[2116]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  392.400435] cia_control_layer[2116]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  392.401423] cia_control_layer[2116]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  392.437115] cia_control_layer[2116]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  392.477810] cia_control_layer[2116]: Control Layer started successfully. <NL> [  392.478666] cia_control_layer[2116]: Got the unitName from Platform General topic: BDC2-C200 <NL> [  392.642146] cia_control_layer[2116]: Xml found in the map for unitName: BDC2-C200 <NL> [  392.643150] cia_control_layer[2116]: Going with file C200_shelfData.xml <NL> [  392.858758] cia_control_layer[2116]: Setting Pm xml files as below: <NL> [  392.882771] cia_control_layer[2116]: Shelf: C200_shelfPmData.xml <NL> [  392.883834] cia_control_layer[2116]: Port: C200_pluggablePmData.xml <NL> [  392.929741] cia_control_layer[2116]: Eth: C200_dcnL2EthernetIfData.xml <NL> [  393.154295] common_alarm_handler[2114]: topic = AclProfileProv; id = 114 <NL> [  393.155855] common_alarm_handler[2114]: topic = OtuProv; id = 115 <NL> [  393.663315] common_alarm_handler[2114]: topic = GeProv; id = 116 <NL> [  393.664163] common_alarm_handler[2114]: topic = OduProv; id = 117 <NL> [  393.664904] common_alarm_handler[2114]: topic = TcmProv; id = 118 <NL> [  393.666826] common_alarm_handler[2114]: topic = OCnProv; id = 119 <NL> [  393.966525] common_alarm_handler[2114]: topic = OnDemandDM; id = 120 <NL> [  394.124292] common_alarm_handler[2114]: topic = OducnProv; id = 121 <NL> [  394.273668] common_alarm_handler[2114]: topic = OtsiProv; id = 122 <NL> [  394.295833] common_alarm_handler[2114]: topic = OtsigProv; id = 123 <NL> [  394.296684] common_alarm_handler[2114]: topic = OtucnProv; id = 124 <NL> [  394.375063] common_alarm_handler[2114]: topic = YpgProv; id = 125 <NL> [  394.387172] common_alarm_handler[2114]: topic = EpgProv; id = 126 <NL> [  394.523780] common_alarm_handler[2114]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  394.637769] common_alarm_handler[2114]: topic = DataEncryptionOperReq; id = 128 <NL> [  394.652373] common_alarm_handler[2114]: topic = RoutePolicyTableProv; id = 129 <NL> [  394.665553] common_alarm_handler[2114]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  395.193492] common_alarm_handler[2114]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  395.754854] common_alarm_handler[2114]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  396.095672] common_alarm_handler[2114]: topic = ShapingProfileProv; id = 133 <NL> [  396.232194] common_alarm_handler[2114]: topic = TaildropProfileProv; id = 134 <NL> [  396.251535] common_alarm_handler[2114]: topic = PolicingProfileProv; id = 135 <NL> [  396.328263] common_alarm_handler[2114]: topic = CapabilityProfileProv; id = 136 <NL> [  396.396837] common_alarm_handler[2114]: topic = TransportInterfaceRateProv; id = 137 <NL> [  396.626177] common_alarm_handler[2114]: topic = PmRtrvReqSess; id = 138 <NL> [  396.662255] common_alarm_handler[2114]: topic = PmRtrvRespSess; id = 139 <NL> [  396.721939] common_alarm_handler[2114]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  396.819546] common_alarm_handler[2114]: topic = DataEncryptionPskReq; id = 141 <NL> [  397.208974] common_alarm_handler[2114]: topic = SystemWebserverProv; id = 142 <NL> [  397.397813] common_alarm_handler[2114]: NO match: <NL> [  397.410298] common_alarm_handler[2114]: NO match: <NL> [  397.480861] common_alarm_handler[2114]: NO match: <NL> Exception: Connect failed <NL> [  398.298256] usb_script_handler.py[2511]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf noSecondaryStorage' <NL> [  398.308980] usb_script_handler.py[2511]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" noSecondaryStorage' <NL> [  398.324451] usb_script_handler.py[2511]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  398.342114] usb_script_handler.py[2511]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  398.358841] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  398.371318] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  398.380319] ntputils[1725]: child pid is 2824 <NL> [  398.384675] ntputils[1725]: exited, status is 0 <NL> [  398.388774] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  398.402035] ntputils[1725]: poller time change delta is: 1 <NL> [  398.482380] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  398.491212] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  398.497154] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  398.502846] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  398.510049] ntputils[1725]: push_local_changes OK <NL> [  398.514364] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  398.521092] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  398.522775] ntputils[1725]: child pid is 2836 <NL> [  398.528339] ntputils[1725]: exited, status is 0 <NL> [  398.535925] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  398.543453] ntputils[1725]: poller time change delta is: 1 <NL> [  398.546266] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  398.553359] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  398.559324] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  398.605522] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  398.611814] ntputils[1725]: push_local_changes OK <NL> [  398.612908] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  398.634251] ntputils[1725]: /sbin/hwclock -u --systohc <NL> HA_MODE=1+1, MAIN_TRIB_RED=FALSE <NL> [  398.644699] ntputils[1725]: child pid is 2853 <NL> grep: [  398.837266] ntputils[1725]: exited, status is 0 <NL> /var/shared/confd/ResetType[  398.942655] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  398.963184] ntputils[1725]: poller time change delta is: 2 <NL> [  398.963974] ntputils[1725]: push_local_changes user_changed: 0 delta: 2 <NL> [  398.964765] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> : No such file or directory <NL> [  399.666310] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  399.846791] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  400.166243] ntputils[1725]: push_local_changes OK <NL> [  400.417286] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  400.877209] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  400.877863] ntputils[1725]: child pid is 2873 <NL> [  401.072479] ntputils[1725]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:19:36.478Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  401.263936] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  401.375267] ntputils[1725]: poller time change delta is: 2 <NL> [  401.632708] ntputils[1725]: push_local_changes user_changed: 0 delta: 2 <NL> [  401.638704] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  401.639978] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  401.649783] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  401.661380] ntputils[1725]: push_local_changes OK <NL> [  402.186200] usb_script_handler.py[2504]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf invalidUSB' <NL> [  402.286177] usb_script_handler.py[2504]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" invalidUSB' <NL> # 03:19:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:36 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:37.856Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:38.130Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:37 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:40.018Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:19:39 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37229\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:19:41.905Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:41 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:42.832Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  402.287538] usb_script_handler.py[2504]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  402.288784] usb_script_handler.py[2504]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  404.520248] python3[2135]: [.374] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  404.735586] python3[2135]: [.375] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  404.775431] python3[2135]: [.414] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  404.910585] python3[2135]: [.414] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  404.922926] python3[2135]: [.415] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  404.925715] python3[2135]: [.475] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  405.082309] python3[2135]: [.475] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  405.083533] python3[2135]: [.475] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  405.215949] python3[2135]: [.475] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  405.217541] python3[2135]: [.489] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  405.218816] python3[2135]: [.489] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  405.576513] python3[2135]: [.489] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  405.678152] python3[2135]: [.489] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  405.682435] python3[2135]: [.490] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  405.706226] python3[2135]: [.490] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  405.708682] python3[2135]: [.490] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  405.848457] python3[2135]: [.524] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  405.981528] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  406.028241] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  406.074175] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  406.079855] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  406.083424] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  406.087386] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  406.231205] python3[2135]: [.966] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  406.242285] python3[2135]: [.449] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  406.249836] python3[2135]: [.599] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  406.278911] python3[2135]: [.346] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  406.516447] python3[2135]: [.853] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  406.517703] python3[2135]: [.854] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  406.536337] python3[2135]: [.854] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  406.537613] python3[2135]: [.854] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  406.645588] python3[2135]: [.854] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  406.647580] python3[2135]: [.998] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  406.664925] python3[2135]: [.123] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  406.666273] python3[2135]: [.123] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  406.693764] python3[2135]: [.123] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  406.824466] python3[2135]: [.123] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  406.845182] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  407.051595] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  408.174467] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> 2024-07-31 08:19:41,849 swdllite(mgr): INFO - swdl_base_fsm_fn.cmd_line_processing[110] executing command: ssw-sync <NL> [  408.203367] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> 2024-07-31 08:19:41,891 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  408.215085] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> 2024-07-31 08:19:41,906 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  408.248699] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  408.266415] python3[2135]: [.124] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> 2024-07-31 08:19:41,936 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  408.288491] python3[2135]: [.522] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> 2024-07-31 08:19:41,989 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  408.312215] python3[2135]: [.524] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  408.322474] python3[2135]: [.601] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  408.323825] python3[2135]: [.601] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  408.346804] python3[2135]: [.601] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  408.348307] python3[2135]: [.601] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> 2024-07-31 08:19:42,044 swdllite(mgr): INFO - swdl_mgr_ssw_fn.start_ssw_read[652] start_ssw_read_repo_thread returned 0 <NL> 2024-07-31 08:19:42,044 swdllite(mgr): INFO - swdl_ssw.is_ssw_mount_present[193] simulated ssw mount: /mnt/secondary <NL> [  408.380201] python3[2135]: [.617] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> 2024-07-31 08:19:42,073 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_repo[353] mount present <NL> [  408.426457] python3[2135]: [.786] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:19:43.088Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:42 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:42 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37261\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:19:44.975Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:19:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:46.860Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:46 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:48.223Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:47 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',) <NL> # 03:19:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:19:49.619Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "INFO:root:Running confd_mgr_swdl_ready.py <NL> 2024-07-31 08:19:24,997 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  390.171072] common_alarm_handler[2225]: topic = router_ospf_dds_ospf_if_group_prov; id = 29 <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> 2024-07-31 08:19:28,872 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  393.026659] common_alarm_handler[2225]: topic = router_ospf_dds_ospf_network_group_prov; id = 30 <NL> 2024-07-31 08:19:29,996 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  394.471756] common_alarm_handler[2225]: topic = router_router_policy_dds_BgpRtPolDefinedSetsTable; id = 31 <NL> [  394.668631] common_alarm_handler[2225]: topic = router_router_policy_dds_RoutePolicyConditionsTable; id = 32 <NL> 2024-07-31 08:19:30,779 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> [  394.752738] common_alarm_handler[2225]: topic = router_router_policy_dds_RoutePolicySetActionsTable; id = 33 <NL> [  394.845432] common_alarm_handler[2225]: topic = router_router_policy_dds_RoutePolicyTable; id = 34 <NL> 2024-07-31 08:19:30,983 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> [  395.058597] common_alarm_handler[2225]: topic = router_static_route_dds_static_route_prov; id = 35 <NL> [  395.060813] common_alarm_handler[2225]: topic = AlarmNotification; id = 40 <NL> [  395.180231] common_alarm_handler[2225]: topic = GenericOperInfoReq; id = 41 <NL> [  395.180990] common_alarm_handler[2225]: topic = PmRtrvReq; id = 42 <NL> [  395.226487] common_alarm_handler[2225]: topic = PmRtrvResp; id = 43 <NL> [  395.227339] common_alarm_handler[2225]: topic = PmInitReq; id = 44 <NL> [  395.228746] common_alarm_handler[2225]: topic = PmOperData; id = 45 <NL> 2024-07-31 08:19:31,433 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  395.432990] common_alarm_handler[2225]: topic = StateChange; id = 46 <NL> [  395.921191] common_alarm_handler[2225]: topic = DcnIpInterfaceIntfAttributes; id = 48 <NL> 2024-07-31 08:19:32,112 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  396.211937] common_alarm_handler[2225]: topic = DcnIpv4Ipv4Attributes; id = 49 <NL> 2024-07-31 08:19:33,356 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124] <NL> [  398.041180] common_alarm_handler[2225]: topic = DcnIpv6Ipv6Attributes; id = 50 <NL> 2024-07-31 08:19:34,543 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  398.875754] common_alarm_handler[2225]: topic = DcnStaticRouteRoutingInfoTable; id = 52 <NL> 2024-07-31 08:19:38,582 swdllite(mgr): INFO - swdllited_mgr_version.read_active_version[61] active version: 24.1.1_fss3_cd4528,20240726224122 <NL> [  402.866676] common_alarm_handler[2225]: topic = router_bgp_dds_AddressFamily; id = 53 <NL> 2024-07-31 08:19:39,571 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[79] staging version: <NL> [  404.068633] common_alarm_handler[2225]: topic = router_ospf_dds_ospf_nbr_group_prov; id = 54 <NL> 2024-07-31 08:19:40,330 swdllite(mgr): INFO - swdllited_mgr_version.read_other_versions[85] backup version: <NL> [  404.402981] confd_director.py[2489]: rm: cannot remove '/var/shared/confd/ha_status': No such file or directory <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> 2024-07-31 08:19:41,054 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[47] active repo: <NL> [  405.019438] startup_finished.py[2080]: Startup Finished: systemd state is non-Production mode and running <NL> 2024-07-31 08:19:41,191 swdllite(mgr): INFO - swdllited_mgr_version.update_repo_summary[48] staging repo: <NL> [  405.148693] startup_finished.py[2080]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  405.150295] startup_finished.py[2080]: *****Startup Finished: stopping EOW timer***** <NL> [  405.165760] startup_finished.py[2080]: systemctl stop startup_finished_limit.timer"}
{"timestamp_utc": "2024-07-31T08:19:49.620Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "2024-07-31 08:19:41,334 swdllite(mgr): INFO - swdl_state_version.replay[51] mgr_version: bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> STANDALONE <NL> [  405.348886] usb_script_handler.py[2042]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf invalidUSB' <NL> ======= Changing UNKNOWN redMode ========= <NL> [  405.620854] usb_script_handler.py[2042]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" invalidUSB' <NL> [  405.801973] usb_script_handler.py[2042]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm invalidUSB invalidUSB' <NL> [  405.878139] usb_script_handler.py[2042]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm invalidUSB invalidUSB' <NL> 2024-07-31 08:19:41,857 swdllite(mgr): INFO - swdl_publish_dds.do_dds_swdl_publish[189] Publishing Platform::Swdl main.working.standalone, READY <NL> 2024-07-31 08:19:42,717 swdllite(mgr): INFO - swdl_gpb_support.adjust_versions[474] version adjustment: state=READY <NL> [  406.808103] python3[2242]: [.170] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> 2024-07-31 08:19:43,146 swdllite(mgr): INFO - swdl_publish_dds.dds_sw_version_publish[131] dds_send: o Platform::SwVersion # <NL> state: \"READY\" <NL> bank { <NL> bank_id: ACTIVE <NL> gissue: \"24.1.1\" <NL> build_detail: \"fss3_cd4528,20240726224122\" <NL> } <NL> [  407.689171] python3[2242]: [.530] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  409.081117] python3[2242]: [.644] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  409.427865] python3[2242]: [.146] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  409.447146] python3[2242]: [.147] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  409.588965] python3[2242]: [.371] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  409.973828] python3[2242]: [.372] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  410.038793] python3[2242]: [.390] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  410.071297] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  410.180782] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  410.218544] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  410.961579] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  411.330582] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  411.785698] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:19:51.511Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:51 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:53.400Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:52 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:56.665Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:19:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:56 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:57.593Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:19:42,122 swdllite(mgr): INFO - swdl_gpb_support.populate_repository_buffer[371] exiting with retval=0 <NL> [  408.454803] python3[2135]: [.813] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  408.484566] python3[2135]: [.813] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  408.498899] python3[2135]: [.813] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  408.535637] python3[2135]: [.813] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  408.555488] python3[2135]: [.813] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  409.218899] usb_script_handler.py[2512]: {\"command\": \"ssw-sync\"} <NL> [  409.926973] usb_script_handler.py[2512]: {'return-value': 0, 'response-message': 'Ok, command accepted'} <NL> [  409.946323] python3[2135]: [.814] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> 2024-07-31 08:19:42,784 swdllite(mgr): INFO - swdllited_mgr_repo.read_secondary_integrity[321] integrity subproc: timeout -s SIGKILL 180 swdl_run_integrity.py --ip  --mount /mnt/secondary --script remote_file_info_client.py --base /mnt/secondary/var/shared --algorithm longest-match BDC2-C200.0001 /mnt/secondary/var/shared/swdl/repository/active <NL> [  410.246946] python3[2135]: [.825] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  411.034694] python3[2135]: [.825] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  411.206325] python3[2135]: [.825] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  411.313544] python3[2135]: [.825] hookhdlr 140644876773184 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  411.809952] python3[2135]: [.826] hookhdlr 140644876773184 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  412.190739] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  412.513604] python3[2135]: [.885] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  412.539870] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  412.637867] python3[2135]: [.961] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  412.788048] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  412.866907] python3[2135]: [.157] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  413.309987] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  413.638202] python3[2135]: [.823] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  414.472904] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  414.551761] python3[2135]: [.284] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  414.746283] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  414.840603] python3[2135]: [.629] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  414.850220] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  414.852382] python3[2135]: [.671] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  415.597020] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  416.163317] python3[2135]: [.754] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  416.386447] confd_phase_sentry[2140]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> /run/rdm_status.sh created successfully <NL> [  416.436848] confd_phase_sentry[2140]: ConfdPhaseSentry: Connecting to confd: port = 4000; retry_delay = 5; waiting on phase = 2 <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> [  416.488838] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  416.891967] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  417.095791] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  417.493087] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  417.670696] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:19:57.594Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  417.895145] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  418.903901] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  419.679345] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  419.749960] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  419.890536] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  420.064426] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  420.159104] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  420.163125] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  420.178144] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  420.545714] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  421.095801] python3[2135]: [.852] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  421.361865] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  421.777868] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  421.949589] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  422.116676] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  422.175179] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.260786] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:19:58.156Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:19:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:19:57 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:19:58.718Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  423.267349] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.284624] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.304124] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.400222] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.405901] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.422721] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.430839] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.443135] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.448946] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.477761] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.522736] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> ERROR:root:empty repository <NL> [  423.532168] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.536273] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.546644] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.550177] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.557295] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.565346] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.574551] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.595443] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.601484] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.603699] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.613479] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.615667] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.632132] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.634178] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.647927] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.676522] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.695299] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.701782] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.719761] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.729202] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.749813] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.761853] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.782655] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.789231] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:19:57,515 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[307] Raising alarm: swRepoIncomplete COM <NL> [  423.871428] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.886162] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.892232] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  423.920540] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.927601] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> 2024-07-31 08:19:57,610 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: redundantCfgSwRepoOutOfSync COM <NL> [  423.932181] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  423.953319] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> 2024-07-31 08:19:57,656 swdllite(mgr): INFO - swdl_state_repo.replay[37] mgr_repo: <NL> 2024-07-31 08:19:57,674 swdllite(mgr): INFO - swdl_publish_dds.do_dds_sw_repository_publish[115] dds_send: o Platform::SwRepository # bytearray(b'')... <NL> 2024-07-31 08:19:57,687 swdllite(mgr): INFO - swdl_state_alarm.replay[117] publish softwareSyncInProgress: entity=COM, clear=True <NL> [  424.020213] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:19:57,706 swdllite(mgr): INFO - swdl_publish_dds.dds_publish_condition[318] Clearing alarm: softwareSyncInProgress COM <NL> [  424.036502] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.041297] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> 2024-07-31 08:19:57,719 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[124]"}
{"timestamp_utc": "2024-07-31T08:20:01.234Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  412.103519] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  412.660526] python3[2242]: [.698] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  413.134426] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  413.374570] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  413.501912] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  413.553831] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  413.583905] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  413.947481] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  413.954584] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  413.956736] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  413.957866] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  413.979604] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  413.982875] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  414.044276] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  414.274596] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  414.666588] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  414.855200] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  415.823366] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  416.016850] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  416.238956] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  416.770880] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  416.817239] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  416.960421] common_alarm_handler[2225]: topic = router_ospf_dds_key_chain_prov; id = 55 <NL> [  417.218516] common_alarm_handler[2225]: topic = EthIfProv; id = 56 <NL> [  417.219401] common_alarm_handler[2225]: topic = DcnNat64Attributes; id = 57 <NL> [  417.220264] common_alarm_handler[2225]: topic = DcnNat44Nat44Attributes; id = 58 <NL> [  417.221202] common_alarm_handler[2225]: topic = LldpGlobalCfgProv; id = 59 <NL> [  417.326383] common_alarm_handler[2225]: topic = LldpPortCfgProv; id = 60 <NL> [  417.496058] common_alarm_handler[2225]: topic = DcnDhcpDhcpv4RelayAttributes; id = 61 <NL> [  417.706666] common_alarm_handler[2225]: topic = DcnDhcpv6Dhcpv6RelayAttributes; id = 62 <NL> [  417.719240] common_alarm_handler[2225]: topic = rstp_bridge_dds_rstp_bridge_prov; id = 63 <NL> [  418.100924] common_alarm_handler[2225]: topic = rstp_bridge_dds_rstp_bridge_port_prov; id = 64 <NL> [  418.408669] common_alarm_handler[2225]: topic = DcnAclAcl_ip_Prov; id = 65 <NL> [  418.410091] common_alarm_handler[2225]: topic = DcnAclIpAttachAcl_ip_attach_Prov; id = 66 <NL> [  418.469937] common_alarm_handler[2225]: topic = DcnDhcpDhcpServerGlobalAttributesProv; id = 67 <NL> [  418.567676] common_alarm_handler[2225]: topic = DcnDhcpDhcpServerSharedNetAttributesProv; id = 68 <NL> [  418.695682] common_alarm_handler[2225]: topic = DcnDhcpDhcpServerUserdefAttributesProv; id = 69 <NL> [  418.870059] common_alarm_handler[2225]: topic = DcnPppAttributesProv; id = 70 <NL> [  418.946039] common_alarm_handler[2225]: topic = LldpGlobalInstCfgProv; id = 71 <NL> [  418.946970] common_alarm_handler[2225]: topic = LldpBladeCfgProv; id = 72 <NL> [  418.974868] common_alarm_handler[2225]: topic = LldpPortInstCfgProv; id = 73 <NL> [  419.014811] common_alarm_handler[2225]: topic = DcnGreTunnelProv; id = 74 <NL> [  419.030972] common_alarm_handler[2225]: topic = DcnDnsClientResolverProv; id = 75 <NL> [  419.901537] common_alarm_handler[2225]: topic = DcnDnsClientSearchProv; id = 76 <NL> HA_MODE=1+1, MAIN_TRIB_RED=FALSE <NL> [  420.242271] common_alarm_handler[2225]: topic = DcnDnsClientOptionsProv; id = 77 <NL> [  420.515995] common_alarm_handler[2225]: topic = SysGnmiCertProv; id = 78 <NL> [  420.598308] common_alarm_handler[2225]: topic = IetfInterfaceProv; id = 79 <NL> [  420.884428] common_alarm_handler[2225]: topic = DcnQosDcnQosAttributesProv; id = 80 <NL> [  421.195220] common_alarm_handler[2225]: topic = SystemAutoLogoffProv; id = 81 <NL> [  421.515303] common_alarm_handler[2225]: topic = SystemSshClientKeepaliveProv; id = 82 <NL> [  422.302365] common_alarm_handler[2225]: topic = SystemPortsProv; id = 83 <NL> [  422.370715] common_alarm_handler[2225]: topic = OspfProvisioningModeProv; id = 84 <NL> [  422.387751] common_alarm_handler[2225]: topic = dcn_ospfv3_dds_AreaGroupProv; id = 85 <NL> [  422.389659] common_alarm_handler[2225]: topic = dcn_ospfv3_dds_AreaRangeGroupProv; id = 86 <NL> [  422.393315] common_alarm_handler[2225]: topic = BasicGroupProv; id = 87 <NL> [  422.395376] common_alarm_handler[2225]: topic = dcn_ospfv3_dds_IfGroupProv; id = 88 <NL> [  422.397719] common_alarm_handler[2225]: topic = dcn_ospfv3_dds_RedistributeGroupProv; id = 89 <NL> [  422.401186] common_alarm_handler[2225]: topic = SystemFipsProv; id = 90 <NL> [  422.402232] common_alarm_handler[2225]: topic = SystemFipsCriteriaProv; id = 91 <NL> [  422.403511] common_alarm_handler[2225]: topic = SecuritySystemwideProv; id = 92 <NL> [  422.452864] common_alarm_handler[2225]: topic = DataEncryptionProv; id = 93 <NL> [  422.558245] common_alarm_handler[2225]: topic = SystemServicesProv; id = 94 <NL> [  422.572718] common_alarm_handler[2225]: topic = DcnProxyNdpProxyNdpAttributesProv; id = 95 <NL> [  422.588792] common_alarm_handler[2225]: topic = SystemSshAlgorithmProv; id = 96 <NL> [  422.597569] common_alarm_handler[2225]: topic = SecurityRadiusAuthProv; id = 97 <NL> [  422.603688] common_alarm_handler[2225]: topic = SecurityRadiusAcctProv; id = 98"}
{"timestamp_utc": "2024-07-31T08:20:01.235Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  422.733109] common_alarm_handler[2225]: topic = SecurityTacacsAuthProv; id = 99 <NL> [  422.761092] common_alarm_handler[2225]: topic = SecurityTacacsAcctProv; id = 100 <NL> [  422.977808] common_alarm_handler[2225]: topic = SystemwideAuthOrderProv; id = 101 <NL> [  422.978856] common_alarm_handler[2225]: topic = SystemwideAcctOrderProv; id = 102 <NL> [  422.979909] common_alarm_handler[2225]: topic = FscProv; id = 111 <NL> [  423.142719] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  423.176864] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  423.225597] ntputils[1724]: child pid is 2949 <NL> [  423.274832] ntputils[1724]: exited, status is 0 <NL> [  423.495103] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  423.608434] ntputils[1724]: poller time change delta is: 1 <NL> [  423.670183] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  423.810588] ntputils[1724]: local_push OK u Platform::Time changedByUser 0"}
{"timestamp_utc": "2024-07-31T08:20:01.797Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:01 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:03.162Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:02 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:06.429Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "2024-07-31 08:19:57,735 swdllite(mgr): INFO - swdllited_mgr_repo.publish_repository_data_fn[125] Repo integrity: { <NL> \"ACTIVE\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> }, <NL> \"SECONDARY\": { <NL> \"match_value\": 2, <NL> \"summary\": { <NL> \"corrupt_count\": 0, <NL> \"is_default\": 0, <NL> \"is_spare\": 0, <NL> \"missing_count\": 0, <NL> \"result\": \"MISSING\", <NL> \"valid_count\": 0, <NL> \"version_dict\": {}, <NL> \"version_match\": 2 <NL> } <NL> } <NL> } <NL> [  424.056618] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.104901] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  424.109232] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.111228] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  424.119258] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.121244] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  424.127215] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.130279] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  424.151472] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.175306] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  424.177426] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  424.227638] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  424.392689] temp_acct_cleanup_app[2147]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  424.407690] temp_acct_cleanup_app[2147]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  424.440792] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 1 <NL> [  424.496528] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 2 <NL> [  424.501149] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 3 <NL> [  424.522546] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 4 <NL> [  424.524950] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 5 <NL> [  424.530475] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 6 <NL> [  424.554108] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 7 <NL> [  424.564273] txid_tracker[2148]: ::::create_confd_subscription_connection() try number 8"}
{"timestamp_utc": "2024-07-31T08:20:06.430Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  424.782715] cseries_hal[2157]: HAL main() begins. <NL> [  424.786762] cseries_hal[2157]: hal_default::hal_init() called <NL> [  424.850574] cseries_hal[2157]: EsalPmiClient::EsalPmiClient <NL> [  425.164172] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  425.188086] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  425.247414] startup_finished.py[2040]: Startup Finished: systemd state is non-Production mode and running <NL> [  426.429513] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 1 <NL> [  426.430520] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 2 <NL> [  426.469734] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 3 <NL> [  426.514195] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 4 <NL> [  426.790050] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 5 <NL> [  426.795858] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 6 <NL> [  426.867305] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 7 <NL> [  426.868311] txid_tracker[2328]: ::::create_confd_subscription_connection() try number 8 <NL> [  427.127580] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 1 <NL> [  427.128616] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 2 <NL> [  427.206709] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 3 <NL> [  427.209237] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 4 <NL> [  427.291669] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 5 <NL> [  427.292631] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 6 <NL> [  427.293716] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 7 <NL> [  427.294722] txid_tracker[2437]: ::::create_confd_subscription_connection() try number 8 <NL> [  427.451301] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 1 <NL> [  427.630052] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 2 <NL> [  427.888173] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 3 <NL> [  427.899251] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 4 <NL> [  427.911275] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 5 <NL> [  427.943136] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 6 <NL> [  427.986917] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 7 <NL> [  428.128717] txid_tracker[2546]: ::::create_confd_subscription_connection() try number 8 <NL> [  428.239436] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 1 <NL> [  428.357443] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 2 <NL> [  428.454085] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 3 <NL> [  428.558963] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 4 <NL> [  428.561759] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 5 <NL> [  428.710902] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 6 <NL> [  428.729769] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 7 <NL> [  429.441811] txid_tracker[2702]: ::::create_confd_subscription_connection() try number 8 <NL> [  429.827455] cseries_hal[2157]: EsalPmiClient::sharedMemoryInit nPorts/size/nPorts/additionalBuffers 50/6160/50/49 <NL> [  429.902383] cseries_hal[2157]: EsalShm::createShmSegment <NL> [  429.935939] cseries_hal[2157]: EsalShm::createShmSegment attaching to existing shm segment <NL> [  430.204940] startup_finished.py[2040]: Startup Finished: Systemd reports a \"running\" system state, clearing bootcounter <NL> [  430.946712] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 1 <NL> [  431.094464] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 2 <NL> [  431.110249] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 3 <NL> [  431.147751] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 4 <NL> [  431.354635] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 5"}
{"timestamp_utc": "2024-07-31T08:20:06.685Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:06 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:08.064Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:07 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:10.603Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  423.961623] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  424.292789] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  424.626837] ntputils[1724]: push_local_changes OK <NL> [  425.290823] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  425.379936] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  425.604349] ntputils[1724]: child pid is 2972 <NL> [  425.635249] ntputils[1724]: exited, status is 0 <NL> [  425.867070] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  425.877904] ntputils[1724]: poller time change delta is: 2 <NL> [  425.887418] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [  425.897133] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  425.942816] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [  425.946148] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  425.950904] ntputils[1724]: push_local_changes OK <NL> [  426.226680] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  426.274818] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  426.275574] ntputils[1724]: child pid is 2995 <NL> [  426.276225] ntputils[1724]: exited, status is 0 <NL> [  426.276851] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  426.357686] ntputils[1724]: poller time change delta is: 1 <NL> [  426.359808] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  426.389894] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  426.643641] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  426.666497] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  426.694748] ntputils[1724]: push_local_changes OK <NL> [  426.696446] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  426.706937] ntputils[1724]: /sbin/hwclock -u --systohc"}
{"timestamp_utc": "2024-07-31T08:20:10.604Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  426.737514] ntputils[1724]: child pid is 3050 <NL> [  426.739118] ntputils[1724]: exited, status is 0 <NL> [  426.747583] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  426.749921] ntputils[1724]: poller time change delta is: 1 <NL> [  426.810545] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  426.822565] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  426.833913] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  426.834865] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  426.933749] ntputils[1724]: push_local_changes OK <NL> [  426.962793] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  426.993137] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  426.999291] ntputils[1724]: child pid is 3063 <NL> [  427.162713] ntputils[1724]: exited, status is 0 <NL> [  427.163559] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  427.164493] ntputils[1724]: poller time change delta is: 1 <NL> [  427.195780] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  427.230409] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  427.239423] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  427.295945] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  427.695411] ntputils[1724]: push_local_changes OK <NL> [  427.851833] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  427.880893] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  427.881656] ntputils[1724]: child pid is 3080 <NL> [  428.022180] ntputils[1724]: exited, status is 0 <NL> [  428.043931] healthcheck_agt.py[3042]: /bin/sh: line 1: podman: command not found <NL> [  428.358943] cia_control_layer[2227]: EsalConfig::EsalConfig main 1 <NL> [  429.038154] cia_control_layer[2227]: EsalConfig::EsalConfig trib 0 <NL> [  429.432497] cia_control_layer[2227]: EsalConfig::EsalConfig ciRole 0 <NL> [  429.504305] cia_control_layer[2227]: EsalConfig is not running inside container. <NL> [  429.597309] cia_control_layer[2227]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  429.901715] cia_control_layer[2227]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  429.915568] cia_control_layer[2227]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  430.085393] cia_control_layer[2227]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  430.245844] cia_control_layer[2227]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  430.643317] cia_control_layer[2227]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  430.729695] cia_control_layer[2227]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  430.838561] cia_control_layer[2227]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  430.865932] cia_control_layer[2227]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  430.885714] cia_control_layer[2227]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  430.898762] cia_control_layer[2227]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  430.985336] cia_control_layer[2227]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  431.041649] cia_control_layer[2227]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  431.094669] cia_control_layer[2227]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  431.249199] cia_control_layer[2227]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  431.637563] cia_control_layer[2227]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  431.724534] cia_control_layer[2227]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  431.773862] cia_control_layer[2227]: Control Layer started successfully. <NL> [  431.881650] cia_control_layer[2227]: Got the unitName from Platform General topic: BDC2-C200 <NL> [  431.882745] cia_control_layer[2227]: Xml found in the map for unitName: BDC2-C200 <NL> [  431.883715] cia_control_layer[2227]: Going with file C200_shelfData.xml <NL> [  431.884543] cia_control_layer[2227]: Setting Pm xml files as below: <NL> [  431.914831] cia_control_layer[2227]: Shelf: C200_shelfPmData.xml <NL> [  431.916945] cia_control_layer[2227]: Port: C200_pluggablePmData.xml <NL> [  431.941645] cia_control_layer[2227]: Eth: C200_dcnL2EthernetIfData.xml <NL> [  432.527724] usb_script_handler.py[2044]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm entity_type Shelf noSecondaryStorage' <NL> [  432.608366] usb_script_handler.py[2044]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm location \"{\\\"shelf\\\":200}\" noSecondaryStorage' <NL> [  432.666430] usb_script_handler.py[2044]: /usr/bin/platform_event_control.py: msg='u Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  432.790052] usb_script_handler.py[2044]: /usr/bin/platform_event_control.py: msg='d Platform::Alarm alarm noSecondaryStorage noSecondaryStorage' <NL> [  432.932345] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  432.944378] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  432.949597] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> INFO:root:Data sent from swdl is parsed as NONE,SUCCESS, <NL> [  433.234658] python3[2242]: [.799] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  433.246051] python3[2242]: [.232] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  433.247332] python3[2242]: [.232] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  433.293344] python3[2242]: [.937] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, to confd_mgr <NL> [  433.327784] python3[2242]: [.971] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'}"}
{"timestamp_utc": "2024-07-31T08:20:11.969Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:11 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:13.331Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:12 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:17.492Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:16 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:18.052Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:17 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37229\" AuthenticationException('Authentication timeout.',) <NL> # 03:20:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:17 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:19.948Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  433.329329] python3[2242]: [.971] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  433.347616] python3[2242]: [.971] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  433.352738] python3[2242]: [.971] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  433.354204] python3[2242]: [.971] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> [  433.355514] python3[2242]: [.972] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  433.434856] python3[2242]: [.972] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  433.458339] python3[2242]: [.972] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  433.489157] python3[2242]: [.015] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.hookypgintfdelete'} <NL> [  433.492328] python3[2242]: [.742] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookeqptportcapability'} <NL> [  433.493636] python3[2242]: [.743] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethportcapability'} <NL> [  433.504597] python3[2242]: [.755] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookoduportcapability'} <NL> [  433.536756] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  433.644638] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  433.791663] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  434.097917] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  434.326917] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:20:19.949Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  434.388519] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  434.563068] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  435.239892] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  435.474679] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  435.867677] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  436.133610] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  436.378592] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  436.545936] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  436.822600] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  436.854973] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  436.955974] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  437.135436] common_alarm_handler[2225]: topic = XconProv_v2Prov; id = 112 <NL> [  437.251684] common_alarm_handler[2225]: topic = OchIfProv; id = 113 <NL> [  437.366310] common_alarm_handler[2225]: topic = AclProfileProv; id = 114 <NL> [  437.908732] common_alarm_handler[2225]: topic = OtuProv; id = 115 <NL> [  437.981435] common_alarm_handler[2225]: topic = GeProv; id = 116 <NL> [  437.982324] common_alarm_handler[2225]: topic = OduProv; id = 117 <NL> [  437.983289] common_alarm_handler[2225]: topic = TcmProv; id = 118 <NL> [  438.048522] common_alarm_handler[2225]: topic = OCnProv; id = 119 <NL> [  438.080361] common_alarm_handler[2225]: topic = OnDemandDM; id = 120 <NL> [  438.084114] common_alarm_handler[2225]: topic = OducnProv; id = 121 <NL> [  438.131838] common_alarm_handler[2225]: topic = OtsiProv; id = 122 <NL> [  438.279198] common_alarm_handler[2225]: topic = OtsigProv; id = 123 <NL> [  438.340838] common_alarm_handler[2225]: topic = OtucnProv; id = 124 <NL> [  438.341709] common_alarm_handler[2225]: topic = YpgProv; id = 125 <NL> [  438.565444] common_alarm_handler[2225]: topic = EpgProv; id = 126 <NL> [  438.883712] common_alarm_handler[2225]: topic = DataEncryptionInterfaceProv; id = 127 <NL> [  439.118190] common_alarm_handler[2225]: topic = DataEncryptionOperReq; id = 128 <NL> [  439.661734] common_alarm_handler[2225]: topic = RoutePolicyTableProv; id = 129 <NL> [  439.662846] common_alarm_handler[2225]: topic = RoutePolicyConditionsTableProv; id = 130 <NL> [  439.824181] common_alarm_handler[2225]: topic = RoutePolicySetActionsTableProv; id = 131 <NL> [  439.919585] common_alarm_handler[2225]: topic = BgpRtPolDefinedSetsTableProv; id = 132 <NL> [  439.978602] common_alarm_handler[2225]: topic = ShapingProfileProv; id = 133 <NL> [  440.074599] common_alarm_handler[2225]: topic = TaildropProfileProv; id = 134 <NL> [  440.257992] common_alarm_handler[2225]: topic = PolicingProfileProv; id = 135 <NL> [  440.398663] common_alarm_handler[2225]: topic = CapabilityProfileProv; id = 136 <NL> [  440.548560] common_alarm_handler[2225]: topic = TransportInterfaceRateProv; id = 137 <NL> [  440.833415] common_alarm_handler[2225]: topic = PmRtrvReqSess; id = 138 <NL> [  440.946938] common_alarm_handler[2225]: topic = PmRtrvRespSess; id = 139 <NL> [  441.007787] common_alarm_handler[2225]: topic = DataEncryptionZeroizeReq; id = 140 <NL> [  441.069705] common_alarm_handler[2225]: topic = DataEncryptionPskReq; id = 141 <NL> [  441.420524] common_alarm_handler[2225]: topic = SystemWebserverProv; id = 142 <NL> [  441.606247] common_alarm_handler[2225]: NO match: <NL> [  441.646512] common_alarm_handler[2225]: NO match: <NL> [  441.879305] common_alarm_handler[2225]: NO match: <NL> [  441.941298] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  441.974346] ntputils[1724]: poller time change delta is: 1 <NL> [  441.993313] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  442.022314] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  442.056292] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  442.083223] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  442.111304] ntputils[1724]: push_local_changes OK <NL> [  442.193974] usb_script_handler.py[2047]: {\"command\": \"ssw-sync\"} <NL> [  442.288208] usb_script_handler.py[2047]: {'return-value': 1, 'error-tag': 'resource-denied', 'response-message': 'secondary software is busy'} <NL> [  442.354620] python3[2242]: [.756] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsig.hookotsigportcapability'} <NL> [  442.439421] python3[2242]: [.756] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otucn.hookotucnportcapability'} <NL> [  442.549792] python3[2242]: [.756] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookservaffect'} <NL> [  442.639716] python3[2242]: [.837] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  442.711940] python3[2242]: [.837] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'}"}
{"timestamp_utc": "2024-07-31T08:20:20.882Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:20:20 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37261\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:21.808Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:21 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:23.210Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:23 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:24.141Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  442.757140] python3[2242]: [.855] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_ops_services.max_sessions_hook'} <NL> [  442.802389] python3[2242]: [.856] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_ops_services.restconf_hook'} <NL> [  442.821310] python3[2242]: [.736] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksubport'} <NL> [  442.850427] python3[2242]: [.737] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  442.896613] python3[2242]: [.737] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otsi.otsidefaulthook'} <NL> [  442.942213] python3[2242]: [.737] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  442.976101] python3[2242]: [.737] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  442.986322] python3[2242]: [.737] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'} <NL> [  443.014243] python3[2242]: [.896] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.suppifhook'} <NL> [  443.046157] python3[2242]: [.896] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooksysname'} <NL> [  443.060677] python3[2242]: [.896] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookautotx'} <NL> [  443.103496] python3[2242]: [.896] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hooktcmlist'} <NL> [  443.234582] python3[2242]: [.896] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_och.hookochdefault'} <NL> [  443.368226] python3[2242]: [.897] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_otu.otudefaulthook'} <NL> 2024-07-31 08:20:19,579 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  443.556432] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.640328] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.651626] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.683474] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.696410] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.716962] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.718803] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.743191] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.754160] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.797810] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.798914] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.822835] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.823876] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.850773] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.857410] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  443.859975] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  443.917520] python3[2242]: [.897] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.odudefaulthook'} <NL> [  443.941807] python3[2242]: [.897] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer2_ethernet.hookethdef'} <NL> [  443.964766] python3[2242]: [.897] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.hookadminstatus'}"}
{"timestamp_utc": "2024-07-31T08:20:24.142Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  443.986296] python3[2242]: [.897] hookhdlr 140665309656896 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.hookparentodualloc'} <NL> [  444.006835] python3[2242]: [.897] hookhdlr 140665309656896 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  444.026850] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.046778] python3[2242]: [.854] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 1 of -1! <NL> [  444.079642] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.124523] python3[2242]: [.865] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 2 of -1! <NL> [  444.212339] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.275471] python3[2242]: [.013] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 3 of -1! <NL> [  444.353687] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.381587] python3[2242]: [.664] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 4 of -1! <NL> [  444.512757] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.559378] python3[2242]: [.040] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 5 of -1! <NL> [  444.715629] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.771864] python3[2242]: [.083] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 6 of -1! <NL> [  444.874800] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  444.915414] python3[2242]: [.098] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 7 of -1! <NL> [  444.978308] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  445.051174] python3[2242]: [.252] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 8 of -1! <NL> [  445.203840] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  445.285962] python3[2242]: [.267] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 9 of -1! <NL> [  445.568594] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  445.613323] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  445.750064] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  446.319188] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  446.471750] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:20:26.029Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:20:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:20:26.954Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:26 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:28.318Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:28 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:32.482Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:31 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:33.409Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:33 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:37.574Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:36 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:38.135Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:38 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:40.022Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  431.685615] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 6 <NL> [  431.927353] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 7 <NL> [  431.928635] txid_tracker[2893]: ::::create_confd_subscription_connection() try number 8 <NL> [  431.986846] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  432.115911] python3[2135]: [.873] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  432.432988] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  432.624926] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  433.131684] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 1 <NL> [  433.536356] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 2 <NL> [  433.608992] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 3 <NL> [  433.711644] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 4 <NL> [  434.064072] dcn_dns_controller[1366]: dnsClientStartup() <NL> [  434.409964] dcn_dns_controller[1366]: dnsClientStartup - Waiting in dnsClientMgr Main Thread Starts <NL> [  434.411145] dcn_dns_controller[1366]: fin_dnsmasq_conf is open <NL> [  434.416406] confd_director.py[3013]: rm: cannot remove '/var/shared/confd/ha_status': No such file or directory <NL> [  435.225713] startup_finished.py[2040]: *****Startup Finished: stopping EOW timer***** <NL> [  435.837953] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 5 <NL> [  436.460610] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  437.146917] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  438.787264] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 6 <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> [  439.331571] startup_finished.py[2040]: systemctl stop startup_finished_limit.timer <NL> INFO:root:Generating /run/swdl_ready.sh <NL> [  440.346610] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:20:40.023Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  440.379528] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  440.816242] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  440.984458] python3[2135]: [.052] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  441.136934] cseries_hal[2157]: EsalShm::createShmSegment timeout opening syncPath <NL> [  441.584445] cseries_hal[2157]: EsalPmiClient::dumpShm pmShm is null <NL> 2024-07-31 08:20:15,691 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  442.150610] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 7 <NL> [  442.565142] dcn_ka[1368]: KaSessMgr Process Startup <NL> [  442.715949] confd_mgr[3031]: ConfdMgrConf: DB signature is NOT supported <NL> [  442.746295] confd_mgr[3031]: Read reset type failed basic_ios::clear: iostream error <NL> [  442.747337] confd_mgr[3031]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  444.122996] cseries_hal[2157]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  445.800564] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  446.086433] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  447.144149] confd_mgr[3031]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  447.146762] confd_mgr[3031]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  447.292763] txid_tracker[2962]: ::::create_confd_subscription_connection() try number 8 <NL> [  447.513098] cia_control_layer[2116]:    ChalApi Constructor with tid = 2870 <NL> [  447.750141] led_controller[2158]:    ChalApi Constructor with tid = 2158 <NL> [  450.599177] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  450.746542] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  452.985839] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  453.408034] python3[2135]: [.147] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  454.093912] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 1 <NL> [  455.817540] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  456.431527] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  456.659092] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 2 <NL> [  458.972838] confd_mgr[3046]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:20:32 UTC 2024 <NL> [  459.358596] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  459.378508] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  459.578992] ntputils[1725]: child pid is 3099 <NL> [  459.703154] ntputils[1725]: exited, status is 0 <NL> [  460.194763] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  460.980695] ntputils[1725]: poller time change delta is: 1 <NL> [  461.364609] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  461.484740] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  461.828692] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  461.864640] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  462.139692] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 3 <NL> [  462.199969] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 4 <NL> [  463.038621] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  463.237790] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  463.317757] ntputils[1725]: push_local_changes OK <NL> [  463.358577] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  463.359606] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  463.360268] ntputils[1725]: child pid is 3118 <NL> [  463.379114] ntputils[1725]: exited, status is 0 <NL> [  463.420821] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  463.422772] ntputils[1725]: poller time change delta is: 1 <NL> [  463.424081] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  463.606342] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  463.622371] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  463.623403] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  463.624205] ntputils[1725]: push_local_changes OK <NL> [  463.799570] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  463.867969] python3[2135]: [.593] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  463.925466] confd_mgr[3134]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  465.305721] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 5 <NL> [  465.606519] confd_mgr[3046]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  465.682447] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:20:41.911Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:41 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:43.315Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  446.860818] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  447.040884] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  447.617360] cseries_hal[2283]: HAL main() begins. <NL> [  447.729842] cseries_hal[2283]: hal_default::hal_init() called <NL> [  447.932585] cseries_hal[2283]: EsalPmiClient::EsalPmiClient <NL> [  448.010304] cseries_hal[2283]: EsalPmiClient::sharedMemoryInit nPorts/size/nPorts/additionalBuffers 50/6160/50/49 <NL> [  448.034622] cseries_hal[2283]: EsalShm::createShmSegment <NL> [  448.049266] cseries_hal[2283]: EsalShm::createShmSegment attaching to existing shm segment <NL> [  448.121592] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  448.301833] python3[2242]: [.286] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 10 of -1! <NL> [  449.610622] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  449.970718] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  452.110575] cseries_hal[2283]: EsalShm::createShmSegment timeout opening syncPath <NL> [  452.182392] cseries_hal[2283]: EsalPmiClient::dumpShm pmShm is null <NL> [  452.838173] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 1 <NL> [  453.400618] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 2 <NL> [  453.418561] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 3 <NL> [  453.452409] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 4 <NL> [  453.636943] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 5 <NL> [  453.704142] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 6 <NL> [  453.852879] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 7 <NL> [  453.873238] txid_tracker[2479]: ::::create_confd_subscription_connection() try number 8 <NL> [  455.022466] cia_control_layer[2227]:    ChalApi Constructor with tid = 3125 <NL> [  455.184818] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  455.208832] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  455.358671] cseries_hal[2283]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 2, state= 5 <NL> [  455.466291] confd_mgr[2516]: ConfdMgrConf: DB signature is NOT supported <NL> [  455.498244] confd_mgr[2516]: Read reset type failed basic_ios::clear: iostream error <NL> [  455.731271] confd_mgr[2516]: Use reset_type = NONE    rollback_timer = 000000 <NL> [  455.787347] confd_mgr[2516]: main:: Creating ResetType file. Writes NONE/000000 <NL> [  455.818411] confd_mgr[2516]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [  455.995307] led_controller[2284]:    ChalApi Constructor with tid = 2284 <NL> [  456.764202] confd_mgr[2698]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:18:42 UTC 2024 <NL> [  457.249772] confd_mgr[2761]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  457.251937] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 1 <NL> [  457.382055] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 2 <NL> [  457.450467] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 3 <NL> [  457.452835] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 4 <NL> [  457.454980] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 5 <NL> [  457.468462] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 6 <NL> [  457.523850] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 7 <NL> [  457.580130] txid_tracker[2590]: ::::create_confd_subscription_connection() try number 8 <NL> [  457.756257] confd_mgr[2698]: Remove default cdb dir on SWUPGRADE - will recreate <NL> [  457.938636] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  458.048566] python3[2242]: [.325] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 11 of -1! <NL> [  458.316750] confd_mgr[2775]: /usr/bin/ui_sys_reset.py NONE <NL> [  459.057051] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 1 <NL> [  459.358287] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 2 <NL> [  459.894267] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 3 <NL> [  460.317153] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 4 <NL> [  460.759702] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 5 <NL> [  461.396535] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 6 <NL> [  461.425763] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 7 <NL> [  461.554552] txid_tracker[2712]: ::::create_confd_subscription_connection() try number 8 <NL> [  461.918499] confd_mgr[3021]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  461.932448] confd_mgr[3021]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  462.252701] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  462.852802] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  463.445377] confd_mgr[3022]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  463.521746] confd_mgr[3022]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  463.540725] confd_mgr[3023]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  463.548879] confd_mgr[3023]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  463.580309] confd_mgr[2778]: DDS Peristency is enabled <NL> [  463.592817] confd_mgr[2778]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  463.607404] confd_mgr[2778]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  463.609523] confd_mgr[2778]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  463.697557] confd_mgr[2778]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  463.859436] confd_mgr[2775]: /usr/bin/dbrestore_no.py <NL> [  463.860732] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 1 <NL> [  463.962526] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 2 <NL> [  463.963751] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 3 <NL> [  463.964903] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 4 <NL> [  464.194749] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 5 <NL> [  464.289449] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 6 <NL> [  464.355083] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 7 <NL> [  464.528266] txid_tracker[2947]: ::::create_confd_subscription_connection() try number 8 <NL> [  464.765732] confd_mgr[3031]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  464.871506] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 1 <NL> [  464.941648] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 2 <NL> [  464.972298] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 3 <NL> [  465.051951] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 4 <NL> [  465.067671] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 5 <NL> [  465.115289] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 6 <NL> [  465.262647] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 7 <NL> [  465.571283] txid_tracker[3101]: ::::create_confd_subscription_connection() try number 8 <NL> [  465.819418] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> # 03:20:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:43 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:47.478Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:46 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:48.404Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:48 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:52.583Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:51 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:53.509Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:53 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:54.872Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:54 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37229\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:20:56.242Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  465.820486] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  466.215467] confd_mgr[2516]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  466.726303] confd_mgr[2516]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  467.086938] confd_mgr[2516]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  467.238824] confd_mgr[2516]: ha_sm : wait_for_SWDL_s timer is set <NL> [  467.446972] confd_mgr[2516]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  467.649853] confd_mgr[2516]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  467.782166] confd_mgr[2516]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  467.991968] confd_mgr[2516]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  468.192448] confd_mgr[2516]: entering: at_sm::wait_for_SWDL <NL> [  468.340757] confd_mgr[2516]: entering: wait_for_alarm_event <NL> [  468.438099] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  468.467782] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  468.486983] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  468.628966] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  468.812728] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  468.903503] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  469.111650] confd_mgr[2516]: StartEvent::rdm_status: sMain_trib_red_check_completed_=false <NL> [  469.304805] confd_mgr[2516]: StartEvent::rdm_status: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  469.631729] confd_mgr[3106]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': '1+1', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  469.844930] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  469.987774] python3[2242]: [.587] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 12 of -1! <NL> [  470.280621] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  470.467824] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  470.727682] confd_mgr[2516]: ConfdMgrConf::reload: DB signature set to false <NL> [  470.826824] confd_mgr[2516]: ConfdMgrConf::reload: DB signature set to false <NL> [  470.923828] confd_mgr[2516]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  470.991955] confd_mgr[2516]: ha_sm leaving: wait_for_SWDL_s <NL> [  471.125558] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  471.192303] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  471.325204] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  471.383355] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  471.448717] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  471.511561] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  471.651266] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  471.695930] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  471.740358] confd_mgr[2516]: is_swdl_alarm_0 <NL> [  471.768216] confd_mgr[2516]: sdb_restore_= 0 <NL> [  471.876504] confd_mgr[2516]: swdl_alarm_ = NONE <NL> [  471.888282] confd_mgr[2516]: swdl_alarm_tag_ = <NL> [  471.888976] confd_mgr[2516]: swdl status = SUCCESS <NL> [  471.889676] confd_mgr[2516]: is_swdl_in_swupgrade = 0 <NL> [  471.890392] confd_mgr[2516]: confd_db_init::sConfd_db_init_executed_=false <NL> [  471.976322] confd_mgr[2516]: is_swdl_alarm_0 <NL> [  472.022643] confd_mgr[2516]: sdb_restore_= 0 <NL> [  472.094878] confd_mgr[2516]: swdl_alarm_ = NONE <NL> [  472.206585] confd_mgr[2516]: swdl_alarm_tag_ = <NL> [  472.223921] confd_mgr[2516]: swdl status = SUCCESS <NL> [  472.260882] confd_mgr[2516]: is_swdl_in_swupgrade = 0 <NL> [  472.358637] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 1 <NL> [  472.464593] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 2 <NL> [  472.603793] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 3 <NL> [  472.724510] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 4 <NL> [  472.884203] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 5 <NL> [  472.966210] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 6 <NL> [  473.032451] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 7 <NL> [  473.148207] txid_tracker[3221]: ::::create_confd_subscription_connection() try number 8 <NL> [  473.313888] confd_mgr[3246]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  473.427650] confd_mgr[3200]: build /etc/confd/confd.conf.bank0 1+1 <NL> [  473.642736] confd_mgr[3200]: 1+1 <NL> [  473.712474] confd_mgr[3200]: add_child <NL> [  473.799270] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 1 <NL> [  473.937765] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 2 <NL> [  474.171531] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 3 <NL> [  474.260045] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 4 <NL> [  474.652581] confd_mgr[3255]: add field enabled true <NL> [  475.591400] confd_mgr[3255]: add field ip 127.1.254.253 <NL> [  476.480439] confd_mgr[3255]: add field port 4569 <NL> [  476.805897] confd_mgr[3255]: add field tickTimeout PT20S <NL> [  477.047221] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 5 <NL> [  477.512142] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 6 <NL> [  477.733424] confd_mgr[3260]: add field enabled false <NL> [  477.734236] confd_mgr[3260]: add field address <NL> [  477.735517] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  477.736792] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  477.757585] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  477.826651] python3[2242]: [.708] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 13 of -1! <NL> [  478.026562] confd_mgr[3200]: /etc/confd/default_backup.dbs <NL> [  478.181169] confd_mgr[3200]: Create default DB in bank0 <NL> [  478.366816] confd_mgr[2516]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  478.404456] confd_mgr[2516]: confd_db_init::RESET REASON IS NONE <NL> [  478.500275] confd_mgr[2516]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  478.576662] confd_mgr[2516]: ha_sm is_ha_mode_not_none_g cur_mode is 1+1 <NL> [  478.606557] confd_mgr[2516]: ha_sm leaving: wait_for_SWDL_s <NL> [  478.635749] confd_mgr[2516]: ha_sm::start_active_agent_a: The HA mode is 1+1 <NL> [  478.673847] confd_mgr[2516]: ha_sm_active entering: wait_for_active_agent_s <NL> [  478.710737] confd_mgr[2516]: ConfdHA::process_swdl_ready: process_start_event() returned1 <NL> [  478.730288] confd_mgr[2516]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  478.754841] confd_mgr[2516]: leaving: at_sm::wait_for_SWDL <NL> [  478.780096] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  478.804251] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  478.822883] confd_mgr[2516]: ConfdTribActiveAgent start_rep_server <NL> [  478.837627] confd_mgr[2516]: entering: at_sm::wait_for_start_bank <NL> [  478.839227] confd_mgr[2516]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  478.841094] confd_mgr[2516]: leaving: at_sm::wait_for_start_bank <NL> [  478.842292] confd_mgr[2516]: ha_sm_active leaving: wait_for_active_agent_s"}
{"timestamp_utc": "2024-07-31T08:20:56.803Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:20:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:56 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:58.690Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:20:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:20:58 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:20:59.652Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:20:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:02.167Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:01 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:03.538Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:03 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:04.465Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:21:04 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37261\" AuthenticationException('Authentication timeout.',) <NL> [  387.721503] python3[3920]: [.105] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  389.935863] python3[3920]: [.295] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  389.987540] python3[3920]: [.377] valhdlr 140012999513920 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  389.987773] python3[3920]: [.377] valhdlr 140012999513920 callbackhdlr:391 Done register data callbacks <NL> [  389.987895] python3[3920]: DEBUG No crypto keys configured <NL> [  389.990813] python3[3920]: [.379] valhdlr 140012999513920 callbackhdlr:401 Unable to install crypto keys! <NL> [  390.028787] python3[3920]: [.420] valhdlr 140012999513920 callbackhdlr:322 Started data handler daemon... <NL> [  390.029050] python3[3920]: [.420] valhdlr 140012999513920 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  390.096384] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  390.096744] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  390.096844] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  390.096926] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  390.097016] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  390.097129] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  390.134183] confd_mgr[3001]: sm_startconfd::p0_ready_dbc <NL> [  390.168484] confd_mgr[3001]: Find message VALHDLR_CONFIRM <NL> [  390.168595] confd_mgr[3001]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  390.168670] confd_mgr[3001]: sm_startconfd::p0_not_ready <NL> [  390.168739] confd_mgr[3001]: Find message VALHDLR_CONFIRM <NL> [  390.168808] confd_mgr[3001]: sm_startconfd::p0_ready_no_dbc <NL> [  390.168885] confd_mgr[3001]: Find message VALHDLR_CONFIRM <NL> [  390.168960] confd_mgr[3001]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  390.169043] confd_mgr[3001]: leaving: sm_startconfd::wait_for_p0 <NL> [  390.169196] confd_mgr[3001]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  390.169314] confd_mgr[3001]: entering: sm_startconfd::start_confd_p1 <NL> [  390.169398] confd_mgr[3001]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  390.169513] confd_mgr[3001]: ConfdHA Not supported command CONFIRM <NL> [  390.206651] confd_mgr[3999]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:19:26 UTC 2024 <NL> [  390.526403] confd_mgr[4009]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  390.527982] confd_mgr[3001]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  431.303129] txid_tracker[3776]: ::::create_confd_subscription_connection() connected <NL> [  444.413216] confd_mgr[3001]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  444.505195] confd_mgr[4196]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:20:20 UTC 2024 <NL> [  444.642281] confd_mgr[4196]: Invoking confd_load_upgrade_xml.py <NL> [  446.824539] confd_mgr[4203]: confd_load_upgrade_xml.py: Start <NL> [  446.824982] confd_mgr[4203]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  447.469444] confd_mgr[3001]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  447.642619] confd_mgr[4213]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  447.696714] confd_mgr[3001]: CONFD IN PHASE 1 <NL> [  447.696933] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  447.697046] confd_mgr[3001]: leaving: sm_startconfd::start_confd_p1 <NL> [  447.697124] confd_mgr[3001]: entering: sm_startconfd::wait_for_p1 <NL> [  447.697209] confd_mgr[3001]: PROCESS3 has not registered yet. <NL> [  447.699435] python3[3997]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  447.699795] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  447.699908] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT"}
{"timestamp_utc": "2024-07-31T08:21:04.466Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  447.842073] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  447.842750] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  447.842879] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  447.843076] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  447.843152] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  447.843233] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  447.843307] confd_mgr[3001]: sm_startconfd::p1_not_ready <NL> [  447.843396] confd_mgr[3001]: Find message MESSAGE3 <NL> [  447.843540] confd_mgr[3001]: sm_startconfd::p1_ready <NL> [  447.843626] confd_mgr[3001]: Find message MESSAGE3 <NL> [  447.843715] confd_mgr[3001]: leaving: sm_startconfd::wait_for_p1 <NL> [  447.843799] confd_mgr[3001]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  447.843879] confd_mgr[3001]: entering: sm_startconfd::wait_for_rm <NL> [  447.843976] confd_mgr[3001]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  447.844071] confd_mgr[3001]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  447.844811] confd_mgr[3001]: ConfdHA Not supported command CONFIRM <NL> [  448.176990] confd_mgr[4217]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:20:24 UTC 2024 <NL> [  448.435196] confd_mgr[4229]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  448.501433] confd_mgr[4232]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  448.634704] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  448.644593] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  448.644797] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  448.656610] confd_mgr[4242]: /usr/bin/replay_manager NONE <NL> [  448.688075] confd_mgr[4240]: redundancy_status is STANDALONE <NL> [  448.688310] confd_mgr[4240]: DDS ports will be opened. <NL> [  448.694325] confd_mgr[4240]: execute replay_manager NONE TRUE <NL> [  449.127412] confd_mgr[4247]: TRACE Connected (cdb) to ConfD <NL> [  449.169227] confd_mgr[4247]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  449.184608] confd_mgr[4247]: TRACE Connected (cdb) to ConfD <NL> [  449.214593] confd_mgr[4247]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  454.416490] confd_mgr[4247]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  454.589080] txid_tracker[3776]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  454.682222] confd_mgr[4247]: TRACE CDB_TRIGGER_SUBS <NL> [  454.696569] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  454.744421] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  454.759744] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  454.779245] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  454.801162] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  454.810371] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  454.814125] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  454.821881] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  454.853113] txid_tracker[4276]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  469.262023] systemd-journald[360]: Data hash table of /run/log/journal/f38823065b5945208cb896204d6562ff/system.journal has a fill level at 75.0 (13654 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  469.292702] systemd-journald[360]: /run/log/journal/f38823065b5945208cb896204d6562ff/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  481.859423] systemd-sysv-generator[4353]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust."}
{"timestamp_utc": "2024-07-31T08:21:06.978Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:06 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:06 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:08.342Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:08 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:09.708Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s01.NE3-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s01.NE3-main-debug-ssh", "step_id": "s01.NE3-main-debug-ssh", "message_content": "# 03:21:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37261, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:12.225Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:11 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:11 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:13.589Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:13 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:16.854Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:16 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:16 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:18.744Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:18 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:22.029Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  378.969496] python3[3922]: [.912] valhdlr 139905129789248 callbackhdlr:401 Unable to install crypto keys! <NL> [  378.993770] python3[3922]: [.929] valhdlr 139905129789248 callbackhdlr:322 Started data handler daemon... <NL> [  379.013808] python3[3922]: [.930] valhdlr 139905129789248 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  379.029217] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  379.038893] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  379.040494] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  379.073349] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  379.114892] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  379.117335] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  379.118745] confd_mgr[3010]: ConfdHA Not supported command CONFIRM <NL> [  379.119615] confd_mgr[3010]: sm_startconfd::p0_ready_dbc <NL> [  379.125864] confd_mgr[3010]: Find message VALHDLR_CONFIRM <NL> [  379.126578] confd_mgr[3010]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  379.138949] confd_mgr[3010]: sm_startconfd::p0_not_ready <NL> [  379.145422] confd_mgr[3010]: Find message VALHDLR_CONFIRM <NL> [  379.160359] confd_mgr[3010]: sm_startconfd::p0_ready_no_dbc <NL> [  379.169436] confd_mgr[3010]: Find message VALHDLR_CONFIRM <NL> [  379.179422] confd_mgr[3010]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  379.190548] confd_mgr[3010]: leaving: sm_startconfd::wait_for_p0 <NL> [  379.194863] confd_mgr[3010]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  379.195854] confd_mgr[3010]: entering: sm_startconfd::start_confd_p1 <NL> [  379.196713] confd_mgr[3010]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  379.222130] confd_mgr[4025]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:19:13 UTC 2024 <NL> [  379.349542] confd_mgr[4035]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  379.350440] confd_mgr[3010]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  421.154130] txid_tracker[3791]: ::::create_confd_subscription_connection() connected <NL> [  432.327421] confd_mgr[3010]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  432.385734] confd_mgr[4213]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:20:06 UTC 2024 <NL> [  432.510121] confd_mgr[4213]: Invoking confd_load_upgrade_xml.py <NL> [  434.633662] confd_mgr[4220]: confd_load_upgrade_xml.py: Start <NL> [  434.634263] confd_mgr[4220]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  435.128840] confd_mgr[3010]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  435.229715] confd_mgr[4238]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  435.255815] confd_mgr[3010]: CONFD IN PHASE 1 <NL> [  435.256441] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  435.262799] confd_mgr[3010]: leaving: sm_startconfd::start_confd_p1 <NL> [  435.263236] confd_mgr[3010]: entering: sm_startconfd::wait_for_p1 <NL> [  435.263409] confd_mgr[3010]: PROCESS3 has not registered yet. <NL> [  435.334265] python3[4023]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  435.334849] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  435.335137] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  435.335495] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  435.337370] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  435.337490] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  435.417513] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  435.417598] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  435.417670] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  435.418952] confd_mgr[3010]: ConfdHA Not supported command CONFIRM <NL> [  435.419111] confd_mgr[3010]: sm_startconfd::p1_not_ready <NL> [  435.419247] confd_mgr[3010]: Find message MESSAGE3 <NL> [  435.419340] confd_mgr[3010]: sm_startconfd::p1_ready <NL> [  435.419434] confd_mgr[3010]: Find message MESSAGE3 <NL> [  435.419512] confd_mgr[3010]: leaving: sm_startconfd::wait_for_p1 <NL> [  435.419592] confd_mgr[3010]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  435.419692] confd_mgr[3010]: entering: sm_startconfd::wait_for_rm <NL> [  435.419791] confd_mgr[3010]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  435.419875] confd_mgr[3010]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  435.454445] confd_mgr[4242]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:20:09 UTC 2024 <NL> [  435.572642] confd_mgr[4254]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  435.610690] confd_mgr[4257]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  435.763057] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  435.783615] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  435.783747] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  435.824806] confd_mgr[4267]: /usr/bin/replay_manager NONE <NL> [  435.867085] confd_mgr[4265]: redundancy_status is STANDALONE <NL> [  435.867295] confd_mgr[4265]: DDS ports will be opened. <NL> [  435.877295] confd_mgr[4265]: execute replay_manager NONE TRUE <NL> [  436.075771] confd_mgr[4272]: TRACE Connected (cdb) to ConfD <NL> [  436.120891] confd_mgr[4272]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  436.143466] confd_mgr[4272]: TRACE Connected (cdb) to ConfD <NL> [  436.191090] confd_mgr[4272]: TRACE CDB_GET_TXID  --> CONFD_OK"}
{"timestamp_utc": "2024-07-31T08:21:22.030Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  441.242138] confd_mgr[4272]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  441.316707] txid_tracker[3791]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  441.404944] confd_mgr[4272]: TRACE CDB_TRIGGER_SUBS <NL> [  441.423706] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  441.453260] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  441.510331] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  441.510430] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  441.510527] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  441.510598] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  441.531783] txid_tracker[4296]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  441.690109] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  441.690284] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  454.175041] systemd-journald[359]: Data hash table of /run/log/journal/12df99ced2034c9fba488a3b06dd9477/system.journal has a fill level at 75.0 (13654 of 18204 items, 10485760 file size, 767 bytes per hash table item), suggesting rotation. <NL> [  454.307426] systemd-journald[359]: /run/log/journal/12df99ced2034c9fba488a3b06dd9477/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  464.800440] systemd-sysv-generator[4363]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  470.706703] systemd-sysv-generator[4386]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  507.088994] dcn_dns_controller[1604]: fin_file is open <NL> [  507.248596] userddssub[4480]: useradd: user 'fujitsu' already exists <NL> [  507.337497] ntputils[1971]: bool NTPServer::handle_command(const string&) <NL> [  507.337728] ntputils[1971]: bool NTPServer::handle_configure_cmd(const string&) <NL> # 03:21:21 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:21 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:23.395Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:23 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:25.285Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  465.733626] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  466.151368] confd_mgr[3147]: /usr/bin/ui_sys_reset.py NONE <NL> [  468.351944] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 6 <NL> [  468.619411] dcn_dns_controller[1366]: subscribe_data Enter main loop <NL> [  471.646788] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  472.505340] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  473.824825] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  475.320174] python3[2135]: [.620] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  475.716632] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 7"}
{"timestamp_utc": "2024-07-31T08:21:25.286Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  475.742521] txid_tracker[3063]: ::::create_confd_subscription_connection() try number 8 <NL> [  475.838551] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  476.156575] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  480.654500] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  481.267393] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  482.373930] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 1 <NL> [  482.964217] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  483.286130] python3[2135]: [.635] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 15 of -1! <NL> [  484.260428] confd_mgr[3212]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  484.334674] confd_mgr[3212]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  484.505632] confd_mgr[3213]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  484.557308] confd_mgr[3213]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  485.277800] confd_mgr[3214]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  486.196766] confd_mgr[3214]: /dev/root       2.2G  1.8G  308M  86% / <NL> [  486.491267] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 2 <NL> [  486.888575] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  486.895752] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  487.387698] confd_mgr[3148]: DDS Peristency is enabled <NL> [  487.600772] confd_mgr[3148]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  487.875207] confd_mgr[3148]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  488.163533] confd_mgr[3148]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  488.201234] confd_mgr[3148]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  488.364461] confd_mgr[3147]: /usr/bin/dbrestore_no.py <NL> [  488.854459] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 3 <NL> [  489.470402] confd_mgr[3226]: /usr/bin/common_confd_mgr_start_cb.sh: line 24: /usr/bin/dbrestore_no.py: No such file or directory <NL> [  489.765849] confd_mgr[3031]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  490.426170] confd_mgr[3031]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  490.648549] confd_mgr[3031]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [  491.445884] confd_mgr[3031]: entering: wait_for_alarm_event <NL> [  491.677323] confd_mgr[3031]: ha_sm entering: wait_for_SWDL_s 0 <NL> [  492.570707] confd_mgr[3031]: ha_sm : wait_for_SWDL_s timer is set <NL> [  493.017318] confd_mgr[3031]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  493.148759] confd_mgr[3031]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  493.308421] confd_mgr[3031]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [  493.346726] confd_mgr[3031]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [  493.639136] confd_mgr[3031]: entering: at_sm::wait_for_SWDL <NL> [  493.695547] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  494.134275] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  494.679899] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,MAIN,FALSE,FALSE,NONE,SUCCESS, <NL> [  495.398253] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  495.991920] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  496.257281] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  496.258140] confd_mgr[3031]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [  496.388605] confd_mgr[3031]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [  496.786143] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  496.914391] python3[2135]: [.737] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 16 of -1! <NL> [  497.932596] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  498.162105] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  499.438149] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  499.681181] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  499.699903] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 4 <NL> [  499.841376] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 5 <NL> [  499.842358] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 6 <NL> [  500.026178] healthcheck_agt.py[3257]: /bin/sh: line 1: podman: command not found <NL> [  500.405287] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 7 <NL> [  500.753777] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  500.771687] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  502.195885] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  502.587996] python3[2135]: [.752] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 17 of -1! <NL> [  503.464883] txid_tracker[3198]: ::::create_confd_subscription_connection() try number 8 <NL> [  504.844583] confd_mgr[3245]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': '1+1', 'MAIN_TRIB_RED': 'FALSE'} <NL> [  506.237045] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  507.109527] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  508.919647] confd_mgr[3031]: ConfdMgrConf::reload: DB signature set to false <NL> [  509.398323] confd_mgr[3031]: is_swdl_alarm_0 <NL> [  510.079669] confd_mgr[3031]: sdb_restore_= 0 <NL> [  510.573884] confd_mgr[3031]: swdl_alarm_ = NONE <NL> [  510.672900] confd_mgr[3031]: swdl_alarm_tag_ = <NL> [  510.881214] confd_mgr[3031]: swdl status = SUCCESS <NL> [  510.912160] confd_mgr[3031]: is_swdl_in_swupgrade = 0 <NL> [  510.961298] confd_mgr[3031]: is_swdl_alarm_0"}
{"timestamp_utc": "2024-07-31T08:21:27.174Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:26 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:26 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:28.539Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:28 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:32.700Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:31 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:31 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:33.626Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:33 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',) <NL> [  507.337857] ntputils[1971]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  507.337944] ntputils[1971]: parse_time_persistent_topic ddskind create <NL> [  507.338091] ntputils[1971]: parse_time_persistent_topic name key config <NL> [  507.338263] ntputils[1971]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  507.338382] ntputils[1971]: parse_time_topics command_data enable=yes; <NL> [  507.338467] ntputils[1971]: handle_configure_cmd token is: enable=yes <NL> [  507.338538] ntputils[1971]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  507.338610] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  507.338695] ntputils[1971]: systemctl --no-block stop ntpd <NL> [  507.338785] ntputils[1971]: child pid is 4519 <NL> [  507.338898] dcn_dns_controller[1604]: fin_file is open <NL> [  507.339105] userddssub[2456]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  507.752707] ntputils[1971]: exited, status is 0 <NL> [  507.752918] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  507.754629] ntputils[1971]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  507.861628] ntputils[1971]: child pid is 4523 <NL> [  507.932118] ntputils[1971]: exited, status is 0 <NL> [  507.932268] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  507.932786] ntputils[1971]: /bin/systemctl reset-failed ntpd"}
{"timestamp_utc": "2024-07-31T08:21:33.627Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  507.932891] ntputils[1971]: child pid is 4535 <NL> [  508.277850] ntputils[1971]: exited, status is 0 <NL> [  508.278350] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  508.295253] ntputils[1971]: systemctl --no-block start ntpd <NL> [  508.295384] ntputils[1971]: child pid is 4549 <NL> [  509.079661] ntputils[1971]: exited, status is 0 <NL> [  509.082302] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  509.082423] ntputils[1971]: systemctl --no-block start ntpscript <NL> [  509.082535] ntputils[1971]: child pid is 4575 <NL> [  509.198407] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3263 <NL> [  509.326243] ntputils[1971]: exited, status is 0 <NL> [  509.364891] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  509.412447] ntputils[1971]: /bin/systemctl --no-block start init_state_check.timer <NL> [  509.424704] layer1_control_layer[2425]: EsalConfig::EsalConfig main 1 <NL> [  509.455785] layer1_control_layer[2425]: EsalConfig::EsalConfig trib 0 <NL> [  509.467497] layer1_control_layer[2425]: EsalConfig::EsalConfig ciRole 0 <NL> [  509.488866] layer1_control_layer[2425]: EsalConfig is not running inside container. <NL> [  509.506768] layer1_control_layer[2425]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  509.531146] layer1_control_layer[2425]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  509.541317] layer1_control_layer[2425]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  509.581612] layer1_control_layer[2425]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  509.581718] layer1_control_layer[2425]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  509.581831] layer1_control_layer[2425]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  509.581911] layer1_control_layer[2425]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  509.582162] layer1_control_layer[2425]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  509.582251] layer1_control_layer[2425]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  509.582353] layer1_control_layer[2425]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  509.582433] layer1_control_layer[2425]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  509.582513] layer1_control_layer[2425]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  509.582591] layer1_control_layer[2425]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  509.582667] layer1_control_layer[2425]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  509.607347] layer1_control_layer[2425]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  509.711325] layer1_control_layer[2425]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  509.711440] layer1_control_layer[2425]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  509.753126] ntputils[1971]: child pid is 4586 <NL> [  510.060042] ntputils[1971]: exited, status is 0 <NL> [  510.060212] ntputils[1971]: Configure command handled successfully, writing to RTC <NL> [  510.276080] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  510.277897] ntputils[1971]: /sbin/hwclock -u --systohc <NL> [  510.385364] ntputils[1971]: child pid is 4594 <NL> [  510.426850] ntputils[1971]: exited, status is 0 <NL> [  510.494128] ntputils[1971]: bool NTPServer::handle_command(const string&) <NL> [  510.515934] ntputils[1971]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  510.516943] ntputils[1971]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  510.517982] ntputils[1971]: parse_time_persistent_topic ddskind create <NL> [  510.518742] ntputils[1971]: parse_time_persistent_topic name key setTZ <NL> [  510.603435] ntputils[1971]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  510.606993] ntputils[1971]: parse_time_topics command_data timezone=UTC; <NL> [  510.607921] ntputils[1971]: bool NTPServer::set_timezone(const string&) <NL> [  510.617270] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  510.618073] ntputils[1971]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  510.677774] ntputils[1971]: child pid is 4595 <NL> [  510.678440] ntputils[1971]: exited, status is 0 <NL> [  510.679056] ntputils[1971]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  510.679871] ntputils[1971]: push_local_changes user_changed: 1 delta: 0 <NL> [  510.681064] ntputils[1971]: local_push OK u Platform::Time changedByUser 1 <NL> [  510.702072] ntputils[1971]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  510.703078] ntputils[1971]: local_push OK w Platform::Time 0 0 <NL> [  510.724257] ntputils[1971]: push_local_changes OK <NL> [  510.755248] ntputils[1971]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  510.756181] ntputils[1971]: publish_local_changes OK <NL> [  512.133757] ntp_alarm_event_monitor.py[4584]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  512.134387] ntp_alarm_event_monitor.py[4584]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  513.071878] ntp_alarm_event_monitor.py[4584]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  513.072423] ntp_alarm_event_monitor.py[4584]: INFO:root:redundancy status now set to standalone <NL> [  513.432115] ntp_alarm_event_monitor.py[4584]: INFO:root:Publish Alarm: Raising alarm <NL> [  513.656083] ntp_alarm_event_monitor.py[4584]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  514.480351] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3262 <NL> [  514.492075] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3262 <NL> [  514.697761] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3262 <NL> [  514.697872] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3262 <NL> [  514.796637] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3262 <NL> [  514.850356] layer1_hal[2469]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  514.900266] layer1_hal[2469]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  514.993233] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3262 <NL> [  515.311561] layer1_control_layer[2425]:    ChalApi Constructor with tid = 3265 <NL> [  518.191429] confd_mgr[4272]:  --> CONFD_OK <NL> [  518.731059] confd_mgr[4692]: openDdsPorts interfaces  eth5.2003 <NL> [  518.731268] confd_mgr[4692]: openDdsPorts Input udpPorts-  7660 <NL> [  518.768402] confd_mgr[4692]: openDdsPorts Output udpPorts-  7660 <NL> [  518.962649] confd_mgr[4692]: openDdsPorts Input udpPorts-  7661 <NL> [  519.133724] confd_mgr[4692]: openDdsPorts Output udpPorts-  7661"}
{"timestamp_utc": "2024-07-31T08:21:36.893Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:36 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:36 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:38.789Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:38 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',) <NL> [  478.844515] confd_mgr[2516]: process_ha_alarm raise noSecondaryDatabase <NL> [  478.846673] confd_mgr[2516]: ha_sm_active entering: wait_for_standby_s <NL> [  478.848688] confd_mgr[2516]: Maskable Alarm <NL> [  478.849282] confd_mgr[2516]: leaving: wait_for_alarm_event <NL> [  478.850025] confd_mgr[2516]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:152:add_to_alarms: OPERATION=raise CONDITION=noSecondaryDatabase #ALARMS=1 <NL> [  478.851677] confd_mgr[2516]: entering: wait_for_alarm_process <NL> [  478.852416] confd_mgr[2516]: entering: at_sm_dbready::wait_for_db_status <NL> [  478.853323] confd_mgr[2516]: ConfdTribActiveAgent::server address 127.1.254.254 port 4050 <NL> [  478.854385] confd_mgr[2516]: calling accept_handler"}
{"timestamp_utc": "2024-07-31T08:21:38.790Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  478.854996] confd_mgr[2516]: In ConfdTribActiveAgent::check_reset <NL> [  478.855933] confd_mgr[2516]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  478.856899] confd_mgr[2516]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  478.895574] confd_mgr[3472]: Executing check_db.sh <NL> [  478.898983] confd_mgr[3472]: check_db.sh: found xml files <NL> [  478.899822] confd_mgr[3472]: 0 <NL> [  478.901228] confd_mgr[2516]: Found no error <NL> [  478.901771] confd_mgr[2516]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  478.997205] confd_mgr[2516]: cur_gdbissue 24.1.1 gdbissue 24.1.1 rc = 1 <NL> [  479.038706] confd_mgr[2516]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  479.052282] confd_mgr[2516]: TSeries-CIS is in the list: TSeries-CIS <NL> [  479.089718] confd_mgr[2516]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  479.174335] confd_mgr[2516]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  479.197228] confd_mgr[2516]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  479.263139] confd_mgr[2516]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  479.338998] confd_mgr[2516]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  479.434206] confd_mgr[2516]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  479.589741] confd_mgr[2516]: guard is_db_okay_g: The HA mode is 1+1 <NL> [  479.654774] confd_mgr[2516]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  479.725968] confd_mgr[2516]: entering: sm_startconfd::start_confd_p0 <NL> [  479.837953] confd_mgr[2516]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  479.899888] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  479.983895] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  480.166161] confd_mgr[3478]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:20:19 UTC 2024 <NL> [  480.268810] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 7 <NL> [  480.367068] confd_mgr[2516]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  480.470735] confd_mgr[2516]: leaving: wait_for_alarm_process <NL> [  480.502136] confd_mgr[2516]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:160:write_alarms_to_file: #ALARMS=1 <NL> [  480.653553] confd_mgr[2516]:  write_db_alarm rename was successful <NL> [  480.708714] confd_mgr[2516]: entering: wait_for_alarm_event <NL> [  483.137957] txid_tracker[3568]: ::::create_confd_subscription_connection() try number 8 <NL> [  485.179808] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  485.895680] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  487.820823] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  488.927137] python3[2242]: [.760] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 14 of -1! <NL> [  489.537150] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 1 <NL> [  490.194702] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  490.522080] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  492.535574] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 2 <NL> [  494.831023] systemd-sysv-generator[3715]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  494.821898] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  495.562554] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  497.648922] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 3 <NL> [  497.766270] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  498.138209] python3[2242]: [.771] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 15 of -1! <NL> [  498.423493] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 4 <NL> [  499.827977] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  499.849192] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused[  500.464453] tun: Universal TUN/TAP device driver, 1.6 <NL> [  501.396836] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 5 <NL> [  504.361627] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 6 <NL> [  505.138866] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  505.652166] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  507.515851] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 7 <NL> [  508.117633] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  508.991289] python3[2242]: [.793] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 16 of -1! <NL> [  510.056385] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  510.615698] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  511.825520] txid_tracker[3672]: ::::create_confd_subscription_connection() try number 8 <NL> [  514.950056] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  515.128654] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  515.587857] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 1 <NL> [  517.716201] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  517.724473] python3[2242]: [.813] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 17 of -1! <NL> [  518.430452] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 2 <NL> [  519.970459] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  520.379231] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused"}
{"timestamp_utc": "2024-07-31T08:21:42.056Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:41 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:41 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:42.985Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s01.NE4-main-debug-ssh", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s01.NE4-main-debug-ssh", "step_id": "s01.NE4-main-debug-ssh", "message_content": "# 03:21:42 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37229\" AuthenticationException('Authentication timeout.',)"}
{"timestamp_utc": "2024-07-31T08:21:43.545Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:43 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:45.431Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  487.399233] systemd-sysv-generator[4388]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  519.042450] dcn_dns_controller[1601]: fin_file is open <NL> [  519.103154] dcn_dns_controller[1601]: fin_file is open"}
{"timestamp_utc": "2024-07-31T08:21:45.432Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  519.527725] userddssub[4454]: useradd: user 'fujitsu' already exists <NL> [  519.576792] userddssub[2460]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  520.200671] ntputils[1975]: bool NTPServer::handle_command(const string&) <NL> [  520.200875] ntputils[1975]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  520.201033] ntputils[1975]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  520.201131] ntputils[1975]: parse_time_persistent_topic ddskind create <NL> [  520.201210] ntputils[1975]: parse_time_persistent_topic name key setTZ <NL> [  520.201285] ntputils[1975]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  520.201405] ntputils[1975]: parse_time_topics command_data timezone=UTC; <NL> [  520.201481] ntputils[1975]: bool NTPServer::set_timezone(const string&) <NL> [  520.201552] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  520.201623] ntputils[1975]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  520.312148] ntputils[1975]: child pid is 4532 <NL> [  520.607197] ntputils[1975]: exited, status is 0 <NL> [  520.607662] ntputils[1975]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  520.732686] ntputils[1975]: push_local_changes user_changed: 1 delta: 0 <NL> [  520.732944] ntputils[1975]: local_push OK u Platform::Time changedByUser 1 <NL> [  520.743569] ntputils[1975]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  520.743705] ntputils[1975]: local_push OK w Platform::Time 0 0 <NL> [  520.779864] ntputils[1975]: push_local_changes OK <NL> [  520.884055] ntputils[1975]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  520.886693] ntputils[1975]: publish_local_changes OK <NL> [  521.264644] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3284 <NL> [  521.578460] layer1_control_layer[2444]: EsalConfig::EsalConfig main 1 <NL> [  521.578604] layer1_control_layer[2444]: EsalConfig::EsalConfig trib 0 <NL> [  521.578696] layer1_control_layer[2444]: EsalConfig::EsalConfig ciRole 0 <NL> [  521.648830] layer1_control_layer[2444]: EsalConfig is not running inside container. <NL> [  521.649069] layer1_control_layer[2444]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  521.674422] layer1_control_layer[2444]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  521.734635] layer1_control_layer[2444]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  521.734757] layer1_control_layer[2444]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  521.734857] layer1_control_layer[2444]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  521.734943] layer1_control_layer[2444]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  521.735038] layer1_control_layer[2444]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  521.735117] layer1_control_layer[2444]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  521.735194] layer1_control_layer[2444]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  521.735285] layer1_control_layer[2444]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  521.735366] layer1_control_layer[2444]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  521.735456] layer1_control_layer[2444]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  521.735664] layer1_control_layer[2444]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  521.735744] layer1_control_layer[2444]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  521.735822] layer1_control_layer[2444]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  521.735914] layer1_control_layer[2444]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  521.735988] layer1_control_layer[2444]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  524.651668] systemd-sysv-generator[4638]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  524.392365] ntputils[1975]: bool NTPServer::handle_command(const string&) <NL> [  524.452194] ntputils[1975]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  524.452289] ntputils[1975]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  524.452397] ntputils[1975]: parse_time_persistent_topic ddskind create <NL> [  524.452473] ntputils[1975]: parse_time_persistent_topic name key config <NL> [  524.452546] ntputils[1975]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  524.452638] ntputils[1975]: parse_time_topics command_data enable=yes; <NL> [  524.452712] ntputils[1975]: handle_configure_cmd token is: enable=yes <NL> [  524.452785] ntputils[1975]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  524.452858] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  524.452940] ntputils[1975]: systemctl --no-block stop ntpd <NL> [  524.453030] ntputils[1975]: child pid is 4639 <NL> [  525.558107] confd_mgr[4247]:  --> CONFD_OK <NL> [  525.767860] confd_mgr[4650]: openDdsPorts interfaces  eth5.2003 <NL> [  525.904521] confd_mgr[4650]: openDdsPorts Input udpPorts-  7660 <NL> [  526.002154] confd_mgr[4650]: openDdsPorts Output udpPorts-  7660 <NL> [  526.052580] confd_mgr[4650]: openDdsPorts Input udpPorts-  7661 <NL> [  526.168668] confd_mgr[4650]: openDdsPorts Output udpPorts-  7661 <NL> [  526.281038] confd_mgr[4650]: openDdsPorts Input udpPorts-  7650 <NL> [  526.379682] confd_mgr[4650]: openDdsPorts Output udpPorts-  7650 <NL> [  526.522912] confd_mgr[4650]: openDdsPorts Input udpPorts-  7651 <NL> [  526.523127] confd_mgr[4650]: openDdsPorts Output udpPorts-  7651 <NL> [  526.523207] confd_mgr[4650]: openDdsPorts Input udpPorts-  7900 <NL> [  526.523286] confd_mgr[4650]: openDdsPorts Output udpPorts-  7900 <NL> [  526.523519] confd_mgr[4650]: openDdsPorts Input udpPorts-  7901 <NL> [  526.523599] confd_mgr[4650]: openDdsPorts Output udpPorts-  7901 <NL> [  526.523700] confd_mgr[4650]: openDdsPorts Input udpPorts-  7910 <NL> [  526.523795] confd_mgr[4650]: openDdsPorts Output udpPorts-  7910 <NL> [  526.526981] confd_mgr[4650]: openDdsPorts Input udpPorts-  7911 <NL> [  526.527153] confd_mgr[4650]: openDdsPorts Output udpPorts-  7911 <NL> [  526.527233] confd_mgr[4650]: openDdsPorts Input udpPorts-  8150 <NL> [  526.527449] confd_mgr[4650]: openDdsPorts Output udpPorts-  8150 <NL> [  526.630043] confd_mgr[4650]: openDdsPorts Input udpPorts-  8151 <NL> [  526.654889] confd_mgr[4650]: openDdsPorts Output udpPorts-  8151 <NL> [  526.793807] confd_mgr[4650]: openDdsPorts Input udpPorts-  8160 <NL> [  526.860468] confd_mgr[4650]: openDdsPorts Output udpPorts-  8160 <NL> [  526.881873] confd_mgr[4650]: openDdsPorts Input udpPorts-  8161 <NL> [  526.936120] confd_mgr[4650]: openDdsPorts Output udpPorts-  8161 <NL> [  527.554424] confd_mgr[4247]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  527.591273] confd_mgr[4247]: replay_manager:  Start-Wed Jul 31 08:20:25 2024 <NL> [  527.616985] confd_mgr[4247]:  ++++++++++++++++++++++ <NL> [  527.626598] confd_mgr[4247]: replay_manager: TXID NOT FOUND ================================== <NL> [  527.627990] confd_mgr[4247]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  527.631765] confd_mgr[4247]: replay_manager: Need to do trigger full replay. <NL> [  527.648346] confd_mgr[4247]: replay_manager: Creating the purge file. <NL> [  527.671034] confd_mgr[4247]: replay_manager: Open DDS Ports <NL> [  527.702999] confd_mgr[4247]: replay_manager: NOW deleting the purge file. <NL> [  527.728876] confd_mgr[4247]: replay_manager:  End-Wed Jul 31 08:21:43 2024 <NL> [  527.844732] confd_mgr[4247]:  ++++++++++++++++++++++ <NL> [  528.043080] confd_mgr[4247]: Not 1+1 Mode"}
{"timestamp_utc": "2024-07-31T08:21:47.320Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:46 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:46 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:47 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:21:47 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:21:47 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:21:47 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:21:47 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\": process 3336 terminated with exitcode 0 <NL> # 03:21:47 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:21:47 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:21:47 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37259', '--delay', '5'] (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:21:47 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p05.s02.NE3-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37259', '--delay', '5'] <NL> # 03:21:47 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:21:47 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"command\" <NL> # 03:21:47 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.s01.NE3-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:21:47.881Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:21:47 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37259, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:47 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:21:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37229, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:48.442Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:48.718Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:48 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:51.981Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:51 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:52.915Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:21:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:52 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:53.477Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:21:53.733Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:53 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:57.005Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:21:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:56 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:57.932Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:21:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:57 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:21:58.859Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:21:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:21:58 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:02.126Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:01 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:02.686Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:02 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:03.653Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:03 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:05.540Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  511.022253] confd_mgr[3031]: sdb_restore_= 0 <NL> [  511.142809] confd_mgr[3031]: swdl_alarm_ = NONE <NL> [  511.343173] confd_mgr[3031]: swdl_alarm_tag_ = <NL> [  511.344390] confd_mgr[3031]: swdl status = SUCCESS <NL> [  511.378088] confd_mgr[3031]: is_swdl_in_swupgrade = 0 <NL> [  511.378987] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  511.526407] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  511.642408] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  511.776658] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 1 <NL> [  511.866888] confd_mgr[3242]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [  512.417898] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  512.440555] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  512.441878] confd_mgr[3031]: main::/run/rdm_status.sh found. Invoking it. <NL> [  512.617277] confd_mgr[3031]: confd_ha::process_swdl_ready: Removed /run/swdl_ready.sh <NL> [  513.094871] confd_mgr[3031]: ha_sm leaving: wait_for_SWDL_s <NL> [  513.403292] confd_mgr[3031]: confd_ha_sm::check_swdl_cmd_a: /run/rdm_status.sh found. Invoking it. <NL> [  513.759560] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  514.400830] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  514.805676] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  515.277512] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  515.431145] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  515.759738] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  516.083047] confd_mgr[3031]: ConfdMgrConf::reload: DB signature set to false <NL> [  516.556354] confd_mgr[3031]: confd_db_init::sConfd_db_init_executed_=false <NL> [  516.883830] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  517.007569] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  517.292882] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  517.293828] python3[2135]: [.296] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 18 of -1! <NL> [  517.396666] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 2 <NL> [  517.397656] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 3 <NL> [  519.549210] confd_mgr[3366]: cat: /var/shared/confd/ActiveDB: No such file or directory <NL> [  519.782730] confd_mgr[3315]: build /etc/confd/confd.conf.bank0 1+1 <NL> [  519.784394] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 4 <NL> [  520.095186] confd_mgr[3315]: 1+1 <NL> [  520.472821] confd_mgr[3315]: add_child <NL> [  520.889531] confd_mgr[3375]: add field enabled true <NL> [  520.965813] confd_mgr[3375]: add field ip 127.1.254.253 <NL> [  521.799956] confd_mgr[3375]: add field port 4569 <NL> [  522.234590] confd_mgr[3375]: add field tickTimeout PT20S <NL> [  523.610451] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  524.312425] python3[2135]: [.318] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 19 of -1! <NL> [  524.914985] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 5 <NL> [  525.075328] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:22:05.541Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  525.095450] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  525.382405] confd_mgr[3387]: add field enabled false <NL> [  525.442381] confd_mgr[3387]: add field address <NL> [  525.742831] confd_mgr[3315]: /etc/confd/default_backup.dbs <NL> [  525.915699] confd_mgr[3315]: Create default DB in bank0 <NL> [  526.262784] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  526.263802] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  526.510702] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 6 <NL> [  528.909326] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 7 <NL> [  531.200755] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  531.201822] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  531.775748] txid_tracker[3298]: ::::create_confd_subscription_connection() try number 8 <NL> [  533.114498] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  535.117883] python3[2135]: [.350] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 20 of -1! <NL> [  537.843540] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  538.427375] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  539.525765] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 1 <NL> [  541.097827] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  541.830529] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  542.365225] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 2 <NL> [  542.717404] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  542.903329] python3[2135]: [.370] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 21 of -1! <NL> [  545.276885] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 3 <NL> [  546.129380] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  546.141804] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  548.490084] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 4 <NL> [  550.706472] confd_mgr[3031]: confd_db_init::Executing /usr/bin/confd_db_init.sh /etc/confd /var/shared/confd/SWUPGRADE_IN_PROGRESS /var/shared/defaultSys.txt <NL> [  550.710093] confd_mgr[3031]: confd_db_init::RESET REASON IS NONE <NL> [  550.713758] confd_mgr[3031]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  550.719456] confd_mgr[3031]: leaving: at_sm::wait_for_SWDL <NL> [  550.739252] confd_mgr[3031]: entering: at_sm::wait_for_start_bank <NL> [  550.746550] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [  550.752771] confd_mgr[3031]: leaving: at_sm::wait_for_start_bank <NL> [  550.758981] confd_mgr[3031]: entering: at_sm_dbready::wait_for_db_status <NL> [  550.763273] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  550.768459] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  550.775309] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  550.781715] confd_mgr[3313]: TRUE <NL> [  550.811128] confd_mgr[3031]: ConfdMgrConf::reload: DB signature set to false"}
{"timestamp_utc": "2024-07-31T08:22:07.428Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:07 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:07.989Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:07 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:08.551Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:08.807Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:08 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:12.074Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:12 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:22:12 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:22:12 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:12.330Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:22:12 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"stderr\": DONE <NL> # 03:22:12 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", type \"stdout\": DONE <NL> # 03:22:12 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\": process 3338 terminated with exitcode 0 <NL> # 03:22:12 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p07.s01.NE4-main-debug-ssh) <NL> # 03:22:12 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #0 finished with exit_code 0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:22:12 exec-job-tree INFO: job_cl::start:  ( 5)            (unexecuted) type \"command\": command ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37227', '--delay', '5'] (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:22:12 exec-job-tree INFO: process_cl::__init__: name \"n01.p09.s01.p07.s02.NE4-main-cli\", command: ['retry-ssh-command', '-v', '-v', '-v', '--hostname', 'rtxoialp79', '--port', '37227', '--delay', '5'] <NL> # 03:22:12 exec-job-tree INFO: job_cl::start:  ( 5)            (executing) type \"command\": started (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:22:12 exec-job-tree INFO: process_list_cl::add_job_obj: ----- name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"command\" <NL> # 03:22:12 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.s01.NE4-main-debug-ssh\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:22:12.585Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir/lib64/python3.6/site-packages/paramiko/transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6. <NL> from cryptography.hazmat.backends import default_backend <NL> # 03:22:12 retry-ssh-command INFO: attempting to connect to hostname 'rtxoialp79', port 37227, with username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:12 retry-ssh-command INFO: attempt 1, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:12.840Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:12 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:13.767Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:13 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:17.934Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:17 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:17 retry-ssh-command INFO: attempt 2, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:17 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:18.863Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:18 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp79:37291\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:19.793Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  528.058681] confd_mgr[4247]: DipLog_pimpl destructor called <NL> [  528.225502] confd_mgr[4247]: DipVerbosity Listener ZMQ error <NL> [  528.284297] confd_mgr[4247]:     ret='Context was terminated <NL> [  528.340457] confd_mgr[4247]: deleting subscriber_ socket <NL> [  528.340583] confd_mgr[4247]: Exiting verb listener <NL> [  528.361521] confd_mgr[3001]: CommAT::asio_subscriber: Connection accepted <NL> [  528.719238] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  528.719364] confd_mgr[3001]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  528.719447] confd_mgr[3001]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  528.719524] confd_mgr[3001]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  528.719597] confd_mgr[3001]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  528.719720] confd_mgr[3001]: ConfdHA Not supported command CONFIRM <NL> [  528.719809] confd_mgr[3001]: sm_startconfd::rm_ready <NL> [  528.719883] confd_mgr[3001]: leaving: sm_startconfd::wait_for_rm <NL> [  528.791613] confd_mgr[3001]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  528.791743] confd_mgr[3001]: entering: sm_startconfd::start_confd_p2 <NL> [  528.791826] confd_mgr[3001]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  528.830858] confd_mgr[4688]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:21:44 UTC 2024 <NL> [  529.144742] confd_mgr[4700]: cmnEvtXML has stopped <NL> [  529.144963] confd_mgr[4700]: start event-handler.service <NL> [  531.190511] ntputils[1975]: exited, status is 0 <NL> [  531.407959] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  531.408190] ntputils[1975]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  531.419274] ntputils[1975]: child pid is 4707 <NL> [  531.467679] ntputils[1975]: exited, status is 0 <NL> [  531.467804] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  531.467882] ntputils[1975]: /bin/systemctl reset-failed ntpd <NL> [  531.467987] ntputils[1975]: child pid is 4712 <NL> [  533.327279] systemd-sysv-generator[4723]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  538.793707] ntputils[1975]: exited, status is 0 <NL> [  538.793902] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  538.793997] ntputils[1975]: systemctl --no-block start ntpd <NL> [  538.794096] ntputils[1975]: child pid is 4727 <NL> [  540.435864] ntputils[1975]: exited, status is 0 <NL> [  540.436067] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  540.436150] ntputils[1975]: systemctl --no-block start ntpscript <NL> [  540.437489] ntputils[1975]: child pid is 4746"}
{"timestamp_utc": "2024-07-31T08:22:19.794Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  540.473459] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3283 <NL> [  540.567645] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3283 <NL> [  540.567777] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3283 <NL> [  540.567862] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3283 <NL> [  540.567950] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3283 <NL> [  540.704991] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3283 <NL> [  540.706422] layer1_hal[2471]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  540.706582] layer1_hal[2471]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  540.796214] confd_mgr[4733]: condition_name: systemRestart <NL> [  540.801600] confd_mgr[4733]: entity_type: COM <NL> [  540.818032] confd_mgr[4733]: num_instances: 1 <NL> [  540.818160] confd_mgr[4733]: num_samples: 1 <NL> [  540.818244] confd_mgr[4733]:  EventNotification does not have condition_group. Skipping. <NL> [  540.818325] confd_mgr[4733]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  540.818426] confd_mgr[4733]: CmnEvtPublisher::main: returning <NL> [  540.874212] confd_mgr[4700]: /usr/bin/confd_mgr_in_spm.sh <NL> [  540.997437] layer1_control_layer[2444]:    ChalApi Constructor with tid = 3286 <NL> [  541.289837] ntputils[1975]: exited, status is 0 <NL> [  541.290048] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  541.290128] ntputils[1975]: /bin/systemctl --no-block start init_state_check.timer <NL> [  541.290209] ntputils[1975]: child pid is 4779 <NL> [  541.291451] confd_mgr[4700]: /usr/bin/ui_sys_reset.py NONE <NL> [  541.581811] ntputils[1975]: exited, status is 0 <NL> [  541.632610] ntputils[1975]: Configure command handled successfully, writing to RTC <NL> [  541.632845] ntputils[1975]: NTPServer::execute_cmd spawning: <NL> [  541.632947] ntputils[1975]: /sbin/hwclock -u --systohc <NL> [  541.633097] ntputils[1975]: child pid is 4785 <NL> [  541.633323] ntputils[1975]: exited, status is 0 <NL> [  542.116788] ntp_alarm_event_monitor.py[4777]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  542.120463] ntp_alarm_event_monitor.py[4777]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  542.460536] ntp_alarm_event_monitor.py[4777]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  542.503945] ntp_alarm_event_monitor.py[4777]: INFO:root:redundancy status now set to standalone <NL> [  542.730528] ntp_alarm_event_monitor.py[4777]: INFO:root:Publish Alarm: Raising alarm <NL> [  542.760826] confd_mgr[4811]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  542.761857] confd_mgr[4811]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  542.784786] confd_mgr[4812]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  542.787214] confd_mgr[4812]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  542.796633] confd_mgr[4813]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  542.801856] confd_mgr[4813]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  542.803120] confd_mgr[4778]: DDS Peristency is enabled <NL> [  542.803784] confd_mgr[4778]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  542.844299] confd_mgr[4778]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  542.845215] confd_mgr[4778]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  542.846154] confd_mgr[4778]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  542.902491] ntp_alarm_event_monitor.py[4777]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  543.004803] confd_mgr[4815]: Execute check_db_status.sh <NL> [  543.202284] confd_mgr[4815]: NE is running a default database! <NL> [  543.921670] confd_mgr[4688]: Starting valhdlr.service if not started already <NL> [  544.026082] confd_mgr[4688]: Starting validation-handler.service if not started already <NL> [  544.141827] confd_mgr[4688]: Starting snmp-fss-fw.service if not started already <NL> [  544.266931] confd_mgr[3001]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  545.313886] ops-service[4855]: rebind_listener \"webui\" <NL> [  545.333167] ops-service[4855]: TRACE Connected (maapi) to ConfD <NL> [  545.335605] ops-service[4855]: TRACE MAAPI_REBIND_LISTENER <NL> [  545.336593] ops-service[4855]:  31-Jul-2024::08:22:01.724 4855/7fed72a8dc40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  545.406222] ops-service[4855]:  --> CONFD_OK <NL> [  545.474592] ops-service[4855]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  545.496154] ops-service[4856]: rebind_listener \"snmp\" <NL> [  545.560657] ops-service[4856]: TRACE Connected (maapi) to ConfD <NL> [  545.560911] ops-service[4856]: TRACE MAAPI_REBIND_LISTENER <NL> [  545.561015] ops-service[4856]:  31-Jul-2024::08:22:01.942 4856/7f57dfd1fc40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  545.648763] ops-service[4856]:  --> CONFD_OK <NL> [  545.706436] ops-service[4856]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  559.349815] confd_phase_sentry[2450]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [  559.350276] confd_phase_sentry[2450]: ConfdPhaseSentry: starting confd-ready.service <NL> [  559.598894] confd_mgr[3001]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [  559.644786] echo[4885]: Starting confd-ready <NL> [  560.115573] confd_mgr[4886]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:22:16 UTC 2024 <NL> [  560.117029] netconfEventSyslog[4892]: EventSyslogDaemon: Trying to connect to Confd <NL> [  562.191141] confd_mgr[4913]: Execute common_confd_nb_ready_cb.sh <NL> [  519.163994] confd_mgr[4692]: openDdsPorts Input udpPorts-  7650 <NL> [  519.218666] confd_mgr[4692]: openDdsPorts Output udpPorts-  7650 <NL> [  519.319783] confd_mgr[4692]: openDdsPorts Input udpPorts-  7651 <NL> [  519.404262] confd_mgr[4692]: openDdsPorts Output udpPorts-  7651 <NL> [  519.449060] confd_mgr[4692]: openDdsPorts Input udpPorts-  7900 <NL> [  519.541047] confd_mgr[4692]: openDdsPorts Output udpPorts-  7900 <NL> [  519.541249] confd_mgr[4692]: openDdsPorts Input udpPorts-  7901 <NL> [  519.659302] confd_mgr[4692]: openDdsPorts Output udpPorts-  7901 <NL> [  519.719632] confd_mgr[4692]: openDdsPorts Input udpPorts-  7910 <NL> [  519.909578] confd_mgr[4692]: openDdsPorts Output udpPorts-  7910 <NL> [  519.923560] confd_mgr[4692]: openDdsPorts Input udpPorts-  7911 <NL> [  520.055036] confd_mgr[4692]: openDdsPorts Output udpPorts-  7911 <NL> [  520.115519] confd_mgr[4692]: openDdsPorts Input udpPorts-  8150 <NL> [  520.115694] confd_mgr[4692]: openDdsPorts Output udpPorts-  8150 <NL> [  520.227995] confd_mgr[4692]: openDdsPorts Input udpPorts-  8151 <NL> [  520.294820] confd_mgr[4692]: openDdsPorts Output udpPorts-  8151 <NL> [  520.387087] confd_mgr[4692]: openDdsPorts Input udpPorts-  8160 <NL> [  520.431993] confd_mgr[4692]: openDdsPorts Output udpPorts-  8160 <NL> [  520.533439] confd_mgr[4692]: openDdsPorts Input udpPorts-  8161 <NL> [  520.755732] confd_mgr[4692]: openDdsPorts Output udpPorts-  8161 <NL> [  521.129984] confd_mgr[4272]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  521.130187] confd_mgr[4272]: replay_manager:  Start-Wed Jul 31 08:20:10 2024 <NL> [  521.130264] confd_mgr[4272]:  ++++++++++++++++++++++ <NL> [  521.130341] confd_mgr[4272]: replay_manager: TXID NOT FOUND ================================== <NL> [  521.130416] confd_mgr[4272]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  521.130516] confd_mgr[4272]: replay_manager: Need to do trigger full replay. <NL> [  521.130670] confd_mgr[4272]: replay_manager: Creating the purge file. <NL> [  521.130757] confd_mgr[4272]: replay_manager: Open DDS Ports <NL> [  521.130834] confd_mgr[4272]: replay_manager: NOW deleting the purge file. <NL> [  521.130920] confd_mgr[4272]: replay_manager:  End-Wed Jul 31 08:21:34 2024 <NL> [  521.130999] confd_mgr[4272]:  ++++++++++++++++++++++ <NL> [  521.131092] confd_mgr[4272]: Not 1+1 Mode <NL> [  521.131172] confd_mgr[4272]: DipLog_pimpl destructor called <NL> [  521.131275] confd_mgr[4272]: DipVerbosity Listener ZMQ error <NL> [  521.131374] confd_mgr[4272]:     ret='Context was terminated <NL> [  521.131465] confd_mgr[4272]: deleting subscriber_ socket <NL> [  521.131542] confd_mgr[4272]: Exiting verb listener <NL> [  521.335635] confd_mgr[3010]: CommAT::asio_subscriber: Connection accepted <NL> [  521.335844] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  521.335943] confd_mgr[3010]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  521.336052] confd_mgr[3010]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  521.365513] confd_mgr[3010]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  521.365613] confd_mgr[3010]: CommAT::asio_worker: ASIO_ID = ASIO"}
{"timestamp_utc": "2024-07-31T08:22:19.795Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  521.365774] confd_mgr[3010]: ConfdHA Not supported command CONFIRM <NL> [  521.365853] confd_mgr[3010]: sm_startconfd::rm_ready <NL> [  521.365929] confd_mgr[3010]: leaving: sm_startconfd::wait_for_rm <NL> [  521.366065] confd_mgr[3010]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [  521.366146] confd_mgr[3010]: entering: sm_startconfd::start_confd_p2 <NL> [  521.399499] confd_mgr[3010]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [  521.533392] confd_mgr[4735]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:21:35 UTC 2024 <NL> [  522.638153] confd_mgr[4743]: cmnEvtXML has stopped <NL> [  522.638899] confd_mgr[4743]: start event-handler.service <NL> [  523.757034] ops-service[4758]: rebind_listener \"webui\" <NL> [  523.799194] ops-service[4758]: TRACE Connected (maapi) to ConfD <NL> [  523.799406] ops-service[4758]: TRACE MAAPI_REBIND_LISTENER <NL> [  523.799487] ops-service[4758]:  31-Jul-2024::08:21:37.774 4758/7fbcbeb05c40/4 SEND op=407 isrel=0 th=-1 16 <NL> [  523.845528] ops-service[4758]:  --> CONFD_OK <NL> [  523.847143] ops-service[4758]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  523.906368] ops-service[4769]: rebind_listener \"snmp\" <NL> [  523.906626] ops-service[4769]: TRACE Connected (maapi) to ConfD <NL> [  523.906797] ops-service[4769]: TRACE MAAPI_REBIND_LISTENER <NL> [  523.906876] ops-service[4769]:  31-Jul-2024::08:21:37.852 4769/7fcce015fc40/4 SEND op=407 isrel=0 th=-1 4 <NL> [  523.906950] ops-service[4769]:  --> CONFD_OK <NL> [  523.907501] ops-service[4769]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [  524.084812] confd_mgr[4756]: condition_name: systemRestart <NL> [  524.085041] confd_mgr[4756]: entity_type: COM <NL> [  524.085174] confd_mgr[4756]: num_instances: 1 <NL> [  524.085265] confd_mgr[4756]: num_samples: 1 <NL> [  524.129773] confd_mgr[4756]:  EventNotification does not have condition_group. Skipping. <NL> [  524.129960] confd_mgr[4756]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [  524.130122] confd_mgr[4756]: CmnEvtPublisher::main: returning <NL> [  524.323326] confd_mgr[4743]: /usr/bin/confd_mgr_in_spm.sh <NL> [  524.492218] confd_mgr[4743]: /usr/bin/ui_sys_reset.py NONE <NL> [  525.666210] confd_mgr[4796]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  525.674129] confd_mgr[4796]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  525.709174] confd_mgr[4797]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  525.709277] confd_mgr[4797]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  525.709772] confd_mgr[4798]: Filesystem      Size  Used Avail Use% Mounted on <NL> [  525.709875] confd_mgr[4798]: /dev/root       2.2G  1.8G  295M  87% / <NL> [  525.744796] confd_mgr[4786]: DDS Peristency is enabled <NL> [  525.892816] confd_mgr[4786]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [  525.892926] confd_mgr[4786]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [  525.893015] confd_mgr[4786]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [  525.893091] confd_mgr[4786]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [  526.130202] confd_mgr[4800]: Execute check_db_status.sh <NL> [  526.817358] systemd-sysv-generator[4818]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  526.458729] confd_mgr[4800]: NE is running a default database! <NL> [  527.221454] confd_mgr[4735]: Starting valhdlr.service if not started already <NL> [  532.159565] confd_mgr[4735]: Starting validation-handler.service if not started already <NL> [  533.612016] systemd-sysv-generator[4844]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  538.109122] confd_mgr[4735]: Starting snmp-fss-fw.service if not started already <NL> [  538.700408] confd_mgr[3010]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [  554.048227] confd_phase_sentry[2430]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [  554.109948] confd_phase_sentry[2430]: ConfdPhaseSentry: starting confd-ready.service <NL> [  554.582180] confd_mgr[3010]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [  554.661475] echo[4927]: Starting confd-ready <NL> [  554.894899] confd_mgr[4930]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:22:08 UTC 2024 <NL> [  556.150320] netconfEventSyslog[4937]: EventSyslogDaemon: Trying to connect to Confd <NL> [  556.850250] confd_mgr[4958]: Execute common_confd_nb_ready_cb.sh <NL> [  556.919473] automater.sh[4931]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [  556.960465] confd_mgr[4930]: Invoking confd_nb_enable.py <NL> [  558.040510] snmp_trapd[4946]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  559.071278] snmp_trapd[4946]: gen_util: DDS_P2MP not available <NL> [  565.323456] confd_mgr[4968]: nb_enable.py: INFO: Start <NL> [  565.323649] confd_mgr[4968]: Running \"systemctl stop netconf_socket_change.path\""}
{"timestamp_utc": "2024-07-31T08:22:20.724Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  241.395353] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.217875, delay 0.02734\\n31 Jul 08:16:55 ntpdate[2732]: no server suitable for synchronization found\\n' <NL> [  253.198344] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  253.198804] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  253.198894] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.214111, delay 0.03743\\n31 Jul 08:17:07 ntpdate[2780]: no server suitable for synchronization found\\n' <NL> [  265.129278] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  265.129656] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  265.129768] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.217715, delay 0.02678\\n31 Jul 08:17:19 ntpdate[2806]: no server suitable for synchronization found\\n' <NL> [  277.012666] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  277.013241] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  277.013341] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.223226, delay 0.04420\\n31 Jul 08:17:31 ntpdate[2840]: no server suitable for synchronization found\\n' <NL> [  288.877463] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  288.877843] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  288.877939] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.217989, delay 0.02763\\n31 Jul 08:17:43 ntpdate[2873]: no server suitable for synchronization found\\n' <NL> [  300.765973] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  300.780044] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  300.780189] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.207330, delay 0.05293\\n31 Jul 08:17:55 ntpdate[2901]: no server suitable for synchronization found\\n' <NL> [  313.131538] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  313.131829] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  313.131929] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.190963, delay 0.11978\\n31 Jul 08:18:07 ntpdate[2942]: no server suitable for synchronization found\\n' <NL> [  324.954420] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  324.954813] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  324.954910] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.220350, delay 0.03186\\n31 Jul 08:18:19 ntpdate[2969]: no server suitable for synchronization found\\n' <NL> [  336.789344] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  336.789937] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  336.790095] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.215931, delay 0.03508\\n31 Jul 08:18:31 ntpdate[3010]: no server suitable for synchronization found\\n' <NL> [  348.763101] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  348.814215] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:22:20.725Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  348.819054] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.231178, delay 0.09523\\n31 Jul 08:18:43 ntpdate[3045]: no server suitable for synchronization found\\n' <NL> [  360.625084] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  360.674600] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  360.776137] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.206752, delay 0.06143\\n31 Jul 08:18:55 ntpdate[3073]: no server suitable for synchronization found\\n' <NL> [  372.396391] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  372.399072] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  372.419962] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.215515, delay 0.03349\\n31 Jul 08:19:06 ntpdate[3131]: no server suitable for synchronization found\\n' <NL> [  384.255056] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  384.258022] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  384.273180] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.222457, delay 0.07306\\n31 Jul 08:19:18 ntpdate[3170]: no server suitable for synchronization found\\n' <NL> [  396.268989] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  396.269246] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  396.269336] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.218349, delay 0.02734\\n31 Jul 08:19:30 ntpdate[3207]: no server suitable for synchronization found\\n' <NL> [  408.139054] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  408.139264] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  408.139460] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.224302, delay 0.04871\\n31 Jul 08:19:42 ntpdate[3238]: no server suitable for synchronization found\\n' <NL> [  420.017442] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  420.017619] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  420.017697] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.217813, delay 0.02673\\n31 Jul 08:19:54 ntpdate[3265]: no server suitable for synchronization found\\n' <NL> [  431.967852] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  431.968058] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  431.984100] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.221554, delay 0.03613\\n31 Jul 08:20:06 ntpdate[3299]: no server suitable for synchronization found\\n' <NL> [  443.865105] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  443.924660] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  443.972824] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.217741, delay 0.03261\\n31 Jul 08:20:18 ntpdate[3331]: no server suitable for synchronization found\\n' <NL> [  455.749955] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  455.751985] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  455.771890] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.217951, delay 0.02698\\n31 Jul 08:20:30 ntpdate[3372]: no server suitable for synchronization found\\n' <NL> [  519.432825] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  519.434147] ntputils_client.py[1689]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  519.461861] ntputils_client.py[1689]: b'31 Jul 08:21:34 ntpdate[3534]: no server suitable for synchronization found\\n' <NL> [  522.473784] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  522.473970] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  522.474088] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.014331, delay 0.04224\\n31 Jul 08:21:37 ntpdate[3573]: no server suitable for synchronization found\\n' <NL> [  531.127607] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  531.127892] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  531.128013] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.035405, delay 0.08521\\n31 Jul 08:21:45 ntpdate[3609]: no server suitable for synchronization found\\n' <NL> [  542.991956] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  542.995796] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  543.021429] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.000276, delay 0.04190\\n31 Jul 08:21:57 ntpdate[3641]: no server suitable for synchronization found\\n' <NL> [  554.920240] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  554.936221] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  554.940612] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.019010, delay 0.05194\\n31 Jul 08:22:09 ntpdate[3696]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:22:22.115Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:22 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37319\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:22.676Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:22 retry-ssh-command INFO: attempt 3, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:22.933Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:22 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:23.860Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37291, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:27.127Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37319, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:27.691Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:27 retry-ssh-command INFO: attempt 4, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:27.947Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:27 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:29.840Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  288.139730] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  288.139839] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349367, delay 0.02785\\n31 Jul 08:17:40 ntpdate[2857]: no server suitable for synchronization found\\n' <NL> [  300.075509] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  300.076088] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  300.076218] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.347875, delay 0.05666\\n31 Jul 08:17:52 ntpdate[2886]: no server suitable for synchronization found\\n' <NL> [  312.002511] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  312.073086] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  312.074678] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.348330, delay 0.02985\\n31 Jul 08:18:04 ntpdate[2914]: no server suitable for synchronization found\\n' <NL> [  323.946211] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  323.946811] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  323.946946] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.359439, delay 0.04803\\n31 Jul 08:18:16 ntpdate[2955]: no server suitable for synchronization found\\n' <NL> [  335.832146] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  335.910829] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:22:29.841Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  335.926279] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.351410, delay 0.04256\\n31 Jul 08:18:28 ntpdate[2986]: no server suitable for synchronization found\\n' <NL> [  347.699085] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  347.727833] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  347.736163] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.362460, delay 0.09189\\n31 Jul 08:18:40 ntpdate[3029]: no server suitable for synchronization found\\n' <NL> [  359.785781] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  359.786377] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  359.786464] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.353818, delay 0.04381\\n31 Jul 08:18:52 ntpdate[3057]: no server suitable for synchronization found\\n' <NL> [  371.640298] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  371.640572] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  371.640754] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.350633, delay 0.06047\\n31 Jul 08:19:03 ntpdate[3110]: no server suitable for synchronization found\\n' <NL> [  383.489291] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  383.489842] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  383.489951] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349029, delay 0.03668\\n31 Jul 08:19:15 ntpdate[3154]: no server suitable for synchronization found\\n' <NL> [  395.435908] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  395.436475] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  395.436600] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349137, delay 0.02805\\n31 Jul 08:19:27 ntpdate[3182]: no server suitable for synchronization found\\n' <NL> [  407.382688] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  407.482103] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  407.482899] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.350045, delay 0.03328\\n31 Jul 08:19:39 ntpdate[3222]: no server suitable for synchronization found\\n' <NL> [  419.340437] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  419.341369] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  419.359563] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.348514, delay 0.02974\\n31 Jul 08:19:51 ntpdate[3249]: no server suitable for synchronization found\\n' <NL> [  431.216555] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  431.279901] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  431.280112] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.314937, delay 0.12802\\n31 Jul 08:20:03 ntpdate[3276]: no server suitable for synchronization found\\n' <NL> [  443.055663] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  443.068406] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  443.096893] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.347098, delay 0.03589\\n31 Jul 08:20:15 ntpdate[3308]: no server suitable for synchronization found\\n' <NL> [  454.872363] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  454.896996] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  454.928566] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349520, delay 0.03188\\n31 Jul 08:20:27 ntpdate[3355]: no server suitable for synchronization found\\n' <NL> [  466.765844] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  466.780732] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  466.792556] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.324928, delay 0.10677\\n31 Jul 08:20:39 ntpdate[3392]: no server suitable for synchronization found\\n' <NL> [  478.654772] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  478.656028] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  478.664195] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.348157, delay 0.03900\\n31 Jul 08:20:51 ntpdate[3419]: no server suitable for synchronization found\\n' <NL> [  550.180448] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  550.180854] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  550.180953] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.346867, delay 0.04169\\n31 Jul 08:22:02 ntpdate[3647]: no server suitable for synchronization found\\n' <NL> [  558.758365] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  558.763580] ntputils_client.py[1708]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  558.763721] ntputils_client.py[1708]: b'31 Jul 08:22:11 ntpdate[3655]: no server suitable for synchronization found\\n' <NL> [  563.890546] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  563.891370] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  563.892413] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349258, delay 0.02763\\n31 Jul 08:22:16 ntpdate[3687]: no server suitable for synchronization found\\n' <NL> [  576.041732] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  576.042260] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  576.042345] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.348735, delay 0.04373\\n31 Jul 08:22:28 ntpdate[3731]: no server suitable for synchronization found\\n' <NL> [  576.076318] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2370 <NL> [  576.122926] layer1_control_layer[2080]: EsalConfig::EsalConfig main 0 <NL> [  576.123152] layer1_control_layer[2080]: EsalConfig::EsalConfig trib 1 <NL> [  576.123230] layer1_control_layer[2080]: EsalConfig::EsalConfig ciRole 0 <NL> [  576.320308] layer1_control_layer[2080]: EsalConfig is not running inside container. <NL> [  576.321186] layer1_control_layer[2080]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  576.321502] layer1_control_layer[2080]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  576.455425] layer1_control_layer[2080]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  576.455628] layer1_control_layer[2080]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:22:30.451Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p03.s02.NE2-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p03", "keyword_name": "s02.NE2-main-cli", "step_id": "s02.NE2-main-cli", "message_content": "# 03:22:30 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:22:30 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:22:30 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"stderr\": DONE <NL> # 03:22:30 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\", type \"stdout\": DONE <NL> # 03:22:30 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p03.s02.NE2-main-cli\": process 3416 terminated with exitcode 0 <NL> # 03:22:30 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p03.s02.NE2-main-cli) <NL> # 03:22:30 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p03.main-startup (s)) <NL> # 03:22:30 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p03.main-startup (s)) <NL> # 03:22:30 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #2 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:22:30 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 3 children running (n01.p09.s01.startup (p)) <NL> # 03:22:30 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.s02.NE2-main-cli\", exit_code 0 <NL> # 03:22:30 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p03.main-startup (s)\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:22:32.339Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p01.s02.NE1-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p01", "keyword_name": "s02.NE1-main-cli", "step_id": "s02.NE1-main-cli", "message_content": "# 03:22:31 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:22:31 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:22:31 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"stderr\": DONE <NL> # 03:22:31 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\", type \"stdout\": DONE <NL> # 03:22:31 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p01.s02.NE1-main-cli\": process 3428 terminated with exitcode 0 <NL> # 03:22:31 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p01.s02.NE1-main-cli) <NL> # 03:22:31 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p01.main-startup (s)) <NL> # 03:22:31 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p01.main-startup (s)) <NL> # 03:22:31 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #0 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:22:31 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 2 children running (n01.p09.s01.startup (p)) <NL> # 03:22:31 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.s02.NE1-main-cli\", exit_code 0 <NL> # 03:22:31 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p01.main-startup (s)\", exit_code 0"}
{"timestamp_utc": "2024-07-31T08:22:32.596Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:32 retry-ssh-command INFO: attempt 5, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:32.853Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:32 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:37.021Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  550.817573] confd_mgr[3031]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  550.823124] confd_mgr[3031]: ha_sm is_ha_mode_not_none_g cur_mode is 1+1 <NL> [  550.843809] confd_mgr[3031]: ha_sm leaving: wait_for_SWDL_s <NL> [  550.852500] confd_mgr[3031]: ha_sm::start_active_agent_a: The HA mode is 1+1 <NL> [  550.862708] confd_mgr[3031]: ha_sm_active entering: wait_for_active_agent_s <NL> [  550.874789] confd_mgr[3031]: confd_at_common::check_dbssm: Skipping DB signature check <NL> [  550.884455] confd_mgr[3031]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  550.897233] confd_mgr[3031]: ConfdTribActiveAgent start_rep_server <NL> [  550.905415] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  550.917481] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,MAIN,WORK,STANDALONE <NL> [  550.929080] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  550.936343] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  550.944620] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  551.003931] confd_mgr[3031]: ConfdTribActiveAgent::server address 127.1.254.254 port 4050 <NL> [  551.041545] confd_mgr[3031]: calling accept_handler <NL> [  551.063274] confd_mgr[3031]: In ConfdTribActiveAgent::check_reset <NL> [  551.071637] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  551.076817] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  551.088325] confd_mgr[3717]: Executing check_db.sh <NL> [  551.097180] confd_mgr[3031]: confd_ha::process_rdm_status: Removed /run/rdm_status.sh <NL> [  551.102722] confd_mgr[3031]: ha_sm_active leaving: wait_for_active_agent_s <NL> [  551.107302] confd_mgr[3031]: process_ha_alarm raise noSecondaryDatabase <NL> [  551.111629] confd_mgr[3031]: ha_sm_active entering: wait_for_standby_s <NL> [  551.118099] confd_mgr[3031]: ConfdMgrConf::reload: DB signature set to false <NL> [  551.122620] confd_mgr[3031]: Start_type: GO_ACTIVE (STANDALONE/WORK)"}
{"timestamp_utc": "2024-07-31T08:22:37.022Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  551.128354] confd_mgr[3031]: Maskable Alarm <NL> [  551.133126] confd_mgr[3031]: leaving: wait_for_alarm_event <NL> [  551.165958] confd_mgr[3031]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:152:add_to_alarms: OPERATION=raise CONDITION=noSecondaryDatabase #ALARMS=1 <NL> [  551.179996] confd_mgr[3031]: entering: wait_for_alarm_process <NL> [  551.187689] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  551.204828] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  551.217894] confd_mgr[3311]: TRUE <NL> [  551.224640] confd_mgr[3717]: check_db.sh: found xml files <NL> [  551.230191] confd_mgr[3717]: 0 <NL> [  551.235207] confd_mgr[3031]: Found no error <NL> [  551.237249] confd_mgr[3031]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  551.243258] confd_mgr[3031]: cur_gdbissue 24.1.1 gdbissue 24.1.1 rc = 1 <NL> [  551.251417] confd_mgr[3031]: Cdb::get_field DBMgmtData.NE_TYPE <NL> [  551.262301] confd_mgr[3031]: TSeries-CIS is in the list: TSeries-CIS <NL> [  551.267953] confd_mgr[3031]: at_sm_dbready::wait_for_db_status: db_status.alarm= databaseOkay , db_status.alarm_state= clear <NL> [  551.279954] confd_mgr[3031]: guard at_sm_dbready::is_halting_db_alarm_g <NL> [  551.286249] confd_mgr[3031]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  551.302243] confd_mgr[3031]: guard at_sm_dbready::sw_not_synced_dfltsys_g <NL> [  551.313380] confd_mgr[3031]: guard at_sm_dbready::is_db_alarm_wo_init_sdb <NL> [  551.331678] confd_mgr[3031]: guard at_sm_dbready::is_db_alarm_w_init_sdb: evt.alarm_type_= databaseOkay <NL> [  551.341250] confd_mgr[3031]: guard is_db_okay_g: The HA mode is 1+1 <NL> [  551.356265] confd_mgr[3031]: The reset reason is NONE, Alarm type is databaseOkay, Alarm State is clear <NL> [  551.407701] confd_mgr[3031]: entering: sm_startconfd::start_confd_p0 <NL> [  551.471036] confd_mgr[3031]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_start_phase0_cb.sh NONE <NL> [  551.502615] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 5 <NL> [  551.514781] confd_mgr[3725]: Execute confd_start_phase0_cb.sh - Wed Jul 31 08:22:04 UTC 2024 <NL> [  551.516069] confd_mgr[3031]: CONFD_IPC_PORT=4000 /usr/sbin/confd -c /etc/confd/confd.conf.bank0 --start-phase0 <NL> [  552.812093] confd_mgr[3031]: leaving: wait_for_alarm_process <NL> [  552.856760] confd_mgr[3031]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/git/src/alarm_at_sm_sml.h:160:write_alarms_to_file: #ALARMS=1 <NL> [  553.362438] confd_mgr[3031]:  write_db_alarm rename was successful <NL> [  553.388179] confd_mgr[3031]: entering: wait_for_alarm_event <NL> [  553.605881] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  553.621181] python3[2135]: [.886] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 22 of -1! <NL> [  554.448981] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 6 <NL> [  556.059097] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.585333] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  557.474815] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 7 <NL> [  560.468142] txid_tracker[3501]: ::::create_confd_subscription_connection() try number 8 <NL> [  561.700722] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  562.090650] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  563.934968] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  564.747051] python3[2135]: [.308] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 23 of -1! <NL> [  565.442128] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 1 <NL> [  566.097639] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  566.298434] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  568.530546] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 2 <NL> [  571.081052] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  571.085903] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  571.603940] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 3 <NL> [  573.640102] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  573.781768] python3[2135]: [.332] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 24 of -1! <NL> [  575.044491] systemd-sysv-generator[3897]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  575.228796] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 4 <NL> [  576.282770] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  576.798368] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  578.539493] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 5 <NL> [  580.643125] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 6"}
{"timestamp_utc": "2024-07-31T08:22:37.603Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:37 retry-ssh-command INFO: attempt 6, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:37.860Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:37 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:43.105Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:42 retry-ssh-command INFO: attempt 7, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:43.106Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:42 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:47.269Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  565.323737] confd_mgr[4968]: Running \"systemctl stop cli_socket_change.path\" <NL> [  565.323813] confd_mgr[4968]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [  565.323876] confd_mgr[4968]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [  565.324507] confd_mgr[4968]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [  565.511890] confd_mgr[4930]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:22:19 UTC 2024 <NL> [  567.709315] confd_mgr[3010]: Sending Startup notif <NL> [  572.187589] zero-touch-boot[4952]: NO match: <NL> [  572.197745] zero-touch-boot[4952]: NO match: <NL> [  572.232145] zero-touch-boot[4952]: NO match: <NL> [  574.972823] confd_mgr[5134]:  DB Notif Gen <NL> [  575.267720] confd_mgr[3010]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  575.327404] confd_mgr[3010]: leaving: sm_startconfd::start_confd_p2. <NL> [  575.371609] confd_mgr[4733]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  575.424309] confd_mgr[3010]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  575.461734] confd_mgr[3010]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  575.508827] confd_mgr[4265]: DDS Ports are opened <NL> [  575.920174] confd_mgr[5239]: openDdsPorts interfaces  eth5.2003 <NL> [  575.921335] confd_mgr[5239]: openDdsPorts Input udpPorts-  7660 <NL> [  575.934543] confd_mgr[5242]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  575.942443] confd_mgr[5239]: openDdsPorts Output udpPorts-  7660 <NL> [  575.969443] confd_mgr[5243]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  575.983150] confd_mgr[5239]: openDdsPorts Input udpPorts-  7661 <NL> [  576.064400] confd_mgr[5246]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.076337] confd_mgr[5239]: openDdsPorts Output udpPorts-  7661 <NL> [  576.259813] confd_mgr[5249]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.276093] confd_mgr[5239]: openDdsPorts Input udpPorts-  7650 <NL> [  576.297648] confd_mgr[5252]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.378246] confd_mgr[5239]: openDdsPorts Output udpPorts-  7650 <NL> [  576.402358] confd_mgr[5254]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.408379] confd_mgr[5239]: openDdsPorts Input udpPorts-  7651 <NL> [  576.507479] confd_mgr[5257]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.507657] confd_mgr[5239]: openDdsPorts Output udpPorts-  7651 <NL> [  576.508293] confd_mgr[5258]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.706225] confd_mgr[5239]: openDdsPorts Input udpPorts-  7900 <NL> [  576.797242] confd_mgr[5262]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.844634] confd_mgr[5239]: openDdsPorts Output udpPorts-  7900 <NL> [  576.959250] confd_mgr[5264]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  576.960253] confd_mgr[5239]: openDdsPorts Input udpPorts-  7901 <NL> [  576.986540] confd_mgr[5266]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.113099] confd_mgr[5239]: openDdsPorts Output udpPorts-  7901 <NL> [  577.169082] confd_mgr[5271]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.230114] confd_mgr[5239]: openDdsPorts Input udpPorts-  7910 <NL> [  577.283573] confd_mgr[5274]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.332434] confd_mgr[5239]: openDdsPorts Output udpPorts-  7910 <NL> [  577.368625] confd_mgr[5280]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.503604] confd_mgr[5239]: openDdsPorts Input udpPorts-  7911 <NL> [  577.569153] confd_mgr[5282]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.665161] confd_mgr[5239]: openDdsPorts Output udpPorts-  7911 <NL> [  578.531483] confd_mgr[5284]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  578.641530] confd_mgr[5239]: openDdsPorts Input udpPorts-  8150 <NL> [  578.660094] confd_mgr[5302]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  578.679912] confd_mgr[5239]: openDdsPorts Output udpPorts-  8150 <NL> [  579.046127] confd_mgr[5303]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.176597] confd_mgr[5239]: openDdsPorts Input udpPorts-  8151 <NL> [  579.178953] confd_mgr[5310]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.265451] confd_mgr[5239]: openDdsPorts Output udpPorts-  8151 <NL> [  579.394193] confd_mgr[5313]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.394426] confd_mgr[5239]: openDdsPorts Input udpPorts-  8160 <NL> [  579.395118] confd_mgr[5314]: iptables: Bad rule (does a matching rule exist in that chain?)."}
{"timestamp_utc": "2024-07-31T08:22:47.270Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p03.NE2-main-console", "warrior_node_id": "n01", "project_id": "p03", "test_suite_id": "NE2-main-console", "message_content": "[  579.451262] confd_mgr[5239]: openDdsPorts Output udpPorts-  8160 <NL> [  579.547607] confd_mgr[5316]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.599572] confd_mgr[5239]: openDdsPorts Input udpPorts-  8161 <NL> [  579.711192] confd_mgr[5320]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.740425] confd_mgr[5239]: openDdsPorts Output udpPorts-  8161 <NL> [  579.773806] confd_mgr[5321]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.924152] netconfEventSyslog[4937]: EventSyslogDaemon Waiting for event notifications... <NL> [  580.477072] confd_mgr[5345]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  588.026819] ntputils[1971]: NTPServer::execute_cmd spawning: <NL> [  588.027052] ntputils[1971]: /sbin/hwclock -u --systohc <NL> [  588.040120] ntputils[1971]: child pid is 5386 <NL> [  588.079514] ntputils[1971]: exited, status is 0 <NL> [  588.079699] ntputils[1971]: poller time change reason is: local_pub_str.ntp_drift <NL> [  588.079788] ntputils[1971]: poller time change delta is: 1 <NL> [  588.079871] ntputils[1971]: push_local_changes user_changed: 0 delta: 1 <NL> [  588.079997] ntputils[1971]: local_push OK u Platform::Time changedByUser 0 <NL> [  588.106259] ntputils[1971]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  588.349803] ntputils[1971]: local_push OK w Platform::Time 0 0 <NL> [  588.457526] ntputils[1971]: push_local_changes OK <NL> [  588.458734] confd_mgr[5345]: ==================== saving database ================== <NL> [  588.597688] confd_mgr[5395]: A.cdb <NL> [  588.894496] confd_mgr[5395]: A.cdb.sig <NL> [  588.894619] confd_mgr[5395]: C.cdb <NL> [  591.642926] confd_mgr[5395]: C.cdb.sig <NL> [  591.643133] confd_mgr[5395]: DefTxId <NL> [  591.643213] confd_mgr[5395]: O.cdb <NL> [  591.643327] confd_mgr[5395]: compact.lock <NL> [  591.643405] confd_mgr[5395]: dbmgmtdata.conf <NL> [  591.643490] confd_mgr[5395]: replay.cdb <NL> [  591.918205] confd_mgr[5395]: schema.sig <NL> [  591.964603] confd_mgr[3010]: entering: sm_startconfd::exit_to_ready <NL> [  591.964885] confd_mgr[3010]: leaving: sm_startconfd::exit_to_ready <NL> [  591.964976] confd_mgr[3010]: action at_sm_dbready::do_db_ready_a <NL> [  591.966853] confd_mgr[3010]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME <NL> [  591.967029] confd_mgr[3010]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME not defined. <NL> [  591.968664] confd_mgr[3010]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/recipe-sysroot/usr/include/boost/property_tree/detail/ptree_implementation.hpp(576): Throw in function boost::property_tree::basic_ptree<K, D, C>& boost::property_tree::basic_ptree<Key, Data, KeyCompare>::get_child(const path_type&) [with Key = std::__cxx11::basic_string<char>; Data = std::__cxx11::basic_string<char>; KeyCompare = std::less<std::__cxx11::basic_string<char> >; boost::property_tree::basic_ptree<Key, Data, KeyCompare>::path_type = boost::property_tree::string_path<std::__cxx11::basic_string<char>, boost::property_tree::id_translator<std::__cxx11::basic_string<char> > >] <NL> [  591.968819] confd_mgr[3010]: Dynamic exception type: boost::wrapexcept<boost::property_tree::ptree_bad_path> <NL> [  591.970157] confd_mgr[3010]: std::exception::what: No such node (DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME) <NL> [  592.016137] confd_mgr[3010]: Node is not present in the xml. Ignore the above exception."}
{"timestamp_utc": "2024-07-31T08:22:47.526Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  521.443773] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 3 <NL> [  524.534877] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 4 <NL> [  524.820524] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  525.285473] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  527.814466] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 5 <NL> [  527.989868] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  528.002377] python3[2242]: [.089] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 18 of -1! <NL> [  529.844056] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  530.051445] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  531.229342] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 6 <NL> [  533.705295] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 7 <NL> [  534.868036] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  534.925930] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  536.684379] txid_tracker[3770]: ::::create_confd_subscription_connection() try number 8 <NL> [  537.939526] systemd-journald[324]: Data hash table of /run/log/journal/8a0d242a701141fb8e8d4bd1e8332dde/system.journal has a fill level at 75.0 (13654 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation."}
{"timestamp_utc": "2024-07-31T08:22:47.527Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  538.649435] systemd-journald[324]: /run/log/journal/8a0d242a701141fb8e8d4bd1e8332dde/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  539.940907] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  540.724994] python3[2242]: [.118] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 19 of -1! <NL> [  540.728200] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  540.729239] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  542.438559] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 1 <NL> [  544.902572] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  544.903761] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  545.520984] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 2 <NL> [  548.149574] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  548.499403] python3[2242]: [.301] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 20 of -1! <NL> [  549.117888] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 3 <NL> [  549.920489] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  549.921591] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  551.589596] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 4 <NL> [  554.632991] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 5 <NL> [  556.336711] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  556.974867] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  557.974143] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 6 <NL> [  558.639940] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  559.062284] python3[2242]: [.340] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 21 of -1! <NL> [  559.988277] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  560.825959] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  563.028112] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 7 <NL> [  564.072924] txid_tracker[3861]: ::::create_confd_subscription_connection() try number 8 <NL> [  564.947038] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  565.202304] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  568.257042] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  568.319480] python3[2242]: [.353] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 22 of -1! <NL> [  568.875656] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 1 <NL> [  569.948320] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  570.290435] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  571.997934] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 2 <NL> [  574.974368] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  575.312312] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  575.786588] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 3 <NL> [  578.037522] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 4 <NL> [  578.423768] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  578.663424] python3[2242]: [.603] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 23 of -1! <NL> [  580.093852] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  580.302382] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  581.127292] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 5 <NL> [  584.056035] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 6 <NL> [  585.037521] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  585.211481] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  587.071560] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 7 <NL> [  588.591268] python3[2242]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  588.625730] python3[2242]: [.619] hookhdlr 140665309656896 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 24 of -1!"}
{"timestamp_utc": "2024-07-31T08:22:47.783Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:47 retry-ssh-command INFO: attempt 8, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:48.038Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:22:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:47 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:53.335Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:52 retry-ssh-command INFO: attempt 9, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:52 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:22:58.585Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:22:58.586Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:22:57 retry-ssh-command INFO: attempt 10, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:22:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:22:57 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:03.840Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:02 retry-ssh-command INFO: attempt 11, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:02 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:08.012Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:07 retry-ssh-command INFO: attempt 12, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:07 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:12.187Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  562.200970] automater.sh[4889]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [  562.313537] confd_mgr[4886]: Invoking confd_nb_enable.py <NL> [  562.525679] snmp_trapd[4903]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  564.577753] snmp_trapd[4903]: gen_util: DDS_P2MP not available <NL> [  565.787036] confd_mgr[4926]: nb_enable.py: INFO: Start <NL> [  565.868264] confd_mgr[4926]: Running \"systemctl stop netconf_socket_change.path\" <NL> [  566.120516] confd_mgr[4926]: Running \"systemctl stop cli_socket_change.path\" <NL> [  566.289260] confd_mgr[4926]: Running \"iptables -w -F chain-incoming-northbound\" <NL> [  566.470844] confd_mgr[4926]: Running \"iptables -w -D INPUT -p tcp -j chain-incoming-northbound\" <NL> [  566.614617] confd_mgr[4926]: Running \"iptables -w -X chain-incoming-northbound\" <NL> [  566.642076] confd_mgr[4886]: Exiting confd_nb_ready_cb.sh - Wed Jul 31 08:22:22 UTC 2024 <NL> [  568.234357] confd_mgr[3001]: Sending Startup notif <NL> [  576.903817] confd_mgr[5065]:  DB Notif Gen <NL> [  577.050712] confd_mgr[3001]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  577.235443] confd_mgr[3001]: leaving: sm_startconfd::start_confd_p2. <NL> [  577.235863] confd_mgr[4686]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  577.236110] confd_mgr[3001]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  577.236239] confd_mgr[3001]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT"}
{"timestamp_utc": "2024-07-31T08:23:12.188Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p01.NE1-main-console", "warrior_node_id": "n01", "project_id": "p01", "test_suite_id": "NE1-main-console", "message_content": "[  577.236763] confd_mgr[4240]: DDS Ports are opened <NL> [  577.692039] confd_mgr[5172]: openDdsPorts interfaces  eth5.2003 <NL> [  577.692280] confd_mgr[5172]: openDdsPorts Input udpPorts-  7660 <NL> [  577.885360] confd_mgr[5179]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.885632] confd_mgr[5172]: openDdsPorts Output udpPorts-  7660 <NL> [  577.939043] confd_mgr[5182]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  577.939741] confd_mgr[5172]: openDdsPorts Input udpPorts-  7661 <NL> [  578.097072] confd_mgr[5184]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  578.142242] confd_mgr[5172]: openDdsPorts Output udpPorts-  7661 <NL> [  578.429374] confd_mgr[5185]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  578.429628] confd_mgr[5172]: openDdsPorts Input udpPorts-  7650 <NL> [  578.844393] confd_mgr[5187]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  578.858719] confd_mgr[5172]: openDdsPorts Output udpPorts-  7650 <NL> [  578.936253] confd_mgr[5194]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.113562] confd_mgr[5172]: openDdsPorts Input udpPorts-  7651 <NL> [  579.114332] confd_mgr[5196]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.197182] confd_mgr[5172]: openDdsPorts Output udpPorts-  7651 <NL> [  579.391844] confd_mgr[5199]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.578738] confd_mgr[5172]: openDdsPorts Input udpPorts-  7900 <NL> [  579.611672] confd_mgr[5204]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.678643] confd_mgr[5172]: openDdsPorts Output udpPorts-  7900 <NL> [  579.693341] confd_mgr[5206]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.693473] confd_mgr[5172]: openDdsPorts Input udpPorts-  7901 <NL> [  579.731528] confd_mgr[5209]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.809703] confd_mgr[5172]: openDdsPorts Output udpPorts-  7901 <NL> [  579.810041] confd_mgr[5211]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  579.810168] confd_mgr[5172]: openDdsPorts Input udpPorts-  7910 <NL> [  579.857026] confd_mgr[5212]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.044733] confd_mgr[5172]: openDdsPorts Output udpPorts-  7910 <NL> [  580.045096] confd_mgr[5213]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.045231] confd_mgr[5172]: openDdsPorts Input udpPorts-  7911 <NL> [  580.045725] confd_mgr[5215]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.054679] confd_mgr[5172]: openDdsPorts Output udpPorts-  7911 <NL> [  580.239971] confd_mgr[5216]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.240231] confd_mgr[5172]: openDdsPorts Input udpPorts-  8150 <NL> [  580.240687] confd_mgr[5217]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.313333] confd_mgr[5172]: openDdsPorts Output udpPorts-  8150 <NL> [  580.369484] confd_mgr[5218]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.475901] confd_mgr[5172]: openDdsPorts Input udpPorts-  8151 <NL> [  580.643488] confd_mgr[5221]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  580.746348] zero-touch-boot[4909]: NO match: <NL> [  580.746540] zero-touch-boot[4909]: NO match: <NL> [  580.764450] zero-touch-boot[4909]: NO match: <NL> [  581.019103] confd_mgr[5172]: openDdsPorts Output udpPorts-  8151 <NL> [  581.021387] confd_mgr[5227]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  581.021547] confd_mgr[5172]: openDdsPorts Input udpPorts-  8160 <NL> [  581.122617] confd_mgr[5241]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  581.136542] confd_mgr[5172]: openDdsPorts Output udpPorts-  8160 <NL> [  581.136870] confd_mgr[5243]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  581.137029] confd_mgr[5172]: openDdsPorts Input udpPorts-  8161 <NL> [  581.137304] confd_mgr[5246]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  581.137455] confd_mgr[5172]: openDdsPorts Output udpPorts-  8161 <NL> [  581.137664] confd_mgr[5248]: iptables: Bad rule (does a matching rule exist in that chain?). <NL> [  582.584701] confd_mgr[5314]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  583.892918] netconfEventSyslog[4892]: EventSyslogDaemon Waiting for event notifications... <NL> [  590.688742] confd_mgr[5314]: ==================== saving database ================== <NL> [  590.733344] confd_mgr[5350]: A.cdb <NL> [  590.833248] confd_mgr[5350]: A.cdb.sig <NL> [  590.841179] confd_mgr[5350]: C.cdb <NL> [  593.354110] confd_mgr[5350]: C.cdb.sig <NL> [  593.354314] confd_mgr[5350]: DefTxId <NL> [  593.354815] confd_mgr[5350]: O.cdb <NL> [  593.354983] confd_mgr[5350]: compact.lock <NL> [  593.355110] confd_mgr[5350]: dbmgmtdata.conf <NL> [  593.355192] confd_mgr[5350]: replay.cdb <NL> [  593.474751] confd_mgr[5350]: schema.sig <NL> [  593.553160] confd_mgr[3001]: entering: sm_startconfd::exit_to_ready <NL> [  593.555167] confd_mgr[3001]: leaving: sm_startconfd::exit_to_ready <NL> [  593.555277] confd_mgr[3001]: action at_sm_dbready::do_db_ready_a <NL> [  593.555365] confd_mgr[3001]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME <NL> [  593.555453] confd_mgr[3001]: Cdb::get_field DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME not defined. <NL> [  593.555536] confd_mgr[3001]: /usr/src/debug/confdmgr/1.0+gitr359+2a3ac8235d-r359/recipe-sysroot/usr/include/boost/property_tree/detail/ptree_implementation.hpp(576): Throw in function boost::property_tree::basic_ptree<K, D, C>& boost::property_tree::basic_ptree<Key, Data, KeyCompare>::get_child(const path_type&) [with Key = std::__cxx11::basic_string<char>; Data = std::__cxx11::basic_string<char>; KeyCompare = std::less<std::__cxx11::basic_string<char> >; boost::property_tree::basic_ptree<Key, Data, KeyCompare>::path_type = boost::property_tree::string_path<std::__cxx11::basic_string<char>, boost::property_tree::id_translator<std::__cxx11::basic_string<char> > >] <NL> [  593.555680] confd_mgr[3001]: Dynamic exception type: boost::wrapexcept<boost::property_tree::ptree_bad_path> <NL> [  593.555771] confd_mgr[3001]: std::exception::what: No such node (DBMgmtData.DATABASE_LAST_RESTORED_DATE_TIME) <NL> [  593.555894] confd_mgr[3001]: Node is not present in the xml. Ignore the above exception. <NL> [  593.556136] confd_mgr[3001]: The dbmgmt_data_path_ and cdb file path passed to timestamp_operation.py script /var/shared/confd/bank0/dbmgmtdata.conf   /var/shared/confd/bank0/A.cdb <NL> [  595.561245] confd_mgr[3001]: ConfdHA::process_sdb_op SDB_REP_START <NL> [  595.561696] confd_mgr[3001]: ha_sm leaving: no_ha_s <NL> [  595.561807] confd_mgr[3001]: ha_sm entering: no_ha_s"}
{"timestamp_utc": "2024-07-31T08:23:13.115Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:12 retry-ssh-command INFO: attempt 13, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:13.116Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:23:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:13 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:14.528Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  590.101073] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  590.212992] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  590.511387] txid_tracker[3947]: ::::create_confd_subscription_connection() try number 8 <NL> [  595.277339] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  595.450530] confd_phase_sentry[2246]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc0600d55c7; Failed to connect to ConfD: Connection refused <NL> [  595.953903] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 1 <NL> [  598.605806] python3[2242]: DEBUG EOF on socket to ConfD <NL> [  598.691785] python3[2242]: [.702] hookhdlr 140665309656896 callbackhdlr:457 Exception to create daemon <NL> [  598.695408] python3[2242]: Traceback (most recent call last): <NL> [  598.696166] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  598.697395] python3[2242]:     daemon = self.create_daemon() <NL> [  598.704500] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  598.720825] python3[2242]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  598.721930] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  598.738069] python3[2242]:     self._init_connection() <NL> [  598.738754] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  598.740062] python3[2242]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  598.763429] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  598.838319] python3[2242]:     _tm.dp.connect( <NL> [  598.885619] python3[2242]: _confd.error.EOF: ConfD closed connection <NL> [  599.016441] python3[2242]: [.749] hookhdlr 140665309656896 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  599.196886] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 2 <NL> [  600.030141] confd_phase_sentry[2246]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  600.168648] confd_phase_sentry[2246]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  601.726917] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 3 <NL> [  604.734553] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 4 <NL> [  606.105793] python3[4033]: INFO:root:Started rsync_logfile.py... <NL> [  606.178828] python3[4033]: INFO:root:redundancy status = STANDALONE <NL> [  606.220655] python3[4033]: INFO:root:redundancy mode = UNKNOWN <NL> [  606.241878] python3[4033]: <NL> [  606.268502] python3[4033]: ERROR:root:Error: System is not in redundancy mode <NL> [  607.187118] db_info.py[2234]: Traceback (most recent call last): <NL> [  607.447302] db_info.py[2234]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  607.496750] db_info.py[2234]:     main() <NL> [  607.519116] db_info.py[2234]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  607.644216] db_info.py[2234]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  607.761209] db_info.py[2234]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  608.047528] db_info.py[2234]:     self._init_connection() <NL> [  608.215430] db_info.py[2234]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  608.295193] db_info.py[2234]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  608.300259] db_info.py[2234]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  608.301591] db_info.py[2234]:     _tm.dp.connect( <NL> [  608.358917] db_info.py[2234]: _confd.error.EOF: ConfD closed connection <NL> [  609.038899] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 5"}
{"timestamp_utc": "2024-07-31T08:23:14.529Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  609.571433] python3[2242]: [.786] hookhdlr 140665309656896 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  610.258605] healthcheck_result_display.py[2240]: Traceback (most recent call last): <NL> [  610.615120] healthcheck_result_display.py[2240]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  611.092886] healthcheck_result_display.py[2240]:     main(hc_utils.setup_logging(__name__)) <NL> [  611.259637] healthcheck_result_display.py[2240]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  611.260850] healthcheck_result_display.py[2240]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  611.738774] healthcheck_result_display.py[2240]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  611.965875] healthcheck_result_display.py[2240]:     self._init_connection() <NL> [  612.063301] healthcheck_result_display.py[2240]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  612.112868] healthcheck_result_display.py[2240]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  612.202160] healthcheck_result_display.py[2240]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  612.276467] healthcheck_result_display.py[2240]:     _tm.dp.connect( <NL> [  612.379219] healthcheck_result_display.py[2240]: _confd.error.EOF: ConfD closed connection <NL> [  612.580677] python3[2242]: DEBUG EOF on socket to ConfD <NL> [  612.743380] python3[2242]: [.483] hookhdlr 140665309656896 callbackhdlr:457 Exception to create daemon <NL> [  612.855974] python3[2242]: Traceback (most recent call last): <NL> [  613.161927] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  613.661906] python3[2242]:     daemon = self.create_daemon() <NL> [  613.888441] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  614.035124] python3[2242]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  614.191281] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  614.728124] python3[2242]:     self._init_connection() <NL> [  615.011399] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  615.023940] python3[2242]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  615.083275] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  615.432578] python3[2242]:     _tm.dp.connect( <NL> [  615.616780] python3[2242]: _confd.error.EOF: ConfD closed connection <NL> [  615.630768] python3[2242]: [.484] hookhdlr 140665309656896 callbackhdlr:471 Failed to run daemon main, retry 2 of -1 <NL> [  615.841758] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 6 <NL> [  616.163359] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 7 <NL> [  616.437543] rasis_system_stats.py[2248]: Traceback (most recent call last): <NL> [  616.474513] rasis_system_stats.py[2248]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  616.533667] rasis_system_stats.py[2248]:     main() <NL> [  616.597759] rasis_system_stats.py[2248]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  616.740880] rasis_system_stats.py[2248]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  616.774311] rasis_system_stats.py[2248]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  616.790612] rasis_system_stats.py[2248]:     self._init_connection() <NL> [  616.817421] rasis_system_stats.py[2248]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  616.823854] rasis_system_stats.py[2248]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  616.856522] rasis_system_stats.py[2248]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  616.859305] rasis_system_stats.py[2248]:     _tm.dp.connect("}
{"timestamp_utc": "2024-07-31T08:23:18.699Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:17 retry-ssh-command INFO: attempt 14, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:18 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:23.944Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:22 retry-ssh-command INFO: attempt 15, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:23 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:28.112Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:27 retry-ssh-command INFO: attempt 16, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:28 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:31.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  582.010656] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  583.640460] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused[  584.033166] tun: Universal TUN/TAP device driver, 1.6 <NL> [  583.944802] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  584.151302] python3[2135]: [.443] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 25 of -1! <NL> [  584.369590] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 7 <NL> [  586.255648] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  587.526962] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  587.974535] txid_tracker[3838]: ::::create_confd_subscription_connection() try number 8 <NL> [  591.327529] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  591.760185] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  592.655939] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 1 <NL> [  593.863760] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  593.999079] python3[2135]: [.553] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 26 of -1! <NL> [  595.655690] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 2 <NL> [  596.346836] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd."}
{"timestamp_utc": "2024-07-31T08:23:31.399Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  596.348392] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  598.671192] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 3 <NL> [  601.397934] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  601.909260] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  602.879535] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 4 <NL> [  604.127313] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  604.192874] python3[2135]: [.820] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 27 of -1! <NL> [  604.918249] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 5 <NL> [  606.698567] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  607.349650] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  608.178951] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  608.209699] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  608.210890] ntputils[1725]: child pid is 3962 <NL> [  608.246896] ntputils[1725]: exited, status is 0 <NL> [  608.382236] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  608.506127] ntputils[1725]: poller time change delta is: 1 <NL> [  608.584654] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  608.591986] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  608.701144] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  608.919835] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  609.076791] ntputils[1725]: push_local_changes OK <NL> [  609.357250] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 6 <NL> [  609.791176] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [  610.094644] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [  610.153736] ntputils[1725]: child pid is 3977 <NL> [  610.205274] ntputils[1725]: exited, status is 0 <NL> [  610.205912] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [  610.206849] ntputils[1725]: poller time change delta is: 1 <NL> [  610.207510] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [  610.852839] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [  611.538239] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  611.650916] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [  611.652181] ntputils[1725]: push_local_changes OK <NL> [  611.682477] python3[3947]: INFO:root:Started rsync_logfile.py... <NL> [  611.683388] python3[3947]: INFO:root:redundancy status = STANDALONE <NL> [  611.984108] python3[3947]: INFO:root:redundancy mode = UNKNOWN <NL> [  612.015358] python3[3947]: <NL> [  612.066245] python3[3947]: ERROR:root:Error: System is not in redundancy mode <NL> [  612.583497] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  612.609143] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  612.782787] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 7 <NL> [  613.740415] txid_tracker[3916]: ::::create_confd_subscription_connection() try number 8 <NL> [  614.174669] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  614.283888] python3[2135]: [.892] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 28 of -1! <NL> [  616.538541] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  616.539808] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  618.869397] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 1 <NL> [  621.700555] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  621.702865] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  622.356901] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 2 <NL> [  624.273668] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  624.355503] python3[2135]: [.960] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 29 of -1! <NL> [  624.913625] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 3 <NL> [  626.654834] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  626.792833] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  627.923304] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 4 <NL> [  631.130155] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 5 <NL> [  631.724104] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  632.108696] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  633.936981] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 6 <NL> [  634.497255] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  634.628682] python3[2135]: [.168] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 30 of -1!"}
{"timestamp_utc": "2024-07-31T08:23:33.304Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:32 retry-ssh-command INFO: attempt 17, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:33.305Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:23:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:33 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:38.548Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:38 retry-ssh-command INFO: attempt 18, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:38 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:43.865Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:43 retry-ssh-command INFO: attempt 19, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:43 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:49.105Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:48 retry-ssh-command INFO: attempt 20, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:48 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:53.272Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:53 retry-ssh-command INFO: attempt 21, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:53 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:23:58.515Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:23:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:58 retry-ssh-command INFO: attempt 22, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:23:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:23:58 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:03.812Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:03 retry-ssh-command INFO: attempt 23, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:03 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:09.094Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:08 retry-ssh-command INFO: attempt 24, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:08 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:13.264Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:13 retry-ssh-command INFO: attempt 25, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:13.519Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:13 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:18.819Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:18 retry-ssh-command INFO: attempt 26, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:18 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:24.129Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:23 retry-ssh-command INFO: attempt 27, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:23 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:28.293Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:28 retry-ssh-command INFO: attempt 28, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:28.549Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:28 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:30.439Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  636.752550] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  636.902841] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  637.067564] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 7 <NL> [  640.015827] txid_tracker[4010]: ::::create_confd_subscription_connection() try number 8 <NL> [  641.767133] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  641.904080] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  644.561714] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 1 <NL> [  644.658258] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  645.031868] python3[2135]: [.288] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 31 of -1! <NL> [  646.724807] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  647.262876] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  648.061030] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 2 <NL> [  650.599477] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 3 <NL> [  651.756500] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  652.061363] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  653.787968] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 4 <NL> [  654.642731] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  654.786989] python3[2135]: [.438] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 32 of -1! <NL> [  656.602453] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 5 <NL> [  656.757305] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  656.988209] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  659.612785] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 6 <NL> [  661.729423] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  661.730531] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  662.616840] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 7 <NL> [  664.783328] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  664.847601] python3[2135]: [.497] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 33 of -1! <NL> [  665.653448] txid_tracker[4060]: ::::create_confd_subscription_connection() try number 8 <NL> [  666.730679] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  666.820748] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  671.615424] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 1 <NL> [  671.804204] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  671.963981] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  674.636146] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 2 <NL> [  674.847629] python3[2135]: DEBUG Failed to connect to ConfD: Connection refused <NL> [  674.921901] python3[2135]: [.527] hookhdlr 140644876773184 callbackhdlr:279 Unable to connect to 127.0.0.1:4000, attempt 34 of -1! <NL> [  676.945100] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  677.239847] confd_phase_sentry[2140]: sll::confdapi::ConfdReturnValue sll::confd_phase_sentry::ConfdPhaseSentry::ConnectToConfd(int): unable to connect (confd_errno = 24): 0x7fc42e57b5c7; Failed to connect to ConfD: Connection refused <NL> [  677.639460] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 3 <NL> [  680.691717] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 4 <NL> [  681.841338] confd_phase_sentry[2140]: ConfdPhaseSentry: Retrying connection to confd. <NL> [  682.090900] confd_phase_sentry[2140]: ConfdPhaseSentry: Connected to confd, blocking on phase = 2 <NL> [  683.692969] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 5 <NL> [  685.243961] python3[2135]: DEBUG EOF on socket to ConfD <NL> [  685.519526] python3[2135]: [.903] hookhdlr 140644876773184 callbackhdlr:457 Exception to create daemon <NL> [  685.812696] python3[2135]: Traceback (most recent call last): <NL> [  685.994795] python3[2135]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  686.220495] python3[2135]:     daemon = self.create_daemon() <NL> [  686.877939] python3[2135]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  687.054787] python3[2135]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  687.055793] python3[2135]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  687.056869] python3[2135]:     self._init_connection() <NL> [  687.180922] python3[2135]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  687.202143] python3[2135]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  687.385528] python3[2135]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  687.516700] python3[2135]:     _tm.dp.connect( <NL> [  687.527714] python3[2135]: _confd.error.EOF: ConfD closed connection <NL> [  687.577058] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 6 <NL> [  687.691851] python3[2135]: [.243] hookhdlr 140644876773184 callbackhdlr:471 Failed to run daemon main, retry 1 of -1 <NL> [  689.736576] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 7 <NL> [  692.739283] txid_tracker[4124]: ::::create_confd_subscription_connection() try number 8 <NL> [  695.584535] python3[2135]: [.255] hookhdlr 140644876773184 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  695.657474] python3[2135]: DEBUG EOF on socket to ConfD <NL> [  695.661949] python3[2135]: [.336] hookhdlr 140644876773184 callbackhdlr:457 Exception to create daemon <NL> [  695.698671] python3[2135]: Traceback (most recent call last): <NL> [  695.699524] python3[2135]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  695.700764] python3[2135]:     daemon = self.create_daemon() <NL> [  695.701484] python3[2135]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  695.730536] python3[2135]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  695.796837] python3[2135]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  695.867272] python3[2135]:     self._init_connection() <NL> [  695.930769] python3[2135]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  695.986818] python3[2135]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET)"}
{"timestamp_utc": "2024-07-31T08:24:33.709Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:33 retry-ssh-command INFO: attempt 29, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:33 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:38.957Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:24:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:38 retry-ssh-command INFO: attempt 30, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:38 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:44.202Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:43 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:43 retry-ssh-command INFO: attempt 31, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:49.448Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:48 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:48 retry-ssh-command INFO: attempt 32, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:49.706Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  616.916870] rasis_system_stats.py[2248]: _confd.error.EOF: ConfD closed connection <NL> [  616.934926] txid_tracker[4020]: ::::create_confd_subscription_connection() try number 8 <NL> [  619.445644] python3[2242]: [.499] hookhdlr 140665309656896 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  619.543493] python3[2242]: DEBUG EOF on socket to ConfD <NL> [  619.544589] python3[2242]: [.606] hookhdlr 140665309656896 callbackhdlr:457 Exception to create daemon <NL> [  619.567340] python3[2242]: Traceback (most recent call last): <NL> [  619.587568] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  619.588849] python3[2242]:     daemon = self.create_daemon() <NL> [  619.589464] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  619.590743] python3[2242]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  619.595282] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  619.710622] python3[2242]:     self._init_connection() <NL> [  619.741594] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  619.788794] python3[2242]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  619.812877] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  619.893546] python3[2242]:     _tm.dp.connect( <NL> [  619.894912] python3[2242]: _confd.error.EOF: ConfD closed connection <NL> [  619.965764] python3[2242]: [.607] hookhdlr 140665309656896 callbackhdlr:471 Failed to run daemon main, retry 3 of -1 <NL> [  621.782224] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 1 <NL> [  624.781606] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 2 <NL> [  627.883331] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 3 <NL> [  629.535170] python3[2242]: [.631] hookhdlr 140665309656896 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  630.589415] python3[2242]: DEBUG EOF on socket to ConfD <NL> [  630.875855] python3[2242]: [.542] hookhdlr 140665309656896 callbackhdlr:457 Exception to create daemon <NL> [  631.293475] python3[2242]: Traceback (most recent call last): <NL> [  631.707858] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 451, in main <NL> [  632.078657] python3[2242]:     daemon = self.create_daemon() <NL> [  632.177505] python3[2242]:   File \"/usr/lib/python3.10/site-packages/py_handler_daemon/callbackhdlr.py\", line 271, in create_daemon <NL> [  632.352083] python3[2242]:     daemon = self._daemon_cls(name=self._daemon_name, <NL> [  632.457545] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  632.678674] python3[2242]:     self._init_connection() <NL> [  632.891992] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  632.909281] python3[2242]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  632.910775] python3[2242]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  632.913464] python3[2242]:     _tm.dp.connect( <NL> [  632.995877] python3[2242]: _confd.error.EOF: ConfD closed connection <NL> [  633.009570] python3[2242]: [.567] hookhdlr 140665309656896 callbackhdlr:471 Failed to run daemon main, retry 4 of -1 <NL> [  633.094474] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 4 <NL> [  633.785855] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 5 <NL> [  636.787818] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 6 <NL> [  639.789106] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 7 <NL> [  640.493695] python3[2242]: [.590] hookhdlr 140665309656896 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  640.903851] python3[2242]: [.001] hookhdlr 140665309656896 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  640.905340] python3[2242]: [.003] hookhdlr 140665309656896 callbackhdlr:293 Loading schemas <NL> [  641.136898] python3[2242]: DEBUG item does not exist - shared memory schema not enabled <NL> [  642.807493] txid_tracker[4094]: ::::create_confd_subscription_connection() try number 8 <NL> [  647.490953] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 1 <NL> [  648.740479] python3[2242]: [.837] hookhdlr 140665309656896 callbackhdlr:382 Done load schemas <NL> [  648.761639] python3[2242]: [.849] hookhdlr 140665309656896 callbackhdlr:389 Done register transaction callback <NL> [  650.491288] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 2 <NL> [  650.810485] python3[2242]: [.907] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb supp-if-hook <NL> [  650.931590] python3[2242]: [.965] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb admin-status-hook"}
{"timestamp_utc": "2024-07-31T08:24:49.707Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  651.198382] python3[2242]: [.296] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  651.241456] python3[2242]: [.319] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  651.304585] python3[2242]: [.322] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  651.355165] python3[2242]: [.361] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  651.414679] python3[2242]: [.375] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  651.504737] python3[2242]: [.443] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  651.565124] python3[2242]: [.448] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  651.641858] python3[2242]: [.488] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  651.673459] python3[2242]: [.496] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  651.799777] python3[2242]: [.545] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  652.216232] python3[2242]: [.550] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  653.501035] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 3 <NL> [  653.670154] python3[2242]: [.644] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  656.518763] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 4 <NL> [  659.600378] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 5 <NL> [  661.137396] python3[2242]: [.178] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  662.602429] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 6 <NL> [  665.175887] python3[2242]: [.272] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  665.712931] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 7 <NL> [  668.635544] txid_tracker[4163]: ::::create_confd_subscription_connection() try number 8 <NL> [  671.151942] python3[2242]: [.248] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  673.868349] txid_tracker[4217]: ::::create_confd_subscription_connection() connected <NL> [  676.612508] python3[2242]: [.709] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  676.715798] python3[2242]: [.753] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  676.946883] python3[2242]: [.794] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  677.060584] python3[2242]: [.806] hookhdlr 140665309656896 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  677.259302] python3[2242]: [.976] hookhdlr 140665309656896 callbackhdlr:391 Done register data callbacks <NL> [  712.290360] confd_mgr[2516]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh"}
{"timestamp_utc": "2024-07-31T08:24:53.876Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:53 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:53 retry-ssh-command INFO: attempt 33, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:24:59.120Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:24:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:58 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:24:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:24:58 retry-ssh-command INFO: attempt 34, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:04.371Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:03 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:03 retry-ssh-command INFO: attempt 35, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:05.735Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  712.329382] confd_mgr[4321]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:24:48 UTC 2024 <NL> [  712.359286] confd_mgr[4321]: Starting valhdlr.service <NL> [  712.460250] confd_mgr[4321]: Starting validation-handler.service <NL> [  712.650500] confd_mgr[4321]: Starting snmp-fss-fw.service <NL> [  712.963428] python3[2242]: DEBUG No crypto keys configured <NL> [  713.218190] confd_mgr[2516]: leaving: sm_startconfd::start_confd_p0"}
{"timestamp_utc": "2024-07-31T08:25:05.992Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  713.390635] confd_mgr[2516]: entering: sm_startconfd::wait_for_p0 <NL> [  713.391526] confd_mgr[2516]: PROCESS1 has not registered yet. <NL> [  713.392628] confd_mgr[2516]: PROCESS_SNMP_CLID has not registered yet. <NL> [  713.515294] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  713.649868] python3[2242]: [.058] hookhdlr 140665309656896 callbackhdlr:401 Unable to install crypto keys! <NL> [  713.830307] python3[2242]: [.190] hookhdlr 140665309656896 callbackhdlr:322 Started data handler daemon... <NL> [  713.946936] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  713.949098] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  713.997239] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  714.044713] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  714.108850] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  714.213376] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  714.275277] confd_mgr[2516]: ConfdHA Not supported command CONFIRM <NL> [  714.277502] confd_mgr[2516]: sm_startconfd::p0_ready_dbc <NL> [  714.285196] confd_mgr[2516]: Find message MESSAGE1 <NL> [  714.286058] confd_mgr[2516]: PROCESS_SNMP_CLID has not registered yet. <NL> [  714.287464] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  714.307566] confd_mgr[2516]: sm_startconfd::p0_not_ready <NL> [  714.393431] confd_mgr[2516]: Find message MESSAGE1 <NL> [  714.450753] confd_mgr[2516]: PROCESS_SNMP_CLID has not registered yet. <NL> [  714.641190] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  714.655191] confd_mgr[2516]: leaving: sm_startconfd::wait_for_p0 <NL> [  714.655988] confd_mgr[2516]: entering: sm_startconfd::wait_for_p0 <NL> [  714.656728] confd_mgr[2516]: PROCESS_SNMP_CLID has not registered yet. <NL> [  714.657548] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  714.759302] confd_mgr[2516]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  715.044143] confd_mgr[2516]: Timer /ConfdAT|wait_for_p0 already created <NL> [  715.065819] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  715.211030] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  716.309866] python3[4329]: [.407] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  716.505744] python3[4329]: [.466] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  716.808172] python3[4329]: [.466] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  716.983115] python3[4329]: [.467] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  717.059436] python3[4329]: [.480] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  717.341983] python3[4329]: [.480] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  717.619860] python3[4329]: [.480] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  717.835724] python3[4329]: [.480] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  717.837087] python3[4329]: [.480] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  717.949530] python3[4329]: [.480] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  718.081445] python3[4329]: [.486] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  718.170245] python3[4329]: [.487] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  718.255171] python3[4329]: [.487] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  718.730391] python3[4329]: [.487] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  718.958166] python3[4329]: [.487] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  719.210583] python3[4329]: [.487] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  719.644845] python3[4329]: [.487] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  719.992857] python3[4329]: [.497] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  720.320070] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  720.321913] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  720.650438] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  721.445802] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  722.615780] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  723.509031] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  724.238491] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  724.794452] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'}"}
{"timestamp_utc": "2024-07-31T08:25:05.993Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  725.151929] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  725.795749] python3[4329]: [.498] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  726.317744] python3[4329]: [.499] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  726.505306] python3[4329]: [.499] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  726.797639] python3[4329]: [.499] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  726.914537] python3[4329]: [.499] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  727.071573] python3[4329]: [.499] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  727.073217] python3[4329]: [.499] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  727.176954] python3[4329]: [.500] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  727.400964] python3[4329]: [.500] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  727.609064] python3[4329]: [.500] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  727.807697] python3[4329]: [.501] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  727.922546] python3[4329]: [.520] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  728.099043] python3[4329]: [.520] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  728.214402] python3[4329]: [.534] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  728.503452] snmp_clid[4335]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set."}
{"timestamp_utc": "2024-07-31T08:25:08.514Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:08 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:08.770Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:25:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:08 retry-ssh-command INFO: attempt 36, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:10.658Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  565.309432] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2450 <NL> [  565.319134] layer1_control_layer[2075]: EsalConfig::EsalConfig main 0 <NL> [  565.350168] layer1_control_layer[2075]: EsalConfig::EsalConfig trib 1 <NL> [  565.375503] layer1_control_layer[2075]: EsalConfig::EsalConfig ciRole 0 <NL> [  565.399196] layer1_control_layer[2075]: EsalConfig is not running inside container. <NL> [  565.461452] layer1_control_layer[2075]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:25:10.659Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p04.NE2-trib1-console", "warrior_node_id": "n01", "project_id": "p04", "test_suite_id": "NE2-trib1-console", "message_content": "[  565.461584] layer1_control_layer[2075]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  565.470632] layer1_control_layer[2075]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  565.470837] layer1_control_layer[2075]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  565.470919] layer1_control_layer[2075]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  565.471018] layer1_control_layer[2075]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  565.471109] layer1_control_layer[2075]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  565.472282] layer1_control_layer[2075]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  565.490353] layer1_control_layer[2075]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  565.490455] layer1_control_layer[2075]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  565.490530] layer1_control_layer[2075]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  565.490608] layer1_control_layer[2075]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  565.490691] layer1_control_layer[2075]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  565.490783] layer1_control_layer[2075]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  565.490860] layer1_control_layer[2075]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  565.490938] layer1_control_layer[2075]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [  565.491069] layer1_control_layer[2075]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  565.597738] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2449 <NL> [  565.609855] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2449 <NL> [  565.618588] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2449 <NL> [  565.654658] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2449 <NL> [  565.713775] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2449 <NL> [  565.766249] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2449 <NL> [  565.850996] layer1_hal[2094]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  565.886311] layer1_hal[2094]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  566.304724] layer1_control_layer[2075]:    ChalApi Constructor with tid = 2452 <NL> [  566.992168] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  566.993147] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  566.993260] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.024586, delay 0.17207\\n31 Jul 08:22:21 ntpdate[3744]: no server suitable for synchronization found\\n' <NL> [  579.278727] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  579.278922] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  579.279057] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset +0.004835, delay 0.04863\\n31 Jul 08:22:34 ntpdate[3810]: no server suitable for synchronization found\\n' <NL> [  591.263557] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  591.265990] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  591.299842] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.000238, delay 0.03864\\n31 Jul 08:22:46 ntpdate[3837]: no server suitable for synchronization found\\n' <NL> [  603.087640] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  603.098601] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  603.099620] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.004780, delay 0.03349\\n31 Jul 08:22:57 ntpdate[3863]: no server suitable for synchronization found\\n' <NL> [  614.941146] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  614.959740] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  614.984239] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.007285, delay 0.04039\\n31 Jul 08:23:09 ntpdate[3905]: no server suitable for synchronization found\\n' <NL> [  626.814874] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  626.858264] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  626.885954] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.007020, delay 0.02779\\n31 Jul 08:23:21 ntpdate[3944]: no server suitable for synchronization found\\n' <NL> [  638.794570] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  638.795242] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  638.795359] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.015408, delay 0.04500\\n31 Jul 08:23:33 ntpdate[3978]: no server suitable for synchronization found\\n' <NL> [  650.685175] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  650.685539] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  650.685644] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.005749, delay 0.03117\\n31 Jul 08:23:45 ntpdate[4013]: no server suitable for synchronization found\\n' <NL> [  662.524136] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  662.524521] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  662.524649] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.004993, delay 0.03374\\n31 Jul 08:23:57 ntpdate[4039]: no server suitable for synchronization found\\n' <NL> [  675.413365] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  675.413578] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  675.413713] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.010126, delay 0.07393\\n31 Jul 08:24:10 ntpdate[4071]: no server suitable for synchronization found\\n' <NL> [  687.317843] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  687.318877] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  687.325057] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.007501, delay 0.03461\\n31 Jul 08:24:22 ntpdate[4110]: no server suitable for synchronization found\\n' <NL> [  699.183222] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  699.184138] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  699.185152] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.001837, delay 0.03961\\n31 Jul 08:24:33 ntpdate[4144]: no server suitable for synchronization found\\n' <NL> [  711.104358] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  711.105484] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  711.106523] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.008075, delay 0.02968\\n31 Jul 08:24:45 ntpdate[4178]: no server suitable for synchronization found\\n' <NL> [  723.036501] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  723.037517] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  723.038524] ntputils_client.py[1689]: b'server 127.1.254.254, stratum 16, offset -0.008997, delay 0.04523\\n31 Jul 08:24:57 ntpdate[4204]: no server suitable for synchronization found\\n' <NL> [  734.993900] ntputils_client.py[1689]: INFO:root:command failed. <NL> [  735.075588] ntputils_client.py[1689]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:25:13.954Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:13 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:13 retry-ssh-command INFO: attempt 37, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:19.246Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:18 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:18 retry-ssh-command INFO: attempt 38, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:24.566Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:23 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:23 retry-ssh-command INFO: attempt 39, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:28.737Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:28 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:28 retry-ssh-command INFO: attempt 40, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:34.070Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:33 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:33 retry-ssh-command INFO: attempt 41, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> [  728.563597] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  728.589378] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  728.614365] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  728.637441] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  728.652869] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  728.671912] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  728.693378] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  728.713266] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  728.741809] python3[4329]: [.535] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  728.800958] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  728.870482] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  728.956443] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  729.099661] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  729.228608] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  729.323413] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  729.413657] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  729.459537] python3[4329]: [.536] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  729.559120] python3[4329]: [.537] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  729.663768] python3[4329]: [.551] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  729.982108] python3[4329]: [.551] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  730.124859] snmp_clid[4401]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  730.172821] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  730.204187] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  730.207797] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  730.210294] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  730.278775] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  730.337948] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  730.360873] confd_mgr[2516]: ConfdHA Not supported command CONFIRM <NL> [  730.376285] confd_mgr[2516]: sm_startconfd::p0_ready_dbc <NL> [  730.488329] confd_mgr[2516]: Find message SNMP_CLID_CONFIRM"}
{"timestamp_utc": "2024-07-31T08:25:34.071Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  730.652241] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  730.947959] confd_mgr[2516]: sm_startconfd::p0_not_ready <NL> [  731.012488] confd_mgr[2516]: Find message SNMP_CLID_CONFIRM <NL> [  731.143614] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  731.223830] confd_mgr[2516]: leaving: sm_startconfd::wait_for_p0 <NL> [  731.244685] confd_mgr[2516]: entering: sm_startconfd::wait_for_p0 <NL> [  731.307151] confd_mgr[2516]: PROCESS_VALHDLR has not registered yet. <NL> [  731.360275] confd_mgr[2516]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  731.442144] confd_mgr[2516]: Timer /ConfdAT|wait_for_p0 already created <NL> [  731.504626] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  731.607336] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  731.690718] python3[4329]: [.551] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  731.744818] python3[4329]: [.551] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  731.825526] python3[4329]: [.552] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  731.925477] python3[4329]: [.552] valhdlr 140296396851008 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  732.111423] python3[4329]: [.552] valhdlr 140296396851008 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  732.245690] python3[4329]: [.566] valhdlr 140296396851008 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  732.280783] python3[4329]: [.566] valhdlr 140296396851008 callbackhdlr:293 Loading schemas <NL> [  732.348899] python3[4329]: DEBUG item does not exist - shared memory schema not enabled <NL> [  732.386850] python3[4329]: [.937] valhdlr 140296396851008 callbackhdlr:382 Done load schemas <NL> [  732.387814] python3[4329]: [.937] valhdlr 140296396851008 callbackhdlr:389 Done register transaction callback <NL> [  732.389200] python3[4329]: [.284] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  732.390557] python3[4329]: [.581] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  732.555529] python3[4329]: [.803] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  732.557068] python3[4329]: [.828] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  743.874743] python3[4329]: [.970] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  743.927116] python3[4329]: [.024] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  743.958783] python3[4329]: [.050] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  744.178799] python3[4329]: [.276] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  744.260911] python3[4329]: [.358] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  744.402231] python3[4329]: [.408] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  744.502705] python3[4329]: [.428] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  744.624525] python3[4329]: [.449] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  744.705816] python3[4329]: [.453] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation <NL> [  747.210885] python3[4329]: [.307] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  750.345834] python3[4329]: [.442] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb port_capability_validation <NL> [  753.307646] python3[4329]: [.404] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  755.991141] python3[4329]: [.074] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  756.015814] python3[4329]: [.090] valhdlr 140296396851008 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  756.187753] python3[4329]: [.090] valhdlr 140296396851008 callbackhdlr:391 Done register data callbacks <NL> [  756.317128] python3[4329]: DEBUG No crypto keys configured <NL> [  756.373307] python3[4329]: [.181] valhdlr 140296396851008 callbackhdlr:401 Unable to install crypto keys! <NL> [  756.419373] python3[4329]: [.225] valhdlr 140296396851008 callbackhdlr:322 Started data handler daemon..."}
{"timestamp_utc": "2024-07-31T08:25:39.342Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:38 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:38 retry-ssh-command INFO: attempt 42, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:44.589Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:43 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:43 retry-ssh-command INFO: attempt 43, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:48.775Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:48 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:48 retry-ssh-command INFO: attempt 44, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:54.131Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:53 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:53 retry-ssh-command INFO: attempt 45, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:25:59.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:25:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:58 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:25:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:25:58 retry-ssh-command INFO: attempt 46, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:03.570Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  576.455712] layer1_control_layer[2080]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  576.476837] layer1_control_layer[2080]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  576.498512] layer1_control_layer[2080]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  576.498685] layer1_control_layer[2080]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  576.498768] layer1_control_layer[2080]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  576.498849] layer1_control_layer[2080]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  576.498929] layer1_control_layer[2080]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  576.499020] layer1_control_layer[2080]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  576.499092] layer1_control_layer[2080]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  576.499162] layer1_control_layer[2080]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  576.499294] layer1_control_layer[2080]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  576.499366] layer1_control_layer[2080]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:26:03.571Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  576.499473] layer1_control_layer[2080]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  576.499853] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2369 <NL> [  576.632108] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2369 <NL> [  576.704598] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2369 <NL> [  576.704808] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2369 <NL> [  576.752867] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2369 <NL> [  576.829412] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2369 <NL> [  576.886281] layer1_hal[2103]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  576.996828] layer1_hal[2103]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [  577.008143] layer1_control_layer[2080]:    ChalApi Constructor with tid = 2372 <NL> [  588.090748] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  588.091985] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  588.119604] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.344790, delay 0.03691\\n31 Jul 08:22:40 ntpdate[3801]: no server suitable for synchronization found\\n' <NL> [  600.020982] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  600.021330] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  600.021412] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.358578, delay 0.05362\\n31 Jul 08:22:52 ntpdate[3828]: no server suitable for synchronization found\\n' <NL> [  611.845865] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  611.846251] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  611.846392] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.346970, delay 0.05205\\n31 Jul 08:23:04 ntpdate[3863]: no server suitable for synchronization found\\n' <NL> [  623.744938] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  623.745445] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  623.745544] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.350234, delay 0.02940\\n31 Jul 08:23:16 ntpdate[3896]: no server suitable for synchronization found\\n' <NL> [  635.699444] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  635.700352] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  635.700471] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.350653, delay 0.03473\\n31 Jul 08:23:28 ntpdate[3922]: no server suitable for synchronization found\\n' <NL> [  647.650377] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  647.650916] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  647.651024] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.350551, delay 0.03183\\n31 Jul 08:23:39 ntpdate[3978]: no server suitable for synchronization found\\n' <NL> [  659.532873] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  659.533131] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  659.533245] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349486, delay 0.02715\\n31 Jul 08:23:51 ntpdate[4007]: no server suitable for synchronization found\\n' <NL> [  671.417111] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  671.418700] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  671.419751] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.341610, delay 0.05302\\n31 Jul 08:24:03 ntpdate[4033]: no server suitable for synchronization found\\n' <NL> [  683.396981] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  683.397449] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:26:03.572Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "[  683.397533] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.356378, delay 0.03923\\n31 Jul 08:24:15 ntpdate[4069]: no server suitable for synchronization found\\n' <NL> [  695.314851] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  695.315582] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  695.315703] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349338, delay 0.04868\\n31 Jul 08:24:27 ntpdate[4095]: no server suitable for synchronization found\\n' <NL> [  707.338141] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  707.355649] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  707.356725] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.352102, delay 0.03836\\n31 Jul 08:24:39 ntpdate[4130]: no server suitable for synchronization found\\n' <NL> [  719.227653] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  719.253617] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  719.264796] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.349490, delay 0.02733\\n31 Jul 08:24:51 ntpdate[4170]: no server suitable for synchronization found\\n' <NL> [  731.078774] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  731.080798] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  731.144933] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.340644, delay 0.11517\\n31 Jul 08:25:03 ntpdate[4224]: no server suitable for synchronization found\\n' <NL> [  743.101289] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  743.101706] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  743.101803] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.351838, delay 0.03117\\n31 Jul 08:25:15 ntpdate[4266]: no server suitable for synchronization found\\n' <NL> [  754.919606] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  754.920192] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  754.920315] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.342649, delay 0.05788\\n31 Jul 08:25:27 ntpdate[4292]: no server suitable for synchronization found\\n' <NL> [  766.956531] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  766.957105] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  766.957267] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.356948, delay 0.04399\\n31 Jul 08:25:39 ntpdate[4328]: no server suitable for synchronization found\\n' <NL> [  778.713872] ntputils_client.py[1708]: INFO:root:command failed. <NL> [  778.714423] ntputils_client.py[1708]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  778.714529] ntputils_client.py[1708]: b'server 127.1.254.254, stratum 16, offset -0.348159, delay 0.03023\\n31 Jul 08:25:51 ntpdate[4369]: no server suitable for synchronization found\\n'"}
{"timestamp_utc": "2024-07-31T08:26:03.829Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:03 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:04.085Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:26:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:03 retry-ssh-command INFO: attempt 47, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:09.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:08 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:08 retry-ssh-command INFO: attempt 48, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:14.579Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:13 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:13 retry-ssh-command INFO: attempt 49, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:17.845Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  696.039066] python3[2135]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  696.118253] python3[2135]:     _tm.dp.connect( <NL> [  696.194913] python3[2135]: _confd.error.EOF: ConfD closed connection <NL> [  696.596271] python3[2135]: [.337] hookhdlr 140644876773184 callbackhdlr:471 Failed to run daemon main, retry 2 of -1 <NL> [  697.127598] healthcheck_result_display.py[2133]: Traceback (most recent call last): <NL> [  697.160489] healthcheck_result_display.py[2133]:   File \"/usr/bin/healthcheck_result_display.py\", line 354, in <module> <NL> [  697.390728] healthcheck_result_display.py[2133]:     main(hc_utils.setup_logging(__name__)) <NL> [  697.661676] healthcheck_result_display.py[2133]:   File \"/usr/bin/healthcheck_result_display.py\", line 328, in main <NL> [  697.945896] healthcheck_result_display.py[2133]:     hc_results_daemon = Daemon(name='hcresults', port=CONFD_PORT) <NL> [  698.138356] healthcheck_result_display.py[2133]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  698.421382] healthcheck_result_display.py[2133]:     self._init_connection() <NL> [  698.511739] healthcheck_result_display.py[2133]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  698.526832] healthcheck_result_display.py[2133]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  698.636217] healthcheck_result_display.py[2133]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  698.767316] healthcheck_result_display.py[2133]:     _tm.dp.connect( <NL> [  698.770359] healthcheck_result_display.py[2133]: _confd.error.EOF: ConfD closed connection <NL> [  698.891769] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 1 <NL> [  700.559897] rasis_system_stats.py[2142]: Traceback (most recent call last): <NL> [  700.799431] rasis_system_stats.py[2142]:   File \"/usr/bin/rasis_system_stats.py\", line 416, in <module> <NL> [  700.800615] rasis_system_stats.py[2142]:     main() <NL> [  700.912069] rasis_system_stats.py[2142]:   File \"/usr/bin/rasis_system_stats.py\", line 363, in main <NL> [  700.932895] rasis_system_stats.py[2142]:     system_stats_daemon = Daemon(name='systemstats', port=CONFD_PORT) <NL> [  701.444880] rasis_system_stats.py[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  702.056845] rasis_system_stats.py[2142]:     self._init_connection() <NL> [  702.068993] rasis_system_stats.py[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  702.129155] rasis_system_stats.py[2142]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  702.307230] rasis_system_stats.py[2142]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  702.457839] rasis_system_stats.py[2142]:     _tm.dp.connect( <NL> [  702.509638] rasis_system_stats.py[2142]: _confd.error.EOF: ConfD closed connection <NL> [  702.591731] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 2 <NL> [  702.631663] db_info.py[2123]: Traceback (most recent call last): <NL> [  702.655821] db_info.py[2123]:   File \"/usr/bin/db_info.py\", line 448, in <module> <NL> [  702.717421] db_info.py[2123]:     main() <NL> [  702.740934] db_info.py[2123]:   File \"/usr/bin/db_info.py\", line 418, in main <NL> [  702.769950] db_info.py[2123]:     database_stats_daemon = Daemon(name='db-info-oper', port=CONFD_PORT) <NL> [  702.802606] db_info.py[2123]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 377, in __init__ <NL> [  702.867983] db_info.py[2123]:     self._init_connection() <NL> [  702.912471] db_info.py[2123]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 526, in _init_connection <NL> [  703.054382] db_info.py[2123]:     self._csock = self._connect_sock(_tm.dp.CONTROL_SOCKET) <NL> [  703.220907] db_info.py[2123]:   File \"/usr/lib/python3.10/site-packages/confd/dp.py\", line 381, in _connect_sock <NL> [  703.350209] db_info.py[2123]:     _tm.dp.connect( <NL> [  703.407429] db_info.py[2123]: _confd.error.EOF: ConfD closed connection <NL> [  704.525581] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 3 <NL> [  705.673379] python3[2135]: [.352] hookhdlr 140644876773184 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  705.802734] python3[2135]: [.482] hookhdlr 140644876773184 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  705.954147] python3[2135]: [.537] hookhdlr 140644876773184 callbackhdlr:293 Loading schemas <NL> [  706.012673] python3[2135]: DEBUG item does not exist - shared memory schema not enabled <NL> [  707.534160] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 4 <NL> [  710.114197] python3[2135]: [.781] hookhdlr 140644876773184 callbackhdlr:382 Done load schemas <NL> [  710.145073] python3[2135]: [.784] hookhdlr 140644876773184 callbackhdlr:389 Done register transaction callback <NL> [  710.547330] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 5 <NL> [  713.752060] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 6 <NL> [  714.740718] python3[2135]: [.414] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb supp-if-hook"}
{"timestamp_utc": "2024-07-31T08:26:17.846Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  714.776653] python3[2135]: [.456] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb admin-status-hook <NL> [  715.465983] python3[2135]: [.145] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb ethDefaultHook <NL> [  715.534694] python3[2135]: [.214] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb autotxDefaultHook <NL> [  715.860153] python3[2135]: [.274] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb auto_tx_hook <NL> [  716.344979] python3[2135]: [.457] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb ochDefaultHook <NL> [  716.863729] python3[2135]: [.714] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb otuRateDefaultHook <NL> [  717.411773] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 7 <NL> [  717.795056] python3[2135]: [.475] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb oduDefaultHook <NL> [  718.091229] python3[2135]: [.686] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb tcmListHook <NL> [  718.761379] python3[2135]: [.441] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb ypgIntfDelHook <NL> [  718.905614] python3[2135]: [.585] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb sa-hook <NL> [  719.412406] python3[2135]: [.092] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb otsiDefaultHook <NL> [  719.446627] python3[2135]: [.126] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb subport-hook <NL> [  719.720123] txid_tracker[4183]: ::::create_confd_subscription_connection() try number 8 <NL> [  725.840054] txid_tracker[4264]: ::::create_confd_subscription_connection() connected <NL> [  730.503693] python3[2135]: [.143] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb port-capability-hook <NL> [  737.478510] python3[2135]: [.157] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb eth-port-capability-hook <NL> [  741.449834] python3[2135]: [.129] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb odu-port-capability-hook <NL> [  744.089950] python3[2135]: [.745] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb otsig-port-capability-hook <NL> [  752.995472] python3[2135]: [.675] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb otucn-port-capability-hook <NL> [  753.346159] python3[2135]: [.913] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb parent-odu-allocation-hook <NL> [  753.446217] python3[2135]: [.983] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb max-session-hook <NL> [  753.632134] python3[2135]: [.106] hookhdlr 140644876773184 callbackhdlr:252 Done register callpoint cb restconf-services-hook <NL> [  753.680855] python3[2135]: [.210] hookhdlr 140644876773184 callbackhdlr:391 Done register data callbacks <NL> [  802.906941] confd_mgr[3031]: confd_at_common::start_confd_phase0: Invoking /usr/bin/confd_post_phase0_cb.sh"}
{"timestamp_utc": "2024-07-31T08:26:18.775Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:18 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:19.031Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:26:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:18 retry-ssh-command INFO: attempt 50, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:24.290Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:26:24.291Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:23 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:23 retry-ssh-command INFO: attempt 51, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:27.561Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  803.013643] confd_mgr[4481]: Execute confd_post_phase0_cb.sh - Wed Jul 31 08:26:16 UTC 2024 <NL> [  803.128546] confd_mgr[4481]: Starting valhdlr.service <NL> [  803.287148] confd_mgr[4481]: Starting validation-handler.service <NL> [  803.342117] confd_mgr[4481]: Starting snmp-fss-fw.service <NL> [  803.635078] confd_mgr[3031]: leaving: sm_startconfd::start_confd_p0 <NL> [  803.959156] confd_mgr[3031]: entering: sm_startconfd::wait_for_p0 <NL> [  804.026735] confd_mgr[3031]: PROCESS1 has not registered yet. <NL> [  804.252471] confd_mgr[3031]: PROCESS_SNMP_CLID has not registered yet. <NL> [  804.350542] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  804.361446] confd_mgr[3031]: ConfdMgrConf::reload: DB signature set to false <NL> [  804.378121] confd_mgr[3031]: Start_type: GO_ACTIVE (STANDALONE/WORK) <NL> [  804.402073] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,FALSE <NL> [  804.443196] python3[2135]: DEBUG No crypto keys configured <NL> [  804.470152] python3[2135]: [.121] hookhdlr 140644876773184 callbackhdlr:401 Unable to install crypto keys! <NL> [  804.481606] python3[2135]: [.186] hookhdlr 140644876773184 callbackhdlr:322 Started data handler daemon... <NL> [  804.597193] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  804.658249] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  804.705543] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE1 <NL> [  804.763488] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  804.823652] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  804.898283] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  804.986495] confd_mgr[3031]: ConfdHA Not supported command CONFIRM <NL> [  804.987316] confd_mgr[3031]: sm_startconfd::p0_ready_dbc <NL> [  805.047828] confd_mgr[3031]: Find message MESSAGE1 <NL> [  805.094509] confd_mgr[3031]: PROCESS_SNMP_CLID has not registered yet. <NL> [  805.182347] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  805.184695] confd_mgr[3031]: sm_startconfd::p0_not_ready <NL> [  805.199071] confd_mgr[3031]: Find message MESSAGE1 <NL> [  805.305116] confd_mgr[3031]: PROCESS_SNMP_CLID has not registered yet. <NL> [  805.431689] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  805.564911] confd_mgr[3031]: leaving: sm_startconfd::wait_for_p0 <NL> [  805.585848] confd_mgr[3031]: entering: sm_startconfd::wait_for_p0 <NL> [  805.725484] confd_mgr[3031]: PROCESS_SNMP_CLID has not registered yet. <NL> [  805.954539] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  805.955700] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  806.271784] confd_mgr[3031]: Timer /ConfdAT|wait_for_p0 already created <NL> [  806.288814] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  806.309916] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  807.173525] python3[4489]: [.852] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  807.367472] python3[4489]: [.898] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  807.368864] python3[4489]: [.909] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  807.490858] python3[4489]: [.910] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  807.607648] python3[4489]: [.910] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  807.839648] python3[4489]: [.910] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  808.094448] python3[4489]: [.915] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  808.112824] python3[4489]: [.915] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  808.180653] python3[4489]: [.915] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  808.678971] python3[4489]: [.916] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  809.347697] python3[4489]: [.002] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  809.504901] python3[4489]: [.002] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  809.588408] python3[4489]: [.002] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  809.684587] python3[4489]: [.002] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  809.717706] python3[4489]: [.002] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  809.870816] python3[4489]: [.002] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  809.938918] python3[4489]: [.003] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  810.268143] python3[4489]: [.003] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  810.421459] python3[4489]: [.004] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  810.728153] python3[4489]: [.004] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  811.080969] python3[4489]: [.004] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  811.193041] python3[4489]: [.107] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  811.314635] python3[4489]: [.108] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'}"}
{"timestamp_utc": "2024-07-31T08:26:27.562Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  811.322163] python3[4489]: [.108] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  811.329986] python3[4489]: [.109] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  811.386546] python3[4489]: [.109] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  811.510222] python3[4489]: [.109] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  811.592389] python3[4489]: [.109] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  811.648040] python3[4489]: [.137] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  811.683166] python3[4489]: [.147] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  811.718548] python3[4489]: [.280] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  811.775546] python3[4489]: [.280] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  811.777443] python3[4489]: [.280] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  811.808779] python3[4489]: [.281] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  811.810390] python3[4489]: [.310] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  811.882413] python3[4489]: [.311] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  811.934856] python3[4489]: [.311] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  812.003264] python3[4489]: [.311] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  812.232551] python3[4489]: [.311] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  812.696910] python3[4489]: [.311] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'}"}
{"timestamp_utc": "2024-07-31T08:26:28.931Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:28 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:29.225Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:26:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:28 retry-ssh-command INFO: attempt 52, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:34.500Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:33 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:34 retry-ssh-command INFO: attempt 53, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:39.754Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:38 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:39 retry-ssh-command INFO: attempt 54, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:43.927Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:43 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:44.185Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:26:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:44 retry-ssh-command INFO: attempt 55, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:49.437Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:48 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:49 retry-ssh-command INFO: attempt 56, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:54.684Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:53 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:54 retry-ssh-command INFO: attempt 57, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:26:59.939Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:26:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:58 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:26:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:26:59 retry-ssh-command INFO: attempt 58, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:04.114Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:03 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:27:04.371Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:04 retry-ssh-command INFO: attempt 59, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:05.407Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  812.830973] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  812.919556] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  812.981505] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  813.073449] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  813.195499] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  813.312267] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientportratecomb'} <NL> [  813.588067] python3[4489]: [.326] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrpairvalues'} <NL> [  814.341658] systemd-journald[325]: Data hash table of /run/log/journal/4918541f0c414dc3ac4876918905f3f5/system.journal has a fill level at 75.0 (13654 of 18204 items, 8388608 file size, 614 bytes per hash table item), suggesting rotation. <NL> [  814.432889] systemd-journald[325]: /run/log/journal/4918541f0c414dc3ac4876918905f3f5/system.journal: Journal header limits reached or header out-of-date, rotating. <NL> [  814.696960] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_odu.valnwodupt'} <NL> [  816.168267] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valfreq'} <NL> [  816.467642] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valclientpeertype'} <NL> [  816.495827] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  816.682151] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1_ypg.valypgattr'} <NL> [  816.921471] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valintfportcapability'} <NL> [  817.009857] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valeqptportcapability'} <NL> [  817.777085] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  817.778390] python3[4489]: [.327] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valprofileid'} <NL> [  817.779680] python3[4489]: [.328] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_capability_profile.valnwframetype'} <NL> [  817.979061] python3[4489]: [.328] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valpluggdata'} <NL> [  817.980314] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valiftype'} <NL> [  818.279199] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valshelfmode'} <NL> [  818.291425] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valadminstat'} <NL> [  818.313379] snmp_clid[4496]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [  818.314778] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valautotx'} <NL> [  818.486914] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valpmthreshold'} <NL> [  818.515651] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_layer1.valattrdependency'} <NL> [  818.551882] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:202 xml module {'name': 'py_cmn_base.valportadminstat'} <NL> [  818.682931] python3[4489]: [.498] valhdlr 139998162696000 callbackhdlr:265 Connecting to 127.0.0.1:4000 <NL> [  819.003585] python3[4489]: [.703] valhdlr 139998162696000 callbackhdlr:275 Connected to 127.0.0.1:4000 <NL> [  819.112279] python3[4489]: [.703] valhdlr 139998162696000 callbackhdlr:293 Loading schemas <NL> [  819.137961] python3[4489]: DEBUG item does not exist - shared memory schema not enabled <NL> [  819.154415] python3[4489]: [.438] valhdlr 139998162696000 callbackhdlr:382 Done load schemas <NL> [  819.165886] python3[4489]: [.439] valhdlr 139998162696000 callbackhdlr:389 Done register transaction callback <NL> [  819.464953] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  819.627497] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  819.657553] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,SNMP_CLID_CONFIRM <NL> [  819.707757] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  819.761743] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  819.810353] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  819.890908] confd_mgr[3031]: ConfdHA Not supported command CONFIRM <NL> [  820.052344] confd_mgr[3031]: sm_startconfd::p0_ready_dbc <NL> [  820.155710] confd_mgr[3031]: Find message SNMP_CLID_CONFIRM <NL> [  820.160177] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  820.179189] confd_mgr[3031]: sm_startconfd::p0_not_ready <NL> [  820.515484] confd_mgr[3031]: Find message SNMP_CLID_CONFIRM <NL> [  820.675580] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  820.818923] confd_mgr[3031]: leaving: sm_startconfd::wait_for_p0 <NL> [  821.006907] confd_mgr[3031]: entering: sm_startconfd::wait_for_p0 <NL> [  821.086599] confd_mgr[3031]: PROCESS_VALHDLR has not registered yet. <NL> [  821.320470] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  821.583898] confd_mgr[3031]: Timer /ConfdAT|wait_for_p0 already created <NL> [  821.584726] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  821.585735] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  822.041926] snmp_clid[4542]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  822.554562] python3[4489]: [.112] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb if-type-validation <NL> [  822.771267] python3[4489]: [.798] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb equipment_shelf_mode_validation <NL> [  823.013031] python3[4489]: [.961] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb admin_status_validation <NL> [  823.062283] python3[4489]: [.276] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb auto_tx_validation <NL> [  839.506885] python3[4489]: [.160] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb pm_threshold_validation <NL> [  839.606360] python3[4489]: [.266] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb och_eth_client_port_rate_validation <NL> [  839.624750] python3[4489]: [.304] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb frequency_validation <NL> [  840.145549] python3[4489]: [.825] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb attribute_dependency_validation <NL> [  840.312103] python3[4489]: [.992] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb ypg_attr_validation <NL> [  840.373843] python3[4489]: [.054] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb port_admin_status <NL> [  840.493209] python3[4489]: [.161] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb attrib_pair_validation <NL> [  840.646779] python3[4489]: [.308] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb odu_nw_pt_validation <NL> [  840.912712] python3[4489]: [.462] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb client_port_interfaces_validation"}
{"timestamp_utc": "2024-07-31T08:27:05.408Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  844.981726] python3[4489]: [.651] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb intf_port_capability_validation <NL> [  847.438708] python3[4489]: [.054] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb port_capability_validation"}
{"timestamp_utc": "2024-07-31T08:27:09.584Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:08 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:09 retry-ssh-command INFO: attempt 60, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:14.875Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:13 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:14 retry-ssh-command INFO: attempt 61, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:19.123Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:19 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:19.379Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:19 retry-ssh-command INFO: attempt 62, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:24.627Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:24 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:24 retry-ssh-command INFO: attempt 63, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:29.877Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:29 retry-ssh-command INFO: attempt 64, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:29 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:35.125Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:34 retry-ssh-command INFO: attempt 65, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:34 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:39.295Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:39 retry-ssh-command INFO: attempt 66, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:39.553Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:39 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:44.805Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:44 retry-ssh-command INFO: attempt 67, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:44 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:50.051Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:49 retry-ssh-command INFO: attempt 68, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:49 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:55.301Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:54 retry-ssh-command INFO: attempt 69, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:27:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:54 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:59.474Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:27:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:59 retry-ssh-command INFO: attempt 70, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:27:59.730Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:27:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:27:59 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:04.988Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:04 retry-ssh-command INFO: attempt 71, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:04 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:10.301Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:09 retry-ssh-command INFO: attempt 72, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:09 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:14.501Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:14 retry-ssh-command INFO: attempt 73, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:14.758Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:14 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:20.062Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:19 retry-ssh-command INFO: attempt 74, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:19 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:25.311Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:24 retry-ssh-command INFO: attempt 75, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:24 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:30.562Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:29 retry-ssh-command INFO: attempt 76, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:29 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:34.771Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:34 retry-ssh-command INFO: attempt 77, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:34 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:40.019Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:39 retry-ssh-command INFO: attempt 78, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:39 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:45.270Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:44 retry-ssh-command INFO: attempt 79, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:44 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:50.622Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:49 retry-ssh-command INFO: attempt 80, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',) <NL> # 03:28:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:28:50.623Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:49 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:54.797Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:54 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:28:55.062Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:28:55 retry-ssh-command INFO: attempt 81, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:00.320Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:28:59 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:28:59 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:00 retry-ssh-command INFO: attempt 82, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:04.496Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  756.623612] python3[4329]: [.225] valhdlr 140296396851008 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  756.635411] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  756.649589] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  756.712847] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  756.762275] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  756.764281] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  756.765483] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  756.831162] confd_mgr[2516]: ConfdHA Not supported command CONFIRM <NL> [  756.884765] confd_mgr[2516]: sm_startconfd::p0_ready_dbc <NL> [  756.933491] confd_mgr[2516]: Find message VALHDLR_CONFIRM <NL> [  757.033209] confd_mgr[2516]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  757.502474] confd_mgr[2516]: sm_startconfd::p0_not_ready <NL> [  757.725269] confd_mgr[2516]: Find message VALHDLR_CONFIRM <NL> [  757.821301] confd_mgr[2516]: sm_startconfd::p0_ready_no_dbc <NL> [  757.944636] confd_mgr[2516]: Find message VALHDLR_CONFIRM <NL> [  758.082071] confd_mgr[2516]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  758.220409] confd_mgr[2516]: leaving: sm_startconfd::wait_for_p0 <NL> [  758.347452] confd_mgr[2516]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  758.521317] confd_mgr[2516]: entering: sm_startconfd::start_confd_p1 <NL> [  758.594812] confd_mgr[2516]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  758.949685] confd_mgr[4474]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:25:32 UTC 2024 <NL> [  759.008919] confd_mgr[4486]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  759.262327] confd_mgr[2516]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  832.884602] txid_tracker[4217]: ::::create_confd_subscription_connection() connected <NL> [  839.454577] confd_mgr[2516]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  839.637493] confd_mgr[4768]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:26:55 UTC 2024 <NL> [  840.233786] confd_mgr[4768]: Invoking confd_load_upgrade_xml.py <NL> [  843.554282] confd_mgr[4777]: confd_load_upgrade_xml.py: Start <NL> [  843.555300] confd_mgr[4777]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  844.023821] confd_mgr[2516]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  844.265235] confd_mgr[4800]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  844.551358] confd_mgr[2516]: CONFD IN PHASE 1 <NL> [  844.687202] confd_mgr[2516]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  844.903816] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  844.929288] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  844.978770] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  844.982200] confd_mgr[2516]: leaving: sm_startconfd::start_confd_p1 <NL> [  845.146660] confd_mgr[2516]: entering: sm_startconfd::wait_for_p1 <NL> [  845.178965] confd_mgr[2516]: PROCESS3 has not registered yet. <NL> [  845.268626] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  845.355957] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  845.410834] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  845.499192] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  845.596337] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  845.684571] confd_mgr[2516]: ConfdHA Not supported command CONFIRM <NL> [  845.762554] confd_mgr[2516]: sm_startconfd::p1_not_ready <NL> [  845.795652] confd_mgr[2516]: Find message MESSAGE3 <NL> [  845.847806] confd_mgr[2516]: sm_startconfd::p1_ready <NL> [  845.922609] confd_mgr[2516]: Find message MESSAGE3 <NL> [  845.975671] confd_mgr[2516]: leaving: sm_startconfd::wait_for_p1 <NL> [  846.024756] confd_mgr[2516]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  846.217835] confd_mgr[2516]: entering: sm_startconfd::wait_for_rm <NL> [  846.267966] confd_mgr[2516]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  846.434132] confd_mgr[2516]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  846.460848] python3[4472]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE"}
{"timestamp_utc": "2024-07-31T08:29:04.497Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  846.546435] confd_mgr[4810]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:27:01 UTC 2024 <NL> [  846.690154] confd_mgr[4828]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  846.787833] confd_mgr[4831]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  846.913986] confd_mgr[2516]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  847.090297] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  847.171454] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  847.453998] confd_mgr[4855]: /usr/bin/replay_manager NONE <NL> [  847.600493] confd_mgr[4848]: redundancy_status is STANDALONE <NL> [  847.841865] confd_mgr[4848]: DDS ports will be opened. <NL> [  847.945654] confd_mgr[4848]: execute replay_manager NONE TRUE <NL> [  848.645467] confd_mgr[4861]: TRACE Connected (cdb) to ConfD <NL> [  848.748296] confd_mgr[4861]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  848.815813] confd_mgr[4861]: TRACE Connected (cdb) to ConfD <NL> [  848.816795] confd_mgr[4861]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  853.997172] confd_mgr[4861]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  854.135078] txid_tracker[4217]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  854.182388] confd_mgr[4861]: TRACE CDB_TRIGGER_SUBS <NL> [  854.225121] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  854.283355] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  854.420771] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  854.603211] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  854.811632] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  855.003708] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  855.112018] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  855.149396] confd_mgr[2516]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  855.152120] txid_tracker[4893]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  907.042344] systemd-sysv-generator[5040]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  912.534578] systemd-sysv-generator[5067]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [  951.922533] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  951.951083] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  951.963469] ntputils[1724]: child pid is 5153 <NL> [  951.970194] ntputils[1724]: exited, status is 0 <NL> [  951.997239] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  952.017986] ntputils[1724]: poller time change delta is: 1 <NL> [  952.029194] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  952.048466] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  952.173532] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  952.174756] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  952.175710] ntputils[1724]: push_local_changes OK <NL> [  965.754724] userddssub[5215]: useradd: user 'fujitsu' already exists <NL> [  966.034705] dcn_dns_controller[1387]: fin_file is open"}
{"timestamp_utc": "2024-07-31T08:29:05.061Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:04 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:04 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:05 retry-ssh-command INFO: attempt 83, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:10.315Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:09 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:10 retry-ssh-command INFO: attempt 84, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:15.578Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:14 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:14 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:15 retry-ssh-command INFO: attempt 85, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:20.879Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:19 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:19 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:20 retry-ssh-command INFO: attempt 86, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:25.049Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:24 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:24 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:25.304Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:25 retry-ssh-command INFO: attempt 87, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:25.561Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  966.436629] userddssub[2257]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [  968.621235] dcn_dns_controller[1387]: fin_file is open <NL> [  969.700513] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  970.305138] ntputils[1724]: bool NTPServer::handle_configure_cmd(const string&) <NL> [  970.613754] ntputils[1724]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  970.826672] ntputils[1724]: parse_time_persistent_topic ddskind create <NL> [  970.897333] ntputils[1724]: parse_time_persistent_topic name key config <NL> [  971.166761] ntputils[1724]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [  971.167780] ntputils[1724]: parse_time_topics command_data enable=yes; <NL> [  971.168561] ntputils[1724]: handle_configure_cmd token is: enable=yes <NL> [  971.169357] ntputils[1724]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [  971.655886] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  971.816097] ntputils[1724]: systemctl --no-block stop ntpd <NL> [  972.303715] ntputils[1724]: child pid is 5264 <NL> [  972.330934] ntputils[1724]: exited, status is 0 <NL> [  972.349547] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  972.375665] ntputils[1724]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [  972.392948] ntputils[1724]: child pid is 5291 <NL> [  972.405383] ntputils[1724]: exited, status is 0 <NL> [  972.427910] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  972.460433] ntputils[1724]: /bin/systemctl reset-failed ntpd"}
{"timestamp_utc": "2024-07-31T08:29:25.562Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  972.483435] ntputils[1724]: child pid is 5326 <NL> [  972.597868] ntputils[1724]: exited, status is 0 <NL> [  972.609898] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  972.619458] ntputils[1724]: systemctl --no-block start ntpd <NL> [  972.620216] ntputils[1724]: child pid is 5340 <NL> [  972.632857] ntputils[1724]: exited, status is 0 <NL> [  972.640216] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  972.646855] ntputils[1724]: systemctl --no-block start ntpscript <NL> [  972.661993] ntputils[1724]: child pid is 5355 <NL> [  972.671709] ntputils[1724]: exited, status is 0 <NL> [  972.677719] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  972.687363] ntputils[1724]: /bin/systemctl --no-block start init_state_check.timer <NL> [  972.697614] ntputils[1724]: child pid is 5363 <NL> [  972.703823] ntputils[1724]: exited, status is 0 <NL> [  972.711185] ntputils[1724]: Configure command handled successfully, writing to RTC <NL> [  972.712201] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  972.729387] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  972.739169] ntputils[1724]: child pid is 5371 <NL> [  972.903187] ntputils[1724]: exited, status is 0 <NL> [  972.938972] ntputils[1724]: bool NTPServer::handle_command(const string&) <NL> [  973.043885] ntputils[1724]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [  973.177458] ntputils[1724]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [  973.198935] ntputils[1724]: parse_time_persistent_topic ddskind create <NL> [  973.212219] ntputils[1724]: parse_time_persistent_topic name key setTZ <NL> [  973.215937] ntputils[1724]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [  973.334186] ntputils[1724]: parse_time_topics command_data timezone=UTC; <NL> [  973.350929] ntputils[1724]: bool NTPServer::set_timezone(const string&) <NL> [  973.391365] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  973.392268] ntputils[1724]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [  973.393116] ntputils[1724]: child pid is 5376 <NL> [  973.395208] ntputils[1724]: exited, status is 0 <NL> [  973.395937] ntputils[1724]: set new timezone: /usr/share/zoneinfo/UTC <NL> [  973.396886] ntputils[1724]: push_local_changes user_changed: 1 delta: 0 <NL> [  973.589871] ntputils[1724]: local_push OK u Platform::Time changedByUser 1 <NL> [  973.598497] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [  973.655606] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  973.657353] ntputils[1724]: push_local_changes OK <NL> [  973.785361] ntputils[1724]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [  973.794531] ntputils[1724]: publish_local_changes OK <NL> [  974.493879] confd_mgr[4861]:  --> CONFD_OK <NL> [  976.530080] confd_mgr[5457]: openDdsPorts interfaces  eth5.2003 <NL> [  977.097144] confd_mgr[5457]: openDdsPorts Input udpPorts-  7660 <NL> [  977.140664] cia_control_layer[5461]: grep: product_systemData.xml: No such file or directory <NL> [  977.189088] confd_mgr[5457]: openDdsPorts Output udpPorts-  7660 <NL> [  977.329597] confd_mgr[5457]: openDdsPorts Input udpPorts-  7661 <NL> [  977.821782] confd_mgr[5457]: openDdsPorts Output udpPorts-  7661 <NL> [  978.071576] confd_mgr[5457]: openDdsPorts Input udpPorts-  7650 <NL> [  978.235644] confd_mgr[5457]: openDdsPorts Output udpPorts-  7650 <NL> [  978.246680] confd_mgr[5457]: openDdsPorts Input udpPorts-  7651 <NL> [  978.248272] confd_mgr[5457]: openDdsPorts Output udpPorts-  7651 <NL> [  978.350470] confd_mgr[5457]: openDdsPorts Input udpPorts-  7900 <NL> [  978.401098] confd_mgr[5457]: openDdsPorts Output udpPorts-  7900 <NL> [  978.570491] confd_mgr[5457]: openDdsPorts Input udpPorts-  7901 <NL> [  978.597233] confd_mgr[5457]: openDdsPorts Output udpPorts-  7901 <NL> [  978.927431] confd_mgr[5457]: openDdsPorts Input udpPorts-  7910 <NL> [  979.064749] confd_mgr[5457]: openDdsPorts Output udpPorts-  7910 <NL> [  979.085743] confd_mgr[5457]: openDdsPorts Input udpPorts-  7911 <NL> [  979.099300] confd_mgr[5457]: openDdsPorts Output udpPorts-  7911 <NL> [  979.863233] confd_mgr[5457]: openDdsPorts Input udpPorts-  8150 <NL> [  980.536594] confd_mgr[5457]: openDdsPorts Output udpPorts-  8150 <NL> [  980.618554] cia_control_layer[2227]:    ChalApi Constructor with tid = 3124 <NL> [  980.690688] cia_control_layer[2227]: EsalConfig::EsalConfig main 1 <NL> [  980.811128] cia_control_layer[2227]: EsalConfig::EsalConfig trib 0 <NL> [  980.905094] cia_control_layer[2227]: EsalConfig::EsalConfig ciRole 0 <NL> [  980.927380] ntp_alarm_event_monitor.py[5362]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [  980.973541] ntp_alarm_event_monitor.py[5362]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [  982.022440] confd_mgr[5457]: openDdsPorts Input udpPorts-  8151 <NL> [  982.322561] confd_mgr[5457]: openDdsPorts Output udpPorts-  8151 <NL> [  983.707078] confd_mgr[5457]: openDdsPorts Input udpPorts-  8160 <NL> [  983.746635] confd_mgr[5457]: openDdsPorts Output udpPorts-  8160 <NL> [  983.877066] cia_control_layer[2227]: EsalConfig is not running inside container. <NL> [  984.188414] cia_control_layer[2227]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  984.255046] cia_control_layer[2227]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  984.817813] cia_control_layer[2227]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  985.408332] cia_control_layer[2227]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [  986.607257] cia_control_layer[2227]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  987.554536] cia_control_layer[2227]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [  987.592168] cia_control_layer[2227]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [  987.611095] cia_control_layer[2227]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [  987.613365] cia_control_layer[2227]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [  987.651941] cia_control_layer[2227]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [  987.659591] cia_control_layer[2227]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [  987.741802] cia_control_layer[2227]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [  987.887307] cia_control_layer[2227]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [  987.956121] cia_control_layer[2227]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [  988.123084] cia_control_layer[2227]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [  988.154202] cia_control_layer[2227]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf"}
{"timestamp_utc": "2024-07-31T08:29:30.835Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:29 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:29 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:30 retry-ssh-command INFO: attempt 88, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:35.015Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:34 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:34 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:35.272Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:35 retry-ssh-command INFO: attempt 89, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:40.527Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:39 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:39 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:40 retry-ssh-command INFO: attempt 90, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:45.777Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:44 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:44 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:45 retry-ssh-command INFO: attempt 91, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:50.006Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:49 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:49 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:50.263Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:50 retry-ssh-command INFO: attempt 92, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:29:55.638Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:29:54 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:29:54 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',) <NL> # 03:29:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:29:57.006Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "openDdsPorts Output udpPorts-  7900 <NL> openDdsPorts Input udpPorts-  7901 <NL> openDdsPorts Output udpPorts-  7901 <NL> 2024-07-31 08:19:11,143 swdllite(agt): INFO - fsm.log[314] LOGFSM: entry -> READY_STATE -> ready_entry_fn <NL> openDdsPorts Input udpPorts-  7910 <NL> openDdsPorts Output udpPorts-  7910 <NL> openDdsPorts Input udpPorts-  7911 <NL> openDdsPorts Output udpPorts-  7911 <NL> openDdsPorts Input udpPorts-  8150 <NL> openDdsPorts Output udpPorts-  8150 <NL> openDdsPorts Input udpPorts-  8151 <NL> openDdsPorts Output udpPorts-  8151 <NL> openDdsPorts Input udpPorts-  8160 <NL> openDdsPorts Output udpPorts-  8160 <NL> openDdsPorts Input udpPorts-  8161 <NL> openDdsPorts Output udpPorts-  8161 <NL> 2024-07-31 08:19:11,420 swdllite(int): INFO - swdl_dds_port_control.dds_port_control[92] /usr/bin/iptable_ports.sh dds_port_control enable returned status: 0 <NL> 2024-07-31 08:19:11,421 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> DISABLED_STATE -> ENABLE_PENDING_STATE <NL> 2024-07-31 08:19:11,495 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLE_PENDING_STATE -> start_dds_port_timer"}
{"timestamp_utc": "2024-07-31T08:29:57.007Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "INFO:root:Running confd_mgr_swdl_ready.py <NL> DEBUG:root:Arguments received from SWDL: {'mode': 'NORMAL', 'alarm': 'NONE', 'status': 'SUCCESS', 'wait': 'UNKNOWN', 'additional_info': '', 'rdm_status': 'STANDALONE'} <NL> Executing confd_mgr_rdm_status.sh STANDALONE <NL> STANDALONE <NL> ======= Changing UNKNOWN redMode ========= <NL> 2024-07-31 08:19:17,539 swdllite(int): INFO - fsm.log[312] DDS-PORTS: ENABLE_EVT -> ENABLE_PENDING_STATE -> ENABLED_STATE <NL> 2024-07-31 08:19:17,539 swdllite(int): INFO - fsm.log[314] DDS-PORTS: entry -> ENABLED_STATE -> dds_enable_entry_fn <NL> [  388.735739] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  388.736387] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  388.736484] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.033534, delay 0.03719\\n31 Jul 08:19:22 ntpdate[2994]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> HA_MODE=NONE, MAIN_TRIB_RED=FALSE <NL> grep: /var/shared/confd/ResetType: No such file or directory <NL> Skipping enable/disable confd - not needed for HA_MODE NONE, chassis_type FALSE, MAIN_TRIB_RED FALSE <NL> /run/rdm_status.sh created successfully <NL> ERROR:root:confd_mgr_rdm_status did not successfully execute <NL> INFO:root:/tmp/sdbhost.txt is not available <NL> INFO:root:Secondary Host ip address is 0.0.0.0 <NL> DEBUG:root:Command generated to send to confd_mgr: /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> INFO:root:Sending /usr/bin/confd_mgr_cmd -o REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 to confd_mgr <NL> [  400.743318] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  400.744660] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  400.786558] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.040256, delay 0.03806\\n31 Jul 08:19:34 ntpdate[3023]: no server suitable for synchronization found\\n' <NL> [  413.338412] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  413.339168] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  413.339271] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.048136, delay 0.06079\\n31 Jul 08:19:47 ntpdate[3053]: no server suitable for synchronization found\\n' <NL> Exception: Connect failed <NL> INFO:root:Confd_mgr not available yet, creating /run/swdl_ready.sh <NL> INFO:root:Generating /run/swdl_ready.sh <NL> 2024-07-31 08:19:54,729 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  425.309580] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  425.334051] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  425.334196] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.040776, delay 0.06804\\n31 Jul 08:19:59 ntpdate[3099]: no server suitable for synchronization found\\n' <NL> [  437.663443] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  437.663912] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  437.663996] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.036642, delay 0.12851\\n31 Jul 08:20:11 ntpdate[3138]: no server suitable for synchronization found\\n' <NL> [  449.755148] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  449.755731] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  449.755827] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.038778, delay 0.03705\\n31 Jul 08:20:23 ntpdate[3180]: no server suitable for synchronization found\\n' <NL> [  461.605629] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  461.606372] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  461.606498] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.035732, delay 0.03412\\n31 Jul 08:20:35 ntpdate[3222]: no server suitable for synchronization found\\n' <NL> [  473.619570] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  473.627839] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  473.628913] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.033988, delay 0.03073\\n31 Jul 08:20:47 ntpdate[3249]: no server suitable for synchronization found\\n' <NL> [  485.436129] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  485.464279] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  485.503030] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.034226, delay 0.03087\\n31 Jul 08:20:59 ntpdate[3282]: no server suitable for synchronization found\\n' <NL> [  497.324103] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  497.344713] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  497.350214] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.046548, delay 0.05811\\n31 Jul 08:21:11 ntpdate[3337]: no server suitable for synchronization found\\n' <NL> [  978.624548] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  978.625048] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  978.625140] ntputils_client.py[1717]: b'31 Jul 08:29:12 ntpdate[4881]: no server suitable for synchronization found\\n' <NL> [  978.706285] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  978.706493] ntputils_client.py[1717]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [  978.706573] ntputils_client.py[1717]: b'31 Jul 08:29:12 ntpdate[4899]: the NTP socket is in use, exiting\\n' <NL> [  994.775601] ntputils_client.py[1717]: INFO:root:command failed. <NL> [  994.775814] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  994.775950] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset -0.004178, delay 0.02650\\n31 Jul 08:29:28 ntpdate[4974]: no server suitable for synchronization found\\n' <NL> [ 1006.686963] ntputils_client.py[1717]: INFO:root:command failed. <NL> [ 1006.703520] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1006.703636] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset -0.001646, delay 0.03123\\n31 Jul 08:29:40 ntpdate[5014]: no server suitable for synchronization found\\n' <NL> [ 1021.061252] confd_director.py[5164]: mkdir: cannot create directory '/var/shared/confd': File exists <NL> [ 1021.508193] ntputils_client.py[1717]: INFO:root:command failed. <NL> [ 1021.508717] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1021.520315] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset -0.008191, delay 0.04933\\n31 Jul 08:29:55 ntpdate[5105]: no server suitable for synchronization found\\n' <NL> [ 1021.525296] confd_mgr[5168]: ConfdMgrConf: DB signature is NOT supported <NL> [ 1021.626749] confd_mgr[5168]: Read reset type failed basic_ios::clear: iostream error <NL> [ 1021.626909] confd_mgr[5168]: Use reset_type = NONE    rollback_timer = 000000 <NL> [ 1021.872299] confd_mgr[5168]: main:: Creating ResetType file. Writes NONE/000000"}
{"timestamp_utc": "2024-07-31T08:29:57.264Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:29:57 retry-ssh-command INFO: attempt 93, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:00.586Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:00 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:02.559Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:02 retry-ssh-command INFO: attempt 94, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:05.084Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:05 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:07.668Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:07 retry-ssh-command INFO: attempt 95, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:10.191Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[  988.164591] cia_control_layer[2227]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [  988.480908] ntp_alarm_event_monitor.py[5362]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [  988.482374] ntp_alarm_event_monitor.py[5362]: INFO:root:redundancy status now set to standalone <NL> [  988.707451] ntp_alarm_event_monitor.py[5362]: INFO:root:Publish Alarm: Raising alarm <NL> [  988.760212] ntp_alarm_event_monitor.py[5362]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [  989.620927] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  989.638167] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  989.647381] ntputils[1724]: child pid is 5523 <NL> [  989.696670] ntputils[1724]: exited, status is 0 <NL> [  989.861759] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  990.397764] ntputils[1724]: poller time change delta is: 1 <NL> [  990.812876] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  991.343522] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  991.799301] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  992.444677] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  992.995760] ntputils[1724]: push_local_changes OK <NL> [  993.194891] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  993.690283] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  994.075717] ntputils[1724]: child pid is 5538 <NL> [  994.544707] ntputils[1724]: exited, status is 0 <NL> [  994.699370] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  995.026360] ntputils[1724]: poller time change delta is: 1 <NL> [  995.033977] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  995.035989] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  995.037956] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  995.045333] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  995.054292] ntputils[1724]: push_local_changes OK <NL> [  995.063070] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [  995.173216] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [  995.339206] ntputils[1724]: child pid is 5555 <NL> [  995.341473] ntputils[1724]: exited, status is 0 <NL> [  995.400710] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [  995.496343] ntputils[1724]: poller time change delta is: 1 <NL> [  995.788713] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [  996.134869] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [  996.357608] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [  996.422348] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [  996.462645] ntputils[1724]: push_local_changes OK <NL> [  996.526881] confd_mgr[5457]: openDdsPorts Input udpPorts-  8161 <NL> [  996.720372] confd_mgr[5457]: openDdsPorts Output udpPorts-  8161 <NL> [  997.284513] confd_mgr[4861]: TRACE Connected (ha) to ConfD <NL> [  997.291438] confd_mgr[4861]: replay_manager: Purge file needs to be erased at replay-mgr startup. <NL> [  997.295954] confd_mgr[4861]: replay_manager:  Start-Wed Jul 31 08:27:04 2024 <NL> [  997.478269] confd_mgr[4861]:  ++++++++++++++++++++++ <NL> [  998.108774] confd_mgr[4861]: replay_manager: TXID NOT FOUND ================================== <NL> [  999.001148] confd_mgr[4861]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [  999.305541] confd_mgr[4861]: replay_manager: Need to do trigger full replay. <NL> [  999.306992] confd_mgr[4861]: replay_manager: Creating the purge file. <NL> [  999.308748] confd_mgr[4861]: replay_manager: Open DDS Ports <NL> [  999.368896] confd_mgr[4861]: replay_manager: NOW deleting the purge file. <NL> [  999.387990] confd_mgr[4861]: replay_manager:  End-Wed Jul 31 08:29:18 2024 <NL> [  999.388909] confd_mgr[4861]:  ++++++++++++++++++++++ <NL> [  999.389575] confd_mgr[4861]: 1+1 Mode <NL> [  999.390182] confd_mgr[4861]: Not in Slave Mode - Ready for Phase 2 ========== <NL> [  999.499549] confd_mgr[4861]: DipLog_pimpl destructor called <NL> [  999.501227] confd_mgr[4861]: DipVerbosity Listener ZMQ error <NL> [  999.519328] confd_mgr[4861]:     ret='Context was terminated <NL> [  999.533333] confd_mgr[4861]: deleting subscriber_ socket <NL> [  999.553365] confd_mgr[4861]: Exiting verb listener <NL> [  999.696319] confd_mgr[2516]: CommAT::asio_subscriber: Connection accepted <NL> [  999.782481] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [  999.854576] confd_mgr[2516]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [ 1000.043418] confd_mgr[2516]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1000.176630] confd_mgr[2516]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1000.203844] confd_mgr[2516]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1000.204670] confd_mgr[2516]: ConfdHA Not supported command CONFIRM <NL> [ 1000.205424] confd_mgr[2516]: sm_startconfd::rm_ready <NL> [ 1000.460302] confd_mgr[2516]: leaving: sm_startconfd::wait_for_rm <NL> [ 1000.461155] confd_mgr[2516]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [ 1000.462233] confd_mgr[2516]: entering: sm_startconfd::start_confd_p2 <NL> [ 1000.463051] confd_mgr[2516]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [ 1000.562275] confd_mgr[5540]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:29:22 UTC 2024 <NL> [ 1000.912855] confd_mgr[5567]: cmnEvtXML has stopped <NL> [ 1000.915801] confd_mgr[5567]: start event-handler.service <NL> [ 1000.952985] confd_mgr[5582]: condition_name: systemRestart <NL> [ 1000.958528] confd_mgr[5582]: entity_type: COM <NL> [ 1000.959315] confd_mgr[5582]: num_instances: 1 <NL> [ 1000.961288] confd_mgr[5582]: num_samples: 1 <NL> [ 1000.961830] confd_mgr[5582]:  EventNotification does not have condition_group. Skipping. <NL> [ 1001.119827] confd_mgr[5582]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [ 1001.339567] confd_mgr[5582]: CmnEvtPublisher::main: returning <NL> [ 1001.519307] confd_mgr[5567]: /usr/bin/confd_mgr_in_spm.sh <NL> [ 1001.555620] confd_mgr[5567]: /usr/bin/ui_sys_reset.py NONE <NL> [ 1008.585168] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1009.243972] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1012.426851] ntputils[1724]: child pid is 5652 <NL> [ 1012.486415] ntputils[1724]: exited, status is 0 <NL> [ 1013.697673] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1013.794616] ntputils[1724]: poller time change delta is: 1 <NL> [ 1015.267889] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1016.986528] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1020.279143] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1023.387787] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1024.259025] ntputils[1724]: push_local_changes OK <NL> [ 1024.261888] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1024.262747] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1024.281223] ntputils[1724]: child pid is 5669 <NL> [ 1024.411751] ntputils[1724]: exited, status is 0 <NL> [ 1024.596450] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1026.499670] ntputils[1724]: poller time change delta is: 2 <NL> [ 1027.776560] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [ 1028.193755] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1028.237556] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [ 1029.975980] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1030.614222] ntputils[1724]: push_local_changes OK <NL> [ 1030.787641] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1031.307691] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1031.537586] ntputils[1724]: child pid is 5679 <NL> [ 1032.129074] ntputils[1724]: exited, status is 0"}
{"timestamp_utc": "2024-07-31T08:30:10.192Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1032.271174] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1032.563288] ntputils[1724]: poller time change delta is: 3 <NL> [ 1032.831727] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [ 1032.833043] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1032.857157] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> # 03:30:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:10 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:12.751Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:12 retry-ssh-command INFO: attempt 96, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:15.309Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:15 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:17.825Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:17 retry-ssh-command INFO: attempt 97, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:20.361Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:20 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:22.878Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:22 retry-ssh-command INFO: attempt 98, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:25.398Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:25 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:27.914Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:27 retry-ssh-command INFO: attempt 99, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:30.429Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:30 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:32.316Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:30:32.572Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:32 retry-ssh-command INFO: attempt 100, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:35.856Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:35 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:37.743Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:37 retry-ssh-command INFO: attempt 101, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:40.258Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:40 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:42.782Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:42 retry-ssh-command INFO: attempt 102, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:45.300Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:30:45.301Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:45 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:47.872Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:47 retry-ssh-command INFO: attempt 103, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:48.434Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[ 1021.872502] confd_mgr[5168]: main:: Invoking /usr/bin/confd_mgr_start_cb.sh NONE <NL> [ 1021.975918] confd_mgr[5174]: Execute confd_mgr_start_cb.sh - Wed Jul 31 08:29:56 UTC 2024 <NL> [ 1022.060289] confd_mgr[5174]: TRIB don't call callback script. <NL> [ 1022.095385] confd_mgr[5168]: main:: /run/swdl_ready.sh found. Invoking it. <NL> [ 1022.095662] confd_mgr[5168]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [ 1022.095755] confd_mgr[5168]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [ 1022.130730] confd_mgr[5168]: entering: wait_for_alarm_event <NL> [ 1022.132339] confd_mgr[5168]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [ 1022.132442] confd_mgr[5168]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [ 1022.132523] confd_mgr[5168]: Creating ConfdAT startconfd SM, bank type = 1 <NL> [ 1022.132621] confd_mgr[5168]: Creating ConfdAT startconfd SM, bank type = 2 <NL> [ 1022.132691] confd_mgr[5168]: entering: at_sm::wait_for_SWDL"}
{"timestamp_utc": "2024-07-31T08:30:48.435Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[ 1022.132815] confd_mgr[5168]: ha_sm entering: wait_for_SWDL_s 0 <NL> [ 1022.132894] confd_mgr[5168]: ha_sm : wait_for_SWDL_s timer is set <NL> [ 1022.165546] confd_mgr[5168]: CommAT::asio_subscriber: Connection accepted <NL> [ 1022.165842] confd_mgr[5168]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> [ 1022.165924] confd_mgr[5168]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,SWDL_READY,TRIB,FALSE,0.0.0.0 <NL> [ 1022.165999] confd_mgr[5168]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1022.166101] confd_mgr[5168]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1022.166195] confd_mgr[5168]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1022.166277] confd_mgr[5168]: swdl_ready: sMain_trib_red_check_completed_=false <NL> [ 1022.166352] confd_mgr[5168]: swdl_ready: Executing /usr/bin/configure_main_trib_red_params.py STANDALONE <NL> [ 1023.614309] confd_mgr[5192]: INFO:root:Current HA_MODE and MAIN_TRIB_RED flag value is {'HA_MODE': 'TRIB', 'MAIN_TRIB_RED': 'FALSE'} <NL> [ 1023.899556] confd_mgr[5168]: ConfdMgrConf::reload: DB signature set to false <NL> [ 1023.918215] confd_mgr[5190]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,SWDL_READY,TRUE <NL> [ 1023.918335] confd_mgr[5168]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,SWDL_READY,TRUE <NL> [ 1023.943333] confd_mgr[5168]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1023.943543] confd_mgr[5168]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1023.943648] confd_mgr[5168]: main::/run/rdm_status.sh found. Invoking it. <NL> [ 1023.998758] confd_mgr[5168]: CommAT::asio_subscriber: Connection accepted <NL> [ 1023.999839] confd_mgr[5168]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,TRIB,WORK,STANDALONE <NL> [ 1023.999957] confd_mgr[5168]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,RDM_STATUS,TRIB,WORK,STANDALONE <NL> [ 1024.005289] confd_mgr[5168]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1024.005405] confd_mgr[5168]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1024.005482] confd_mgr[5168]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1024.005602] confd_mgr[5168]: ConfdMgrConf::reload: DB signature set to false <NL> [ 1024.005728] confd_mgr[5168]: Start_type: GO_NONE <NL> [ 1024.005811] confd_mgr[5168]: leaving: at_sm::wait_for_SWDL <NL> [ 1024.005897] confd_mgr[5168]: entering: at_sm::SDB_sleep <NL> [ 1024.005974] confd_mgr[5168]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,RDM_STATUS,TRUE <NL> [ 1024.032306] confd_mgr[5168]: ConfdMgrConf::reload: DB signature set to false <NL> [ 1024.097547] confd_mgr[5168]: Start_type: GO_NONE <NL> [ 1024.097647] confd_mgr[5168]: ha_sm leaving: wait_for_SWDL_s <NL> [ 1024.097721] confd_mgr[5168]: ha_sm entering: no_ha_s <NL> [ 1024.097813] confd_mgr[5168]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [ 1024.097888] confd_mgr[5168]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1024.098299] confd_mgr[5197]: TRUE <NL> [ 1031.796133] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2352 <NL> [ 1031.848099] layer1_control_layer[2044]: EsalConfig::EsalConfig main 0 <NL> [ 1031.848970] layer1_control_layer[2044]: EsalConfig::EsalConfig trib 1 <NL> [ 1031.849827] layer1_control_layer[2044]: EsalConfig::EsalConfig ciRole 0 <NL> [ 1031.951606] layer1_control_layer[2044]: EsalConfig is not running inside container. <NL> [ 1031.952912] layer1_control_layer[2044]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1031.954186] layer1_control_layer[2044]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1031.955228] layer1_control_layer[2044]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1031.957080] layer1_control_layer[2044]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1031.958150] layer1_control_layer[2044]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [ 1031.959425] layer1_control_layer[2044]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [ 1031.960686] layer1_control_layer[2044]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [ 1031.969940] layer1_control_layer[2044]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [ 1031.978924] layer1_control_layer[2044]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [ 1031.979972] layer1_control_layer[2044]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [ 1031.982261] layer1_control_layer[2044]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [ 1031.983647] layer1_control_layer[2044]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [ 1031.984798] layer1_control_layer[2044]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [ 1031.985837] layer1_control_layer[2044]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [ 1031.987116] layer1_control_layer[2044]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [ 1031.996898] layer1_control_layer[2044]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [ 1031.998944] layer1_control_layer[2044]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [ 1032.205441] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2351 <NL> [ 1032.256565] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2351 <NL> [ 1032.274074] layer1_hal[2055]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [ 1032.274307] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2351 <NL> [ 1032.341955] layer1_hal[2055]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [ 1032.342185] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2351 <NL> [ 1032.358184] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2351 <NL> [ 1032.370702] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2351 <NL> [ 1032.663587] layer1_control_layer[2044]:    ChalApi Constructor with tid = 2354 <NL> [ 1037.025256] ntputils_client.py[1717]: INFO:root:command failed. <NL> [ 1037.025879] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:30:48.436Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p08.NE4-trib1-console", "warrior_node_id": "n01", "project_id": "p08", "test_suite_id": "NE4-trib1-console", "message_content": "[ 1037.025972] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.004225, delay 0.04794\\n31 Jul 08:30:11 ntpdate[5287]: no server suitable for synchronization found\\n' <NL> [ 1049.045704] ntputils_client.py[1717]: INFO:root:command failed. <NL> [ 1049.046476] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1049.046579] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.000984, delay 0.03621\\n31 Jul 08:30:23 ntpdate[5351]: no server suitable for synchronization found\\n' <NL> [ 1060.944393] ntputils_client.py[1717]: INFO:root:command failed. <NL> [ 1060.953219] ntputils_client.py[1717]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1060.953333] ntputils_client.py[1717]: b'server 127.1.254.254, stratum 16, offset +0.000505, delay 0.03870\\n31 Jul 08:30:34 ntpdate[5409]: no server suitable for synchronization found\\n' <NL> [ 1073.082396] ntputils_client.py[1717]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:30:50.332Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:50 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:50 retry-ssh-command INFO: attempt 109, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:52.849Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:52 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:52 retry-ssh-command INFO: attempt 104, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:55.364Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:30:55 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:55 retry-ssh-command INFO: attempt 110, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:30:57.885Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:30:57 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:30:57 retry-ssh-command INFO: attempt 105, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:00.415Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:00 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:00 retry-ssh-command INFO: attempt 111, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:02.965Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:02 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:02 retry-ssh-command INFO: attempt 106, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:04.330Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  851.150378] python3[4489]: [.829] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb profile_id_validation <NL> [  851.744764] python3[4489]: [.425] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb nw_frame_type_validation <NL> [  851.764276] python3[4489]: [.437] valhdlr 139998162696000 callbackhdlr:252 Done register callpoint cb pluggable_data_validation <NL> [  851.768850] python3[4489]: [.437] valhdlr 139998162696000 callbackhdlr:391 Done register data callbacks <NL> [  851.772262] python3[4489]: DEBUG No crypto keys configured <NL> [  851.775920] python3[4489]: [.439] valhdlr 139998162696000 callbackhdlr:401 Unable to install crypto keys! <NL> [  851.781821] python3[4489]: [.443] valhdlr 139998162696000 callbackhdlr:322 Started data handler daemon... <NL> [  851.788587] python3[4489]: [.443] valhdlr 139998162696000 callbackhdlr:325 Send VALHDLR_CONFIRM msg to confd_mgr <NL> [  851.794566] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  851.798541] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  851.804649] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,VALHDLR_CONFIRM <NL> [  851.806624] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  851.807543] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  851.808334] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  851.810026] confd_mgr[3031]: ConfdHA Not supported command CONFIRM <NL> [  851.810793] confd_mgr[3031]: sm_startconfd::p0_ready_dbc <NL> [  851.811676] confd_mgr[3031]: Find message VALHDLR_CONFIRM <NL> [  851.812390] confd_mgr[3031]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  851.814513] confd_mgr[3031]: sm_startconfd::p0_not_ready <NL> [  851.816205] confd_mgr[3031]: Find message VALHDLR_CONFIRM <NL> [  851.816890] confd_mgr[3031]: sm_startconfd::p0_ready_no_dbc <NL> [  851.817622] confd_mgr[3031]: Find message VALHDLR_CONFIRM <NL> [  851.818319] confd_mgr[3031]: Cdb::get_field DBMgmtData.GDBISSUE <NL> [  851.820175] confd_mgr[3031]: leaving: sm_startconfd::wait_for_p0 <NL> [  851.820944] confd_mgr[3031]: action confd_at_sm_startconfd::cancel_timer_p0_a <NL> [  851.821786] confd_mgr[3031]: entering: sm_startconfd::start_confd_p1 <NL> [  851.822596] confd_mgr[3031]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_start_phase1_cb.sh NONE <NL> [  851.939374] confd_mgr[4627]: Execute confd_start_phase1_cb.sh - Wed Jul 31 08:27:05 UTC 2024 <NL> [  852.682675] confd_mgr[4637]: /usr/bin/common_confd_start_phase1_cb.sh NONE <NL> [  852.748462] confd_mgr[3031]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase1 <NL> [  938.889484] txid_tracker[4264]: ::::create_confd_subscription_connection() connected <NL> [  958.159678] confd_mgr[3031]: confd_at_common::start_confd_phase1: Invoking /usr/bin/confd_post_phase1_cb.sh NONE <NL> [  958.559896] confd_mgr[4986]: Execute confd_post_phase1_cb.sh - Wed Jul 31 08:28:52 UTC 2024 <NL> [  959.059908] confd_mgr[4986]: Invoking confd_load_upgrade_xml.py <NL> [  961.636335] confd_mgr[5003]: confd_load_upgrade_xml.py: Start <NL> [  961.878942] confd_mgr[5003]: confd_load_upgrade_xml.py: End. Result: 0 <NL> [  962.984528] confd_mgr[3031]: CONFD_IPC_PORT=4000 /usr/bin/confd_cmd -c \"get_txid\" > /var/shared/confd/bank0/DefTxId <NL> [  963.082920] confd_mgr[5027]: Execute confd_mgr_verify_and_save_mdb.sh <NL> [  963.213910] confd_mgr[3031]: CONFD IN PHASE 1 <NL> [  963.250159] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  963.347094] confd_mgr[3031]: leaving: sm_startconfd::start_confd_p1 <NL> [  963.454044] confd_mgr[3031]: entering: sm_startconfd::wait_for_p1 <NL> [  963.564629] confd_mgr[3031]: PROCESS3 has not registered yet. <NL> [  963.638383] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  963.765938] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  963.902115] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  963.950313] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  964.041247] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,MESSAGE3 <NL> [  964.093365] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  964.174454] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  964.236483] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO"}
{"timestamp_utc": "2024-07-31T08:31:04.331Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[  964.294741] confd_mgr[3031]: ConfdHA Not supported command CONFIRM <NL> [  964.295547] confd_mgr[3031]: sm_startconfd::p1_not_ready <NL> [  964.296227] confd_mgr[3031]: Find message MESSAGE3 <NL> [  964.296872] confd_mgr[3031]: sm_startconfd::p1_ready <NL> [  964.297539] confd_mgr[3031]: Find message MESSAGE3 <NL> [  964.333640] confd_mgr[3031]: leaving: sm_startconfd::wait_for_p1 <NL> [  964.334735] confd_mgr[3031]: action confd_at_sm_startconfd::cancel_timer_p1_a <NL> [  964.335655] confd_mgr[3031]: entering: sm_startconfd::wait_for_rm <NL> [  964.368251] confd_mgr[3031]: confd_at_sm_startconfd::wait_for_rm: sConfdResetType.get_reset_type() = NONE <NL> [  964.412178] confd_mgr[3031]: confd_at_sm_startconfd::wait_for_rm: Invoking /usr/bin/confd_db_replay_cb.sh NONE <NL> [  964.534469] confd_mgr[5031]: Execute confd_db_replay_cb.sh - Wed Jul 31 08:28:57 UTC 2024 <NL> [  964.535688] python3[4625]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  964.548577] confd_mgr[5043]: cp: cannot stat '/var/shared/sharedlogs/cdsfLogBackup': No such file or directory <NL> [  964.559495] confd_mgr[5046]: find: /var/shared/cdsf.d/PortMacInfo: No such file or directory <NL> [  964.586564] confd_mgr[3031]: ConfdAT::process_cmd: Sending Cmd = /CommAT/ASIO,/ConfdAT,RESPONSE,CONFIRM,TRUE <NL> [  964.736544] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  964.737586] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [  964.739164] confd_mgr[5056]: /usr/bin/replay_manager NONE <NL> [  964.787645] confd_mgr[5054]: redundancy_status is STANDALONE <NL> [  964.895328] confd_mgr[5054]: DDS ports will be opened. <NL> [  964.896190] confd_mgr[5054]: execute replay_manager NONE TRUE <NL> [  965.694294] confd_mgr[5061]: TRACE Connected (cdb) to ConfD <NL> [  965.791879] confd_mgr[5061]: TRACE CDB_WAIT_START  --> CONFD_OK <NL> [  965.953532] confd_mgr[5061]: TRACE Connected (cdb) to ConfD <NL> [  965.989766] confd_mgr[5061]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  971.061598] confd_mgr[5061]: TRACE CDB_GET_TXID  --> CONFD_OK <NL> [  971.105830] txid_tracker[4264]: TXID-Tracker::Alerting confdmgr of database provisioning <NL> [  971.253852] txid_tracker[5106]: confd_mgr_cmd:: Reply is: /Confd_mgr_cmd,/ConfdHA,RESPONSE,DB_PROV,FALSE <NL> [  971.360141] confd_mgr[5061]: TRACE CDB_TRIGGER_SUBS <NL> [  971.507992] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [  971.785765] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV <NL> [  971.823953] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,DB_PROV, <NL> [  972.026345] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [  972.113346] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [  972.228560] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [  972.431400] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT <NL> [  972.744815] confd_mgr[3031]: CommAT::asio_worker: Client sent a terminator, cmd.get_op() = EXIT <NL> [ 1026.898579] systemd-sysv-generator[5261]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1034.152631] systemd-sysv-generator[5277]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1089.907595] ntputils[1725]: bool NTPServer::handle_command(const string&) <NL> [ 1089.908806] ntputils[1725]: bool NTPServer::handle_configure_cmd(const string&) <NL> [ 1089.916464] ntputils[1725]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv"}
{"timestamp_utc": "2024-07-31T08:31:05.694Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:05 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:05 retry-ssh-command INFO: attempt 112, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:07.581Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:07 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:07 retry-ssh-command INFO: attempt 107, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:10.854Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:10 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:10 retry-ssh-command INFO: attempt 113, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:12.744Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:12 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:12 retry-ssh-command INFO: attempt 108, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:16.012Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:15 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:15 retry-ssh-command INFO: attempt 114, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:17.901Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:17 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:17 retry-ssh-command INFO: attempt 109, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:20.416Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:20 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:31:20.673Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:20 retry-ssh-command INFO: attempt 115, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:22.564Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:22 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:22 retry-ssh-command INFO: attempt 110, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:24.475Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1032.858104] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1032.919912] ntputils[1724]: push_local_changes OK <NL> [ 1033.115070] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1033.254409] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1033.301990] ntputils[1724]: child pid is 5701 <NL> [ 1033.442291] ntputils[1724]: exited, status is 0 <NL> [ 1033.465713] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1033.506893] ntputils[1724]: poller time change delta is: 2 <NL> [ 1033.507653] ntputils[1724]: push_local_changes user_changed: 0 delta: 2 <NL> [ 1033.546801] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1033.548609] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 2 <NL> [ 1033.968150] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1033.970634] ntputils[1724]: push_local_changes OK <NL> [ 1034.104542] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1034.283143] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1034.304492] ntputils[1724]: child pid is 5716 <NL> [ 1034.699521] confd_mgr[5870]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1035.169883] confd_mgr[5870]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1035.251312] ntputils[1724]: exited, status is 0 <NL> [ 1035.429840] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1035.536213] ntputils[1724]: poller time change delta is: 5 <NL> [ 1035.724895] ntputils[1724]: push_local_changes user_changed: 0 delta: 5 <NL> [ 1035.929333] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1036.095728] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 5 <NL> [ 1036.528693] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1036.650377] ntputils[1724]: push_local_changes OK <NL> [ 1036.653585] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1036.657361] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1036.662265] ntputils[1724]: child pid is 5726 <NL> [ 1036.665678] ntputils[1724]: exited, status is 0 <NL> [ 1036.670104] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1036.686661] ntputils[1724]: poller time change delta is: 1 <NL> [ 1036.693055] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1036.704629] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1036.728323] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1036.793698] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1036.888411] ntputils[1724]: push_local_changes OK <NL> [ 1036.968906] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1036.975213] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1036.975883] ntputils[1724]: child pid is 5762 <NL> [ 1036.976497] ntputils[1724]: exited, status is 0 <NL> [ 1036.977528] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1037.012278] ntputils[1724]: poller time change delta is: 3 <NL> [ 1037.032649] ntputils[1724]: push_local_changes user_changed: 0 delta: 3 <NL> [ 1037.081093] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1037.106538] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [ 1037.145172] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1037.229622] ntputils[1724]: push_local_changes OK <NL> [ 1037.340290] ntputils[1724]: NTPServer::execute_cmd spawning: <NL> [ 1037.422946] ntputils[1724]: /sbin/hwclock -u --systohc <NL> [ 1037.441110] ntputils[1724]: child pid is 5792 <NL> [ 1037.541929] ntputils[1724]: exited, status is 0 <NL> [ 1037.663920] ntputils[1724]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1037.680793] ntputils[1724]: poller time change delta is: 1 <NL> [ 1037.686233] ntputils[1724]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1037.687107] ntputils[1724]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1037.757055] ntputils[1724]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1037.945680] ntputils[1724]: local_push OK w Platform::Time 0 0 <NL> [ 1037.983865] ntputils[1724]: push_local_changes OK <NL> [ 1038.060671] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1038.484520] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1039.280359] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1039.498354] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1039.499278] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1039.585721] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1039.717579] cia_control_layer[2227]:    ChalApi Constructor with tid = 3123 <NL> [ 1040.003904] confd_mgr[5871]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1040.047501] confd_mgr[5871]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1040.241840] ops-service[5892]: rebind_listener \"webui\" <NL> [ 1040.357053] ops-service[5892]: TRACE Connected (maapi) to ConfD <NL> [ 1040.457386] ops-service[5892]: TRACE MAAPI_REBIND_LISTENER <NL> [ 1040.569762] ops-service[5892]:  31-Jul-2024::08:30:12.682 5892/7f7b92588c40/4 SEND op=407 isrel=0 th=-1 16 <NL> [ 1040.935376] ops-service[5892]:  --> CONFD_OK <NL> [ 1040.944834] ops-service[5892]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [ 1041.158424] confd_mgr[5872]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1041.307663] confd_mgr[5872]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1041.478940] confd_mgr[5623]: DDS Peristency is enabled <NL> [ 1041.577995] confd_mgr[5623]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [ 1041.641435] confd_mgr[5623]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [ 1041.743818] confd_mgr[5623]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [ 1041.798482] confd_mgr[5623]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [ 1041.934697] confd_mgr[5875]: Execute check_db_status.sh <NL> [ 1041.935580] confd_mgr[5875]: NE is running a default database! <NL> [ 1041.939849] ops-service[5933]: rebind_listener \"snmp\" <NL> [ 1042.014512] confd_mgr[5540]: Starting valhdlr.service if not started already"}
{"timestamp_utc": "2024-07-31T08:31:24.476Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p07.NE4-main-console", "warrior_node_id": "n01", "project_id": "p07", "test_suite_id": "NE4-main-console", "message_content": "[ 1042.307627] confd_mgr[5540]: Starting validation-handler.service if not started already <NL> [ 1042.507669] confd_mgr[5540]: Starting snmp-fss-fw.service if not started already <NL> [ 1042.633999] ops-service[5933]: TRACE Connected (maapi) to ConfD <NL> [ 1042.671737] ops-service[5933]: TRACE MAAPI_REBIND_LISTENER <NL> [ 1042.810503] ops-service[5933]:  31-Jul-2024::08:30:18.079 5933/7fe5e0ef0c40/4 SEND op=407 isrel=0 th=-1 4 <NL> [ 1042.938814] confd_mgr[2516]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [ 1043.062655] ops-service[5933]:  --> CONFD_OK <NL> [ 1043.103233] ops-service[5933]: TRACE MAAPI_END_USER_SESSION  --> CONFD_OK <NL> [ 1051.295688] systemd-sysv-generator[5996]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1061.807059] systemd-sysv-generator[6035]: SysV service '/etc/init.d/fuse3' lacks a native systemd unit file. Automatically generating a unit file for compatibility. Please update package to include a native systemd unit file, in order to make it more safe and robust. <NL> [ 1081.637960] confd_phase_sentry[2246]: ConfdPhaseSentry: phase reached; rc = 0 <NL> [ 1081.713651] confd_phase_sentry[2246]: ConfdPhaseSentry: starting confd-ready.service <NL> [ 1083.046251] echo[6104]: Starting confd-ready <NL> [ 1085.016105] netconfEventSyslog[6112]: EventSyslogDaemon: Trying to connect to Confd <NL> [ 1089.961786] automater.sh[6109]: {anonymous}::DefaultBSapiLogger::DefaultBSapiLogger(): Default bsapi logger set. <NL> [ 1090.700192] confd_mgr[2516]: start_confd_phase2 invoking /usr/bin/confd_nb_ready_cb.sh <NL> [ 1091.057275] snmp_trapd[6118]: {anonymous}::DefaultConfdapiLogger::DefaultConfdapiLogger(): Default confdapi logger set. <NL> [ 1092.823551] snmp_trapd[6118]: gen_util: DDS_P2MP not available <NL> [ 1093.869234] confd_mgr[6176]: Execute confd_nb_ready_cb.sh - Wed Jul 31 08:31:09 UTC 2024 <NL> [ 1095.108845] confd_mgr[6234]: Execute common_confd_nb_ready_cb.sh <NL> [ 1096.082462] confd_mgr[6176]: Invoking confd_nb_enable.py <NL> [ 1105.614121] confd_mgr[5537]: confd_mgr_cmd:: Reply is: Receive failed <NL> [ 1106.318205] confd_mgr[2516]: CommAT::asio_worker: Received /confd_mgr,/confd_mgr_cmd,REQUEST,EXIT"}
{"timestamp_utc": "2024-07-31T08:31:25.842Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:25 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:25 retry-ssh-command INFO: attempt 116, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:27.729Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:27 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:27 retry-ssh-command INFO: attempt 111, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:30.999Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:30 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:30 retry-ssh-command INFO: attempt 117, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:32.942Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:32 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:32 retry-ssh-command INFO: attempt 112, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:34.834Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1090.056031] ntputils[1725]: parse_time_persistent_topic ddskind create <NL> [ 1090.537661] ntputils[1725]: parse_time_persistent_topic name key config <NL> [ 1090.587241] ntputils[1725]: parse_time_persistent_topic command Time;configure enable=yes; <NL> [ 1090.633669] ntputils[1725]: parse_time_topics command_data enable=yes; <NL> [ 1090.680141] ntputils[1725]: handle_configure_cmd token is: enable=yes <NL> [ 1090.812538] ntputils[1725]: bool NTPServer::external_ntp_enable(std::string, std::string) <NL> [ 1091.254451] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1091.406748] ntputils[1725]: systemctl --no-block stop ntpd <NL> [ 1092.100244] ntputils[1725]: child pid is 5437 <NL> [ 1092.504572] ntputils[1725]: exited, status is 0 <NL> [ 1093.771833] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1094.624894] ntputils[1725]: /usr/local/fnc/ntputils/ext_config.sh -e /etc/ntp.conf <NL> [ 1095.460111] ntputils[1725]: child pid is 5464 <NL> [ 1095.997826] userddssub[5416]: useradd: user 'fujitsu' already exists <NL> [ 1096.094484] dcn_dns_controller[1366]: fin_file is open <NL> [ 1097.487310] ntputils[1725]: exited, status is 0 <NL> [ 1097.635106] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1097.804833] ntputils[1725]: /bin/systemctl reset-failed ntpd <NL> [ 1098.301499] ntputils[1725]: child pid is 5502 <NL> [ 1098.359751] ntputils[1725]: exited, status is 0 <NL> [ 1098.729021] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1098.766476] ntputils[1725]: systemctl --no-block start ntpd <NL> [ 1098.770323] ntputils[1725]: child pid is 5523 <NL> [ 1098.782190] ntputils[1725]: exited, status is 0 <NL> [ 1098.782867] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1098.795978] ntputils[1725]: systemctl --no-block start ntpscript"}
{"timestamp_utc": "2024-07-31T08:31:34.835Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1098.796902] ntputils[1725]: child pid is 5533 <NL> [ 1098.797534] ntputils[1725]: exited, status is 0 <NL> [ 1098.798206] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1099.038487] ntputils[1725]: /bin/systemctl --no-block start init_state_check.timer <NL> [ 1099.622258] ntputils[1725]: child pid is 5546 <NL> [ 1099.911903] ntputils[1725]: exited, status is 0 <NL> [ 1100.130214] ntputils[1725]: Configure command handled successfully, writing to RTC <NL> [ 1100.376764] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1100.557449] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1101.095987] ntputils[1725]: child pid is 5560 <NL> [ 1101.478874] ntputils[1725]: exited, status is 0 <NL> [ 1101.889880] ntputils[1725]: bool NTPServer::handle_command(const string&) <NL> [ 1102.170777] ntputils[1725]: bool NTPServer::handle_set_time_cmd(const string&) <NL> [ 1102.904223] ntputils[1725]: Received TimePersistentProv topic: Platform_dds_TimePersistentProv <NL> [ 1103.984107] ntputils[1725]: parse_time_persistent_topic ddskind create <NL> [ 1104.561477] ntputils[1725]: parse_time_persistent_topic name key setTZ <NL> [ 1104.919905] ntputils[1725]: parse_time_persistent_topic command Time;set_time timezone=UTC; <NL> [ 1105.056356] ntputils[1725]: parse_time_topics command_data timezone=UTC; <NL> [ 1105.057111] ntputils[1725]: bool NTPServer::set_timezone(const string&) <NL> [ 1105.057837] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1105.148180] ntputils[1725]: /bin/ln -sf /usr/share/zoneinfo/UTC /etc/localtime <NL> [ 1105.185078] ntputils[1725]: child pid is 5567 <NL> [ 1105.376538] ntputils[1725]: exited, status is 0 <NL> [ 1105.785065] ntputils[1725]: set new timezone: /usr/share/zoneinfo/UTC <NL> [ 1106.043167] ntputils[1725]: push_local_changes user_changed: 1 delta: 0 <NL> [ 1106.210409] ntputils[1725]: local_push OK u Platform::Time changedByUser 1 <NL> [ 1106.226280] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 0 <NL> [ 1106.247473] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1106.248207] ntputils[1725]: push_local_changes OK <NL> [ 1106.345269] ntputils[1725]: publish_local_changes: local_pub_str.timezone_change delta: 0 <NL> [ 1106.461622] ntputils[1725]: publish_local_changes OK"}
{"timestamp_utc": "2024-07-31T08:31:34.836Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1106.567831] userddssub[2149]: user_mgmt::ShadowAdapter::ReturnValue user_mgmt::ShadowAdapter::AddUser(const string&, const string&, const string&, const string&, const string&) const:result:9 <NL> [ 1106.743821] confd_mgr[5061]:  --> CONFD_OK <NL> [ 1106.982394] confd_mgr[5629]: openDdsPorts interfaces  eth5.2003 <NL> [ 1107.205536] confd_mgr[5629]: openDdsPorts Input udpPorts-  7660 <NL> [ 1107.470683] confd_mgr[5629]: openDdsPorts Output udpPorts-  7660 <NL> [ 1107.730431] confd_mgr[5629]: openDdsPorts Input udpPorts-  7661 <NL> [ 1107.850758] confd_mgr[5629]: openDdsPorts Output udpPorts-  7661 <NL> [ 1108.010466] confd_mgr[5629]: openDdsPorts Input udpPorts-  7650 <NL> [ 1108.226427] confd_mgr[5629]: openDdsPorts Output udpPorts-  7650 <NL> [ 1108.399321] confd_mgr[5629]: openDdsPorts Input udpPorts-  7651 <NL> [ 1108.467348] ntp_alarm_event_monitor.py[5545]: INFO:root:error in redundancy_mode: unknown, default to 'working' <NL> [ 1108.538547] ntp_alarm_event_monitor.py[5545]: INFO:root:get_redundancy_mode: redundancy_mode set to: working <NL> [ 1108.631906] ntp_alarm_event_monitor.py[5545]: INFO:root:msg_id: Platform_dds_Redundancy, dds_kind: create, redundancyStatus: standalone <NL> [ 1108.633293] ntp_alarm_event_monitor.py[5545]: INFO:root:redundancy status now set to standalone <NL> [ 1108.634600] confd_mgr[5629]: openDdsPorts Output udpPorts-  7651 <NL> [ 1109.045560] confd_mgr[5629]: openDdsPorts Input udpPorts-  7900 <NL> [ 1109.401122] confd_mgr[5629]: openDdsPorts Output udpPorts-  7900 <NL> [ 1110.018803] confd_mgr[5629]: openDdsPorts Input udpPorts-  7901 <NL> [ 1110.131688] confd_mgr[5629]: openDdsPorts Output udpPorts-  7901 <NL> [ 1110.397132] confd_mgr[5629]: openDdsPorts Input udpPorts-  7910 <NL> [ 1111.149609] confd_mgr[5629]: openDdsPorts Output udpPorts-  7910 <NL> [ 1111.676718] confd_mgr[5629]: openDdsPorts Input udpPorts-  7911 <NL> [ 1111.873796] confd_mgr[5629]: openDdsPorts Output udpPorts-  7911 <NL> [ 1111.971305] confd_mgr[5629]: openDdsPorts Input udpPorts-  8150 <NL> [ 1112.040091] confd_mgr[5629]: openDdsPorts Output udpPorts-  8150 <NL> [ 1112.103282] confd_mgr[5629]: openDdsPorts Input udpPorts-  8151 <NL> [ 1112.215062] confd_mgr[5629]: openDdsPorts Output udpPorts-  8151 <NL> [ 1112.426803] confd_mgr[5629]: openDdsPorts Input udpPorts-  8160 <NL> [ 1112.508190] confd_mgr[5629]: openDdsPorts Output udpPorts-  8160 <NL> [ 1112.832506] confd_mgr[5629]: openDdsPorts Input udpPorts-  8161 <NL> [ 1112.978581] ntp_alarm_event_monitor.py[5634]: ntpq: read: Connection refused <NL> [ 1113.125515] confd_mgr[5629]: openDdsPorts Output udpPorts-  8161 <NL> [ 1113.486422] ntp_alarm_event_monitor.py[5545]: INFO:root:Publish Alarm: Raising alarm <NL> [ 1113.690650] ntp_alarm_event_monitor.py[5545]: INFO:root:NOT_SYNC_ALARM raised, not_active is False <NL> [ 1113.921624] confd_mgr[5061]: TRACE Connected (ha) to ConfD <NL> [ 1114.348826] confd_mgr[5061]: replay_manager: Purge file needs to be erased at replay-mgr startup."}
{"timestamp_utc": "2024-07-31T08:31:34.837Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1114.368269] confd_mgr[5061]: replay_manager:  Start-Wed Jul 31 08:28:59 2024 <NL> [ 1114.621135] confd_mgr[5061]:  ++++++++++++++++++++++ <NL> [ 1115.026736] confd_mgr[5061]: replay_manager: TXID NOT FOUND ================================== <NL> [ 1115.068282] confd_mgr[5061]: replay_manager: TXID mismatch. Forcing full replay (hotfix) <NL> [ 1115.202897] confd_mgr[5061]: replay_manager: Need to do trigger full replay. <NL> [ 1115.465335] confd_mgr[5061]: replay_manager: Creating the purge file. <NL> [ 1115.641469] confd_mgr[5061]: replay_manager: Open DDS Ports <NL> [ 1116.124876] confd_mgr[5061]: replay_manager: NOW deleting the purge file. <NL> [ 1116.559813] confd_mgr[5061]: replay_manager:  End-Wed Jul 31 08:31:24 2024 <NL> [ 1117.177772] confd_mgr[5061]:  ++++++++++++++++++++++ <NL> [ 1117.363879] confd_mgr[5061]: 1+1 Mode <NL> [ 1117.661148] confd_mgr[5061]: Not in Slave Mode - Ready for Phase 2 ========== <NL> [ 1118.027096] confd_mgr[5061]: DipLog_pimpl destructor called <NL> [ 1118.184851] confd_mgr[5061]: DipVerbosity Listener ZMQ error <NL> [ 1118.462198] confd_mgr[5061]:     ret='Context was terminated <NL> [ 1118.734391] confd_mgr[5061]: deleting subscriber_ socket <NL> [ 1118.884818] confd_mgr[5061]: Exiting verb listener <NL> [ 1119.590147] confd_mgr[3031]: CommAT::asio_subscriber: Connection accepted <NL> [ 1119.979279] confd_mgr[3031]: CommAT::asio_worker: Received /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE"}
{"timestamp_utc": "2024-07-31T08:31:35.806Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:35 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:35 retry-ssh-command INFO: attempt 118, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:37.730Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:37 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:37 retry-ssh-command INFO: attempt 113, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:41.000Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:40 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:40 retry-ssh-command INFO: attempt 119, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:42.889Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:42 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:42 retry-ssh-command INFO: attempt 114, sleep 5: \"rtxoialp79:37227\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:46.177Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:45 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:31:46.433Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:46 retry-ssh-command INFO: attempt 120, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:47.801Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:31:47 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37227, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:31:51.988Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:51 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:51 retry-ssh-command INFO: attempt 121, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:31:57.256Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:31:56 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:31:56 retry-ssh-command INFO: attempt 122, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:01.512Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:01 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:32:03.401Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:03 retry-ssh-command INFO: attempt 123, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:08.647Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p07.s02.NE4-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p07", "keyword_name": "s02.NE4-main-cli", "step_id": "s02.NE4-main-cli", "message_content": "# 03:32:07 retry-ssh-command INFO: client_cl.__enter__ <NL> # 03:32:07 retry-ssh-command INFO: client_cl.__exit__: exc_type \"None\" <NL> # 03:32:07 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"stderr\": DONE <NL> # 03:32:07 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\", type \"stdout\": DONE <NL> # 03:32:07 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p07.s02.NE4-main-cli\": process 3691 terminated with exitcode 0 <NL> # 03:32:07 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p07.s02.NE4-main-cli) <NL> # 03:32:07 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code 0 (n01.p09.s01.p07.main-startup (s)) <NL> # 03:32:07 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p07.main-startup (s)) <NL> # 03:32:07 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #6 finished with exit_code 0, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:32:07 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": still have 1 children running (n01.p09.s01.startup (p)) <NL> # 03:32:07 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.s02.NE4-main-cli\", exit_code 0 <NL> # 03:32:07 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p07.main-startup (s)\", exit_code 0 <NL> # 03:32:08 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:08 retry-ssh-command INFO: attempt 124, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:13.889Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:13 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:13 retry-ssh-command INFO: attempt 125, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:14.819Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1120.613453] confd_mgr[3031]: CommAT::asio_worker: cmd.get_cmd() = /confd_mgr,/Confd_mgr_cmd,REQUEST,CONFIRM,RM_MESSAGE <NL> [ 1120.990760] confd_mgr[3031]: CommAT::asio_worker: ext_id_ = /Confd_mgr_cmd <NL> [ 1121.472870] confd_mgr[3031]: CommAT::asio_worker: mq_name() = /CommAT <NL> [ 1121.794518] confd_mgr[3031]: CommAT::asio_worker: ASIO_ID = ASIO <NL> [ 1122.441467] confd_mgr[3031]: ConfdHA Not supported command CONFIRM <NL> [ 1122.973028] confd_mgr[3031]: sm_startconfd::rm_ready <NL> [ 1123.142771] confd_mgr[3031]: leaving: sm_startconfd::wait_for_rm <NL> [ 1123.406170] confd_mgr[3031]: action confd_at_sm_startconfd::cancel_timer_rm_a <NL> [ 1124.073427] confd_mgr[3031]: entering: sm_startconfd::start_confd_p2 <NL> [ 1124.174394] confd_mgr[3031]: confd_at_common::start_confd_phase2: Invoking /usr/bin/confd_start_phase2_cb.sh NONE <NL> [ 1124.848971] confd_mgr[5682]: Execute confd_start_phase2_cb.sh - Wed Jul 31 08:31:25 UTC 2024 <NL> [ 1125.534790] confd_mgr[5695]: cmnEvtXML has stopped <NL> [ 1125.942234] confd_mgr[5695]: start event-handler.service <NL> [ 1126.492297] confd_mgr[5703]: condition_name: systemRestart <NL> [ 1126.504266] confd_mgr[5703]: entity_type: COM <NL> [ 1126.504856] confd_mgr[5703]: num_instances: 1 <NL> [ 1126.530306] confd_mgr[5703]: num_samples: 1 <NL> [ 1126.531021] confd_mgr[5703]:  EventNotification does not have condition_group. Skipping. <NL> [ 1126.826407] confd_mgr[5703]: CmnEvtPublisher::main: Populated sample, sending: locn: add_info: <NL> [ 1127.145893] confd_mgr[5703]: CmnEvtPublisher::main: returning <NL> [ 1127.674493] confd_mgr[5695]: /usr/bin/confd_mgr_in_spm.sh <NL> [ 1128.007080] confd_mgr[5695]: /usr/bin/ui_sys_reset.py NONE <NL> [ 1128.983564] dcn_dns_controller[1366]: fin_file is open <NL> [ 1138.762448] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1139.883114] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1140.220560] ntputils[1725]: child pid is 5786 <NL> [ 1140.437547] ntputils[1725]: exited, status is 0 <NL> [ 1140.443873] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1140.937668] ntputils[1725]: poller time change delta is: 1 <NL> [ 1141.012938] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1141.018489] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1141.048269] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1141.050768] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1141.062210] ntputils[1725]: push_local_changes OK <NL> [ 1141.069589] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1141.104413] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1141.119519] ntputils[1725]: child pid is 5811 <NL> [ 1141.148480] ntputils[1725]: exited, status is 0 <NL> [ 1141.151977] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1142.239139] ntputils[1725]: poller time change delta is: 8 <NL> [ 1142.264890] ntputils[1725]: push_local_changes user_changed: 0 delta: 8 <NL> [ 1142.525293] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1142.541392] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 8 <NL> [ 1142.582836] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1142.654140] confd_mgr[5821]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1142.655054] confd_mgr[5821]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1142.655908] ntputils[1725]: push_local_changes OK <NL> [ 1142.705371] confd_mgr[5822]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1142.706234] confd_mgr[5822]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1143.072716] confd_mgr[5823]: Filesystem      Size  Used Avail Use% Mounted on <NL> [ 1145.123443] confd_mgr[5823]: /dev/root       2.2G  1.8G  295M  87% / <NL> [ 1145.257732] confd_mgr[5726]: DDS Peristency is enabled <NL> [ 1145.258635] confd_mgr[5726]: (ui-sys-reset) Running /usr/sbin/pwck -q -r... <NL> [ 1145.273420] confd_mgr[5726]: (ui-sys-reset) Running /bin/df -h /home/... <NL> [ 1145.274318] confd_mgr[5726]: (ui-sys-reset) Running /bin/df -h /var/shared... <NL> [ 1145.275225] confd_mgr[5726]: (ui-sys-reset) Running /bin/df -h /etc... <NL> [ 1149.180107] cia_control_layer[5866]: grep: product_systemData.xml: No such file or directory <NL> [ 1149.956680] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1149.973102] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1149.973966] ntputils[1725]: child pid is 5877 <NL> [ 1149.974777] ntputils[1725]: exited, status is 0 <NL> [ 1149.975570] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1149.976963] ntputils[1725]: poller time change delta is: 1 <NL> [ 1150.089046] ntputils[1725]: push_local_changes user_changed: 0 delta: 1"}
{"timestamp_utc": "2024-07-31T08:32:14.820Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p05.NE3-main-console", "warrior_node_id": "n01", "project_id": "p05", "test_suite_id": "NE3-main-console", "message_content": "[ 1150.102396] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1150.220397] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1151.540611] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1151.838434] ntputils[1725]: push_local_changes OK <NL> [ 1152.606795] confd_mgr[5865]: Execute check_db_status.sh <NL> [ 1152.607653] confd_mgr[5865]: NE is running a default database! <NL> [ 1152.769021] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1154.179742] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1154.856396] ntputils[1725]: child pid is 5896 <NL> [ 1154.879285] ntputils[1725]: exited, status is 0 <NL> [ 1154.880204] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1154.908169] ntputils[1725]: poller time change delta is: 1 <NL> [ 1154.910068] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1155.464929] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1156.229939] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1156.293276] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1156.508861] ntputils[1725]: push_local_changes OK <NL> [ 1156.765294] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1156.850410] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1156.954585] ntputils[1725]: child pid is 5915 <NL> [ 1156.993266] ntputils[1725]: exited, status is 0 <NL> [ 1157.040814] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1157.122433] ntputils[1725]: poller time change delta is: 1 <NL> [ 1157.124332] ntputils[1725]: push_local_changes user_changed: 0 delta: 1 <NL> [ 1157.127225] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1157.129451] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 1 <NL> [ 1157.133076] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1157.136278] ntputils[1725]: push_local_changes OK <NL> [ 1157.139166] ntputils[1725]: NTPServer::execute_cmd spawning: <NL> [ 1157.145038] ntputils[1725]: /sbin/hwclock -u --systohc <NL> [ 1157.146066] ntputils[1725]: child pid is 5923 <NL> [ 1157.267536] ntputils[1725]: exited, status is 0 <NL> [ 1157.268603] ntputils[1725]: poller time change reason is: local_pub_str.ntp_drift <NL> [ 1157.287450] ntputils[1725]: poller time change delta is: 3 <NL> [ 1157.288211] ntputils[1725]: push_local_changes user_changed: 0 delta: 3 <NL> [ 1157.288994] ntputils[1725]: local_push OK u Platform::Time changedByUser 0 <NL> [ 1157.289783] ntputils[1725]: local_push OK u Platform::Time deltaTimeChangeSeconds 3 <NL> [ 1157.321284] ntputils[1725]: local_push OK w Platform::Time 0 0 <NL> [ 1157.332400] ntputils[1725]: push_local_changes OK <NL> [ 1157.358519] confd_mgr[5682]: Starting valhdlr.service if not started already <NL> [ 1157.360848] confd_mgr[5682]: Starting validation-handler.service if not started already <NL> [ 1157.363259] confd_mgr[5682]: Starting snmp-fss-fw.service if not started already <NL> [ 1157.465899] confd_mgr[3031]: CONFD_IPC_PORT=4000 /usr/sbin/confd --start-phase2 <NL> [ 1159.054907] cia_control_layer[2116]:    ChalApi Constructor with tid = 2869 <NL> [ 1159.192481] cia_control_layer[2116]: EsalConfig::EsalConfig main 1 <NL> [ 1159.193201] cia_control_layer[2116]: EsalConfig::EsalConfig trib 0 <NL> [ 1159.201130] cia_control_layer[2116]: EsalConfig::EsalConfig ciRole 0 <NL> [ 1159.669543] cia_control_layer[2116]: EsalConfig is not running inside container. <NL> [ 1159.769673] cia_control_layer[2116]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1159.997468] cia_control_layer[2116]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1160.411400] cia_control_layer[2116]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg"}
{"timestamp_utc": "2024-07-31T08:32:16.707Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "2024-07-31 08:19:01,640 swdllite(int): INFO - swdl_int_agent_fn.background_subproc[32] finished: /usr/bin/confd_mgr_swdl_ready.py --mode NORMAL --status SUCCESS --rdm-status STANDALONE, return_code=0 <NL> [  379.500947] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  379.501306] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  379.501400] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.202513, delay 0.02994\\n31 Jul 08:19:13 ntpdate[2971]: no server suitable for synchronization found\\n' <NL> [  392.550770] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  392.551524] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 :"}
{"timestamp_utc": "2024-07-31T08:32:16.708Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p06.NE3-trib1-console", "warrior_node_id": "n01", "project_id": "p06", "test_suite_id": "NE3-trib1-console", "message_content": "[  392.551621] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.282783, delay 0.23938\\n31 Jul 08:19:26 ntpdate[3022]: no server suitable for synchronization found\\n' <NL> [  404.635730] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  404.636003] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  404.667120] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.202809, delay 0.03210\\n31 Jul 08:19:38 ntpdate[3063]: no server suitable for synchronization found\\n' <NL> [  416.816200] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  416.826605] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  416.826780] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.203594, delay 0.03271\\n31 Jul 08:19:50 ntpdate[3096]: no server suitable for synchronization found\\n' <NL> [  428.940121] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  428.940490] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  428.945190] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.194348, delay 0.05803\\n31 Jul 08:20:03 ntpdate[3131]: no server suitable for synchronization found\\n' <NL> [  440.899724] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  440.928207] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  440.928360] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.205036, delay 0.04024\\n31 Jul 08:20:14 ntpdate[3168]: no server suitable for synchronization found\\n' <NL> [  452.987941] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  452.988218] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  452.988301] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.207911, delay 0.04123\\n31 Jul 08:20:27 ntpdate[3201]: no server suitable for synchronization found\\n' <NL> [  465.136846] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  465.137614] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  465.137711] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.197676, delay 0.03537\\n31 Jul 08:20:39 ntpdate[3260]: no server suitable for synchronization found\\n' <NL> [  477.246893] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  477.247425] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  477.247518] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.201848, delay 0.06538\\n31 Jul 08:20:51 ntpdate[3294]: no server suitable for synchronization found\\n' <NL> [  489.138144] ntputils_client.py[1702]: INFO:root:command failed. <NL> [  489.138374] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [  489.138450] ntputils_client.py[1702]: b'server 127.1.254.254, stratum 16, offset +0.201455, delay 0.02768\\n31 Jul 08:21:03 ntpdate[3336]: no server suitable for synchronization found\\n' <NL> [ 1104.396038] ntputils_client.py[1702]: INFO:root:command failed. <NL> [ 1104.396358] ntputils_client.py[1702]: Command - ntpdate 127.1.254.254 127.1.254.253 : <NL> [ 1104.396449] ntputils_client.py[1702]: b'31 Jul 08:31:18 ntpdate[5307]: no server suitable for synchronization found\\n' <NL> [ 1107.499422] ntputils_client.py[1702]: INFO:root:command failed. <NL> [ 1107.541181] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1107.541351] ntputils_client.py[1702]: b'31 Jul 08:31:21 ntpdate[5353]: no server suitable for synchronization found\\n' <NL> [ 1117.001894] ntputils_client.py[1702]: INFO:root:command failed. <NL> [ 1117.002179] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1117.002244] ntputils_client.py[1702]: b'31 Jul 08:31:31 ntpdate[5399]: no server suitable for synchronization found\\n' <NL> [ 1129.144754] ntputils_client.py[1702]: INFO:root:command failed. <NL> [ 1129.145464] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1129.239255] ntputils_client.py[1702]: b'31 Jul 08:31:43 ntpdate[5434]: no server suitable for synchronization found\\n' <NL> [ 1147.186421] ntputils_client.py[1702]: INFO:root:command failed. <NL> [ 1147.186810] ntputils_client.py[1702]: Command - ntpdate -q -p1 127.1.254.254 127.1.254.253 : <NL> [ 1147.186900] ntputils_client.py[1702]: b'31 Jul 08:32:01 ntpdate[5566]: no server suitable for synchronization found\\n' <NL> [ 1156.703866] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2385 <NL> [ 1156.717068] layer1_control_layer[2064]: EsalConfig::EsalConfig main 0 <NL> [ 1156.717279] layer1_control_layer[2064]: EsalConfig::EsalConfig trib 1 <NL> [ 1156.717558] layer1_control_layer[2064]: EsalConfig::EsalConfig ciRole 0 <NL> [ 1156.861546] layer1_control_layer[2064]: EsalConfig is not running inside container. <NL> [ 1156.861780] layer1_control_layer[2064]: getAltConfigPathUpper Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1156.879228] layer1_control_layer[2064]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1156.879413] layer1_control_layer[2064]: getAltConfigPathLower Config path: /usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1156.879493] layer1_control_layer[2064]:  stpAdjFileName=/usr/local/fnc/esal/02_00_00_00/esalModes.cfg <NL> [ 1156.879587] layer1_control_layer[2064]: getConfigPath Config path: /usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [ 1156.879665] layer1_control_layer[2064]:  stpAdjFileName=/usr/local/fnc/esal-config/02_00_00_00/esalModes.cfg <NL> [ 1156.879736] layer1_control_layer[2064]: isFileValid /var/shared/commsStp.conf  returning 1 <NL> [ 1156.879810] layer1_control_layer[2064]: isFileValid /var/shared/commsNetworkMode.conf  returning 1 <NL> [ 1156.879933] layer1_control_layer[2064]: isFileValid /var/shared/commsOscMode.conf  returning 1 <NL> [ 1156.880017] layer1_control_layer[2064]: Libconfig::openAndRead status open path /var/shared/commsStp.conf <NL> [ 1156.880139] layer1_control_layer[2064]: Libconfig::openAndRead /var/shared/commsStp.conf <NL> [ 1156.880216] layer1_control_layer[2064]: Libconfig::openAndRead status open path /var/shared/commsNetworkMode.conf <NL> [ 1156.880285] layer1_control_layer[2064]: Libconfig::openAndRead /var/shared/commsNetworkMode.conf <NL> [ 1156.880379] layer1_control_layer[2064]: Libconfig::openAndRead status open path /var/shared/commsOscMode.conf <NL> [ 1156.880450] layer1_control_layer[2064]: Libconfig::openAndRead /var/shared/commsOscMode.conf <NL> [ 1156.880532] layer1_control_layer[2064]: Libconfig::openAndRead status no file path /var/shared/esalPortVlan.conf <NL> [ 1156.880613] layer1_control_layer[2064]: Libconfig::openAndRead status no file path /var/shared/esalDcnMode.conf <NL> [ 1157.036931] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2384 <NL> [ 1157.066179] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2384 <NL> [ 1157.101424] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2384 <NL> [ 1157.185038] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2384 <NL> [ 1157.239984] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2384 <NL> [ 1157.246919] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2384 <NL> [ 1157.432102] layer1_hal[2091]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [ 1157.471882] layer1_hal[2091]: hal_sucs_notify event hal_sucs for slot 0 published sucs event= 4, state= 6 <NL> [ 1157.517663] layer1_control_layer[2064]:    ChalApi Constructor with tid = 2387 <NL> [ 1161.833233] ntputils_client.py[1702]: INFO:root:command failed."}
{"timestamp_utc": "2024-07-31T08:32:18.601Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:18 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:18 retry-ssh-command INFO: attempt 126, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:23.842Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:23 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:23 retry-ssh-command INFO: attempt 127, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:29.090Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:28 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:28 retry-ssh-command INFO: attempt 128, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:34.333Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:33 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:33 retry-ssh-command INFO: attempt 129, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:38.524Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:38 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:32:38.525Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:38 retry-ssh-command INFO: attempt 130, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:43.788Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:43 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:43 retry-ssh-command INFO: attempt 131, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:49.036Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:48 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:48 retry-ssh-command INFO: attempt 132, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:54.289Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:53 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:32:53 retry-ssh-command INFO: attempt 133, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:32:58.458Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:58 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None"}
{"timestamp_utc": "2024-07-31T08:32:58.714Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:32:58 retry-ssh-command INFO: attempt 134, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:04.025Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:33:03 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:33:04 retry-ssh-command INFO: attempt 135, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:09.277Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p09.s01.p05.s02.NE3-main-cli", "warrior_node_id": "n01", "project_id": "p09", "test_suite_id": "s01", "test_case_id": "p05", "keyword_name": "s02.NE3-main-cli", "step_id": "s02.NE3-main-cli", "message_content": "# 03:33:09 retry-ssh-command INFO: client_cl.__init__: transport.connect: hostname 'rtxoialp79', port 37259, username 'fujitsu', password '1finity', key_filename None <NL> # 03:33:09 retry-ssh-command INFO: attempt 136, sleep 5: \"rtxoialp79:37259\" SSHException('Error reading SSH protocol banner',)"}
{"timestamp_utc": "2024-07-31T08:33:14.523Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:13 exec-job-tree INFO: process_list_cl::wait: queue EMPTY <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: TIMEOUT: check who timed out <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: TIMEOUT: timeout job tree \"n01.p09.s01.startup (p)\" <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p01.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p02.NE1-trib1-debug-ssh)"}
{"timestamp_utc": "2024-07-31T08:33:14.524Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p03.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p04.NE2-trib1-debug-ssh) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p05.s01.NE3-main-debug-ssh) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 5)            (executing) type \"command\": timeout (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (executing) type \"serial\": timeout (n01.p09.s01.p05.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p06.NE3-trib1-debug-ssh) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"serial\": cannot timeout if currently not executing (n01.p09.s01.p07.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 4)          (finished) type \"command\": cannot timeout if currently not executing (n01.p09.s01.p08.NE4-trib1-debug-ssh) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 3)        (executing) type \"parallel\": timeout (n01.p09.s01.startup (p)) <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p09.s01.p05.s02.NE3-main-cli\": send signal Signals.SIGTERM to process group 3671 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\": process 3671 terminated with exitcode -15 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p09.s01.p05.s02.NE3-main-cli\": process 3671 terminated with exitcode -15 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 5)            (finished) type \"command\": finished (n01.p09.s01.p05.s02.NE3-main-cli) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": child #1 finished with exit_code -15 (n01.p09.s01.p05.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 4)          (executing) type \"serial\": aborting because child #1 was terminated (n01.p09.s01.p05.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 4)          (finished) type \"serial\": finished (n01.p09.s01.p05.main-startup (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 3)        (executing) type \"parallel\": child #4 finished with exit_code 1, parallel_siblings_action \"do-nothing\" (n01.p09.s01.startup (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 3)        (finished) type \"parallel\": finished (n01.p09.s01.startup (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (executing) type \"serial\": child #0 finished with exit_code 1 (n01.p09.start+user (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (executing) type \"serial\": aborting because child #0 was terminated (n01.p09.start+user (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"serial\": finished (n01.p09.start+user (s)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #8 finished with exit_code 1, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 8 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p01.NE1-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p02.NE1-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.s02.NE3-main-cli\", exit_code -15 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.p05.main-startup (s)\", exit_code 1 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.s01.startup (p)\", exit_code 1 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p09.start+user (s)\", exit_code 1 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p01.NE1-main-console\": send signal Signals.SIGKILL to process group 3324 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p02.NE1-trib1-console\": send signal Signals.SIGKILL to process group 3325 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": send signal Signals.SIGKILL to process group 3326 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": send signal Signals.SIGKILL to process group 3327 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": send signal Signals.SIGKILL to process group 3328 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": send signal Signals.SIGKILL to process group 3329 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": send signal Signals.SIGKILL to process group 3330 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": send signal Signals.SIGKILL to process group 3331 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3325 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3331 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p02.NE1-trib1-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p02.NE1-trib1-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p02.NE1-trib1-console\": process 3325 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p02.NE1-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #1 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 7 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p01.NE1-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p02.NE1-trib1-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p01.NE1-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3331 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p01.NE1-main-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p01.NE1-main-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p01.NE1-main-console\": process 3324 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p01.NE1-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #0 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 6 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p03.NE2-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p01.NE1-main-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p03.NE2-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3331 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p03.NE2-main-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p03.NE2-main-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p03.NE2-main-console\": process 3326 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p03.NE2-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #2 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p))"}
{"timestamp_utc": "2024-07-31T08:33:14.525Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 5 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p08.NE4-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p03.NE2-main-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p08.NE4-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3331 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p05.NE3-main-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p06.NE3-trib1-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p04.NE2-trib1-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p08.NE4-trib1-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p08.NE4-trib1-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p08.NE4-trib1-console\": process 3331 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p08.NE4-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #7 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 4 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p04.NE2-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p08.NE4-trib1-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p04.NE2-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p07.NE4-main-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p04.NE2-trib1-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p04.NE2-trib1-console\": process 3327 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p04.NE2-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #3 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 3 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p04.NE2-trib1-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p07.NE4-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p07.NE4-main-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p07.NE4-main-console\": process 3330 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p07.NE4-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #6 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 2 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p07.NE4-main-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p05.NE3-main-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p05.NE3-main-console\", type \"stderr\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p05.NE3-main-console\": process 3328 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p05.NE3-main-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #4 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": remaining 1 running children to be terminated (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::terminate_job_tree: ( 2)      (executing) type \"command\": timeout (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p05.NE3-main-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_cl::send_signal: name \"n01.p06.NE3-trib1-console\": already not running <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: name \"n01.p06.NE3-trib1-console\", type \"stdout\": DONE <NL> # 03:33:13 exec-job-tree INFO: process_cl::wait: name \"n01.p06.NE3-trib1-console\": process 3329 terminated with exitcode -9 <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 2)      (finished) type \"command\": finished (n01.p06.NE3-trib1-console) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (executing) type \"parallel\": child #5 finished with exit_code 0, parallel_siblings_action \"terminate-always\" (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 1)    (finished) type \"parallel\": finished (n01.all (p)) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 0)  (executing) type \"none\": child #0 finished with exit_code 1 (none) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 0)  (executing) type \"none\": aborting because child #0 did not pass (none) <NL> # 03:33:13 exec-job-tree INFO: job_cl::finish: ( 0)  (finished) type \"none\": finished (none) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.p06.NE3-trib1-console\", exit_code 0 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"n01.all (p)\", exit_code 1 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::del_job_obj: ----- name \"none\", exit_code 1 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: start_time 1722413593.8728411 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait:   end_time 1722414793.6856043 <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::wait: done, job(s) ran for 1199.8127632141113 second(s) <NL> # 03:33:13 exec-job-tree INFO: process_list_cl::__exit__: exc_type \"None\" <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  Begin           End             Job Name                                ECode Flags                     Notes <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p01.NE1-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p02.NE1-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p03.NE2-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p04.NE2-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p05.NE3-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p06.NE3-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p07.NE4-main-console               0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p08.NE4-trib1-console              0 (-9) passed(FAILED,terminated) None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.031359 n01.p09.s01.p01.s01.NE1-main-debug-ssh      0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031359 20240731.032231 n01.p09.s01.p01.s02.NE1-main-cli            0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.032231 n01.p09.s01.p01.main-startup (s)            0 passed                    all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.031332 n01.p09.s01.p02.NE1-trib1-debug-ssh         0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.031340 n01.p09.s01.p03.s01.NE2-main-debug-ssh      0 passed                    None"}
{"timestamp_utc": "2024-07-31T08:33:14.526Z", "log_type_hint": "WARRIOR_GENERIC", "warrior_context_tag": "n01.p02.NE1-trib1-console", "warrior_node_id": "n01", "project_id": "p02", "test_suite_id": "NE1-trib1-console", "message_content": "# 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031340 20240731.032230 n01.p09.s01.p03.s02.NE2-main-cli            0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.032230 n01.p09.s01.p03.main-startup (s)            0 passed                    all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.031332 n01.p09.s01.p04.NE2-trib1-debug-ssh         0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.032147 n01.p09.s01.p05.s01.NE3-main-debug-ssh      0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.032147 20240731.033313 n01.p09.s01.p05.s02.NE3-main-cli          -15 FAILED,timeout,terminated None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p09.s01.p05.main-startup (s)            1 FAILED,timeout,terminated all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.031332 n01.p09.s01.p06.NE3-trib1-debug-ssh         0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.032212 n01.p09.s01.p07.s01.NE4-main-debug-ssh      0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.032212 20240731.033207 n01.p09.s01.p07.s02.NE4-main-cli            0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033207 n01.p09.s01.p07.main-startup (s)            0 passed                    all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.031326 n01.p09.s01.p08.NE4-trib1-debug-ssh         0 passed                    None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p09.s01.startup (p)                     1 FAILED,timeout,terminated all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  None            None            n01.p09.s02.Warrior                      None unexecuted                None <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.p09.start+user (s)                      1 FAILED                    all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 n01.all (p)                                 1 FAILED                    all children finished <NL> # 03:33:13 exec-job-tree INFO: summary_cl::show:  20240731.031313 20240731.033313 none                                        1 FAILED                    all children finished <NL> # 03:33:13 exec-job-tree INFO: main: result 1 <NL> [  790.571983] ntputils_client.py[1708]: INFO:root:comman20240731.033313 stdout:n01.p01.NE1-main-console # [  614.848953] common_alarm_handler[2388]: D20240731.033313 stdout:n01.p03.NE2-main-console # [  592.077514] confd_mgr[3010]: The dbmgmt_data_path_ and cdb file path passed to timestamp_operation.py script /var/shared/conf20240731.033313 stdout:n01.p05.NE3-main-console # [ 1160.445573] cia_control_layer[2116]:  s20240731.033313 stdout:n01.p08.NE4-trib1-console # [ 1073.082931] ntputils_client.py[1717]: C20240731.033313 stdout:n01.p04.NE2-trib1-console # [  735.133036] ntputils_client.py[1689]: b'server 127.1.254.254, 20240731.033313 stdout:n01.p07.NE4-main-console # [ 1106.890036] confd_mgr[2516]: CommAT::asi20240731.033313 stdout:n01.p06.NE3-trib1-console # [ 1161.833921] ntputils_client.py[1702]: Copip3-virtualenv-install-and-execute-cmd: ERROR: failed executing: \"exec-job-tree\" \"--timeout\" \"28800\" \"--job-begin-parallel\" \"--name\" \"all (p)\" \"--job-begin-command\" \"--name\" \"NE1-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37321\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37299\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37295\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37267\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37263\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37235\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37231\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-console\" \"--ignore-termination-failures\" \"--force-failure\" \"--parallel-siblings-terminate-on-my-completion\" \"--cmd-begin\" \"socket_monitor\" \"--host\" \"rtxoialp79\" \"--port\" \"37203\" \"--retry-interval\" \"5\" \"--max-wait-time\" \"0\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"start+user (s)\" \"--parallel-siblings-terminate-on-my-completion\" \"--job-begin-parallel\" \"--name\" \"startup (p)\" \"--timeout\" \"1200\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE1-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37320\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37319\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE1-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37297\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE2-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37293\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37291\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE2-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37265\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE3-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37261\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37259\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE3-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37233\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-serial\" \"--name\" \"main-startup (s)\" \"--job-begin-command\" \"--name\" \"NE4-main-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37229\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-main-cli\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37227\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"NE4-trib1-debug-ssh\" \"--cmd-begin\" \"retry-ssh-command\" \"-v\" \"-v\" \"-v\" \"--hostname\" \"rtxoialp79\" \"--port\" \"37201\" \"--delay\" \"5\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-begin-command\" \"--name\" \"Warrior\" \"--cmd-begin\" \"run_init\" \"--runinit_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir\" \"--services_env\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json\" \"--work_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148\" \"-v\" \"-e\" \"warrior\" \"--test_engine_venv_dir\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir\" \"--test_engine\" \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json\" \"--cmd-end\" \"--job-end\" \"--job-end\" \"--job-end\" <NL> pip3-virtualenv-install-and-execute-cmd: removing VIRTUALENV_DIR \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir\" <NL> pip3-virtualenv-install-and-execute-cmd: done \"1\" <NL> # 03:33:13 ntp-wait-for-devices INFO: main: result 1 <NL> # 03:33:13 tfwk-exec-test-agent INFO: main: caught exception CalledProcessError(1, ['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json', '--cmd-end', '--job-end']) <NL> # 03:33:13 tfwk-exec-test-agent INFO: main: finally block: caught_exception_flag True <NL> # 03:33:13 tfwk-exec-test-agent INFO: main: args_obj.teardown_topology_action 'teardown-always' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main: teardown_topology_flag True <NL> # 03:33:13 tfwk-exec-test-agent INFO: main: - current exec status info: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   topology_active_flag=True <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   topology_state='running' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   topology info for work dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148': <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     topology_tag_name: ['DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1'] <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     topology_pre_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology.json'] <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     topology_post_fname_list: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/network-topology-data/network-topology-tags/ntp.DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1.topology-post.json'] <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:main' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE1/device:trib1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags'"}
{"timestamp_utc": "2024-07-31T08:33:14.527Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:main' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main-L1-OTSG2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE2/device:trib1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"2\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"2\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:main' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE3/device:trib1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:main' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='main' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-aggr-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-aggr-image-validation-T/product-fss3-24.2_cd4528-pr324-Aggregator-T-qemux86-64-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='200' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"200\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"200\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:   - 'network-element:NE4/device:trib1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-config-name'='trib-L1-OTSG2' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-info-tags-dir'='/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/data/image-info-tags' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-name'='fss-image-validation-T' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'image-zip-path'='/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/release/build.regression/GROUP.ri-fss3-protocol-ddcn-natRedistribute/MACHINE.qemux86-64/IMAGE.fss-image-validation-T/product-fss3-24.2_cd4528-pr324-validation-T-qemu-image.zip' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'machine-name'='qemux86-64' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'product-name'=None <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     defaults: 'regression-group'='ri-fss3-protocol-ddcn-natRedistribute' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance: 'shelf-num'='1' <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     instance config dict: <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         \"qemu_config\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             \"variable_definitions\": { <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"shelfNumber\": \"1\", <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:                 \"simulatedShelf\": \"1\" <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:             } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:         } <NL> # 03:33:13 tfwk-exec-test-agent INFO: main:     }"}
{"timestamp_utc": "2024-07-31T08:33:14.528Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:13 tfwk-exec-test-agent INFO: exec_cmd: ['ntp-topology-teardown', '-v', '-v', '--ntp-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--no-backup-shared-store'] <NL> # 03:33:13 ntp-topology-teardown INFO: args: { <NL> \"backup_shared_store_flag\": false, <NL> \"ntp_info_json_fname\": \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json\", <NL> \"shared_store_backup_fname\": null, <NL> \"show_container_logs_flag\": null, <NL> \"verbosity\": 2 <NL> } <NL> # 03:33:13 ntp-topology-teardown INFO: main: ===== ===== starting cleanup ===== ===== <NL> # 03:33:13 ntp-topology-teardown INFO: exec_cmd: ['ntp-topology', '-v', '-v', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--action', 'delete'] <NL> # 03:33:14 ntp-topology INFO: main: amend_workspace_root_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace' <NL> # 03:33:14 ntp-topology INFO: main: starting action 'delete'"}
{"timestamp_utc": "2024-07-31T08:33:14.788Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:14 ntp-topology INFO: terminate_containers_command: - terminating container main command processes: <NL> # 03:33:14 ntp-topology INFO: get_container_env_exec_command: network_topology_dir /data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology <NL> # 03:33:14 ntp-topology INFO: exec_cmd: ['sudo', '/bin/docker', 'exec', '--privileged', '--user', 'jenkins', '--detach', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/network-topology/ntp-env-exec', 'run-log', '-v', '-v', '--log-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/preStop.log', '--status', '--status-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/preStop.status.json', '--', 'ntp-topology', '-v', '-v', '--logging-stamp', '--logging-progname', '--instance-context', '[{\"instance_name\": \"topology\", \"instance_type\": \"definitions\"}, {\"instance_name\": \"group-device-group-type-qemu-01\", \"instance_type\": \"device_group\"}]', '--shared-store-info-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/shared-store-info.json', '--container-name', 'topology-group-device-group-type-qemu-01', '--action', 'execute-remote-delete']"}
{"timestamp_utc": "2024-07-31T08:33:15.349Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:15 ntp-topology INFO: wait_for_containers_command_status: - waiting max 300s for container_logs_command_status_fname files: <NL> # 03:33:15 ntp-topology INFO: wait_for_containers_command_status:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json' <NL> # 03:33:15 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:15 ntp-topology INFO: wait_for_containers_command_status: 0.000s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:16.275Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:16 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:16 ntp-topology INFO: wait_for_containers_command_status: 1.001s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:17.640Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:17 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:17 ntp-topology INFO: wait_for_containers_command_status: 2.002s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:18.570Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:18 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:18 ntp-topology INFO: wait_for_containers_command_status: 3.003s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:19.496Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:19 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:19 ntp-topology INFO: wait_for_containers_command_status: 4.004s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:20.422Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:20 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:20 ntp-topology INFO: wait_for_containers_command_status: 5.005s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:21.352Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:21 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:21 ntp-topology INFO: wait_for_containers_command_status: 6.006s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:22.285Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:22 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:22 ntp-topology INFO: wait_for_containers_command_status: 7.007s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:23.652Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:23 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:23 ntp-topology INFO: wait_for_containers_command_status: 8.008s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:24.582Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:24 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:24 ntp-topology INFO: wait_for_containers_command_status: 9.009s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:25.509Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:25 ntp-topology INFO: wait_for_containers_command_status: caught RetryFailedError exception, message: No such files or directories: ['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json'] <NL> # 03:33:25 ntp-topology INFO: wait_for_containers_command_status: 10.010s of 300.000 elapsed: delay 1.000s"}
{"timestamp_utc": "2024-07-31T08:33:26.436Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:26 ntp-topology INFO: wait_for_containers_command_status: status for fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/command.status.json': { <NL> \"exit_code\": 0 <NL> } <NL> # 03:33:26 ntp-topology INFO: wait_for_containers_preStop_status: - waiting max 300s for container_logs_preStop_status_fname files: <NL> # 03:33:26 ntp-topology INFO: wait_for_containers_preStop_status:   fname '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-logs/topology-group-device-group-type-qemu-01/preStop.status.json' <NL> # 03:33:26 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'ps', '--all', '--no-trunc', '--format', '{{.ID}}:{{.Names}}'] <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05:hopeful_mirzakhani <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 13e8e1ceb73fb94182bb2d26e230041a7dff30e478b61e09d7a9ee077e45ac52:quirky_brattain <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d:nervous_cori <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: ba4ce35ddbd25b794094736c92e4a5322080bbd5232851447d1da5936fe99b5c:condescending_boyd <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 863fc4d8d70d1b4a5e62454a9919f7317f5d7175c2c3517f800f3e37fd56a835:compassionate_visvesvaraya <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 8be8c7226a5e37253ed43fb6b7b1ca034b5ca9e3ed21264949690f6e22a4e67c:jolly_gates <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 53d787c99a720d29084736a373fd3706e6d0080365fb6e1567ac579b5a1c0b3d:quirky_wright <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 622e1549ca3da2607b8815f2439aef62f990b54e26175a7ea64f2aec41713834:brave_visvesvaraya <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: e1996a6295107b4c0a5a89b97a2300526fb626b49dc3144d44de907a48b07178:quirky_thompson <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 14ae89e97f81d955829ac15b5cf9490d85dd0aedfa62ef12a05608186e6d2e0d:compassionate_lichterman <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 878f7152b281d9161916121152f9852a8a98b010613ee61acfbc45fb72a84d3a:unruffled_wozniak <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: 4f8730fb77ce966611338a23f89060641f596bd660fe734e1b51325082944545:pensive_sinoussi <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: ad49f325d562b63b05603399bfab4d4b23fc6d3606d9b419e6c18b8419945a5b:elegant_galileo <NL> # 03:33:26 ntp-topology INFO: docker_command: stdout: f0015dc6171f611684f9cbc599a7f95d8bb1958f38b5cf1dbf7eab1c3ba40b20:dazzling_varahamihira <NL> # 03:33:26 ntp-topology INFO: delete_single_docker_container: docker_container_name hopeful_mirzakhani <NL> # 03:33:26 ntp-topology INFO: delete_single_docker_container: docker_container_id 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05 <NL> # 03:33:26 ntp-topology INFO: delete_single_docker_container: delete Docker container \"085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05(hopeful_mirzakhani)\" (delete an existing container) <NL> # 03:33:26 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'stop', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05']"}
{"timestamp_utc": "2024-07-31T08:33:34.541Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:33 ntp-topology INFO: docker_command: stdout: 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05 <NL> # 03:33:33 ntp-topology INFO: docker_command: running ['sudo', '/bin/docker', 'rm', '--force', '085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05'] <NL> # 03:33:33 ntp-topology INFO: docker_command: stdout: 085e23d3ac7cf65575ecbe955d507c4ab508563a961f2f61f25588255d0a4f05 <NL> # 03:33:33 ntp-topology INFO: handle_delete_phase_1: show_container_logs_setting 'on-error-only' <NL> # 03:33:33 ntp-topology INFO: main: completed action 'delete' <NL> # 03:33:33 ntp-topology INFO: done <NL> # 03:33:33 ntp-topology-teardown INFO: main: removing container_workspace_basedir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace' <NL> # 03:33:33 ntp-topology-teardown INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64/container-workspace']"}
{"timestamp_utc": "2024-07-31T08:33:35.472Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# 03:33:35 ntp-topology-teardown INFO: main: removing shared_store_dir '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64' <NL> # 03:33:35 ntp-topology-teardown INFO: exec_cmd: ['rm', '-rf', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/ntp-workdir.tag.20240731030818.df250eded7d34577b63247fd091bcb64'] <NL> # 03:33:35 ntp-topology-teardown INFO: main: ===== ===== done cleanup ===== ===== <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 4635, in <module> <NL> main(args_obj=args_obj) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 1329, in main <NL> exec_cmd(command) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/bin/tfwk-exec-test-agent\", line 40, in exec_cmd <NL> raise subprocess.CalledProcessError(result, command)"}
{"timestamp_utc": "2024-07-31T08:33:35.473Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "subprocess.CalledProcessError: Command '['ntp-wait-for-devices', '-v', '-v', '--ntp-info-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/run-info.json', '--virtualenv-dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/wait-for-devices-virtualenv-dir', '--startup-timeout', '1200', '--', '--job-begin-command', '--name', 'Warrior', '--cmd-begin', 'run_init', '--runinit_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/run_init_virtualenv_dir', '--services_env', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/services-env.json', '--work_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148', '-v', '-e', 'warrior', '--test_engine_venv_dir', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/.virtual-env-base-dir/test-engine-virtualenv-dir', '--test_engine', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/workspace_artifacts/testcase-framework-dir/test_framework/exec/tmp/exec.20240731030817.pid-148/test_engine_args.json', '--cmd-end', '--job-end']' returned non-zero exit status 1. <NL> ci-job-info: job returned result \"1\" <NL> ci-job-info: end_job: 1"}
{"timestamp_utc": "2024-07-31T08:33:35.731Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "ci-job-info: end_artifact_job: ----- ----- ----- ----- ----- <NL> ci-job-info: end_artifact_job: 20240731.033335: ending job with status \"FAILED\" <NL> ci-job-info: end_artifact_job: saving ci-data directory \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/ci-data\" into \"/proj/artifacts/projects/fss3-ci-regression/fss3-ci-regression_cd2999/job.project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64.ci-data\" <NL> ./ <NL> ./gitscm-info.json <NL> ./manifest.json <NL> ./project-info-recipe-repo.json <NL> ./project-info-complete.json"}
{"timestamp_utc": "2024-07-31T08:33:42.301Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info.json <NL> ./project-info-extended.json"}
{"timestamp_utc": "2024-07-31T08:33:42.868Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "./project-info-status.json <NL> ./data.json <NL> end_job: Wed Jul 31 03:33:42 CDT 2024 <NL> ci-job-info: ended on Wed Jul 31 03:33:42 CDT 2024 <NL> ci-get-archive-artifacts: failed executing command:  \"ci-job-info\" \"ci-project-sanity-tfwk\" \"--\" \"--testcases-project-name\" \"fss3\" \"--\" \"--test-engine\" \"Warrior\" \"--topology-tag-name\" \"DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1\" \"--define-attr-defaults\" \"machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute\" \"--define-instance-attr\" \"NE1/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE1/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE1/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE1/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE2/main\" \"shelf-num=1\" \"--define-instance-attr\" \"NE2/main\" \"image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2\" \"--define-instance-attr\" \"NE2/trib1\" \"shelf-num=2\" \"--define-instance-attr\" \"NE2/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE3/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE3/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE3/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE3/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--define-instance-attr\" \"NE4/main\" \"shelf-num=200\" \"--define-instance-attr\" \"NE4/main\" \"image-name=fss-aggr-image-validation-T,image-info-config-name=main\" \"--define-instance-attr\" \"NE4/trib1\" \"shelf-num=1\" \"--define-instance-attr\" \"NE4/trib1\" \"image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2\" \"--add-instance\" \"NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1\" \"--device-wait-startup-timeout\" \"1200\" \"--test-engine-begin\" \"--no_logger\" \"--test-engine-end\" \"--\" \"warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml\" <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 107, in <module> <NL> main(args=arg_dict) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 68, in main <NL> subprocess.run(command_list, check=True) <NL> File \"/usr/lib64/python3.6/subprocess.py\", line 438, in run <NL> output=stdout, stderr=stderr) <NL> subprocess.CalledProcessError: Command '['ci-get-archive-artifacts', '--project-info-basename', 'project-info.json', '--project-info-extended-basename', 'project-info-extended.json', '--', 'ci-job-info', 'ci-project-sanity-tfwk', '--', '--testcases-project-name', 'fss3', '--', '--test-engine', 'Warrior', '--topology-tag-name', 'DCN-NE1mt1-NE2mt1-NE3mt1-NE4mt1', '--define-attr-defaults', 'machine-name=qemux86-64,regression-group=ri-fss3-protocol-ddcn-natRedistribute', '--define-instance-attr', 'NE1/main', 'shelf-num=1', '--define-instance-attr', 'NE1/main', 'image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2', '--define-instance-attr', 'NE1/trib1', 'shelf-num=2', '--define-instance-attr', 'NE1/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE2/main', 'shelf-num=1', '--define-instance-attr', 'NE2/main', 'image-name=fss-image-validation-T,image-info-config-name=main-L1-OTSG2', '--define-instance-attr', 'NE2/trib1', 'shelf-num=2', '--define-instance-attr', 'NE2/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE3/main', 'shelf-num=200', '--define-instance-attr', 'NE3/main', 'image-name=fss-aggr-image-validation-T,image-info-config-name=main', '--define-instance-attr', 'NE3/trib1', 'shelf-num=1', '--define-instance-attr', 'NE3/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--define-instance-attr', 'NE4/main', 'shelf-num=200', '--define-instance-attr', 'NE4/main', 'image-name=fss-aggr-image-validation-T,image-info-config-name=main', '--define-instance-attr', 'NE4/trib1', 'shelf-num=1', '--define-instance-attr', 'NE4/trib1', 'image-name=fss-image-validation-T,image-info-config-name=trib-L1-OTSG2', '--add-instance', 'NE1/main,NE1/trib1,NE2/main,NE2/trib1,NE3/main,NE3/trib1,NE4/main,NE4/trib1', '--device-wait-startup-timeout', '1200', '--test-engine-begin', '--no_logger', '--test-engine-end', '--', 'warrior-testcases/dcn/Warriorspace/Projects/Regression/FSS2Apps/Qemu/rel_2/NAT_DDCN/4_Node/project_dcn_regression_nat64.xml']' returned non-zero exit status 1. <NL> Traceback (most recent call last): <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 107, in <module> <NL> main(args=arg_dict) <NL> File \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/continuous-integration/continuous-integration-common/bin/ci-execute-json-command-list\", line 68, in main <NL> subprocess.run(command_list, check=True) <NL> File \"/usr/lib64/python3.6/subprocess.py\", line 438, in run <NL> output=stdout, stderr=stderr) <NL> subprocess.CalledProcessError: Command '['/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/continuous-integration/continuous-integration-common/bin/ci-setup-and-execute', 'ci-execute-json-command-list', '--command-json-fname', '/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/jenkins-job-command-list.json']' returned non-zero exit status 1."}
{"timestamp_utc": "2024-07-31T08:33:42.878Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv"}
{"timestamp_utc": "2024-07-31T08:33:42.879Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:33:42.886Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:33:43.190Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ docker stop 0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d"}
{"timestamp_utc": "2024-07-31T08:33:44.557Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d <NL> + docker rm -f --volumes 0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d <NL> 0a852c6c3ea10e5a0b03a9b2fa5c6c51a6858bfc1c97a5529476283af28d7e5d"}
{"timestamp_utc": "2024-07-31T08:33:44.561Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.568Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:33:44.575Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.581Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:33:44.590Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo <NL> pipeline_execute: Execute stage: catch section of try block: currentBuild.result 'SUCCESS' <NL> pipeline_execute: Execute stage: catch section of try block: exception: hudson.AbortException: script returned exit code 1 <NL> [Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:44.596Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:33:44.604Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] stage"}
{"timestamp_utc": "2024-07-31T08:33:44.605Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] { (Cleanup)"}
{"timestamp_utc": "2024-07-31T08:33:44.611Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] withEnv"}
{"timestamp_utc": "2024-07-31T08:33:44.612Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] {"}
{"timestamp_utc": "2024-07-31T08:33:44.622Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:33:44.900Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ set +x <NL> ci-job-post-build-cleanup: ----- /bin/docker ps -a <NL> CONTAINER ID        IMAGE                                                    COMMAND                  CREATED             STATUS              PORTS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                NAMES <NL> 863fc4d8d70d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago   Up About an hour    22/tcp, 0.0.0.0:37051->5000/tcp, 0.0.0.0:37050->5001/tcp, 0.0.0.0:37049->5002/tcp, 0.0.0.0:37048->5003/tcp, 0.0.0.0:37047->5004/tcp, 0.0.0.0:37046->5005/tcp, 0.0.0.0:37045->5006/tcp, 0.0.0.0:37044->5007/tcp, 0.0.0.0:37043->5008/tcp, 0.0.0.0:37042->5009/tcp, 0.0.0.0:37041->5010/tcp, 0.0.0.0:37040->5011/tcp, 0.0.0.0:37039->5012/tcp, 0.0.0.0:37038->5013/tcp, 0.0.0.0:37037->5014/tcp, 0.0.0.0:37036->5015/tcp, 0.0.0.0:37035->5016/tcp, 0.0.0.0:37034->5017/tcp, 0.0.0.0:37033->5018/tcp, 0.0.0.0:37032->5019/tcp, 0.0.0.0:37031->5020/tcp, 0.0.0.0:37030->5021/tcp, 0.0.0.0:37029->5022/tcp, 0.0.0.0:37028->5023/tcp, 0.0.0.0:37027->5024/tcp, 0.0.0.0:37026->5025/tcp, 0.0.0.0:37025->5026/tcp, 0.0.0.0:37024->5027/tcp, 0.0.0.0:37023->5028/tcp, 0.0.0.0:37022->5029/tcp, 0.0.0.0:37021->5030/tcp, 0.0.0.0:37020->5031/tcp, 0.0.0.0:37019->5032/tcp, 0.0.0.0:37018->5033/tcp, 0.0.0.0:37017->5034/tcp, 0.0.0.0:37016->5035/tcp, 0.0.0.0:37015->5036/tcp, 0.0.0.0:37014->5037/tcp, 0.0.0.0:37013->5038/tcp, 0.0.0.0:37012->5039/tcp, 0.0.0.0:37011->5040/tcp, 0.0.0.0:37010->5041/tcp, 0.0.0.0:37009->5042/tcp, 0.0.0.0:37008->5043/tcp, 0.0.0.0:37007->5044/tcp, 0.0.0.0:37006->5045/tcp, 0.0.0.0:37005->5046/tcp, 0.0.0.0:37004->5047/tcp, 0.0.0.0:37003->5048/tcp, 0.0.0.0:37002->5049/tcp, 0.0.0.0:37001->5050/tcp, 0.0.0.0:37000->5051/tcp, 0.0.0.0:36999->5052/tcp, 0.0.0.0:36998->5053/tcp, 0.0.0.0:36997->5054/tcp, 0.0.0.0:36996->5055/tcp, 0.0.0.0:36995->5056/tcp, 0.0.0.0:36994->5057/tcp, 0.0.0.0:36993->5058/tcp, 0.0.0.0:36992->5059/tcp, 0.0.0.0:36991->5060/tcp, 0.0.0.0:36990->5061/tcp, 0.0.0.0:36989->5062/tcp, 0.0.0.0:36988->5063/tcp, 0.0.0.0:36987->5064/tcp, 0.0.0.0:36986->5065/tcp, 0.0.0.0:36985->5066/tcp, 0.0.0.0:36984->5067/tcp, 0.0.0.0:36983->5068/tcp, 0.0.0.0:36982->5069/tcp, 0.0.0.0:36981->5070/tcp, 0.0.0.0:36980->5071/tcp, 0.0.0.0:36979->5072/tcp, 0.0.0.0:36978->5073/tcp, 0.0.0.0:36977->5074/tcp, 0.0.0.0:36976->5075/tcp   compassionate_visvesvaraya <NL> 8be8c7226a5e        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago   Up About an hour    0.0.0.0:36975->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                jolly_gates <NL> 53d787c99a72        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   About an hour ago   Up About an hour    0.0.0.0:36974->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                quirky_wright"}
{"timestamp_utc": "2024-07-31T08:33:44.901Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "622e1549ca3d        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago         Up 2 hours          22/tcp, 0.0.0.0:36973->5000/tcp, 0.0.0.0:36972->5001/tcp, 0.0.0.0:36971->5002/tcp, 0.0.0.0:36970->5003/tcp, 0.0.0.0:36969->5004/tcp, 0.0.0.0:36968->5005/tcp, 0.0.0.0:36967->5006/tcp, 0.0.0.0:36966->5007/tcp, 0.0.0.0:36965->5008/tcp, 0.0.0.0:36964->5009/tcp, 0.0.0.0:36963->5010/tcp, 0.0.0.0:36962->5011/tcp, 0.0.0.0:36961->5012/tcp, 0.0.0.0:36960->5013/tcp, 0.0.0.0:36959->5014/tcp, 0.0.0.0:36958->5015/tcp, 0.0.0.0:36957->5016/tcp, 0.0.0.0:36956->5017/tcp, 0.0.0.0:36955->5018/tcp, 0.0.0.0:36954->5019/tcp, 0.0.0.0:36953->5020/tcp, 0.0.0.0:36952->5021/tcp, 0.0.0.0:36951->5022/tcp, 0.0.0.0:36950->5023/tcp, 0.0.0.0:36949->5024/tcp, 0.0.0.0:36948->5025/tcp, 0.0.0.0:36947->5026/tcp, 0.0.0.0:36946->5027/tcp, 0.0.0.0:36945->5028/tcp, 0.0.0.0:36944->5029/tcp, 0.0.0.0:36943->5030/tcp, 0.0.0.0:36942->5031/tcp, 0.0.0.0:36941->5032/tcp, 0.0.0.0:36940->5033/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             brave_visvesvaraya <NL> e1996a629510        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   2 hours ago         Up 2 hours          0.0.0.0:36939->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                quirky_thompson <NL> 14ae89e97f81        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          22/tcp, 0.0.0.0:36906->5000/tcp, 0.0.0.0:36905->5001/tcp, 0.0.0.0:36904->5002/tcp, 0.0.0.0:36903->5003/tcp, 0.0.0.0:36902->5004/tcp, 0.0.0.0:36901->5005/tcp, 0.0.0.0:36900->5006/tcp, 0.0.0.0:36899->5007/tcp, 0.0.0.0:36898->5008/tcp, 0.0.0.0:36897->5009/tcp, 0.0.0.0:36896->5010/tcp, 0.0.0.0:36895->5011/tcp, 0.0.0.0:36894->5012/tcp, 0.0.0.0:36893->5013/tcp, 0.0.0.0:36892->5014/tcp, 0.0.0.0:36891->5015/tcp, 0.0.0.0:36890->5016/tcp, 0.0.0.0:36889->5017/tcp, 0.0.0.0:36888->5018/tcp, 0.0.0.0:36887->5019/tcp, 0.0.0.0:36886->5020/tcp, 0.0.0.0:36885->5021/tcp, 0.0.0.0:36884->5022/tcp, 0.0.0.0:36883->5023/tcp, 0.0.0.0:36882->5024/tcp, 0.0.0.0:36881->5025/tcp, 0.0.0.0:36880->5026/tcp, 0.0.0.0:36879->5027/tcp, 0.0.0.0:36878->5028/tcp, 0.0.0.0:36877->5029/tcp, 0.0.0.0:36876->5030/tcp, 0.0.0.0:36875->5031/tcp, 0.0.0.0:36874->5032/tcp, 0.0.0.0:36873->5033/tcp, 0.0.0.0:36872->5034/tcp, 0.0.0.0:36871->5035/tcp, 0.0.0.0:36870->5036/tcp, 0.0.0.0:36869->5037/tcp, 0.0.0.0:36868->5038/tcp, 0.0.0.0:36867->5039/tcp, 0.0.0.0:36866->5040/tcp, 0.0.0.0:36865->5041/tcp, 0.0.0.0:36864->5042/tcp, 0.0.0.0:36863->5043/tcp, 0.0.0.0:36862->5044/tcp, 0.0.0.0:36861->5045/tcp, 0.0.0.0:36860->5046/tcp, 0.0.0.0:36859->5047/tcp, 0.0.0.0:36858->5048/tcp, 0.0.0.0:36857->5049/tcp, 0.0.0.0:36856->5050/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    compassionate_lichterman <NL> 878f7152b281        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          0.0.0.0:36855->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                unruffled_wozniak <NL> 4f8730fb77ce        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          22/tcp, 0.0.0.0:36839->5000/tcp, 0.0.0.0:36837->5001/tcp, 0.0.0.0:36835->5002/tcp, 0.0.0.0:36833->5003/tcp, 0.0.0.0:36831->5004/tcp, 0.0.0.0:36829->5005/tcp, 0.0.0.0:36827->5006/tcp, 0.0.0.0:36825->5007/tcp, 0.0.0.0:36823->5008/tcp, 0.0.0.0:36821->5009/tcp, 0.0.0.0:36819->5010/tcp, 0.0.0.0:36817->5011/tcp, 0.0.0.0:36815->5012/tcp, 0.0.0.0:36813->5013/tcp, 0.0.0.0:36811->5014/tcp, 0.0.0.0:36809->5015/tcp, 0.0.0.0:36807->5016/tcp, 0.0.0.0:36805->5017/tcp, 0.0.0.0:36803->5018/tcp, 0.0.0.0:36801->5019/tcp, 0.0.0.0:36799->5020/tcp, 0.0.0.0:36796->5021/tcp, 0.0.0.0:36793->5022/tcp, 0.0.0.0:36790->5023/tcp, 0.0.0.0:36787->5024/tcp, 0.0.0.0:36784->5025/tcp, 0.0.0.0:36781->5026/tcp, 0.0.0.0:36778->5027/tcp, 0.0.0.0:36775->5028/tcp, 0.0.0.0:36772->5029/tcp, 0.0.0.0:36769->5030/tcp, 0.0.0.0:36766->5031/tcp, 0.0.0.0:36763->5032/tcp, 0.0.0.0:36760->5033/tcp, 0.0.0.0:36757->5034/tcp, 0.0.0.0:36754->5035/tcp, 0.0.0.0:36751->5036/tcp, 0.0.0.0:36748->5037/tcp, 0.0.0.0:36745->5038/tcp, 0.0.0.0:36743->5039/tcp, 0.0.0.0:36741->5040/tcp, 0.0.0.0:36739->5041/tcp, 0.0.0.0:36737->5042/tcp, 0.0.0.0:36735->5043/tcp, 0.0.0.0:36733->5044/tcp, 0.0.0.0:36731->5045/tcp, 0.0.0.0:36729->5046/tcp, 0.0.0.0:36727->5047/tcp, 0.0.0.0:36725->5048/tcp, 0.0.0.0:36723->5049/tcp, 0.0.0.0:36721->5050/tcp, 0.0.0.0:36719->5051/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pensive_sinoussi <NL> ad49f325d562        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   3 hours ago         Up 3 hours          0.0.0.0:36605->22/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                elegant_galileo <NL> f0015dc6171f        harbor.fnc.fujitsu.com/iprepo/centos-7-ci-build:latest   \"/usr/bin/tini -- ...\"   29 hours ago        Up 29 hours         22/tcp, 0.0.0.0:36205->5000/tcp, 0.0.0.0:36204->5001/tcp, 0.0.0.0:36203->5002/tcp, 0.0.0.0:36202->5003/tcp, 0.0.0.0:36201->5004/tcp, 0.0.0.0:36200->5005/tcp, 0.0.0.0:36199->5006/tcp, 0.0.0.0:36198->5007/tcp, 0.0.0.0:36197->5008/tcp, 0.0.0.0:36196->5009/tcp, 0.0.0.0:36195->5010/tcp, 0.0.0.0:36194->5011/tcp, 0.0.0.0:36193->5012/tcp, 0.0.0.0:36192->5013/tcp, 0.0.0.0:36191->5014/tcp, 0.0.0.0:36190->5015/tcp, 0.0.0.0:36189->5016/tcp, 0.0.0.0:36188->5017/tcp, 0.0.0.0:36187->5018/tcp, 0.0.0.0:36186->5019/tcp, 0.0.0.0:36185->5020/tcp, 0.0.0.0:36184->5021/tcp, 0.0.0.0:36183->5022/tcp, 0.0.0.0:36182->5023/tcp, 0.0.0.0:36181->5024/tcp, 0.0.0.0:36180->5025/tcp, 0.0.0.0:36179->5026/tcp, 0.0.0.0:36178->5027/tcp, 0.0.0.0:36177->5028/tcp, 0.0.0.0:36176->5029/tcp, 0.0.0.0:36175->5030/tcp, 0.0.0.0:36174->5031/tcp, 0.0.0.0:36173->5032/tcp, 0.0.0.0:36172->5033/tcp, 0.0.0.0:36171->5034/tcp, 0.0.0.0:36170->5035/tcp, 0.0.0.0:36169->5036/tcp, 0.0.0.0:36168->5037/tcp, 0.0.0.0:36167->5038/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                dazzling_varahamihira <NL> ci-job-post-build-cleanup: ----- ci-resource-tracker -v -v -v --del-all"}
{"timestamp_utc": "2024-07-31T08:33:45.158Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "# DEBUG 2024-07-31 03:33:44,937 ci-resource-tracker: arg_dict: { <NL> \"action\": \"del-all\", <NL> \"command\": null, <NL> \"data_fname\": null, <NL> \"force_flag\": false, <NL> \"hostname\": null, <NL> \"type\": null, <NL> \"verbosity\": 3 <NL> } <NL> # DEBUG 2024-07-31 03:33:44,938 ci-resource-tracker: data_fname \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/ci-data/ci-resource-tracker.json\" <NL> # INFO 2024-07-31 03:33:44,938 ci-resource-tracker: action_del_all: current_hostname \"rtxoialp79\" <NL> # INFO 2024-07-31 03:33:44,938 ci-resource-tracker: action_del_all: nothing to do, data file not there: \"/data/users/jenkins/workspace/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/ci-data/ci-resource-tracker.json\" <NL> ci-job-post-build-cleanup: exit_code \"0\""}
{"timestamp_utc": "2024-07-31T08:33:45.164Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:45.175Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // withEnv"}
{"timestamp_utc": "2024-07-31T08:33:45.182Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:45.188Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // stage"}
{"timestamp_utc": "2024-07-31T08:33:45.196Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:45.202Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // timeout"}
{"timestamp_utc": "2024-07-31T08:33:45.211Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] archive"}
{"timestamp_utc": "2024-07-31T08:33:45.214Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "The archive step is deprecated, please use archiveArtifacts instead."}
{"timestamp_utc": "2024-07-31T08:33:55.634Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] writeFile"}
{"timestamp_utc": "2024-07-31T08:33:55.642Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] sh"}
{"timestamp_utc": "2024-07-31T08:33:55.912Z", "log_type_hint": "JENKINS_SHELL_CMD", "message_content": "+ cp -- ./master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.003/node-info.json /proj/artifacts/jenkins/jenkins-job-utilization-data/master.jenkins.fnc.fujitsu.com/date.20240731/project/fss3/json-nt-ddcn-4-node-natRedistribute-nat64/7/node.003/node-info.json"}
{"timestamp_utc": "2024-07-31T08:33:55.916Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] }"}
{"timestamp_utc": "2024-07-31T08:33:55.923Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] // node"}
{"timestamp_utc": "2024-07-31T08:33:55.932Z", "log_type_hint": "JENKINS_PIPELINE", "message_content": "[Pipeline] echo"}
{"timestamp_utc": "2024-07-31T08:33:55.933Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "pipeline_execute: currentBuild.result 'FAILURE' <NL> ===== ===== ===== ===== ===== <NL> [Pipeline] End of Pipeline"}
{"timestamp_utc": "2024-07-31T08:33:56.151Z", "log_type_hint": "GENERIC_LOG_MESSAGE", "message_content": "Finished: FAILURE"}
